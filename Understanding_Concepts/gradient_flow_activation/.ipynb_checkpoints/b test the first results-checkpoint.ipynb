{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread\n",
    "from imgaug import augmenters as iaa\n",
    "import nibabel as nib\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import util \n",
    "import matplotlib.animation as animation\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "np.random.seed(6278)\n",
    "tf.set_random_seed(6728)\n",
    "ia.seed(6278)\n",
    "\n",
    "# Generate training data\n",
    "import tensorflow as tf\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get the data as well as show image function\n",
    "from ipynb.fs.full.z_util  import show_images,get_train,get_test,get_unlabel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "train_data,train_label = get_train()\n",
    "test_data ,test_label  = get_test()\n",
    "unlabeled              = get_unlabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 2] \n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[7 8 6] \n",
      " [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "0.43950329205254085 0.4383057132586417\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the labels\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "encoder = OneHotEncoder(sparse =True)\n",
    "train_label_encoded = encoder.fit_transform(train_label[:,None]).toarray()\n",
    "test__label_encoded = encoder.fit_transform(test_label [:,None]).toarray()\n",
    "print(train_label[:3],'\\n',train_label_encoded[:3])\n",
    "print(test_label[:3], '\\n',test__label_encoded[:3])\n",
    "\n",
    "train_data = (train_data - train_data.min((1,2),keepdims=True))/(train_data.max((1,2),keepdims=True)-train_data.min((1,2),keepdims=True))\n",
    "test_data  = (test_data -  test_data.min((1,2),keepdims=True))/( test_data.max((1,2),keepdims=True)- test_data.min((1,2),keepdims=True))\n",
    "\n",
    "print(train_data.mean(),test_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show some images of train test and unlabeld\n",
    "show_images(train_data,train_label)\n",
    "show_images(test_data,test_label)\n",
    "show_images(unlabeled,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float64)\n",
    "\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float64)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float64) * x) + 1.0)\n",
    "\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float64))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float64))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) + self.b \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters and layers\n",
    "num_epoch = 100; learning_rate = 0.0008; batch_size = 20 ; print_size= 10\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "\n",
    "l1 = CNN(3,3, 32)\n",
    "l2 = CNN(3,32,32)\n",
    "l3 = CNN(3,32,32)\n",
    "\n",
    "l4 = CNN(3,32,64)\n",
    "l5 = CNN(3,64,64)\n",
    "l6 = CNN(3,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "x = tf.placeholder(shape=[batch_size,96,96,3],dtype=tf.float64)\n",
    "y = tf.placeholder(shape=[batch_size,10],dtype=tf.float64)\n",
    "temperature = tf.cast(tf.placeholder_with_default(1.0,shape=[]),tf.float64)\n",
    "\n",
    "layer1      = l1.feedforward(x)\n",
    "layer2      = l2.feedforward(layer1)\n",
    "layer3      = l3.feedforward(layer2)\n",
    "layer3_pool = tf.nn.avg_pool(layer3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "layer4      = l4.feedforward(layer3_pool)\n",
    "layer5      = l5.feedforward(layer4)\n",
    "layer6      = l6.feedforward(layer5)\n",
    "\n",
    "final_squeeze_temp = tf.squeeze(tf.reduce_mean(layer6,(1,2)))/temperature\n",
    "final_prediction   = tf_softmax(final_squeeze_temp) \n",
    "cost               = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_squeeze_temp,labels=y))\n",
    "accuracy           = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, -1), tf.argmax(final_prediction, -1)),tf.float64))\n",
    "\n",
    "grad        = (final_prediction-y)[:,None,None,:]/batch_size\n",
    "grad_expand = tf.tile(grad,[1,39,39,1])/temperature\n",
    "grad6,grad6_up = l6.backprop(grad_expand)\n",
    "grad5,grad5_up = l5.backprop(grad6)\n",
    "grad4,grad4_up = l4.backprop(grad5)\n",
    "\n",
    "grad3_uppool   = tf.tile(grad4,[1,2,2,1])\n",
    "grad3,grad3_up = l3.backprop(grad3_uppool)\n",
    "grad2,grad2_up = l2.backprop(grad3)\n",
    "grad1,grad1_up = l1.backprop(grad2)\n",
    "\n",
    "grad_update    = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 index: 380/5000 acc: 0.1 cost: 2.4941"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-faafe71496dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_data_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_data_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_update\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         sys.stdout.write('\\riter: ' + str(iter) + \" index: \" + str(current_data_index) + '/' + str(len(train_data)) + \n\u001b[0;32m     11\u001b[0m                          \" acc: \" + str(sess_results[0]) + ' cost: ' + str(np.around(sess_results[1],3))); sys.stdout.flush()\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the session\n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    for current_data_index in range(0,len(train_data),batch_size):\n",
    "        current_data  = train_data[current_data_index:current_data_index+batch_size]\n",
    "        current_label = train_label_encoded[current_data_index:current_data_index+batch_size]  \n",
    "        sess_results  = sess.run([accuracy,cost,grad_update],feed_dict={x:current_data,y:current_label,temperature:1.5})\n",
    "        sys.stdout.write('\\riter: ' + str(iter) + \" index: \" + str(current_data_index) + '/' + str(len(train_data)) + \n",
    "                         \" acc: \" + str(sess_results[0]) + ' cost: ' + str(np.around(sess_results[1],3))); sys.stdout.flush()\n",
    "    if iter % print_size == 0 : print('\\n-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.007 0.    0.012 0.953 0.012 0.008 0.008 0.    0.   ]\n",
      " [0.    0.002 0.    0.003 0.957 0.008 0.023 0.006 0.    0.   ]\n",
      " [0.    0.008 0.    0.029 0.826 0.056 0.04  0.039 0.    0.001]\n",
      " [0.    0.004 0.001 0.013 0.261 0.051 0.587 0.059 0.    0.023]\n",
      " [0.    0.003 0.    0.005 0.979 0.004 0.007 0.002 0.    0.   ]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "-------------------\n",
      "[4 4 4 6 4]\n",
      "[1 5 1 6 3]\n"
     ]
    }
   ],
   "source": [
    "# mid training and testing section\n",
    "mid_test_data    = train_data[:batch_size,:,:,:]; mid_test_label = train_label_encoded[:batch_size,:]\n",
    "mid_sess_results = sess.run(final_prediction,feed_dict={x:mid_test_data,temperature:1.5}) \n",
    "print(np.around(mid_sess_results,3))\n",
    "print(mid_test_label)\n",
    "print('-------------------')\n",
    "print(np.argmax(np.around(mid_sess_results,3),1))\n",
    "print(np.argmax(mid_test_label  ,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. file, i. (2018). import a function from another .ipynb file. Stack Overflow. Retrieved 11 November 2018, from https://stackoverflow.com/questions/44116194/import-a-function-from-another-ipynb-file\n",
    "2. array?, H. (2018). How to print the full NumPy array?. Stack Overflow. Retrieved 11 November 2018, from https://stackoverflow.com/questions/1987694/how-to-print-the-full-numpy-array\n",
    "3. Label Encoder vs. One Hot Encoder in Machine Learning. (2018). Medium. Retrieved 11 November 2018, from https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "4. API Reference — scikit-learn 0.20.0 documentation. (2018). Scikit-learn.org. Retrieved 11 November 2018, from https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "5. Why is there no support for directly computing cross entropy? · Issue #2462 · tensorflow/tensorflow. (2018). GitHub. Retrieved 11 November 2018, from https://github.com/tensorflow/tensorflow/issues/2462\n",
    "6. argmax?, E. (2018). Evaluating softmax (classification) accuracy in Tensorflow with round or argmax?. Stack Overflow. Retrieved 11 November 2018, from https://stackoverflow.com/questions/41759771/evaluating-softmax-classification-accuracy-in-tensorflow-with-round-or-argmax\n",
    "7. tensorflow.placeholder_with_default Python Example. (2018). Programcreek.com. Retrieved 11 November 2018, from https://www.programcreek.com/python/example/90324/tensorflow.placeholder_with_default\n",
    "8. JaeDukSeo/Daily-Neural-Network-Practice-2. (2018). GitHub. Retrieved 11 November 2018, from https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ELU/a%20paper%20adam.py\n",
    "9. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
