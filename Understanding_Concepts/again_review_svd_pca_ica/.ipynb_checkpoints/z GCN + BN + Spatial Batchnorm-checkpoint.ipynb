{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch, min, max :  (500, 64, 64, 3) [0. 0. 0.] [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "# Get the certain STL 10 Data\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def showimages(x,coloums=30,row=3,col=False):\n",
    "    fig=plt.figure(figsize=(30, 3))\n",
    "    columns = coloums; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        if col: plt.imshow(np.squeeze(x[i-1]))\n",
    "        else:   plt.imshow(np.squeeze(x[i-1]),cmap='gray')\n",
    "        plt.tick_params(axis='both', left=False, top=False, right=False, bottom=False, labelleft=False, labeltop=False, labelright=False, labelbottom=False)\n",
    "        plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "data_location = \"../../Dataset/STL10/img/10/\"\n",
    "train_data = []  # create an empty list\n",
    "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
    "    for filename in fileList:\n",
    "        if \".png\" in filename.lower() :\n",
    "            train_data.append(os.path.join(dirName,filename))\n",
    "\n",
    "image_resize_px = 64\n",
    "train_batch = np.zeros(shape=(len(train_data),image_resize_px,image_resize_px,3))\n",
    "for file_index in range(len(train_data)):\n",
    "    train_batch[file_index] = resize(imread(train_data[file_index]),(image_resize_px,image_resize_px))\n",
    "\n",
    "# print out the data shape and the max and min value\n",
    "print('Train batch, min, max : ',train_batch.shape,train_batch.min((0,1,2)),train_batch.max((0,1,2)))\n",
    "train_batch1 = train_batch.copy()\n",
    "\n",
    "data_location = \"../../Dataset/STL10/img/2/\"\n",
    "train_data = []  # create an empty list\n",
    "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
    "    for filename in fileList:\n",
    "        if \".png\" in filename.lower() :\n",
    "            train_data.append(os.path.join(dirName,filename))\n",
    "\n",
    "image_resize_px = 64\n",
    "train_batch = np.zeros(shape=(len(train_data),image_resize_px,image_resize_px,3))\n",
    "for file_index in range(len(train_data)):\n",
    "    train_batch[file_index] = resize(imread(train_data[file_index]),(image_resize_px,image_resize_px))\n",
    "\n",
    "# print out the data shape and the max and min value\n",
    "print('Train batch, min, max : ',train_batch.shape,train_batch.min((0,1,2)),train_batch.max((0,1,2)))\n",
    "train_batch2 = train_batch.copy()\n",
    "\n",
    "data_location = \"../../Dataset/STL10/img/3/\"\n",
    "train_data = []  # create an empty list\n",
    "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
    "    for filename in fileList:\n",
    "        if \".png\" in filename.lower() :\n",
    "            train_data.append(os.path.join(dirName,filename))\n",
    "\n",
    "image_resize_px = 64\n",
    "train_batch = np.zeros(shape=(len(train_data),image_resize_px,image_resize_px,3))\n",
    "for file_index in range(len(train_data)):\n",
    "    train_batch[file_index] = resize(imread(train_data[file_index]),(image_resize_px,image_resize_px))\n",
    "\n",
    "# print out the data shape and the max and min value\n",
    "print('Train batch, min, max : ',train_batch.shape,train_batch.min((0,1,2)),train_batch.max((0,1,2)))\n",
    "train_batch3 = train_batch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the random images\n",
    "from sklearn.utils import shuffle\n",
    "train_batch_final = np.vstack((train_batch1,train_batch2,train_batch3))\n",
    "print(train_batch_final.shape)\n",
    "showimages(shuffle(train_batch_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_iden(x):  return x\n",
    "def d_tf_iden(x):return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Initializer for variable Variable_6/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1baee83f47c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# sess.run(tf.global_variables_initializer())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmean_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_mean_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mmean_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmean_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmean_result\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_batch_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-1baee83f47c6>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vector_shape)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvector_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoving_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvector_shape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[1;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 \"initializer.\" % name)\n\u001b[0m\u001b[0;32m    363\u001b[0m           \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m           shape = (self._initial_value.get_shape()\n",
      "\u001b[1;31mValueError\u001b[0m: Initializer for variable Variable_6/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
     ]
    }
   ],
   "source": [
    "# test out the mean layer\n",
    "class tf_mean_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape],dtype=tf.float64))\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True):\n",
    "        self.input = input\n",
    "        self.mean  = tf.reduce_mean(input,axis=-1)[:,None]\n",
    "        self.output= self.input - self.mean\n",
    "        \n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            using_mean         = tf.reduce_mean(input,axis=-1)[:,None]\n",
    "            update_moving_mean = []\n",
    "            update_moving_mean.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * using_mean ))\n",
    "            return using_mean,update_moving_mean\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            self.mean = self.moving_mean\n",
    "            return self.mean,_\n",
    "        \n",
    "        self.which_mean,update_mean = tf.cond(training_phase,lambda:training_fn,lambda:testing_fn)\n",
    "#         self.output = self.input - self.which_mean\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        return grad * (1)\n",
    "    \n",
    "# make the place holder and start the session\n",
    "x     = tf.placeholder(shape=(100,64*64),dtype=tf.float64)\n",
    "phase = tf.placeholder(shape=[],dtype=tf.bool)\n",
    "mean_layer = tf_mean_layer(100)\n",
    "mean_data  = mean_layer.feedforward(x,training_phase=phase)\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "mean_result= sess.run(mean_data,feed_dict={x:train_batch_final[:100,:,:,0].reshape((100,-1)),phase:True }).reshape((100,64,64))\n",
    "showimages(mean_result,col=False)\n",
    "print('Before Mean Layer ',train_batch_final[:100,:,:,0].mean(-1).sum())\n",
    "print('After  Mean Layer ',mean_result.mean(-1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class global_contrast_layer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.moving_mean = None\n",
    "        pass\n",
    "    \n",
    "    def feedforward(self,input):\n",
    "        self.input      = input\n",
    "        self.image_mean =\n",
    "        \n",
    "        \n",
    "    def backprop(self,grad):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcl = global_contrast_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified code from: https://datascience.stackexchange.com/questions/15110/how-to-implement-global-contrast-normalization-in-python\n",
    "def global_contrast_normalization(image, 1e-5):\n",
    "    X = numpy.array(Image.open(filename))\n",
    "\n",
    "    # replacement for the loop\n",
    "    X_average = numpy.mean(X)\n",
    "    print('Mean: ', X_average)\n",
    "    X = X - X_average\n",
    "\n",
    "    # `su` is here the mean, instead of the sum\n",
    "    contrast = numpy.sqrt(lmda + numpy.mean(X**2))\n",
    "\n",
    "    X = s * X / max(contrast, epsilon)\n",
    "\n",
    "    # scipy can handle it\n",
    "    scipy.misc.imsave('result.jpg', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "! git all-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
