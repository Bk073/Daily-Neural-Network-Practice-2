{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T00:26:18.276169Z",
     "start_time": "2019-01-05T00:26:18.216273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Things to compare</h1>\n",
    "<div>\n",
    "<ul>\n",
    "  <li>Z: Baseline </li>\n",
    "  <li>A: Theta ^ 2 </li>\n",
    "  <li>B: abs(Theta) + sqrt(abs(Theta) ^ 2)</li>\n",
    "  <li>C: Theta </li>\n",
    "  <li>D: sqrt(Theta ^ 2)</li>\n",
    "  <li>E: abs(Theta) </li>\n",
    "  <li>F: sqrt(abs(Theta) ^ 2)</li>\n",
    "  <li>G: sqrt(Theta ^ 2)/Theta</li>\n",
    "  <li>H: - tanh(Theta)</li>\n",
    "  <li>I: - tanh(Theta ^ 2)</li>\n",
    "  <li>J: - log(1+Theta ^ 2)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:35:35.271977Z",
     "start_time": "2019-01-04T23:35:33.058646Z"
    },
    "code_folding": [
     0,
     3,
     30,
     38
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:35:35.450499Z",
     "start_time": "2019-01-04T23:35:35.389662Z"
    },
    "code_folding": [
     15,
     60,
     75,
     83,
     87
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.regularizer    = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.regularizer == 'A': grad = grad + lamda * 2.0 * self.w\n",
    "        if self.regularizer == 'B': grad = grad + lamda * 0.5 * (tf.sign(self.w) + (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-8)) * tf.abs(self.w) * tf.sign(self.w))\n",
    "        if self.regularizer == 'C': grad = grad + lamda * tf.ones_like(self.w)\n",
    "        if self.regularizer == 'D': grad = grad + lamda * (1.0/tf.sqrt(tf.square(self.w)+ 10e-8)) * self.w\n",
    "        if self.regularizer == 'E': grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.regularizer == 'F': grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-8)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.regularizer == 'G': grad = grad + lamda * ( self.w**2/(tf.sqrt(self.w)+10e-8) - tf.sqrt(self.w ** 2))/(self.w**2 + 10e-8)\n",
    "        if self.regularizer == 'H': grad = grad + lamda * -1.0 * (1.0-tf.tanh(self.w) ** 2)\n",
    "        if self.regularizer == 'I': grad = grad + lamda * -1.0 * (1.0-tf.tanh(self.w ** 2) ** 2) * 2.0 * self.w\n",
    "        if self.regularizer == 'J': grad = grad + lamda * -1.0 * (1/(1+self.w ** 2)) * 2.0 * self.w\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     \n",
    "    \n",
    "def append_stat(current_list,data,number):\n",
    "    current_list[0].append(data[number].mean())\n",
    "    current_list[1].append(data[number].std())\n",
    "    current_list[2].append(skew    (data[number].ravel()))\n",
    "    current_list[3].append(kurtosis(data[number].ravel()))\n",
    "    current_list[4].append(np.count_nonzero(data[number]))\n",
    "    return current_list\n",
    "\n",
    "def transform_to_2d(data):\n",
    "    batch,width,height,chan = data.shape\n",
    "    return data.reshape((batch*width,height*chan))\n",
    "\n",
    "def save_to_image(main_data,one,two,three,four,five,six,experiment_name,tran_acc,test_acc,current_exp,iter):\n",
    "    plt.figure(figsize=(20,40))\n",
    "    G = gridspec.GridSpec(8, 6)\n",
    "\n",
    "    plt.figtext(0.5,1.0,\"Iter: \" + str(iter) + \" Histogram Per \" + experiment_name,ha=\"center\", va=\"top\", fontsize=35, color=\"black\")\n",
    "    plt.subplot(G[0, 0]).hist(main_data[0].ravel(),50,color='red');       plt.subplot(G[0, 0]).set_title(experiment_name+' 1')\n",
    "    plt.subplot(G[0, 1]).hist(main_data[1].ravel(),50,color='orange');    plt.subplot(G[0, 1]).set_title(experiment_name+' 2')\n",
    "    plt.subplot(G[0, 2]).hist(main_data[2].ravel(),50,color='yellow');  plt.subplot(G[0, 2]).set_title(experiment_name+' 3')\n",
    "    plt.subplot(G[0, 3]).hist(main_data[3].ravel(),50,color='green');    plt.subplot(G[0, 3]).set_title(experiment_name+' 4')\n",
    "    plt.subplot(G[0, 4]).hist(main_data[4].ravel(),50,color='blue');     plt.subplot(G[0, 4]).set_title(experiment_name+' 5')\n",
    "    plt.subplot(G[0, 5]).hist(main_data[5].ravel(),50,color='black');     plt.subplot(G[0, 5]).set_title(experiment_name+' 6')\n",
    "\n",
    "    plt.subplot(G[1, :]).set_title(\"Mean Per \"+ experiment_name)\n",
    "    plt.subplot(G[1, :]).plot(one[0]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[1, :]).plot(two[0]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[1, :]).plot(three[0],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[1, :]).plot(four[0],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[1, :]).plot(five[0],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[1, :]).plot(six[0],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[2, :]).set_title(\"Standard Deviation Per \"+ experiment_name)\n",
    "    plt.subplot(G[2, :]).plot(one[1]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[2, :]).plot(two[1]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[2, :]).plot(three[1],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[2, :]).plot(four[1],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[2, :]).plot(five[1],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[2, :]).plot(six[1],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[3, :]).set_title(\"Skewness Per \"+ experiment_name)\n",
    "    plt.subplot(G[3, :]).plot(one[2]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[3, :]).plot(two[2]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[3, :]).plot(three[2],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[3, :]).plot(four[2],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[3, :]).plot(five[2],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[3, :]).plot(six[2],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[4, :]).set_title(\"Kurtosis Per \"+ experiment_name)\n",
    "    plt.subplot(G[4, :]).plot(one[3]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[4, :]).plot(two[3]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[4, :]).plot(three[3],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[4, :]).plot(four[3],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[4, :]).plot(five[3],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[4, :]).plot(six[3],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[5, :]).set_title(\"# Non-Zero Per \"+ experiment_name)\n",
    "    plt.subplot(G[5, :]).plot(one[4]  ,c='red',alpha=0.9   ,label='1')\n",
    "    plt.subplot(G[5, :]).plot(two[4]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[5, :]).plot(three[4],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[5, :]).plot(four[4],c='green',alpha=0.9  ,label='4')\n",
    "    plt.subplot(G[5, :]).plot(five[4],c='blue',alpha=0.9   ,label='5')\n",
    "    plt.subplot(G[5, :]).plot(six[4],c='black',alpha=0.9   ,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[6, :]).set_title(\"Train/Test accuracy\")\n",
    "    plt.subplot(G[6, :]).plot(train_acc  ,c='red',alpha=0.9, label='Train')\n",
    "    plt.subplot(G[6, :]).plot(test_acc   ,c='blue',alpha=0.9,label='Test')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figtext(0.5,0,\"Correlation Matrix Per \"+ experiment_name,ha=\"center\", va=\"bottom\", fontsize=30, color=\"black\")\n",
    "    plt.subplot(G[7, 0]).imshow(np.corrcoef(transform_to_2d(main_data[0])),cmap='gray')\n",
    "    plt.subplot(G[7, 1]).imshow(np.corrcoef(transform_to_2d(main_data[1])),cmap='gray')\n",
    "    plt.subplot(G[7, 2]).imshow(np.corrcoef(transform_to_2d(main_data[2])),cmap='gray')\n",
    "    plt.subplot(G[7, 3]).imshow(np.corrcoef(transform_to_2d(main_data[3])),cmap='gray')\n",
    "    plt.subplot(G[7, 4]).imshow(np.corrcoef(transform_to_2d(main_data[4])),cmap='gray')\n",
    "    plt.subplot(G[7, 5]).imshow(np.corrcoef(transform_to_2d(main_data[5])),cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(current_exp + '/' + experiment_name + '/' + str(iter) + '.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:35:36.191741Z",
     "start_time": "2019-01-04T23:35:36.187716Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "num_epoch = 15; learning_rate = 0.0008; batch_size = 20; beta1,beta2,adam_e = 0.9,0.999,1e-9; lamda = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T00:26:04.611986Z",
     "start_time": "2019-01-04T23:36:11.248257Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : 0 Train Acc : 0.12540000249445438 Test Acc : 0.18275000317953527\n",
      "\n",
      "Current : 1 Train Acc : 0.2104000029861927 Test Acc : 0.2545000028051436\n",
      "\n",
      "Current : 2 Train Acc : 0.2788000019043684 Test Acc : 0.31700000175274906\n",
      "\n",
      "Current : 3 Train Acc : 0.3134000022560358 Test Acc : 0.32362500170245767\n",
      "\n",
      "Current : 4 Train Acc : 0.3206000022292137 Test Acc : 0.341375001296401\n",
      "\n",
      "Current : 5 Train Acc : 0.33300000211596487 Test Acc : 0.34437500208616256\n",
      "\n",
      "Current : 6 Train Acc : 0.33740000215172766 Test Acc : 0.3451250017806888\n",
      "\n",
      "Current : 7 Train Acc : 0.3412000019848347 Test Acc : 0.34775000179186466\n",
      "\n",
      "Current : 8 Train Acc : 0.35060000178217887 Test Acc : 0.3521250018663704\n",
      "\n",
      "Current : 9 Train Acc : 0.35760000184178353 Test Acc : 0.3538750013336539\n",
      "\n",
      "Current : 10 Train Acc : 0.3624000012278557 Test Acc : 0.35887500130571426\n",
      "\n",
      "Current : 11 Train Acc : 0.36340000146627427 Test Acc : 0.3648750013206154\n",
      "\n",
      "Current : 12 Train Acc : 0.3678000014126301 Test Acc : 0.36687500144355\n",
      "\n",
      "Current : 13 Train Acc : 0.374800000846386 Test Acc : 0.3701250013615936\n",
      "\n",
      "Current : 14 Train Acc : 0.3786000013053417 Test Acc : 0.37525000144727527\n",
      "\n",
      "Current : 15 Train Acc : 0.38460000148415563 Test Acc : 0.37687500135041774\n",
      "\n",
      "Current : 16 Train Acc : 0.38720000103116037 Test Acc : 0.38087500118650497\n",
      "\n",
      "Current : 17 Train Acc : 0.3914000016152859 Test Acc : 0.3841250011790544\n",
      "\n",
      "Current : 18 Train Acc : 0.39600000068545343 Test Acc : 0.38837500100024047\n",
      "\n",
      "Current : 19 Train Acc : 0.4026000012457371 Test Acc : 0.39300000213086606\n",
      "\n",
      "Current : 20 Train Acc : 0.40420000156760216 Test Acc : 0.3995000011101365\n",
      "\n",
      "Current : 21 Train Acc : 0.41040000215172767 Test Acc : 0.4030000010877848\n",
      "\n",
      "Current : 22 Train Acc : 0.4138000017106533 Test Acc : 0.4067500011436641\n",
      "\n",
      "Current : 23 Train Acc : 0.4160000008046627 Test Acc : 0.40812500109896066\n",
      "\n",
      "Current : 24 Train Acc : 0.416400000333786 Test Acc : 0.4102500011213124\n",
      "\n",
      "Current : 25 Train Acc : 0.4210000009536743 Test Acc : 0.41075000097975134\n",
      "\n",
      "Current : 26 Train Acc : 0.4246000008583069 Test Acc : 0.4142500009201467\n",
      "\n",
      "Current : 27 Train Acc : 0.42660000079870225 Test Acc : 0.4180000011064112\n",
      "\n",
      "Current : 28 Train Acc : 0.42780000072717667 Test Acc : 0.4210000010021031\n",
      "\n",
      "Current : 29 Train Acc : 0.43380000096559523 Test Acc : 0.42312500094994904\n",
      "\n",
      "Current : 30 Train Acc : 0.4338000010251999 Test Acc : 0.426375000923872\n",
      "\n",
      "Current : 31 Train Acc : 0.433800000667572 Test Acc : 0.4280000003427267\n",
      "\n",
      "Current : 32 Train Acc : 0.4394000008702278 Test Acc : 0.4321250005066395\n",
      "\n",
      "Current : 33 Train Acc : 0.43960000079870226 Test Acc : 0.43437500059604645\n",
      "\n",
      "Current : 34 Train Acc : 0.4416000002026558 Test Acc : 0.43537500068545343\n",
      "\n",
      "Current : 35 Train Acc : 0.4472000004649162 Test Acc : 0.43637500088661907\n",
      "\n",
      "Current : 36 Train Acc : 0.4487999997735023 Test Acc : 0.43800000101327896\n",
      "\n",
      "Current : 37 Train Acc : 0.4485999993681908 Test Acc : 0.44112500086426737\n",
      "\n",
      "Current : 38 Train Acc : 0.4517999997735023 Test Acc : 0.4423750013113022\n",
      "\n",
      "Current : 39 Train Acc : 0.4543999996185303 Test Acc : 0.4427500008419156\n",
      "\n",
      "Current : 40 Train Acc : 0.4541999992132187 Test Acc : 0.4443750012293458\n",
      "\n",
      "Current : 41 Train Acc : 0.45780000019073486 Test Acc : 0.44712500140070915\n",
      "\n",
      "Current : 42 Train Acc : 0.45780000019073486 Test Acc : 0.4485000006482005\n",
      "\n",
      "Current : 43 Train Acc : 0.46220000022649765 Test Acc : 0.450000000372529\n",
      "\n",
      "Current : 44 Train Acc : 0.462200000166893 Test Acc : 0.4528749999403954\n",
      "\n",
      "Current : 45 Train Acc : 0.4624000000953674 Test Acc : 0.4540000006556511\n",
      "\n",
      "Current : 46 Train Acc : 0.46420000076293944 Test Acc : 0.4576250007748604\n",
      "\n",
      "Current : 47 Train Acc : 0.46640000069141385 Test Acc : 0.4572500008717179\n",
      "\n",
      "Current : 48 Train Acc : 0.46719999992847444 Test Acc : 0.4577500011771917\n",
      "\n",
      "Current : 49 Train Acc : 0.4715999995470047 Test Acc : 0.46312500115484\n",
      "\n",
      "Current : 50 Train Acc : 0.4728000002503395 Test Acc : 0.46375000115484\n",
      "\n",
      "Current : 51 Train Acc : 0.4753999999165535 Test Acc : 0.4651250009983778\n",
      "\n",
      "Current : 52 Train Acc : 0.4764000002741814 Test Acc : 0.46562500115484\n",
      "\n",
      "Current : 53 Train Acc : 0.4786000002026558 Test Acc : 0.4671250008046627\n",
      "\n",
      "Current : 54 Train Acc : 0.4808000000119209 Test Acc : 0.4670000012218952\n",
      "\n",
      "Current : 55 Train Acc : 0.4804000006318092 Test Acc : 0.4695000012218952\n",
      "\n",
      "Current : 56 Train Acc : 0.48360000091791155 Test Acc : 0.4687500008568168\n",
      "\n",
      "Current : 57 Train Acc : 0.4852000014781952 Test Acc : 0.4693750009685755\n",
      "\n",
      "Current : 58 Train Acc : 0.48600000190734866 Test Acc : 0.4712500014156103\n",
      "\n",
      "Current : 59 Train Acc : 0.4892000010609627 Test Acc : 0.4691250014305115\n",
      "\n",
      "Current : 60 Train Acc : 0.491800001680851 Test Acc : 0.47200000163167716\n",
      "\n",
      "Current : 61 Train Acc : 0.4926000012159348 Test Acc : 0.4722500018030405\n",
      "\n",
      "Current : 62 Train Acc : 0.49500000113248827 Test Acc : 0.47237500179558994\n",
      "\n",
      "Current : 63 Train Acc : 0.49800000166893005 Test Acc : 0.472250001244247\n",
      "\n",
      "Current : 64 Train Acc : 0.49840000134706497 Test Acc : 0.47400000121444463\n",
      "\n",
      "Current : 65 Train Acc : 0.4994000016450882 Test Acc : 0.4737500013038516\n",
      "\n",
      "Current : 66 Train Acc : 0.5028000014424324 Test Acc : 0.47337500128895044\n",
      "\n",
      "Current : 67 Train Acc : 0.501600001513958 Test Acc : 0.47450000166893\n",
      "\n",
      "Current : 68 Train Acc : 0.5042000010609626 Test Acc : 0.47487500112503767\n",
      "\n",
      "Current : 69 Train Acc : 0.5084000006318092 Test Acc : 0.47400000113993884\n",
      "\n",
      "Current : 70 Train Acc : 0.5090000005960464 Test Acc : 0.4767500007525086\n",
      "\n",
      "Current : 71 Train Acc : 0.510800000667572 Test Acc : 0.476875000782311\n",
      "\n",
      "Current : 72 Train Acc : 0.5120000004768371 Test Acc : 0.47550000082701444\n",
      "\n",
      "Current : 73 Train Acc : 0.5150000004768371 Test Acc : 0.47625000115484\n",
      "\n",
      "Current : 74 Train Acc : 0.5144000009298325 Test Acc : 0.47600000124424696\n",
      "\n",
      "Current : 75 Train Acc : 0.5158000003099441 Test Acc : 0.475875001065433\n",
      "\n",
      "Current : 76 Train Acc : 0.5178000007867813 Test Acc : 0.4766250007599592\n",
      "\n",
      "Current : 77 Train Acc : 0.5179999994039536 Test Acc : 0.4761250011995435\n",
      "\n",
      "Current : 78 Train Acc : 0.518399999499321 Test Acc : 0.475500001385808\n",
      "\n",
      "Current : 79 Train Acc : 0.5202000000476837 Test Acc : 0.47637500140815975\n",
      "\n",
      "Current : 80 Train Acc : 0.520200000166893 Test Acc : 0.47725000146776436\n",
      "\n",
      "Current : 81 Train Acc : 0.5211999999284744 Test Acc : 0.4777500016987324\n",
      "\n",
      "Current : 82 Train Acc : 0.5229999994039536 Test Acc : 0.477125001847744\n",
      "\n",
      "Current : 83 Train Acc : 0.5241999998092651 Test Acc : 0.47837500177323816\n",
      "\n",
      "Current : 84 Train Acc : 0.5261999987363816 Test Acc : 0.48025000173598525\n",
      "\n",
      "Current : 85 Train Acc : 0.5278000000715256 Test Acc : 0.4791250018402934\n",
      "\n",
      "Current : 86 Train Acc : 0.5279999997615814 Test Acc : 0.4792500011995435\n",
      "\n",
      "Current : 87 Train Acc : 0.5283999998569489 Test Acc : 0.478625001013279\n",
      "\n",
      "Current : 88 Train Acc : 0.531 Test Acc : 0.47837500136345623\n",
      "\n",
      "Current : 89 Train Acc : 0.5313999999761582 Test Acc : 0.4777500017173588\n",
      "\n",
      "Current : 90 Train Acc : 0.5316000000238419 Test Acc : 0.47825000144541263\n",
      "\n",
      "Current : 91 Train Acc : 0.533800000667572 Test Acc : 0.47950000131502746\n",
      "\n",
      "Current : 92 Train Acc : 0.5352000002861023 Test Acc : 0.48050000103190543\n",
      "\n",
      "Current : 93 Train Acc : 0.5358000007867814 Test Acc : 0.4795000014826655\n",
      "\n",
      "Current : 94 Train Acc : 0.5351999996900558 Test Acc : 0.4797500013187528\n",
      "\n",
      "Current : 95 Train Acc : 0.535800000667572 Test Acc : 0.48075000163167714\n",
      "\n",
      "Current : 96 Train Acc : 0.5380000007152558 Test Acc : 0.48037500156089663\n",
      "\n",
      "Current : 97 Train Acc : 0.539200000166893 Test Acc : 0.4806250014156103\n",
      "\n",
      "Current : 98 Train Acc : 0.5394000005722046 Test Acc : 0.4815000013448298\n",
      "\n",
      "Current : 99 Train Acc : 0.5406000006198883 Test Acc : 0.48225000156089665\n",
      "\n",
      "Current : 100 Train Acc : 0.5396000012159348 Test Acc : 0.4828750010579824\n",
      "\n",
      "Current : 101 Train Acc : 0.5404000014066697 Test Acc : 0.4821250012889504\n",
      "\n",
      "Current : 102 Train Acc : 0.5410000002384185 Test Acc : 0.4832500014267862\n",
      "\n",
      "Current : 103 Train Acc : 0.5422000021934509 Test Acc : 0.4828750015422702\n",
      "\n",
      "Current : 104 Train Acc : 0.5424000008106231 Test Acc : 0.4830000014603138\n",
      "\n",
      "Current : 105 Train Acc : 0.5438000006675721 Test Acc : 0.4828750017657876\n",
      "\n",
      "Current : 106 Train Acc : 0.5442000017166138 Test Acc : 0.4832500021159649\n",
      "\n",
      "Current : 107 Train Acc : 0.5446000008583068 Test Acc : 0.4840000021457672\n",
      "\n",
      "Current : 108 Train Acc : 0.5476000003814697 Test Acc : 0.484000002220273\n",
      "\n",
      "Current : 109 Train Acc : 0.5478000012636185 Test Acc : 0.48387500174343584\n",
      "\n",
      "Current : 110 Train Acc : 0.5464000017642975 Test Acc : 0.48187500178813936\n",
      "\n",
      "Current : 111 Train Acc : 0.5491999998092651 Test Acc : 0.48762500178068874\n",
      "\n",
      "Current : 112 Train Acc : 0.5492000012397766 Test Acc : 0.4856250016763806\n",
      "\n",
      "Current : 113 Train Acc : 0.5508000006675721 Test Acc : 0.486375001706183\n",
      "\n",
      "Current : 114 Train Acc : 0.5532000005245209 Test Acc : 0.4870000019297004\n",
      "\n",
      "Current : 115 Train Acc : 0.5526000008583069 Test Acc : 0.48762500174343587\n",
      "\n",
      "Current : 116 Train Acc : 0.5536000003814697 Test Acc : 0.4861250018700957\n",
      "\n",
      "Current : 117 Train Acc : 0.5548000004291535 Test Acc : 0.48687500230968\n",
      "\n",
      "Current : 118 Train Acc : 0.5550000005960465 Test Acc : 0.48675000220537185\n",
      "\n",
      "Current : 119 Train Acc : 0.5554000005722046 Test Acc : 0.48700000196695326\n",
      "\n",
      "Current : 120 Train Acc : 0.5568000001907348 Test Acc : 0.48775000248104333\n",
      "\n",
      "Current : 121 Train Acc : 0.558600000500679 Test Acc : 0.48750000208616256\n",
      "\n",
      "Current : 122 Train Acc : 0.5608000006675721 Test Acc : 0.48700000207871197\n",
      "\n",
      "Current : 123 Train Acc : 0.562599999666214 Test Acc : 0.4877500021457672\n",
      "\n",
      "Current : 124 Train Acc : 0.5632000012397766 Test Acc : 0.4891250020265579\n",
      "\n",
      "Current : 125 Train Acc : 0.5620000001192093 Test Acc : 0.4882500018924475\n",
      "\n",
      "Current : 126 Train Acc : 0.5636000012159348 Test Acc : 0.48550000205636024\n",
      "\n",
      "Current : 127 Train Acc : 0.5664000011682511 Test Acc : 0.486500002220273\n",
      "\n",
      "Current : 128 Train Acc : 0.5648000005483628 Test Acc : 0.4866250020265579\n",
      "\n",
      "Current : 129 Train Acc : 0.5658000019788743 Test Acc : 0.48700000226497653\n",
      "\n",
      "Current : 130 Train Acc : 0.5662000008821487 Test Acc : 0.4865000019967556\n",
      "\n",
      "Current : 131 Train Acc : 0.5656000024080277 Test Acc : 0.48625000230967996\n",
      "\n",
      "Current : 132 Train Acc : 0.5678000013828277 Test Acc : 0.48737500205636025\n",
      "\n",
      "Current : 133 Train Acc : 0.5706000015735626 Test Acc : 0.4890000019967556\n",
      "\n",
      "Current : 134 Train Acc : 0.570600002169609 Test Acc : 0.4896250020712614\n",
      "\n",
      "Current : 135 Train Acc : 0.5728000011444092 Test Acc : 0.4903750021010637\n",
      "\n",
      "Current : 136 Train Acc : 0.5708000010251999 Test Acc : 0.48862500227987765\n",
      "\n",
      "Current : 137 Train Acc : 0.5708000009059906 Test Acc : 0.48875000193715096\n",
      "\n",
      "Current : 138 Train Acc : 0.5732000012397767 Test Acc : 0.4891250019520521\n",
      "\n",
      "Current : 139 Train Acc : 0.5732000007629394 Test Acc : 0.49050000198185445\n",
      "\n",
      "Current : 140 Train Acc : 0.573800001502037 Test Acc : 0.4906250015646219\n",
      "\n",
      "Current : 141 Train Acc : 0.5752000012397767 Test Acc : 0.49050000198185445\n",
      "\n",
      "Current : 142 Train Acc : 0.5772000008821487 Test Acc : 0.4887500022351742\n",
      "\n",
      "Current : 143 Train Acc : 0.5764000018835068 Test Acc : 0.4886250020563602\n",
      "\n",
      "Current : 144 Train Acc : 0.576400002002716 Test Acc : 0.48762500163167716\n",
      "\n",
      "Current : 145 Train Acc : 0.576800001502037 Test Acc : 0.4891250013560057\n",
      "\n",
      "Current : 146 Train Acc : 0.5758000007867813 Test Acc : 0.4876250011101365\n",
      "\n",
      "Current : 147 Train Acc : 0.5774000006914138 Test Acc : 0.4878750014305115\n",
      "\n",
      "Current : 148 Train Acc : 0.578400000333786 Test Acc : 0.4912500013038516\n",
      "\n",
      "Current : 149 Train Acc : 0.5809999996423721 Test Acc : 0.48787500109523535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Z\n",
    "current_exp_name = 'Z';\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16,which_reg=current_exp_name); \n",
    "l2 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l3 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "\n",
    "l4 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l5 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l6 = CNN(3,16,10,which_reg=current_exp_name); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "\n",
    "# mean std skew kurt non-zero\n",
    "llayer1 = [[],[],[],[],[]]; llayer2 = [[],[],[],[],[]]; llayer3 = [[],[],[],[],[]]\n",
    "llayer4 = [[],[],[],[],[]]; llayer5 = [[],[],[],[],[]]; llayer6 = [[],[],[],[],[]]\n",
    "\n",
    "llayer1a = [[],[],[],[],[]]; llayer2a = [[],[],[],[],[]]; llayer3a = [[],[],[],[],[]]\n",
    "llayer4a = [[],[],[],[],[]]; llayer5a = [[],[],[],[],[]]; llayer6a = [[],[],[],[],[]]\n",
    "\n",
    "weight1 = [[],[],[],[],[]]; weight2 = [[],[],[],[],[]]; weight3 = [[],[],[],[],[]];\n",
    "weight4 = [[],[],[],[],[]]; weight5 = [[],[],[],[],[]]; weight6 = [[],[],[],[],[]];\n",
    "\n",
    "gradw1  = [[],[],[],[],[]]; gradw2  = [[],[],[],[],[]]; gradw3  = [[],[],[],[],[]];\n",
    "gradw4  = [[],[],[],[],[]]; gradw5  = [[],[],[],[],[]]; gradw6  = [[],[],[],[],[]];\n",
    "\n",
    "gradp1  = [[],[],[],[],[]]; gradp2  = [[],[],[],[],[]]; gradp3  = [[],[],[],[],[]];\n",
    "gradp4  = [[],[],[],[],[]]; gradp5  = [[],[],[],[],[]]; gradp6  = [[],[],[],[],[]];\n",
    "\n",
    "gradup1  = [[],[],[],[],[]]; gradup2  = [[],[],[],[],[]]; gradup3  = [[],[],[],[],[]];\n",
    "gradup4  = [[],[],[],[],[]]; gradup5  = [[],[],[],[],[]]; gradup6  = [[],[],[],[],[]];\n",
    "\n",
    "list_of_outputs = [\n",
    "    layer1,layer2,layer3,layer4,layer5,layer6,\n",
    "    layer1a,layer2a,layer3a,layer4a,layer5a,layer6a,\n",
    "    l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw(),\n",
    "    grad1w,grad2w,grad3w,grad4w,grad5w,grad6w,\n",
    "    grad1p,grad2p,grad3p,grad4p,grad5p,grad6p,\n",
    "    grad1_up[0],grad2_up[0],grad3_up[0],grad4_up[0],grad5_up[0],grad6_up[0]\n",
    "]\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    # Training Accuracy    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # get the results\n",
    "    mid_stat = sess.run(list_of_outputs,feed_dict={x:current_data,y:current_label})\n",
    "    \n",
    "    # Test Accuracy    \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    # ======================== extract stats ========================\n",
    "    llayer1 = append_stat(llayer1,mid_stat,0);  llayer2 = append_stat(llayer2,mid_stat,1);  llayer3 = append_stat(llayer3,mid_stat,2);\n",
    "    llayer4 = append_stat(llayer4,mid_stat,3);  llayer5 = append_stat(llayer5,mid_stat,4);  llayer6 = append_stat(llayer6,mid_stat,5);\n",
    "\n",
    "    llayer1a = append_stat(llayer1a,mid_stat,6);  llayer2a = append_stat(llayer2a,mid_stat,7);  llayer3a = append_stat(llayer3a,mid_stat,8);\n",
    "    llayer4a = append_stat(llayer4a,mid_stat,9);  llayer5a = append_stat(llayer5a,mid_stat,10); llayer6a = append_stat(llayer6a,mid_stat,11);\n",
    "    \n",
    "    weight1 = append_stat(weight1,mid_stat,12);  weight2 = append_stat(weight2,mid_stat,13);  weight3 = append_stat(weight3,mid_stat,14);\n",
    "    weight4 = append_stat(weight4,mid_stat,15);  weight5 = append_stat(weight5,mid_stat,16);  weight6 = append_stat(weight6,mid_stat,17);\n",
    "    \n",
    "    gradw1 = append_stat(gradw1,mid_stat,18); gradw2 = append_stat(gradw2,mid_stat,19); gradw3 = append_stat(gradw3,mid_stat,20);\n",
    "    gradw4 = append_stat(gradw4,mid_stat,21); gradw5 = append_stat(gradw5,mid_stat,22); gradw6 = append_stat(gradw6,mid_stat,23);\n",
    "    \n",
    "    gradp1 = append_stat(gradp1,mid_stat,24); gradp2 = append_stat(gradp2,mid_stat,25); gradp3 = append_stat(gradp3,mid_stat,26);\n",
    "    gradp4 = append_stat(gradp4,mid_stat,27); gradp5 = append_stat(gradp5,mid_stat,28); gradp6 = append_stat(gradp6,mid_stat,29);\n",
    "\n",
    "    gradup1 = append_stat(gradup1,mid_stat,30); gradup2 = append_stat(gradup2,mid_stat,31); gradup3 = append_stat(gradup3,mid_stat,32);\n",
    "    gradup4 = append_stat(gradup4,mid_stat,33); gradup5 = append_stat(gradup5,mid_stat,34); gradup6 = append_stat(gradup6,mid_stat,35);\n",
    "\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    # ======================== extract stats ========================\n",
    "    \n",
    "    # ======================== save to image ========================\n",
    "    save_to_image(mid_stat[0:6]   ,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,\"layer\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[6:12]  ,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a,\"layera\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[12:18] ,weight1,weight2,weight3,weight4,weight5,weight6,\"weights\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[18:24] ,gradw1,gradw2,gradw3,gradw4,gradw5,gradw6,\"gradientw\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[24:30] ,gradp1,gradp2,gradp3,gradp4,gradp5,gradp6,\"gradientp\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[30:36] ,gradup1,gradup2,gradup3,gradup4,gradup5,gradup6,\"moment\",train_acc,test_acc,current_exp_name,iter)\n",
    "    # ======================== save to image ========================\n",
    "        \n",
    "    # ======================== print reset ========================\n",
    "    print(\"Current : \"+ str(iter) + \" Train Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    # ======================== print reset ========================\n",
    "\n",
    "np.save(current_exp_name+'/train_acc.npy',train_acc); np.save(current_exp_name+'/test_acc.npy', test_acc)    \n",
    "np.save(current_exp_name+'/llayer1.npy', llayer1);  np.save(current_exp_name+'/llayer2.npy', llayer2);  np.save(current_exp_name+'/llayer3.npy', llayer3); \n",
    "np.save(current_exp_name+'/llayer4.npy', llayer4);  np.save(current_exp_name+'/llayer5.npy', llayer5);  np.save(current_exp_name+'/llayer6.npy', llayer6); \n",
    "\n",
    "np.save(current_exp_name+'/llayer1a.npy', llayer1a);  np.save(current_exp_name+'/llayer2a.npy', llayer2a);  np.save(current_exp_name+'/llayer3a.npy', llayer3a); \n",
    "np.save(current_exp_name+'/llayer4a.npy', llayer4a);  np.save(current_exp_name+'/llayer5a.npy', llayer5a);  np.save(current_exp_name+'/llayer6a.npy', llayer6a); \n",
    "\n",
    "np.save(current_exp_name+'/weight1.npy', weight1);  np.save(current_exp_name+'/weight2.npy', weight2);  np.save(current_exp_name+'/weight3.npy', weight3);  \n",
    "np.save(current_exp_name+'/weight4.npy', weight4);  np.save(current_exp_name+'/weight5.npy', weight5);  np.save(current_exp_name+'/weight6.npy', weight6);  \n",
    "\n",
    "np.save(current_exp_name+'/gradw1.npy', gradw1); np.save(current_exp_name+'/gradw2.npy', gradw2); np.save(current_exp_name+'/gradw3.npy', gradw3);\n",
    "np.save(current_exp_name+'/gradw4.npy', gradw4); np.save(current_exp_name+'/gradw5.npy', gradw5); np.save(current_exp_name+'/gradw6.npy', gradw6);\n",
    "\n",
    "np.save(current_exp_name+'/gradp1.npy', gradp1); np.save(current_exp_name+'/gradp2.npy', gradp2); np.save(current_exp_name+'/gradp3.npy', gradp3);\n",
    "np.save(current_exp_name+'/gradp4.npy', gradp4); np.save(current_exp_name+'/gradp5.npy', gradp5); np.save(current_exp_name+'/gradp6.npy', gradp6);\n",
    "\n",
    "np.save(current_exp_name+'/gradup1.npy', gradup1); np.save(current_exp_name+'/gradup2.npy', gradup2); np.save(current_exp_name+'/gradup3.npy', gradup3);\n",
    "np.save(current_exp_name+'/gradup4.npy', gradup4); np.save(current_exp_name+'/gradup5.npy', gradup5); np.save(current_exp_name+'/gradup6.npy', gradup6);\n",
    "\n",
    "sess.close(); tf.reset_default_graph();\n",
    "\n",
    "%xdel train_acc,test_acc,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a\n",
    "%xdel weight1,weight2,weight3,weight4,weight5,weight6\n",
    "%xdel gradw1,gradw2,gradw3,gradw4,gradw5,gradw6\n",
    "%xdel gradp1,gradp2,gradp3,gradp4,gradp5,gradp6\n",
    "%xdel gradup1,gradup2,gradup3,gradup4,gradup5,gradup6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:00:38.162949Z",
     "start_time": "2018-12-27T08:35:25.446293Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 0 Train Acc : 0.11720000250637531 Test Acc : 0.12575000260956584\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 1 Train Acc : 0.17140000301599503 Test Acc : 0.1890000030491501\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 2 Train Acc : 0.20860000325739383 Test Acc : 0.259625003086403\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 3 Train Acc : 0.2518000030964613 Test Acc : 0.2847500023804605\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 4 Train Acc : 0.2730000028014183 Test Acc : 0.29675000239163635\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 5 Train Acc : 0.29620000219345094 Test Acc : 0.30675000143237413\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 6 Train Acc : 0.3074000027477741 Test Acc : 0.3242500015627593\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 7 Train Acc : 0.3204000018388033 Test Acc : 0.33375000158324836\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 8 Train Acc : 0.3350000014156103 Test Acc : 0.34162500184960665\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 9 Train Acc : 0.3444000012427568 Test Acc : 0.34587500179186464\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Train Acc : 0.34700000217556953 Test Acc : 0.34875000243075194\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 11 Train Acc : 0.34840000174939634 Test Acc : 0.3531250020954758\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 12 Train Acc : 0.35360000194609165 Test Acc : 0.3558750013168901\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 13 Train Acc : 0.3612000023126602 Test Acc : 0.3612500020861626\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 14 Train Acc : 0.3640000020116568 Test Acc : 0.36325000185519457\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 15 Train Acc : 0.3730000020116568 Test Acc : 0.3700000014342368\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 16 Train Acc : 0.37660000218451023 Test Acc : 0.3710000010579824\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 17 Train Acc : 0.3816000015884638 Test Acc : 0.3737500014714897\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 18 Train Acc : 0.38520000196993354 Test Acc : 0.3781250016391277\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 19 Train Acc : 0.3868000022917986 Test Acc : 0.3828750006482005\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Train Acc : 0.39380000211298466 Test Acc : 0.3841250000055879\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 21 Train Acc : 0.3988000019043684 Test Acc : 0.39687500143423676\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Train Acc : 0.4022000014781952 Test Acc : 0.3977500005066395\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 23 Train Acc : 0.40200000208616254 Test Acc : 0.40725000116974114\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 24 Train Acc : 0.4084000009298325 Test Acc : 0.40937500115484\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 25 Train Acc : 0.4202000017464161 Test Acc : 0.4096250012330711\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Train Acc : 0.41900000131130216 Test Acc : 0.41275000194087624\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Train Acc : 0.4256000023782253 Test Acc : 0.41475000156089664\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 28 Train Acc : 0.42940000292658803 Test Acc : 0.41387500094249846\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 29 Train Acc : 0.431400003015995 Test Acc : 0.4173750012367964\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 30 Train Acc : 0.4350000031590462 Test Acc : 0.4210000006109476\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Train Acc : 0.43780000251531603 Test Acc : 0.4263750013336539\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Train Acc : 0.4384000023007393 Test Acc : 0.42875000152736903\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Train Acc : 0.4404000008702278 Test Acc : 0.43087500154972075\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 34 Train Acc : 0.44300000137090684 Test Acc : 0.4328750015422702\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 35 Train Acc : 0.44320000156760214 Test Acc : 0.4383750014007092\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 36 Train Acc : 0.44740000185370443 Test Acc : 0.43725000191479924\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 37 Train Acc : 0.44800000098347664 Test Acc : 0.4383750015869737\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 38 Train Acc : 0.4534000017344952 Test Acc : 0.4381250013783574\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 39 Train Acc : 0.45460000142455104 Test Acc : 0.4412500012665987\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 40 Train Acc : 0.45840000167489053 Test Acc : 0.4456250011920929\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 41 Train Acc : 0.4612000015079975 Test Acc : 0.4461250012367964\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 42 Train Acc : 0.4634000017940998 Test Acc : 0.44775000140070914\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 43 Train Acc : 0.4662000016272068 Test Acc : 0.4490000015869737\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 44 Train Acc : 0.4698000015318394 Test Acc : 0.44962500147521495\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 45 Train Acc : 0.47020000156760217 Test Acc : 0.45012500148266554\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 46 Train Acc : 0.4742000009119511 Test Acc : 0.45100000116974115\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 47 Train Acc : 0.4752000015079975 Test Acc : 0.4526250012591481\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 48 Train Acc : 0.4784000021517277 Test Acc : 0.45625000167638063\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 49 Train Acc : 0.4788000011742115 Test Acc : 0.4572500016540289\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 50 Train Acc : 0.48260000163316724 Test Acc : 0.4578750018775463\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 51 Train Acc : 0.4840000020265579 Test Acc : 0.4582500021532178\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 52 Train Acc : 0.4862000016570091 Test Acc : 0.45875000197440385\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 53 Train Acc : 0.4890000012516975 Test Acc : 0.4582500018179417\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 54 Train Acc : 0.48920000129938124 Test Acc : 0.4617500013485551\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 55 Train Acc : 0.4898000014424324 Test Acc : 0.4645000012218952\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 56 Train Acc : 0.49100000149011613 Test Acc : 0.466375001296401\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 57 Train Acc : 0.49100000166893004 Test Acc : 0.46800000112503765\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 58 Train Acc : 0.4924000016450882 Test Acc : 0.46975000135600564\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 59 Train Acc : 0.49620000219345095 Test Acc : 0.4702500008419156\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 60 Train Acc : 0.4972000018358231 Test Acc : 0.47312500070780517\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 61 Train Acc : 0.4998000015020371 Test Acc : 0.47600000075995924\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 62 Train Acc : 0.5020000014305115 Test Acc : 0.4762500004842877\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 63 Train Acc : 0.5032000017166137 Test Acc : 0.47925000041723254\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 64 Train Acc : 0.5050000014305115 Test Acc : 0.48112500019371507\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 65 Train Acc : 0.5064000020027161 Test Acc : 0.4802499995008111\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 66 Train Acc : 0.5070000023841857 Test Acc : 0.48075000010430813\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 67 Train Acc : 0.5074000017046928 Test Acc : 0.48249999970197677\n",
      "\n",
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 68 Train Acc : 0.5112000012993813 Test Acc : 0.4818749997019768\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 69 Train Acc : 0.5114000012278557 Test Acc : 0.4855000001192093\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 70 Train Acc : 0.5106000016331673 Test Acc : 0.486375000551343\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 71 Train Acc : 0.5126000017523765 Test Acc : 0.48775000050663947\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 72 Train Acc : 0.5122000017762184 Test Acc : 0.4891250006109476\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 73 Train Acc : 0.515400001347065 Test Acc : 0.48962500028312206\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 74 Train Acc : 0.5168000016808509 Test Acc : 0.4906250002235174\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 75 Train Acc : 0.5186000016331672 Test Acc : 0.4897500006109476\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 76 Train Acc : 0.5206000022292138 Test Acc : 0.49012500040233137\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.75\n",
      " Current : 77 Train Acc : 0.5218000015616417 Test Acc : 0.4903750005364418\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 78 Train Acc : 0.5218000015616417 Test Acc : 0.49150000169873237\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 79 Train Acc : 0.5244000015854835 Test Acc : 0.49200000122189524\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 80 Train Acc : 0.5258000011444092 Test Acc : 0.4925000013411045\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 81 Train Acc : 0.5274000009298324 Test Acc : 0.49212500162422657\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 82 Train Acc : 0.5292000015974044 Test Acc : 0.4942500016093254\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 83 Train Acc : 0.5290000009536743 Test Acc : 0.49475000202655794\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 84 Train Acc : 0.5312000019550324 Test Acc : 0.49625000212341547\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 85 Train Acc : 0.5316000010967254 Test Acc : 0.49600000251084564\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 86 Train Acc : 0.5340000014305115 Test Acc : 0.4963750023394823\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 87 Train Acc : 0.534400001168251 Test Acc : 0.4986250018328428\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 88 Train Acc : 0.5360000011324882 Test Acc : 0.4978750021755695\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 89 Train Acc : 0.5376000013947487 Test Acc : 0.5000000016018749\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 90 Train Acc : 0.5360000019073486 Test Acc : 0.49987500108778476\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 91 Train Acc : 0.5360000023841858 Test Acc : 0.5010000013187528\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 92 Train Acc : 0.5398000013828278 Test Acc : 0.5002500016614795\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 93 Train Acc : 0.5378000018596649 Test Acc : 0.502250001206994\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 94 Train Acc : 0.5398000018000603 Test Acc : 0.5020000014454127\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 95 Train Acc : 0.5424000020027161 Test Acc : 0.503000001385808\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 96 Train Acc : 0.5430000013113022 Test Acc : 0.5025000010803342\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 97 Train Acc : 0.5442000013589859 Test Acc : 0.5032500008866191\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 98 Train Acc : 0.5460000007152558 Test Acc : 0.5028750004246831\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 99 Train Acc : 0.5454000015258789 Test Acc : 0.5025000001862645\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 100 Train Acc : 0.5470000011324883 Test Acc : 0.5032500004023314\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 101 Train Acc : 0.5462000014781951 Test Acc : 0.5031250004097819\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 102 Train Acc : 0.5502000019550324 Test Acc : 0.5033750002831221\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 103 Train Acc : 0.5524000012874604 Test Acc : 0.5045000000298023\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 104 Train Acc : 0.550000002026558 Test Acc : 0.5047500006109477\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 105 Train Acc : 0.5528000019788742 Test Acc : 0.5058750003576279\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 106 Train Acc : 0.5546000024080276 Test Acc : 0.5066250007599592\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 107 Train Acc : 0.5536000012159348 Test Acc : 0.5058750008046627\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 108 Train Acc : 0.5568000018596649 Test Acc : 0.5061250008642674\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 109 Train Acc : 0.5580000013113022 Test Acc : 0.5052500008046628\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 110 Train Acc : 0.5578000011444092 Test Acc : 0.5061250004172325\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 111 Train Acc : 0.5594000018835068 Test Acc : 0.5062500010058284\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 112 Train Acc : 0.5608000020980834 Test Acc : 0.5075000010430812\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 113 Train Acc : 0.5634000023603439 Test Acc : 0.5098750007525087\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 114 Train Acc : 0.5654000021219253 Test Acc : 0.5062500013783574\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 115 Train Acc : 0.5656000014543533 Test Acc : 0.5061250013671815\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 116 Train Acc : 0.5680000022649765 Test Acc : 0.5068750014714897\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Train Acc : 0.5696000026464463 Test Acc : 0.5075000009499491\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 118 Train Acc : 0.5686000018119812 Test Acc : 0.5082500013522804\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 119 Train Acc : 0.5690000028610229 Test Acc : 0.507625001501292\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 120 Train Acc : 0.5714000027179718 Test Acc : 0.5071250011585653\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Train Acc : 0.5722000019550324 Test Acc : 0.5078750011511147\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Train Acc : 0.5734000024795533 Test Acc : 0.5087500007636845\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Train Acc : 0.5738000024557114 Test Acc : 0.5090000009723008\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Train Acc : 0.5778000031709671 Test Acc : 0.5092500013113022\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Train Acc : 0.577200003027916 Test Acc : 0.510125001464039\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Train Acc : 0.5794000027179718 Test Acc : 0.5091250015608967\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 127 Train Acc : 0.5802000024318695 Test Acc : 0.5100000012107193\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Train Acc : 0.5818000024557114 Test Acc : 0.5098750011436641\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Train Acc : 0.5848000024557114 Test Acc : 0.5095000009797513\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Train Acc : 0.5842000027894974 Test Acc : 0.5091250012628734\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Train Acc : 0.5872000029087067 Test Acc : 0.5085000013373793\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Train Acc : 0.586200003862381 Test Acc : 0.5086250013113022\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Train Acc : 0.5872000033855438 Test Acc : 0.5087500013411045\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 134 Train Acc : 0.5870000038146973 Test Acc : 0.508625001348555\n",
      "\n",
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Train Acc : 0.5888000034093857 Test Acc : 0.5080000014230609\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Train Acc : 0.5920000034570694 Test Acc : 0.5096250011026859\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 137 Train Acc : 0.593200002670288 Test Acc : 0.5097500007972121\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Train Acc : 0.592200002670288 Test Acc : 0.5106250010430813\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 139 Train Acc : 0.5922000027894974 Test Acc : 0.5106250008940697\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Train Acc : 0.5926000022888184 Test Acc : 0.511125001013279\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Train Acc : 0.5952000033855438 Test Acc : 0.5125000010430812\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 142 Train Acc : 0.5944000021219253 Test Acc : 0.5113750011473894\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 143 Train Acc : 0.5946000016927719 Test Acc : 0.5118750012665987\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 144 Train Acc : 0.5948000012636184 Test Acc : 0.5136250011995435\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 145 Train Acc : 0.5976000022888184 Test Acc : 0.5136250014975667\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 146 Train Acc : 0.597600001335144 Test Acc : 0.5141250014677644\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 147 Train Acc : 0.5984000016450882 Test Acc : 0.5141250013932586\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Train Acc : 0.5992000015974045 Test Acc : 0.5136250014789403\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 149 Train Acc : 0.6024000010490418 Test Acc : 0.5133750018663704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "current_exp_name = 'A';\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16,which_reg=current_exp_name); \n",
    "l2 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l3 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "\n",
    "l4 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l5 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l6 = CNN(3,16,10,which_reg=current_exp_name); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "\n",
    "# mean std skew kurt non-zero\n",
    "llayer1 = [[],[],[],[],[]]; llayer2 = [[],[],[],[],[]]; llayer3 = [[],[],[],[],[]]\n",
    "llayer4 = [[],[],[],[],[]]; llayer5 = [[],[],[],[],[]]; llayer6 = [[],[],[],[],[]]\n",
    "\n",
    "llayer1a = [[],[],[],[],[]]; llayer2a = [[],[],[],[],[]]; llayer3a = [[],[],[],[],[]]\n",
    "llayer4a = [[],[],[],[],[]]; llayer5a = [[],[],[],[],[]]; llayer6a = [[],[],[],[],[]]\n",
    "\n",
    "weight1 = [[],[],[],[],[]]; weight2 = [[],[],[],[],[]]; weight3 = [[],[],[],[],[]];\n",
    "weight4 = [[],[],[],[],[]]; weight5 = [[],[],[],[],[]]; weight6 = [[],[],[],[],[]];\n",
    "\n",
    "gradw1  = [[],[],[],[],[]]; gradw2  = [[],[],[],[],[]]; gradw3  = [[],[],[],[],[]];\n",
    "gradw4  = [[],[],[],[],[]]; gradw5  = [[],[],[],[],[]]; gradw6  = [[],[],[],[],[]];\n",
    "\n",
    "gradp1  = [[],[],[],[],[]]; gradp2  = [[],[],[],[],[]]; gradp3  = [[],[],[],[],[]];\n",
    "gradp4  = [[],[],[],[],[]]; gradp5  = [[],[],[],[],[]]; gradp6  = [[],[],[],[],[]];\n",
    "\n",
    "gradup1  = [[],[],[],[],[]]; gradup2  = [[],[],[],[],[]]; gradup3  = [[],[],[],[],[]];\n",
    "gradup4  = [[],[],[],[],[]]; gradup5  = [[],[],[],[],[]]; gradup6  = [[],[],[],[],[]];\n",
    "\n",
    "list_of_outputs = [\n",
    "    layer1,layer2,layer3,layer4,layer5,layer6,\n",
    "    layer1a,layer2a,layer3a,layer4a,layer5a,layer6a,\n",
    "    l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw(),\n",
    "    grad1w,grad2w,grad3w,grad4w,grad5w,grad6w,\n",
    "    grad1p,grad2p,grad3p,grad4p,grad5p,grad6p,\n",
    "    grad1_up[0],grad2_up[0],grad3_up[0],grad4_up[0],grad5_up[0],grad6_up[0]\n",
    "]\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    # Training Accuracy    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # get the results\n",
    "    mid_stat = sess.run(list_of_outputs,feed_dict={x:current_data,y:current_label})\n",
    "    \n",
    "    # Test Accuracy    \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    # ======================== extract stats ========================\n",
    "    llayer1 = append_stat(llayer1,mid_stat,0);  llayer2 = append_stat(llayer2,mid_stat,1);  llayer3 = append_stat(llayer3,mid_stat,2);\n",
    "    llayer4 = append_stat(llayer4,mid_stat,3);  llayer5 = append_stat(llayer5,mid_stat,4);  llayer6 = append_stat(llayer6,mid_stat,5);\n",
    "\n",
    "    llayer1a = append_stat(llayer1a,mid_stat,6);  llayer2a = append_stat(llayer2a,mid_stat,7);  llayer3a = append_stat(llayer3a,mid_stat,8);\n",
    "    llayer4a = append_stat(llayer4a,mid_stat,9);  llayer5a = append_stat(llayer5a,mid_stat,10); llayer6a = append_stat(llayer6a,mid_stat,11);\n",
    "    \n",
    "    weight1 = append_stat(weight1,mid_stat,12);  weight2 = append_stat(weight2,mid_stat,13);  weight3 = append_stat(weight3,mid_stat,14);\n",
    "    weight4 = append_stat(weight4,mid_stat,15);  weight5 = append_stat(weight5,mid_stat,16);  weight6 = append_stat(weight6,mid_stat,17);\n",
    "    \n",
    "    gradw1 = append_stat(gradw1,mid_stat,18); gradw2 = append_stat(gradw2,mid_stat,19); gradw3 = append_stat(gradw3,mid_stat,20);\n",
    "    gradw4 = append_stat(gradw4,mid_stat,21); gradw5 = append_stat(gradw5,mid_stat,22); gradw6 = append_stat(gradw6,mid_stat,23);\n",
    "    \n",
    "    gradp1 = append_stat(gradp1,mid_stat,24); gradp2 = append_stat(gradp2,mid_stat,25); gradp3 = append_stat(gradp3,mid_stat,26);\n",
    "    gradp4 = append_stat(gradp4,mid_stat,27); gradp5 = append_stat(gradp5,mid_stat,28); gradp6 = append_stat(gradp6,mid_stat,29);\n",
    "\n",
    "    gradup1 = append_stat(gradup1,mid_stat,30); gradup2 = append_stat(gradup2,mid_stat,31); gradup3 = append_stat(gradup3,mid_stat,32);\n",
    "    gradup4 = append_stat(gradup4,mid_stat,33); gradup5 = append_stat(gradup5,mid_stat,34); gradup6 = append_stat(gradup6,mid_stat,35);\n",
    "\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    # ======================== extract stats ========================\n",
    "    \n",
    "    # ======================== save to image ========================\n",
    "    save_to_image(mid_stat[0:6]   ,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,\"layer\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[6:12]  ,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a,\"layera\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[12:18] ,weight1,weight2,weight3,weight4,weight5,weight6,\"weights\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[18:24] ,gradw1,gradw2,gradw3,gradw4,gradw5,gradw6,\"gradientw\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[24:30] ,gradp1,gradp2,gradp3,gradp4,gradp5,gradp6,\"gradientp\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[30:36] ,gradup1,gradup2,gradup3,gradup4,gradup5,gradup6,\"moment\",train_acc,test_acc,current_exp_name,iter)\n",
    "    # ======================== save to image ========================\n",
    "        \n",
    "    # ======================== print reset ========================\n",
    "    print(\"Current : \"+ str(iter) + \" Train Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    # ======================== print reset ========================\n",
    "\n",
    "np.save(current_exp_name+'/train_acc.npy',train_acc); np.save(current_exp_name+'/test_acc.npy', test_acc)    \n",
    "np.save(current_exp_name+'/llayer1.npy', llayer1);  np.save(current_exp_name+'/llayer2.npy', llayer2);  np.save(current_exp_name+'/llayer3.npy', llayer3); \n",
    "np.save(current_exp_name+'/llayer4.npy', llayer4);  np.save(current_exp_name+'/llayer5.npy', llayer5);  np.save(current_exp_name+'/llayer6.npy', llayer6); \n",
    "\n",
    "np.save(current_exp_name+'/llayer1a.npy', llayer1a);  np.save(current_exp_name+'/llayer2a.npy', llayer2a);  np.save(current_exp_name+'/llayer3a.npy', llayer3a); \n",
    "np.save(current_exp_name+'/llayer4a.npy', llayer4a);  np.save(current_exp_name+'/llayer5a.npy', llayer5a);  np.save(current_exp_name+'/llayer6a.npy', llayer6a); \n",
    "\n",
    "np.save(current_exp_name+'/weight1.npy', weight1);  np.save(current_exp_name+'/weight2.npy', weight2);  np.save(current_exp_name+'/weight3.npy', weight3);  \n",
    "np.save(current_exp_name+'/weight4.npy', weight4);  np.save(current_exp_name+'/weight5.npy', weight5);  np.save(current_exp_name+'/weight6.npy', weight6);  \n",
    "\n",
    "np.save(current_exp_name+'/gradw1.npy', gradw1); np.save(current_exp_name+'/gradw2.npy', gradw2); np.save(current_exp_name+'/gradw3.npy', gradw3);\n",
    "np.save(current_exp_name+'/gradw4.npy', gradw4); np.save(current_exp_name+'/gradw5.npy', gradw5); np.save(current_exp_name+'/gradw6.npy', gradw6);\n",
    "\n",
    "np.save(current_exp_name+'/gradp1.npy', gradp1); np.save(current_exp_name+'/gradp2.npy', gradp2); np.save(current_exp_name+'/gradp3.npy', gradp3);\n",
    "np.save(current_exp_name+'/gradp4.npy', gradp4); np.save(current_exp_name+'/gradp5.npy', gradp5); np.save(current_exp_name+'/gradp6.npy', gradp6);\n",
    "\n",
    "np.save(current_exp_name+'/gradup1.npy', gradup1); np.save(current_exp_name+'/gradup2.npy', gradup2); np.save(current_exp_name+'/gradup3.npy', gradup3);\n",
    "np.save(current_exp_name+'/gradup4.npy', gradup4); np.save(current_exp_name+'/gradup5.npy', gradup5); np.save(current_exp_name+'/gradup6.npy', gradup6);\n",
    "\n",
    "sess.close(); tf.reset_default_graph();\n",
    "\n",
    "%xdel train_acc,test_acc,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a\n",
    "%xdel weight1,weight2,weight3,weight4,weight5,weight6\n",
    "%xdel gradw1,gradw2,gradw3,gradw4,gradw5,gradw6\n",
    "%xdel gradp1,gradp2,gradp3,gradp4,gradp5,gradp6\n",
    "%xdel gradup1,gradup2,gradup3,gradup4,gradup5,gradup6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T09:24:14.524066Z",
     "start_time": "2018-12-27T09:00:38.221063Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Train Acc : 0.1392000028192997 Test Acc : 0.1443750027474016\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 1 Train Acc : 0.21400000254809856 Test Acc : 0.2798750027175993\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 2 Train Acc : 0.27320000341534617 Test Acc : 0.2966250023432076\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 3 Train Acc : 0.29900000190734866 Test Acc : 0.3045000023953617\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Train Acc : 0.31880000177025797 Test Acc : 0.31962500205263494\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 5 Train Acc : 0.3328000017106533 Test Acc : 0.3328750017378479\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 6 Train Acc : 0.34660000136494634 Test Acc : 0.3490000013913959\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 7 Train Acc : 0.35760000205039977 Test Acc : 0.3530000016465783\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 8 Train Acc : 0.3704000025391579 Test Acc : 0.3623750018328428\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 9 Train Acc : 0.3768000016212463 Test Acc : 0.3770000012218952\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 10 Train Acc : 0.3818000010251999 Test Acc : 0.383375001270324\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 11 Train Acc : 0.385400001347065 Test Acc : 0.39000000147148967\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 12 Train Acc : 0.39380000114440916 Test Acc : 0.3938750013895333\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 13 Train Acc : 0.40020000118017196 Test Acc : 0.39625000139698385\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 14 Train Acc : 0.4054000011086464 Test Acc : 0.39912500156089664\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 15 Train Acc : 0.4100000006556511 Test Acc : 0.40100000066682695\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 16 Train Acc : 0.413400000333786 Test Acc : 0.40175000082701445\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Train Acc : 0.41520000058412554 Test Acc : 0.40100000094622373\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 18 Train Acc : 0.417200001001358 Test Acc : 0.401875001359731\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 19 Train Acc : 0.42160000121593477 Test Acc : 0.4086250014975667\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Train Acc : 0.425800000846386 Test Acc : 0.40787500141188504\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 21 Train Acc : 0.4310000006556511 Test Acc : 0.4126250009611249\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Train Acc : 0.4334000014066696 Test Acc : 0.41600000131875275\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 23 Train Acc : 0.4420000016093254 Test Acc : 0.41975000154227016\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 24 Train Acc : 0.4426000016927719 Test Acc : 0.4223750014603138\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 25 Train Acc : 0.4456000017523766 Test Acc : 0.4242500016093254\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Train Acc : 0.44740000158548354 Test Acc : 0.4295000013336539\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 27 Train Acc : 0.4514000008702278 Test Acc : 0.43412500109523533\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Train Acc : 0.45340000063180924 Test Acc : 0.43662500102072954\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Train Acc : 0.4601999998688698 Test Acc : 0.43787500116974115\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Train Acc : 0.46039999973773954 Test Acc : 0.4387500011175871\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 31 Train Acc : 0.4635999999046326 Test Acc : 0.43812500063329934\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 32 Train Acc : 0.4644000006914139 Test Acc : 0.439500000923872\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 33 Train Acc : 0.46880000042915343 Test Acc : 0.44187500089406967\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 34 Train Acc : 0.4708000003695488 Test Acc : 0.4436250010505319\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 35 Train Acc : 0.4760000002384186 Test Acc : 0.44462500132620336\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 36 Train Acc : 0.47720000046491623 Test Acc : 0.44825000133365395\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 37 Train Acc : 0.4800000007748604 Test Acc : 0.45050000097602605\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 38 Train Acc : 0.4808000010251999 Test Acc : 0.45262500081211327\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 39 Train Acc : 0.48540000039339065 Test Acc : 0.45387500058859587\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 40 Train Acc : 0.4872000010609627 Test Acc : 0.4553750003874302\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 41 Train Acc : 0.48740000087022783 Test Acc : 0.4551250009611249\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 42 Train Acc : 0.4914000011086464 Test Acc : 0.457750002220273\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Train Acc : 0.49400000035762787 Test Acc : 0.45850000210106373\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Train Acc : 0.4948000007867813 Test Acc : 0.46062500204890966\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Train Acc : 0.4968000009059906 Test Acc : 0.463625002540648\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Train Acc : 0.5002000007629395 Test Acc : 0.46412500236183407\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 47 Train Acc : 0.5053999998569488 Test Acc : 0.4651250026747584\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 48 Train Acc : 0.5064000006914139 Test Acc : 0.47012500155717135\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 49 Train Acc : 0.509400001168251 Test Acc : 0.47362500209361313\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 50 Train Acc : 0.5114000002145768 Test Acc : 0.4726250022277236\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Train Acc : 0.5156000002622604 Test Acc : 0.47450000163167716\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 52 Train Acc : 0.5176000003814697 Test Acc : 0.47612500194460156\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 53 Train Acc : 0.5206000003814697 Test Acc : 0.48162500232458116\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 54 Train Acc : 0.5212000000476837 Test Acc : 0.48375000223517417\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Train Acc : 0.5246000000238419 Test Acc : 0.4850000021979213\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 56 Train Acc : 0.5255999999046326 Test Acc : 0.4860000017657876\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 57 Train Acc : 0.5291999998092651 Test Acc : 0.48687500167638065\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 58 Train Acc : 0.5329999995827674 Test Acc : 0.48975000251084566\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 59 Train Acc : 0.5372000001072884 Test Acc : 0.49087500214576724\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 60 Train Acc : 0.5401999997496605 Test Acc : 0.49387500174343585\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Train Acc : 0.5452000005841255 Test Acc : 0.49687500096857545\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Train Acc : 0.5456000015735626 Test Acc : 0.49525000181049106\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 63 Train Acc : 0.5478000009059906 Test Acc : 0.498125001937151\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 64 Train Acc : 0.5476000015735626 Test Acc : 0.4962500014156103\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 65 Train Acc : 0.5468000010251999 Test Acc : 0.49762500151991845\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 66 Train Acc : 0.5524000008106231 Test Acc : 0.49637500137090684\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Train Acc : 0.5558000007867813 Test Acc : 0.49725000124424695\n",
      "\n",
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 68 Train Acc : 0.5590000005960465 Test Acc : 0.49762500073760746\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Train Acc : 0.5617999999523163 Test Acc : 0.4990000008419156\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Train Acc : 0.5623999993801116 Test Acc : 0.4981250013783574\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Train Acc : 0.5651999996900559 Test Acc : 0.49987500164657833\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Train Acc : 0.5678000007867813 Test Acc : 0.4985000015050173\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Train Acc : 0.5698000009059906 Test Acc : 0.4985000015050173\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 74 Train Acc : 0.570000000834465 Test Acc : 0.4997500012814999\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Train Acc : 0.5742000007629394 Test Acc : 0.5006250010430813\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Train Acc : 0.5758000009059906 Test Acc : 0.5017500013485551\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 77 Train Acc : 0.5766000006198883 Test Acc : 0.5027500013634563\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 78 Train Acc : 0.5782000008821487 Test Acc : 0.504375001527369\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 79 Train Acc : 0.5810000016689301 Test Acc : 0.5042500013485551\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 80 Train Acc : 0.5832000012397767 Test Acc : 0.5056250010058284\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 81 Train Acc : 0.5848000000715255 Test Acc : 0.5061250006780028\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 82 Train Acc : 0.5876000003814698 Test Acc : 0.5056250007078051\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 83 Train Acc : 0.5884000005722045 Test Acc : 0.5085000010207296\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 84 Train Acc : 0.5896000007390976 Test Acc : 0.5108750015869736\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 85 Train Acc : 0.5899999998807907 Test Acc : 0.5101250013336539\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 86 Train Acc : 0.5931999995708466 Test Acc : 0.5097500010579824\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 87 Train Acc : 0.5957999993562698 Test Acc : 0.5105000011995435\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 88 Train Acc : 0.5969999982118607 Test Acc : 0.5141250013932586\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 89 Train Acc : 0.5973999991416931 Test Acc : 0.5131250016018748\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 90 Train Acc : 0.6015999983549118 Test Acc : 0.5137500021979213\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 91 Train Acc : 0.6029999989271164 Test Acc : 0.5137500017508865\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 92 Train Acc : 0.6025999983549118 Test Acc : 0.5145000018551946\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 93 Train Acc : 0.6027999988794327 Test Acc : 0.5143750018626452\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 94 Train Acc : 0.6047999992370605 Test Acc : 0.5160000019147992\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 95 Train Acc : 0.6065999982357025 Test Acc : 0.5178750016540289\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 96 Train Acc : 0.6099999991655349 Test Acc : 0.5186250012367963\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 97 Train Acc : 0.6105999990701675 Test Acc : 0.520375001244247\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 98 Train Acc : 0.6141999990940094 Test Acc : 0.5178750016912818\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 99 Train Acc : 0.6161999992132187 Test Acc : 0.5222500014305115\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 100 Train Acc : 0.6167999997138977 Test Acc : 0.5226250015199184\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 101 Train Acc : 0.6185999994277954 Test Acc : 0.5221250015497207\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Train Acc : 0.6177999999523163 Test Acc : 0.5226250018551946\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 103 Train Acc : 0.6185999997854232 Test Acc : 0.5228750018402935\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 104 Train Acc : 0.620199999332428 Test Acc : 0.5232500025257468\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Train Acc : 0.6228000000715256 Test Acc : 0.5258750020712614\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 106 Train Acc : 0.6221999995708466 Test Acc : 0.5251250025257468\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 107 Train Acc : 0.623599999666214 Test Acc : 0.525125002451241\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 108 Train Acc : 0.6258000001907349 Test Acc : 0.5256250030174852\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 109 Train Acc : 0.6281999998092651 Test Acc : 0.5262500021979213\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 110 Train Acc : 0.6287999989986419 Test Acc : 0.5256250025704503\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 111 Train Acc : 0.6319999984502792 Test Acc : 0.5260000029578805\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 112 Train Acc : 0.6315999982357026 Test Acc : 0.5260000028833747\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Train Acc : 0.6333999979496002 Test Acc : 0.5253750028088688\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Train Acc : 0.633599997997284 Test Acc : 0.5252500032261014\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Train Acc : 0.6349999986886978 Test Acc : 0.5251250028982759\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Train Acc : 0.6365999991893768 Test Acc : 0.5246250030770898\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Train Acc : 0.6373999989032746 Test Acc : 0.5252500027045608\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Train Acc : 0.6389999986886978 Test Acc : 0.5248750031366944\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Train Acc : 0.6401999995708466 Test Acc : 0.5257500029727816\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 120 Train Acc : 0.6437999995946884 Test Acc : 0.5265000027045608\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Train Acc : 0.6438000003099441 Test Acc : 0.5265000029280782\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Train Acc : 0.6463999997377395 Test Acc : 0.5291250030696392\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Train Acc : 0.6461999989748001 Test Acc : 0.5292500026896596\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Train Acc : 0.6467999993562699 Test Acc : 0.5273750026151538\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Train Acc : 0.6479999994039536 Test Acc : 0.5276250029355287\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Train Acc : 0.6503999990224838 Test Acc : 0.5265000028163195\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Train Acc : 0.650399999499321 Test Acc : 0.5272500030696392\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Train Acc : 0.6529999989271164 Test Acc : 0.5286250030994415\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Train Acc : 0.6547999991178513 Test Acc : 0.5285000030323863\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Train Acc : 0.657199998497963 Test Acc : 0.5288750031590461\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Train Acc : 0.657199998497963 Test Acc : 0.5306250027567149\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Train Acc : 0.6575999991893768 Test Acc : 0.5290000028908253\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 133 Train Acc : 0.6595999988317489 Test Acc : 0.5292500027641655\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 134 Train Acc : 0.6625999981164932 Test Acc : 0.5296250020340085\n",
      "\n",
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Train Acc : 0.666199999332428 Test Acc : 0.5291250018775463\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 136 Train Acc : 0.6649999995231628 Test Acc : 0.5291250021755696\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 137 Train Acc : 0.6669999996423721 Test Acc : 0.5307500017061829\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 138 Train Acc : 0.6681999982595443 Test Acc : 0.5310000014305115\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 139 Train Acc : 0.6685999989509582 Test Acc : 0.5293750014901161\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 140 Train Acc : 0.669999999165535 Test Acc : 0.5308750019967556\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Train Acc : 0.6685999995470047 Test Acc : 0.5312500012293458\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 142 Train Acc : 0.6681999999284745 Test Acc : 0.5277500010281801\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 143 Train Acc : 0.6681999996900558 Test Acc : 0.5295000007376075\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 144 Train Acc : 0.6685999997854233 Test Acc : 0.5286250010877848\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 145 Train Acc : 0.6683999991416931 Test Acc : 0.5272500013560056\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 146 Train Acc : 0.6711999998092651 Test Acc : 0.5261250010877848\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 147 Train Acc : 0.6732000007629394 Test Acc : 0.5286250007152558\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 148 Train Acc : 0.6725999997854233 Test Acc : 0.5287500006705522\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 149 Train Acc : 0.6705999995470047 Test Acc : 0.5267500004172325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "current_exp_name = 'A';\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16,which_reg=current_exp_name); \n",
    "l2 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l3 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "\n",
    "l4 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l5 = CNN(3,16,16,which_reg=current_exp_name); \n",
    "l6 = CNN(3,16,10,which_reg=current_exp_name); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "\n",
    "# mean std skew kurt non-zero\n",
    "llayer1 = [[],[],[],[],[]]; llayer2 = [[],[],[],[],[]]; llayer3 = [[],[],[],[],[]]\n",
    "llayer4 = [[],[],[],[],[]]; llayer5 = [[],[],[],[],[]]; llayer6 = [[],[],[],[],[]]\n",
    "\n",
    "llayer1a = [[],[],[],[],[]]; llayer2a = [[],[],[],[],[]]; llayer3a = [[],[],[],[],[]]\n",
    "llayer4a = [[],[],[],[],[]]; llayer5a = [[],[],[],[],[]]; llayer6a = [[],[],[],[],[]]\n",
    "\n",
    "weight1 = [[],[],[],[],[]]; weight2 = [[],[],[],[],[]]; weight3 = [[],[],[],[],[]];\n",
    "weight4 = [[],[],[],[],[]]; weight5 = [[],[],[],[],[]]; weight6 = [[],[],[],[],[]];\n",
    "\n",
    "gradw1  = [[],[],[],[],[]]; gradw2  = [[],[],[],[],[]]; gradw3  = [[],[],[],[],[]];\n",
    "gradw4  = [[],[],[],[],[]]; gradw5  = [[],[],[],[],[]]; gradw6  = [[],[],[],[],[]];\n",
    "\n",
    "gradp1  = [[],[],[],[],[]]; gradp2  = [[],[],[],[],[]]; gradp3  = [[],[],[],[],[]];\n",
    "gradp4  = [[],[],[],[],[]]; gradp5  = [[],[],[],[],[]]; gradp6  = [[],[],[],[],[]];\n",
    "\n",
    "gradup1  = [[],[],[],[],[]]; gradup2  = [[],[],[],[],[]]; gradup3  = [[],[],[],[],[]];\n",
    "gradup4  = [[],[],[],[],[]]; gradup5  = [[],[],[],[],[]]; gradup6  = [[],[],[],[],[]];\n",
    "\n",
    "list_of_outputs = [\n",
    "    layer1,layer2,layer3,layer4,layer5,layer6,\n",
    "    layer1a,layer2a,layer3a,layer4a,layer5a,layer6a,\n",
    "    l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw(),\n",
    "    grad1w,grad2w,grad3w,grad4w,grad5w,grad6w,\n",
    "    grad1p,grad2p,grad3p,grad4p,grad5p,grad6p,\n",
    "    grad1_up[0],grad2_up[0],grad3_up[0],grad4_up[0],grad5_up[0],grad6_up[0]\n",
    "]\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    # Training Accuracy    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # get the results\n",
    "    mid_stat = sess.run(list_of_outputs,feed_dict={x:current_data,y:current_label})\n",
    "    \n",
    "    # Test Accuracy    \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    # ======================== extract stats ========================\n",
    "    llayer1 = append_stat(llayer1,mid_stat,0);  llayer2 = append_stat(llayer2,mid_stat,1);  llayer3 = append_stat(llayer3,mid_stat,2);\n",
    "    llayer4 = append_stat(llayer4,mid_stat,3);  llayer5 = append_stat(llayer5,mid_stat,4);  llayer6 = append_stat(llayer6,mid_stat,5);\n",
    "\n",
    "    llayer1a = append_stat(llayer1a,mid_stat,6);  llayer2a = append_stat(llayer2a,mid_stat,7);  llayer3a = append_stat(llayer3a,mid_stat,8);\n",
    "    llayer4a = append_stat(llayer4a,mid_stat,9);  llayer5a = append_stat(llayer5a,mid_stat,10); llayer6a = append_stat(llayer6a,mid_stat,11);\n",
    "    \n",
    "    weight1 = append_stat(weight1,mid_stat,12);  weight2 = append_stat(weight2,mid_stat,13);  weight3 = append_stat(weight3,mid_stat,14);\n",
    "    weight4 = append_stat(weight4,mid_stat,15);  weight5 = append_stat(weight5,mid_stat,16);  weight6 = append_stat(weight6,mid_stat,17);\n",
    "    \n",
    "    gradw1 = append_stat(gradw1,mid_stat,18); gradw2 = append_stat(gradw2,mid_stat,19); gradw3 = append_stat(gradw3,mid_stat,20);\n",
    "    gradw4 = append_stat(gradw4,mid_stat,21); gradw5 = append_stat(gradw5,mid_stat,22); gradw6 = append_stat(gradw6,mid_stat,23);\n",
    "    \n",
    "    gradp1 = append_stat(gradp1,mid_stat,24); gradp2 = append_stat(gradp2,mid_stat,25); gradp3 = append_stat(gradp3,mid_stat,26);\n",
    "    gradp4 = append_stat(gradp4,mid_stat,27); gradp5 = append_stat(gradp5,mid_stat,28); gradp6 = append_stat(gradp6,mid_stat,29);\n",
    "\n",
    "    gradup1 = append_stat(gradup1,mid_stat,30); gradup2 = append_stat(gradup2,mid_stat,31); gradup3 = append_stat(gradup3,mid_stat,32);\n",
    "    gradup4 = append_stat(gradup4,mid_stat,33); gradup5 = append_stat(gradup5,mid_stat,34); gradup6 = append_stat(gradup6,mid_stat,35);\n",
    "\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    # ======================== extract stats ========================\n",
    "    \n",
    "    # ======================== save to image ========================\n",
    "    save_to_image(mid_stat[0:6]   ,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,\"layer\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[6:12]  ,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a,\"layera\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[12:18] ,weight1,weight2,weight3,weight4,weight5,weight6,\"weights\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[18:24] ,gradw1,gradw2,gradw3,gradw4,gradw5,gradw6,\"gradientw\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[24:30] ,gradp1,gradp2,gradp3,gradp4,gradp5,gradp6,\"gradientp\",train_acc,test_acc,current_exp_name,iter)\n",
    "    save_to_image(mid_stat[30:36] ,gradup1,gradup2,gradup3,gradup4,gradup5,gradup6,\"moment\",train_acc,test_acc,current_exp_name,iter)\n",
    "    # ======================== save to image ========================\n",
    "        \n",
    "    # ======================== print reset ========================\n",
    "    print(\"Current : \"+ str(iter) + \" Train Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    # ======================== print reset ========================\n",
    "\n",
    "np.save(current_exp_name+'/train_acc.npy',train_acc); np.save(current_exp_name+'/test_acc.npy', test_acc)    \n",
    "np.save(current_exp_name+'/llayer1.npy', llayer1);  np.save(current_exp_name+'/llayer2.npy', llayer2);  np.save(current_exp_name+'/llayer3.npy', llayer3); \n",
    "np.save(current_exp_name+'/llayer4.npy', llayer4);  np.save(current_exp_name+'/llayer5.npy', llayer5);  np.save(current_exp_name+'/llayer6.npy', llayer6); \n",
    "\n",
    "np.save(current_exp_name+'/llayer1a.npy', llayer1a);  np.save(current_exp_name+'/llayer2a.npy', llayer2a);  np.save(current_exp_name+'/llayer3a.npy', llayer3a); \n",
    "np.save(current_exp_name+'/llayer4a.npy', llayer4a);  np.save(current_exp_name+'/llayer5a.npy', llayer5a);  np.save(current_exp_name+'/llayer6a.npy', llayer6a); \n",
    "\n",
    "np.save(current_exp_name+'/weight1.npy', weight1);  np.save(current_exp_name+'/weight2.npy', weight2);  np.save(current_exp_name+'/weight3.npy', weight3);  \n",
    "np.save(current_exp_name+'/weight4.npy', weight4);  np.save(current_exp_name+'/weight5.npy', weight5);  np.save(current_exp_name+'/weight6.npy', weight6);  \n",
    "\n",
    "np.save(current_exp_name+'/gradw1.npy', gradw1); np.save(current_exp_name+'/gradw2.npy', gradw2); np.save(current_exp_name+'/gradw3.npy', gradw3);\n",
    "np.save(current_exp_name+'/gradw4.npy', gradw4); np.save(current_exp_name+'/gradw5.npy', gradw5); np.save(current_exp_name+'/gradw6.npy', gradw6);\n",
    "\n",
    "np.save(current_exp_name+'/gradp1.npy', gradp1); np.save(current_exp_name+'/gradp2.npy', gradp2); np.save(current_exp_name+'/gradp3.npy', gradp3);\n",
    "np.save(current_exp_name+'/gradp4.npy', gradp4); np.save(current_exp_name+'/gradp5.npy', gradp5); np.save(current_exp_name+'/gradp6.npy', gradp6);\n",
    "\n",
    "np.save(current_exp_name+'/gradup1.npy', gradup1); np.save(current_exp_name+'/gradup2.npy', gradup2); np.save(current_exp_name+'/gradup3.npy', gradup3);\n",
    "np.save(current_exp_name+'/gradup4.npy', gradup4); np.save(current_exp_name+'/gradup5.npy', gradup5); np.save(current_exp_name+'/gradup6.npy', gradup6);\n",
    "\n",
    "sess.close(); tf.reset_default_graph();\n",
    "\n",
    "%xdel train_acc,test_acc,llayer1,llayer2,llayer3,llayer4,llayer5,llayer6,llayer1a,llayer2a,llayer3a,llayer4a,llayer5a,llayer6a\n",
    "%xdel weight1,weight2,weight3,weight4,weight5,weight6\n",
    "%xdel gradw1,gradw2,gradw3,gradw4,gradw5,gradw6\n",
    "%xdel gradp1,gradp2,gradp3,gradp4,gradp5,gradp6\n",
    "%xdel gradup1,gradup2,gradup3,gradup4,gradup5,gradup6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:20:29.407384Z",
     "start_time": "2018-12-27T09:24:14.573035Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 0 Train Acc : 0.13640000256896018 Test Acc : 0.15525000306777656\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 1 Train Acc : 0.16140000304579735 Test Acc : 0.18450000311248005\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 2 Train Acc : 0.17800000303983687 Test Acc : 0.1927500030491501\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 3 Train Acc : 0.1900000029504299 Test Acc : 0.21975000330246985\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 4 Train Acc : 0.21180000288784503 Test Acc : 0.22387500319629908\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 5 Train Acc : 0.2248000027537346 Test Acc : 0.2497500028181821\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 6 Train Acc : 0.24740000289678574 Test Acc : 0.26612500300630926\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Train Acc : 0.26480000242590906 Test Acc : 0.2808750021457672\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 8 Train Acc : 0.27460000197589396 Test Acc : 0.29175000253133476\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 9 Train Acc : 0.2834000029563904 Test Acc : 0.30037500271573664\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Train Acc : 0.29000000216066835 Test Acc : 0.30500000254251064\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 11 Train Acc : 0.2994000022560358 Test Acc : 0.3070000024791807\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 12 Train Acc : 0.3006000020056963 Test Acc : 0.30987500288523734\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 13 Train Acc : 0.3058000021874905 Test Acc : 0.3117500028386712\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 14 Train Acc : 0.3130000020861626 Test Acc : 0.31387500269338486\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 15 Train Acc : 0.3172000018358231 Test Acc : 0.31850000224076214\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 16 Train Acc : 0.32060000163316726 Test Acc : 0.3226250027585775\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 17 Train Acc : 0.32760000160336494 Test Acc : 0.3236250022146851\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 18 Train Acc : 0.3288000023365021 Test Acc : 0.32875000186264514\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 19 Train Acc : 0.33760000252723693 Test Acc : 0.33412500178441407\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 20 Train Acc : 0.3416000021994114 Test Acc : 0.3391250017192215\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 21 Train Acc : 0.3454000022113323 Test Acc : 0.3442500016372651\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 22 Train Acc : 0.3492000021636486 Test Acc : 0.35337500166147945\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 23 Train Acc : 0.3514000023007393 Test Acc : 0.3555000013671815\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 24 Train Acc : 0.3580000020265579 Test Acc : 0.35987500128336253\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 25 Train Acc : 0.36600000166893004 Test Acc : 0.3638750008866191\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 26 Train Acc : 0.3712000018358231 Test Acc : 0.36800000159069896\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 27 Train Acc : 0.37300000214576723 Test Acc : 0.3715000014565885\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 28 Train Acc : 0.3776000012755394 Test Acc : 0.37350000175647435\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 29 Train Acc : 0.38240000236034394 Test Acc : 0.37812500153668227\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 30 Train Acc : 0.3858000019788742 Test Acc : 0.3806250012759119\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 31 Train Acc : 0.3868000024557114 Test Acc : 0.3842500009573996\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 32 Train Acc : 0.3880000021457672 Test Acc : 0.384125000666827\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 33 Train Acc : 0.3942000023722649 Test Acc : 0.38550000039860605\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 34 Train Acc : 0.39660000199079515 Test Acc : 0.38750000080093744\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 35 Train Acc : 0.3980000017285347 Test Acc : 0.3896250013075769\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 36 Train Acc : 0.4024000016450882 Test Acc : 0.39100000126287343\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 37 Train Acc : 0.40660000091791154 Test Acc : 0.39237500114366414\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 38 Train Acc : 0.40640000069141385 Test Acc : 0.39262500140815976\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 39 Train Acc : 0.410200001001358 Test Acc : 0.39387500178068874\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 40 Train Acc : 0.4144000016450882 Test Acc : 0.3947500018402934\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 41 Train Acc : 0.41540000194311144 Test Acc : 0.3963750021532178\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 42 Train Acc : 0.41560000145435333 Test Acc : 0.4001250023767352\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Train Acc : 0.41680000215768814 Test Acc : 0.40125000236555936\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Train Acc : 0.4234000025391579 Test Acc : 0.4033750020340085\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 45 Train Acc : 0.4250000014305115 Test Acc : 0.4040000019501895\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 46 Train Acc : 0.4288000013232231 Test Acc : 0.40425000167451797\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Train Acc : 0.4294000012874603 Test Acc : 0.40562500099651516\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Train Acc : 0.4342000010609627 Test Acc : 0.4077500011306256\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Train Acc : 0.435000001847744 Test Acc : 0.40800000085495414\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 50 Train Acc : 0.4366000030040741 Test Acc : 0.41087500187568365\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 51 Train Acc : 0.4386000026464462 Test Acc : 0.41212500191293655\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 52 Train Acc : 0.4408000029325485 Test Acc : 0.41250000198371706\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 53 Train Acc : 0.4404000032544136 Test Acc : 0.4155000020284206\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 54 Train Acc : 0.44220000198483467 Test Acc : 0.4143750019092113\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 55 Train Acc : 0.44360000279545786 Test Acc : 0.4165000018570572\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 56 Train Acc : 0.4468000022768974 Test Acc : 0.4161250018980354\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 57 Train Acc : 0.4490000029206276 Test Acc : 0.4170000019762665\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 58 Train Acc : 0.45120000213384626 Test Acc : 0.42012500123120844\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 59 Train Acc : 0.4508000026345253 Test Acc : 0.4208750016335398\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 60 Train Acc : 0.4510000023841858 Test Acc : 0.4218750010523945\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 61 Train Acc : 0.45320000225305557 Test Acc : 0.42262500116601587\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 62 Train Acc : 0.4538000023365021 Test Acc : 0.4251250009052455\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 63 Train Acc : 0.45540000212192533 Test Acc : 0.4261250008828938\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 64 Train Acc : 0.4552000023722649 Test Acc : 0.42600000131875276\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 65 Train Acc : 0.45780000239610674 Test Acc : 0.4282500018551946\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 66 Train Acc : 0.4598000021576881 Test Acc : 0.4297500015050173\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 67 Train Acc : 0.4608000015616417 Test Acc : 0.4320000012218952\n",
      "\n",
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 68 Train Acc : 0.4602000018954277 Test Acc : 0.4315000015497208\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 69 Train Acc : 0.462800002515316 Test Acc : 0.4316250017285347\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 70 Train Acc : 0.463800002515316 Test Acc : 0.43250000186264514\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 71 Train Acc : 0.46480000275373456 Test Acc : 0.4335000016912818\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 72 Train Acc : 0.46620000344514845 Test Acc : 0.43375000189989804\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 73 Train Acc : 0.4668000028729439 Test Acc : 0.4352500012144446\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 74 Train Acc : 0.46860000282526015 Test Acc : 0.436000001616776\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 75 Train Acc : 0.46960000234842303 Test Acc : 0.4352500017732382\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 76 Train Acc : 0.46860000199079516 Test Acc : 0.4368750022724271\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 77 Train Acc : 0.4704000020027161 Test Acc : 0.43612500190734865\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 78 Train Acc : 0.47140000194311144 Test Acc : 0.43687500175088645\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Train Acc : 0.47320000231266024 Test Acc : 0.4368750024214387\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Train Acc : 0.4742000012993813 Test Acc : 0.4353750018775463\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Train Acc : 0.4758000014424324 Test Acc : 0.4373750019073486\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Train Acc : 0.47400000101327894 Test Acc : 0.4370000025629997\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Train Acc : 0.47520000201463697 Test Acc : 0.4372500026971102\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 84 Train Acc : 0.47600000143051147 Test Acc : 0.44012500178068875\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Train Acc : 0.4776000013947487 Test Acc : 0.4401250018179417\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 86 Train Acc : 0.479200001180172 Test Acc : 0.4407500016689301\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 87 Train Acc : 0.4808000014424324 Test Acc : 0.44125000201165676\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 88 Train Acc : 0.48120000088214876 Test Acc : 0.44125000175088647\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 89 Train Acc : 0.4826000011563301 Test Acc : 0.44012500196695326\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 90 Train Acc : 0.4848000014424324 Test Acc : 0.43962500188499687\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 91 Train Acc : 0.483600001335144 Test Acc : 0.43962500177323816\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 92 Train Acc : 0.48640000170469283 Test Acc : 0.4383750017732382\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 93 Train Acc : 0.48680000168085097 Test Acc : 0.44000000137835743\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 94 Train Acc : 0.48520000076293945 Test Acc : 0.4387500014156103\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 95 Train Acc : 0.4866000013947487 Test Acc : 0.43975000120699403\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 96 Train Acc : 0.4874000011086464 Test Acc : 0.4393750013411045\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 97 Train Acc : 0.48680000120401384 Test Acc : 0.44025000106543305\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Train Acc : 0.4886000013947487 Test Acc : 0.44212500091642143\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Train Acc : 0.489200001180172 Test Acc : 0.4418750011175871\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Train Acc : 0.4904000020623207 Test Acc : 0.445375001616776\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Train Acc : 0.494800001680851 Test Acc : 0.44362500101327895\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 102 Train Acc : 0.4922000022232533 Test Acc : 0.4440000013262033\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Train Acc : 0.49480000188946727 Test Acc : 0.4441250005364418\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 104 Train Acc : 0.4954000015556812 Test Acc : 0.4445000008493662\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 105 Train Acc : 0.49740000143647195 Test Acc : 0.4445000012591481\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 106 Train Acc : 0.4948000011742115 Test Acc : 0.44575000159442424\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Train Acc : 0.49540000095963477 Test Acc : 0.44525000132620335\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Train Acc : 0.4972000001966953 Test Acc : 0.44637500170618294\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Train Acc : 0.49960000076889993 Test Acc : 0.4438750012218952\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 110 Train Acc : 0.4988000011742115 Test Acc : 0.44612500131130217\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 111 Train Acc : 0.5005999998152256 Test Acc : 0.4468750013038516\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 112 Train Acc : 0.5026000007688999 Test Acc : 0.44712500121444465\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 113 Train Acc : 0.5038000008165836 Test Acc : 0.4472500007972121\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 114 Train Acc : 0.5056000008136035 Test Acc : 0.4482500011101365\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 115 Train Acc : 0.5046000009328127 Test Acc : 0.4488750014081597\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 116 Train Acc : 0.5068000007420779 Test Acc : 0.4487500011920929\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Train Acc : 0.5082000005990267 Test Acc : 0.44912500139325856\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 118 Train Acc : 0.5088000000268221 Test Acc : 0.45037500109523537\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 119 Train Acc : 0.5118000007420779 Test Acc : 0.45050000116229055\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Train Acc : 0.5098000006228686 Test Acc : 0.44937500152736903\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Train Acc : 0.5118000008612871 Test Acc : 0.45175000112503766\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 122 Train Acc : 0.5122000014334918 Test Acc : 0.45200000155717135\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 123 Train Acc : 0.5124000016003847 Test Acc : 0.44962500128895044\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 124 Train Acc : 0.5134000012427569 Test Acc : 0.45100000146776437\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 125 Train Acc : 0.5150000009089708 Test Acc : 0.45037500131875274\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 126 Train Acc : 0.5132000014334918 Test Acc : 0.4513750007376075\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 127 Train Acc : 0.5150000012665987 Test Acc : 0.45112500060349703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 128 Train Acc : 0.5158000013381243 Test Acc : 0.4517500005289912\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 129 Train Acc : 0.5152000008374452 Test Acc : 0.453500000461936\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 130 Train Acc : 0.5150000012069941 Test Acc : 0.4537500005960464\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 131 Train Acc : 0.5164000016599893 Test Acc : 0.45400000087916853\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 132 Train Acc : 0.5202000006586314 Test Acc : 0.4546250012516975\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 133 Train Acc : 0.5190000013262034 Test Acc : 0.45450000077486036\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 134 Train Acc : 0.5198000016957521 Test Acc : 0.4578750005364418\n",
      "\n",
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 135 Train Acc : 0.5232000011950731 Test Acc : 0.4572500009834766\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 136 Train Acc : 0.5244000011235476 Test Acc : 0.4597500008717179\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 137 Train Acc : 0.525800001218915 Test Acc : 0.4590000005438924\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 138 Train Acc : 0.5258000013381243 Test Acc : 0.45900000028312204\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 139 Train Acc : 0.5276000006943942 Test Acc : 0.4592500006780028\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 140 Train Acc : 0.5278000016957521 Test Acc : 0.4595000006258488\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 141 Train Acc : 0.5292000010758638 Test Acc : 0.4613750007003546\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 142 Train Acc : 0.5322000013142825 Test Acc : 0.4598750005289912\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 143 Train Acc : 0.5342000016719103 Test Acc : 0.4596250005811453\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 144 Train Acc : 0.5346000014096498 Test Acc : 0.45962500050663946\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 145 Train Acc : 0.5368000013381242 Test Acc : 0.4577500008046627\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 146 Train Acc : 0.5376000024825335 Test Acc : 0.45750000040978195\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 147 Train Acc : 0.5374000019580126 Test Acc : 0.4591250006482005\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Train Acc : 0.5370000012665987 Test Acc : 0.4591250013187528\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 149 Train Acc : 0.5374000019133091 Test Acc : 0.45687500085681676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. l1 from M\n",
    "current_exp_name = 'l1_b/'; current_regularizer = 3\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16,which_reg=current_regularizer); \n",
    "l2 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l3 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "\n",
    "l4 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l5 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l6 = CNN(3,16,10,which_reg=current_regularizer); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([layer1,layer2,layer3,layer4,layer5,layer6],feed_dict={x:current_data,y:current_label}),current_exp_name+'layer/')\n",
    "    save_to_image(sess.run([layer1a,layer2a,layer3a,layer4a,layer5a,layer6a],feed_dict={x:current_data,y:current_label}),current_exp_name+'layera/')\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),current_exp_name+'weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Train Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save(current_exp_name+'train.npy',train_acc)\n",
    "np.save(current_exp_name+'test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T10:46:35.861303Z",
     "start_time": "2018-12-27T10:20:29.491067Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Train Acc : 0.13240000261366366 Test Acc : 0.17600000320002437\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Train Acc : 0.16960000324249266 Test Acc : 0.19325000327080488\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 2 Train Acc : 0.18240000335872172 Test Acc : 0.21062500326894223\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 3 Train Acc : 0.20340000374615191 Test Acc : 0.23412500316277146\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 4 Train Acc : 0.22440000316500663 Test Acc : 0.25512500331737104\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 5 Train Acc : 0.24100000357627868 Test Acc : 0.261375003028661\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 6 Train Acc : 0.24660000337660312 Test Acc : 0.26437500294297933\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Train Acc : 0.25220000310242174 Test Acc : 0.26750000324100254\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 8 Train Acc : 0.2588000032454729 Test Acc : 0.2726250030659139\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 9 Train Acc : 0.26320000290870665 Test Acc : 0.27512500310316684\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Train Acc : 0.267000002771616 Test Acc : 0.27950000264681873\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 11 Train Acc : 0.27380000257492065 Test Acc : 0.2835000025201589\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 12 Train Acc : 0.27580000247061254 Test Acc : 0.2881250024680048\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 13 Train Acc : 0.2798000027090311 Test Acc : 0.2876250027026981\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 14 Train Acc : 0.2840000019669533 Test Acc : 0.3031250026170164\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 15 Train Acc : 0.29560000212490556 Test Acc : 0.31075000260025265\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 16 Train Acc : 0.30400000189244747 Test Acc : 0.3211250033415854\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 17 Train Acc : 0.3158000016361475 Test Acc : 0.3298750024288893\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 18 Train Acc : 0.32220000146329403 Test Acc : 0.33587500216439364\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 19 Train Acc : 0.3276000016629696 Test Acc : 0.34125000156462193\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Train Acc : 0.3378000016659498 Test Acc : 0.3481250012014061\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 21 Train Acc : 0.34360000136494634 Test Acc : 0.3518750010896474\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Train Acc : 0.3512000008076429 Test Acc : 0.35225000106729565\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Train Acc : 0.3548000009506941 Test Acc : 0.35737500139512124\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Train Acc : 0.360200001463294 Test Acc : 0.36075000141747293\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Train Acc : 0.3614000009149313 Test Acc : 0.3636250011343509\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Train Acc : 0.3670000008642674 Test Acc : 0.3660000010486692\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 27 Train Acc : 0.3708000016212463 Test Acc : 0.3700000015646219\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Train Acc : 0.37100000175833703 Test Acc : 0.3723750014975667\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 29 Train Acc : 0.37260000202059745 Test Acc : 0.3746250014565885\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 30 Train Acc : 0.3750000014305115 Test Acc : 0.37837500106543304\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Train Acc : 0.3744000015556812 Test Acc : 0.3792500016093254\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Train Acc : 0.37880000096559524 Test Acc : 0.38075000189244745\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Train Acc : 0.3812000006735325 Test Acc : 0.38387500172480943\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Train Acc : 0.3828000010550022 Test Acc : 0.38687500189989804\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Train Acc : 0.3838000009357929 Test Acc : 0.38937500219792126\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Train Acc : 0.3872000009715557 Test Acc : 0.39137500213459137\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Train Acc : 0.3862000009715557 Test Acc : 0.3938750020414591\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Train Acc : 0.3864000006020069 Test Acc : 0.39587500216439364\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Train Acc : 0.3900000005662441 Test Acc : 0.39537500161677597\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 40 Train Acc : 0.39240000081062315 Test Acc : 0.3975000021420419\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 41 Train Acc : 0.3920000014305115 Test Acc : 0.4012500015459955\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 42 Train Acc : 0.3940000016093254 Test Acc : 0.40112500173971055\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 43 Train Acc : 0.3950000019669533 Test Acc : 0.4016250015236437\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 44 Train Acc : 0.3990000014901161 Test Acc : 0.40300000132992864\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Train Acc : 0.3994000009596348 Test Acc : 0.40450000105425715\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Train Acc : 0.4026000007390976 Test Acc : 0.40700000124052166\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 47 Train Acc : 0.4048000010848045 Test Acc : 0.40775000100955366\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 48 Train Acc : 0.4090000012218952 Test Acc : 0.41025000119581817\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 49 Train Acc : 0.4114000024497509 Test Acc : 0.41162500167265537\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 50 Train Acc : 0.41240000212192535 Test Acc : 0.4102500011585653\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Train Acc : 0.41400000274181364 Test Acc : 0.4117500009201467\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Train Acc : 0.4170000025033951 Test Acc : 0.41312500132247804\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 53 Train Acc : 0.41720000302791593 Test Acc : 0.41400000104680656\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 54 Train Acc : 0.42120000314712525 Test Acc : 0.41350000103935597\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Train Acc : 0.423400003015995 Test Acc : 0.41462500097230076\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 56 Train Acc : 0.42580000299215315 Test Acc : 0.4163750006817281\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 57 Train Acc : 0.4286000031232834 Test Acc : 0.41750000094994905\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 58 Train Acc : 0.4316000024676323 Test Acc : 0.41962500058114527\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 59 Train Acc : 0.4330000030398369 Test Acc : 0.41875000078231095\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 60 Train Acc : 0.4362000029683113 Test Acc : 0.41787500102072955\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Train Acc : 0.43680000251531603 Test Acc : 0.4207500013336539\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Train Acc : 0.43540000247955324 Test Acc : 0.4195000011846423\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 63 Train Acc : 0.4386000021696091 Test Acc : 0.4198750011250377\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 64 Train Acc : 0.44040000116825107 Test Acc : 0.4197500012069941\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 65 Train Acc : 0.4434000015258789 Test Acc : 0.421750001385808\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 66 Train Acc : 0.4456000010967255 Test Acc : 0.42412500131875275\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Train Acc : 0.4466000009179115 Test Acc : 0.42537500120699406\n",
      "\n",
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 68 Train Acc : 0.4474000015258789 Test Acc : 0.42600000105798247\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Train Acc : 0.449800001680851 Test Acc : 0.42750000115484\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Train Acc : 0.45180000126361847 Test Acc : 0.4277500005438924\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Train Acc : 0.4542000013589859 Test Acc : 0.4296250008046627\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Train Acc : 0.45620000129938126 Test Acc : 0.43112500090152023\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Train Acc : 0.45860000151395797 Test Acc : 0.4327500007301569\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 74 Train Acc : 0.4596000012755394 Test Acc : 0.4346250009536743\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Train Acc : 0.46120000070333483 Test Acc : 0.4342500016093254\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Train Acc : 0.46180000066757204 Test Acc : 0.4352500018849969\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 77 Train Acc : 0.46340000092983247 Test Acc : 0.43587500162422654\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 78 Train Acc : 0.46520000040531156 Test Acc : 0.43637500148266556\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 79 Train Acc : 0.4662000006437302 Test Acc : 0.4377500012889504\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 80 Train Acc : 0.467200000166893 Test Acc : 0.43812500149011613\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 81 Train Acc : 0.46800000035762784 Test Acc : 0.4400000012665987\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 82 Train Acc : 0.46960000056028367 Test Acc : 0.44087500151246783\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 83 Train Acc : 0.46940000063180926 Test Acc : 0.4417500016838312\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 84 Train Acc : 0.46920000010728835 Test Acc : 0.44275000136345627\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 85 Train Acc : 0.47300000017881394 Test Acc : 0.4427500017732382\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 86 Train Acc : 0.47419999963045123 Test Acc : 0.44437500145286324\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 87 Train Acc : 0.4758000003695488 Test Acc : 0.44625000074505805\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 88 Train Acc : 0.4748000001311302 Test Acc : 0.4481250004842877\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 89 Train Acc : 0.47960000109672546 Test Acc : 0.448500000834465\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 90 Train Acc : 0.4816000007390976 Test Acc : 0.44837500058114527\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 91 Train Acc : 0.4830000005960465 Test Acc : 0.4498750007152557\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 92 Train Acc : 0.4815999997854233 Test Acc : 0.4500000002607703\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 93 Train Acc : 0.48340000021457674 Test Acc : 0.4495000001788139\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 94 Train Acc : 0.4842000004053116 Test Acc : 0.4507500001043081\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 95 Train Acc : 0.4838000003695488 Test Acc : 0.4511250001937151\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 96 Train Acc : 0.4846000004410744 Test Acc : 0.4513750000298023\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 97 Train Acc : 0.4860000005364418 Test Acc : 0.45087499979883433\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 98 Train Acc : 0.48660000067949294 Test Acc : 0.45200000032782556\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 99 Train Acc : 0.48820000094175336 Test Acc : 0.4530000006407499\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 100 Train Acc : 0.49080000096559523 Test Acc : 0.45287500075995923\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 101 Train Acc : 0.49140000075101853 Test Acc : 0.45437500067055225\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Train Acc : 0.49320000094175337 Test Acc : 0.4540000005811453\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 103 Train Acc : 0.49420000141859055 Test Acc : 0.4556250002980232\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 104 Train Acc : 0.49580000108480454 Test Acc : 0.45537499990314245\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Train Acc : 0.49680000072717667 Test Acc : 0.4562500002980232\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 106 Train Acc : 0.497800000846386 Test Acc : 0.4578750003129244\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 107 Train Acc : 0.4990000013113022 Test Acc : 0.4580000004544854\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 108 Train Acc : 0.5004000011086464 Test Acc : 0.4607500001043081\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 109 Train Acc : 0.49940000158548353 Test Acc : 0.4590000005438924\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 110 Train Acc : 0.5028000013232231 Test Acc : 0.4591250002756715\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 111 Train Acc : 0.5020000017285347 Test Acc : 0.4598750002682209\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 112 Train Acc : 0.5050000014901161 Test Acc : 0.4610000003129244\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Train Acc : 0.5038000015616417 Test Acc : 0.4587499999254942\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Train Acc : 0.5042000022530556 Test Acc : 0.45987499978393315\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Train Acc : 0.5052000025510788 Test Acc : 0.4593750001117587\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Train Acc : 0.5074000025987625 Test Acc : 0.4622500000149012\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Train Acc : 0.50800000166893 Test Acc : 0.46075000006705524\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Train Acc : 0.5094000020027161 Test Acc : 0.46062500040978194\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Train Acc : 0.5096000027656555 Test Acc : 0.4610000002384186\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 120 Train Acc : 0.5100000026226044 Test Acc : 0.46100000038743016\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Train Acc : 0.5104000030755996 Test Acc : 0.46137500043958424\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Train Acc : 0.5124000028371811 Test Acc : 0.46112500078976154\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Train Acc : 0.5152000020742417 Test Acc : 0.4628750005364418\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Train Acc : 0.5160000020861626 Test Acc : 0.46262500062584877\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Train Acc : 0.5154000026583672 Test Acc : 0.46375000055879356\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Train Acc : 0.5168000026345253 Test Acc : 0.46287500016391275\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Train Acc : 0.5184000024199485 Test Acc : 0.463375000692904\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Train Acc : 0.5190000024437904 Test Acc : 0.46425000052899124\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Train Acc : 0.5180000025629997 Test Acc : 0.46337500046938657\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Train Acc : 0.5194000025391579 Test Acc : 0.4643750004097819\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Train Acc : 0.5222000029683113 Test Acc : 0.46462500020861625\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Train Acc : 0.5202000024914741 Test Acc : 0.46537500016391276\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Train Acc : 0.5222000022530555 Test Acc : 0.46500000018626453\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 134 Train Acc : 0.5234000019431114 Test Acc : 0.4662500002980232\n",
      "\n",
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Train Acc : 0.5224000014662743 Test Acc : 0.4660000003501773\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Train Acc : 0.5250000017285347 Test Acc : 0.46650000020861626\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 137 Train Acc : 0.5252000024914741 Test Acc : 0.46699999991804364\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Train Acc : 0.5260000023841858 Test Acc : 0.46712499991059303\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 139 Train Acc : 0.5248000030517578 Test Acc : 0.46712500002235174\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Train Acc : 0.5254000023603439 Test Acc : 0.46587500028312206\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Train Acc : 0.5276000024080276 Test Acc : 0.4661250003427267\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 142 Train Acc : 0.5288000028133393 Test Acc : 0.4657499999925494\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 143 Train Acc : 0.5308000024557114 Test Acc : 0.4685000006482005\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 144 Train Acc : 0.5304000029563903 Test Acc : 0.46712500013411046\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 145 Train Acc : 0.5324000024795532 Test Acc : 0.4683750005066395\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 146 Train Acc : 0.532200002193451 Test Acc : 0.46750000059604646\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 147 Train Acc : 0.5350000022649765 Test Acc : 0.4682500002905726\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Train Acc : 0.5332000027894974 Test Acc : 0.4682500006631017\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 149 Train Acc : 0.5350000028610229 Test Acc : 0.4681250001862645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. l2 from M\n",
    "current_exp_name = 'l2_b/'; current_regularizer = 4\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16,which_reg=current_regularizer); \n",
    "l2 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l3 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "\n",
    "l4 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l5 = CNN(3,16,16,which_reg=current_regularizer); \n",
    "l6 = CNN(3,16,10,which_reg=current_regularizer); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([layer1,layer2,layer3,layer4,layer5,layer6],feed_dict={x:current_data,y:current_label}),current_exp_name+'layer/')\n",
    "    save_to_image(sess.run([layer1a,layer2a,layer3a,layer4a,layer5a,layer6a],feed_dict={x:current_data,y:current_label}),current_exp_name+'layera/')\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),current_exp_name+'weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),current_exp_name+'gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Train Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save(current_exp_name+'train.npy',train_acc)\n",
    "np.save(current_exp_name+'test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
