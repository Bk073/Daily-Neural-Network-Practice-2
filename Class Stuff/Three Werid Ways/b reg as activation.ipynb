{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T05:37:57.889841Z",
     "start_time": "2019-02-03T05:37:55.451364Z"
    },
    "code_folding": [
     33,
     60,
     68,
     75
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "# %load_ext jupyternotify\n",
    "\n",
    "# read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "def send_notification_email(letter,episode):\n",
    "    import smtplib, ssl\n",
    "\n",
    "    port = 587  # For starttls\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    sender_email = \"sendresultsforme@gmail.com\"\n",
    "    receiver_email = \"jae.duk.seo@gmail.com\"\n",
    "    password = \"Password123*\"\n",
    "    message = \"Subject: \" + str(letter) + \" : \"+str(episode)+\" is done!\"\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "    with smtplib.SMTP(smtp_server, port) as server:\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.starttls(context=context)\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(sender_email, receiver_email, message)\n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T05:58:52.549987Z",
     "start_time": "2019-02-03T05:58:52.505823Z"
    },
    "code_folding": [
     9,
     16,
     101
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers and the needed functions\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "def d_tf_iden(x): return tf.ones_like(x)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg='A',act=tf_iden,d_act=d_tf_iden):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.current_case   = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input,stride=1,padding='SAME',training_phase=True,std_value=0.0005):\n",
    "        self.input  = input\n",
    "        \n",
    "        if self.current_case == 'B':\n",
    "            def training_fn():  return tf.nn.dropout(tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding),0.8)\n",
    "            def  testing_fn():  return tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "            self.layer  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "            \n",
    "        elif self.current_case == 'E':\n",
    "            def training_fn():  return tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "            def  testing_fn():\n",
    "                sampled_weight = tf.squeeze(tf.distributions.Normal(loc=self.w, scale=std_value).sample(1))\n",
    "                return tf.nn.conv2d(input,sampled_weight,strides=[1,stride,stride,1],padding=padding) \n",
    "            self.layer  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "            \n",
    "        else: self.layer = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,std_value,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        if self.current_case == 'D' or self.current_case == 'E': grad = tf.squeeze(tf.distributions.Normal(loc=grad, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        \n",
    "        if self.current_case == 'C' or self.current_case == 'D' or self.current_case == 'E': adam_middle = tf.squeeze(tf.distributions.Normal(loc=adam_middle, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "\n",
    "class RELU_as_Reg():\n",
    "    \n",
    "    def __init__(self,batch,width,channel,regularizer):\n",
    "#         self.w = tf.Variable(tf.random_uniform([batch,width,width,channel],minval=0.0,maxval=1.0))\n",
    "        self.w = tf.Variable(tf.ones_like([batch,width,width,channel],tf.float32) )\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.regularizer = regularizer\n",
    "        self.lamda = 0.00001\n",
    "    \n",
    "    def feedforward(self,input):\n",
    "        self.input  = input\n",
    "        self.layerA = self.w * input\n",
    "        return self.layerA\n",
    "    \n",
    "    def backprop(self,gradient):\n",
    "        grad = gradient * self.input\n",
    "        gradient_p = self.w * gradient\n",
    "        \n",
    "        # add reg here\n",
    "        if self.regularizer == 'A': grad = grad + self.lamda * tf.sign(self.w)\n",
    "        if self.regularizer == 'B': grad = grad + self.lamda * 2.0 * self.w\n",
    "        if self.regularizer == 'C': grad = grad + self.lamda * (1.0/tf.sqrt(tf.square(self.w)+ 1e-5)) * self.w\n",
    "        if self.regularizer == 'D': grad = grad + self.lamda * -(2*self.w)/(1 + self.w**2)\n",
    "        if self.regularizer == 'E': grad = grad + self.lamda * -(1-tf.tanh(self.w) ** 2)\n",
    "        if self.regularizer == 'F': grad = grad + self.lamda * -(1-tf.tanh(self.w** 2) ** 2) * 2.0 * self.w \n",
    "        if self.regularizer == 'G': grad = grad + self.lamda * -(1-tf.tanh(tf.abs(self.w)) ** 2) * tf.sign(self.w)\n",
    "        if self.regularizer == 'H': grad = grad + self.lamda * -(1-tf.tanh(tf.abs(self.w)** 2) ** 2) * 2.0 * tf.abs(self.w) *  tf.sign(self.w)\n",
    "        if self.regularizer == 'I': grad = grad + self.lamda * tf.cos(self.w)\n",
    "        if self.regularizer == 'J': grad = grad + self.lamda * tf.sign(tf.sin(self.w)) * tf.cos(self.w)\n",
    "        if self.regularizer == 'K': grad = grad + self.lamda * (2)/(self.w + 1e-5)\n",
    "        if self.regularizer == 'L': grad = grad + self.lamda * (tf.log(self.w**2) + 2.0)\n",
    "        # add reg here\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        \n",
    "        gradient_temp = tf.clip_by_value(self.w - adam_middle,clip_value_min=0.0,clip_value_max=1.0)\n",
    "        update_w.append(self.w.assign(gradient_temp))\n",
    "        \n",
    "        return gradient_p,update_w\n",
    "\n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T05:58:53.052362Z",
     "start_time": "2019-02-03T05:58:53.048381Z"
    }
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "num_eps   = 2; num_epoch = 50; learning_rate = 0.0008; batch_size = 20; \n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-9; \n",
    "print_iter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T05:58:53.835409Z",
     "start_time": "2019-02-03T05:58:53.530084Z"
    },
    "code_folding": [
     13,
     89,
     101,
     115
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ================================================\n",
      "                    Starting Episode: 0 for B\n",
      "        ================================================\n",
      "\n",
      "        "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 4 and 16 for 'mul_421' (op: 'Mul') with input shapes: [4], [20,48,48,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 4 and 16 for 'mul_421' (op: 'Mul') with input shapes: [4], [20,48,48,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-88f5fb187fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mlayer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer1a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mlayer1ar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_act\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1ar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_phase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mlayer2ar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2_act\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer2a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-c5712d2e9f7a>\u001b[0m in \u001b[0;36mfeedforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayerA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayerA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[1;34m(a, *args)\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AsTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m     \u001b[1;31m# Propagate __doc__ to wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   5040\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5041\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 5042\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   5043\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5044\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 4 and 16 for 'mul_421' (op: 'Mul') with input shapes: [4], [20,48,48,16]."
     ]
    }
   ],
   "source": [
    "# no batch\n",
    "current_batch_norm_type = 'act_as_reg'\n",
    "all_the_exp = ['B','C','D','E','F','G','H','I','J','K','L']\n",
    "\n",
    "for letter in all_the_exp:\n",
    "    current_exp_name = letter\n",
    "    sess = tf.InteractiveSession()\n",
    "    current_exp_train_accuracy = np.zeros((num_eps,num_epoch))\n",
    "    current_exp_test_accuracy  = np.zeros((num_eps,num_epoch))\n",
    "    MAX_STD_VALUE = 0.0005\n",
    "\n",
    "    for episode in range(num_eps):\n",
    "        sys.stdout.write(\"\"\"\n",
    "        ================================================\n",
    "                    Starting Episode: \"\"\" + str(episode) + \" for \" + str(letter) + \"\"\"\n",
    "        ================================================\\n\n",
    "        \"\"\");sys.stdout.flush();\n",
    "\n",
    "        # create layers\n",
    "        l1 = CNN(3,3, 16,which_reg='A'); \n",
    "        l1_act = RELU_as_Reg(batch_size,48,16,regularizer=letter)\n",
    "        l2 = CNN(3,16,16,which_reg='A'); \n",
    "        l2_act = RELU_as_Reg(batch_size,24,16,regularizer=letter)\n",
    "        l3 = CNN(3,16,16,which_reg='A'); \n",
    "        l3_act = RELU_as_Reg(batch_size,12,16,regularizer=letter)\n",
    "        l4 = CNN(3,16,16,which_reg='A'); \n",
    "        l4_act = RELU_as_Reg(batch_size,6 ,16,regularizer=letter)\n",
    "        l5 = CNN(3,16,16,which_reg='A'); \n",
    "        l5_act = RELU_as_Reg(batch_size,6 ,16,regularizer=letter)\n",
    "        l6 = CNN(3,16,10,which_reg='A'); \n",
    "\n",
    "        # 2. graph \n",
    "        x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "        y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "        is_train  = tf.placeholder_with_default(True,())\n",
    "        std_value = tf.placeholder(tf.float32)\n",
    "\n",
    "        layer1, layer1a = l1. feedforward(x,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer1ar = l1_act.feedforward(layer1a)\n",
    "        layer2, layer2a = l2. feedforward(layer1ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer2ar = l2_act.feedforward(layer2a)\n",
    "        layer3, layer3a = l3. feedforward(layer2ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer3ar = l3_act.feedforward(layer3a)\n",
    "        layer4, layer4a = l4. feedforward(layer3ar,stride=2,training_phase=is_train,std_value=std_value)\n",
    "        layer4ar = l4_act.feedforward(layer4a)\n",
    "        layer5, layer5a = l5. feedforward(layer4ar,training_phase=is_train,std_value=std_value)\n",
    "        layer5ar = l5_act.feedforward(layer5a)\n",
    "        layer6, layer6a = l6. feedforward(layer5ar,training_phase=is_train,std_value=std_value)\n",
    "        \n",
    "        final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "        final_softmax = tf_softmax(final_layer)\n",
    "        cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "        correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "        accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "        grad6p,grad6w,grad6_up = l6.backprop(gradient,std_value=std_value)\n",
    "        \n",
    "        grad5ap,grad5ap_up     = l5_act.backprop(grad6p)\n",
    "        grad5p,grad5w,grad5_up = l5.backprop(grad5ap,std_value=std_value)\n",
    "        \n",
    "        grad4ap,grad4ap_up     = l4_act.backprop(grad5p)\n",
    "        grad4p,grad4w,grad4_up = l4.backprop(grad4ap,stride=2,std_value=std_value)\n",
    "        \n",
    "        grad3ap,grad3ap_up     = l3_act.backprop(grad4p)\n",
    "        grad3p,grad3w,grad3_up = l3.backprop(grad3ap,stride=2,std_value=std_value)\n",
    "\n",
    "        grad2ap,grad2ap_up     = l2_act.backprop(grad3p)\n",
    "        grad2p,grad2w,grad2_up = l2.backprop(grad2ap,stride=2,std_value=std_value)\n",
    "\n",
    "        grad1ap,grad1ap_up     = l1_act.backprop(grad2p)\n",
    "        grad1p,grad1w,grad1_up = l1.backprop(grad1ap,stride=2,std_value=std_value)\n",
    "\n",
    "        gradient_update = grad6_up + \\\n",
    "                          grad5ap_up + grad5_up + \\\n",
    "                          grad4ap_up + grad4_up + \\\n",
    "                          grad3ap_up + grad3_up + \\\n",
    "                          grad2ap_up + grad2_up + \\\n",
    "                          grad1ap_up + grad1_up \n",
    "\n",
    "        # train\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []\n",
    "\n",
    "        for iter in range(num_epoch):\n",
    "\n",
    "            current_std_value = MAX_STD_VALUE\n",
    "\n",
    "            # Training Accuracy    \n",
    "            for current_batch_index in range(0,len(train_images),batch_size):\n",
    "                current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label,std_value:current_std_value})\n",
    "                sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                                 '\\tbatch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                                 '\\tacc : ' + str(sess_results[0]) +\n",
    "                                 '\\tstd  : ' + str(current_std_value) +\n",
    "                                 '\\r')\n",
    "                sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "\n",
    "            # Test Accuracy    \n",
    "            for current_batch_index in range(0,len(test_images), batch_size):\n",
    "                current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "                sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False,std_value:current_std_value})\n",
    "                sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                                 '\\tbatch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                                 '\\tacc : ' + str(sess_results[0]) + \n",
    "                                 '\\tstd  : ' + str(current_std_value) +\n",
    "                                 '\\r')\n",
    "                sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "\n",
    "            # ======================== print reset ========================\n",
    "            train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "            test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "            if iter%print_iter == 0 or iter==num_epoch-1 :\n",
    "                sys.stdout.write(\"Current : \"+ str(iter) + \"\\t\" +\n",
    "                      \" Train Acc : \" + str(np.around(avg_acc_train/(len(train_images)/batch_size),3)) + \"\\t\" +\n",
    "                      \" Test Acc : \"  + str(np.around(avg_acc_test/(len(test_images)/batch_size),3)) +  \"\\t\" +\n",
    "                      \" STD : \"  + str(current_std_value) + \n",
    "                      \"\\t\\n\")\n",
    "                sys.stdout.flush();\n",
    "            avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "            # ======================== print reset ========================\n",
    "            \n",
    "        # save the file\n",
    "        current_exp_train_accuracy[episode,:] = train_acc\n",
    "        current_exp_test_accuracy [episode,:] = test_acc\n",
    "        send_notification_email(letter,episode)\n",
    "\n",
    "    # close the session and save\n",
    "    sess.close()\n",
    "    # save to the file\n",
    "    np.save(str(current_batch_norm_type)+'/'+str(letter)+'/train.npy', current_exp_train_accuracy)\n",
    "    np.save(str(current_batch_norm_type)+'/'+str(letter)+'/test.npy', current_exp_test_accuracy)\n",
    "    print(current_exp_train_accuracy.shape,current_exp_train_accuracy.mean())\n",
    "    print(current_exp_test_accuracy.shape,current_exp_test_accuracy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
