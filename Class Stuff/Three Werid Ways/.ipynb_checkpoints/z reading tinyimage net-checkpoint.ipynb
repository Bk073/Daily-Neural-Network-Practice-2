{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:29:07.212187Z",
     "start_time": "2019-02-01T20:28:52.703276Z"
    }
   },
   "outputs": [],
   "source": [
    "#  import lib\n",
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:29:07.224362Z",
     "start_time": "2019-02-01T20:29:07.220570Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading \n",
    "BATCH_SIZE = 20\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "TRAINING_IMAGES_DIR = './tiny-imagenet-200/train/'\n",
    "TRAIN_SIZE = NUM_IMAGES\n",
    "\n",
    "NUM_VAL_IMAGES = 10000\n",
    "VAL_IMAGES_DIR = './tiny-imagenet-200/val/'\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_ARR_SIZE = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n",
    "IMAGES_URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:29:40.159595Z",
     "start_time": "2019-02-01T20:29:40.146630Z"
    },
    "code_folding": [
     0,
     33,
     39
    ]
   },
   "outputs": [],
   "source": [
    "# needed functions\n",
    "def load_training_images(image_dir, batch_size=500):\n",
    "\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(NUM_IMAGES, IMAGE_ARR_SIZE))\n",
    "    names = []\n",
    "    labels = []                       \n",
    "    \n",
    "    # Loop through all the types directories\n",
    "    for type in os.listdir(image_dir):\n",
    "        if os.path.isdir(image_dir + type + '/images/'):\n",
    "            type_images = os.listdir(image_dir + type + '/images/')\n",
    "            # Loop through all the images of a type directory\n",
    "            batch_index = 0;\n",
    "            #print (\"Loading Class \", type)\n",
    "            for image in type_images:\n",
    "                image_file = os.path.join(image_dir, type + '/images/', image)\n",
    "\n",
    "                # reading the images as they are; no normalization, no color editing\n",
    "                image_data = mpimg.imread(image_file) \n",
    "                #print ('Loaded Image', image_file, image_data.shape)\n",
    "                if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "                    images[image_index, :] = image_data.flatten()\n",
    "\n",
    "                    labels.append(type)\n",
    "                    names.append(image)\n",
    "                    \n",
    "                    image_index += 1\n",
    "                    batch_index += 1\n",
    "                if (batch_index >= batch_size):\n",
    "                    break;\n",
    "                    \n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "def get_label_from_name(data, name):\n",
    "    for idx, row in data.iterrows():       \n",
    "        if (row['File'] == name):\n",
    "            return row['Class']\n",
    "        \n",
    "    return None\n",
    "def load_validation_images(testdir, validation_data, batch_size=NUM_VAL_IMAGES):\n",
    "    labels = []\n",
    "    names = []\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(batch_size, IMAGE_ARR_SIZE))\n",
    "    val_images = os.listdir(testdir + '/images/')\n",
    "           \n",
    "    # Loop through all the images of a val directory\n",
    "    batch_index = 0;\n",
    "    \n",
    "    \n",
    "    for image in val_images:\n",
    "        image_file = os.path.join(testdir, 'images/', image)\n",
    "        #print (testdir, image_file)\n",
    "\n",
    "        # reading the images as they are; no normalization, no color editing\n",
    "        image_data = mpimg.imread(image_file) \n",
    "        if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "            images[image_index, :] = image_data.flatten()\n",
    "            image_index += 1\n",
    "            labels.append(get_label_from_name(validation_data, image))\n",
    "            names.append(image)\n",
    "            batch_index += 1\n",
    "            \n",
    "        if (batch_index >= batch_size):\n",
    "            break;\n",
    "    \n",
    "    print (\"Loaded Validation images \", image_index)\n",
    "    return (images, np.asarray(labels), np.asarray(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:31:05.262930Z",
     "start_time": "2019-02-01T20:30:44.101654Z"
    }
   },
   "outputs": [],
   "source": [
    "# one example load\n",
    "BATCH_SIZE = 20\n",
    "TRAINING_IMAGES_DIR = '../../Dataset/tiny-imagenet-200/train/'\n",
    "training_images, training_labels, training_files = load_training_images(TRAINING_IMAGES_DIR, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:32:23.217589Z",
     "start_time": "2019-02-01T20:32:23.211587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 64, 3)\n",
      "(4000,)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "training_images = training_images.reshape((-1,64,64,3))\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(training_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:33:48.711915Z",
     "start_time": "2019-02-01T20:33:48.704372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 Training Labels [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "training_le = le.fit(training_labels)\n",
    "training_labels_encoded = training_le.transform(training_labels)\n",
    "print (\"First 30 Training Labels\", training_labels_encoded[0:30])\n",
    "\n",
    "numberssss = 0\n",
    "print(training_labels_encoded[numberssss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T19:28:59.996855Z",
     "start_time": "2019-02-01T19:28:59.646004Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T20:29:48.791401Z",
     "start_time": "2019-02-01T20:29:43.507550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 46e606050] s\n",
      " 2 files changed, 230 insertions(+), 20 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Class Stuff/Three Werid Ways/.ipynb_checkpoints/z reading tinyimage net-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Class Stuff/Three Werid Ways/z reading tinyimage net.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "To https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2\n",
      "   a31cfc2aa..46e606050  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git all-go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Python3, S., Jungi, K., Shapovalov, R., Stuart, V., Coutinho, T., & ALBARÃˆDE, P. et al. (2013). StringIO in Python3. Stack Overflow. Retrieved 1 February 2019, from https://stackoverflow.com/questions/11914472/stringio-in-python3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
