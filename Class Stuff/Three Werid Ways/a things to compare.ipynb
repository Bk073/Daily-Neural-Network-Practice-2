{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T06:50:48.908734Z",
     "start_time": "2019-02-02T06:50:42.834007Z"
    },
    "code_folding": [
     0,
     33,
     60,
     68
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     53,
     92,
     106,
     113,
     116,
     189,
     228,
     263,
     297
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers and the needed functions\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.regularizer    = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "    \n",
    "    def feedforward(self,input,stride=1,padding='SAME',training_phase=True,std_value=std_value):\n",
    "        self.input  = input\n",
    "        \n",
    "        # Training      \n",
    "        def training_fn(): \n",
    "            return tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        \n",
    "        # Testing       \n",
    "        def  testing_fn():\n",
    "            sampled_weight = tf.squeeze(tf.distributions.Normal(loc=self.w, scale=std_value).sample(1))\n",
    "            return tf.nn.conv2d(input,sampled_weight,strides=[1,stride,stride,1],padding=padding) \n",
    "        \n",
    "        self.layer  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,std_value,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        # grad_sampled = tf.squeeze(tf.distributions.Normal(loc=grad, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        \n",
    "        # adam_resampled = tf.squeeze(tf.distributions.Normal(loc=adam_middle, scale=std_value).sample(1))\n",
    "        \n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     \n",
    "def append_stat(current_list,data,number):\n",
    "    current_list[0].append(data[number].mean())\n",
    "    current_list[1].append(data[number].std())\n",
    "    current_list[2].append(skew    (data[number].ravel()))\n",
    "    current_list[3].append(kurtosis(data[number].ravel()))\n",
    "    current_list[4].append(np.count_nonzero(data[number]))\n",
    "    return current_list\n",
    "def transform_to_2d(data):\n",
    "    batch,width,height,chan = data.shape\n",
    "    return data.reshape((batch*width,height*chan))\n",
    "def save_to_image(main_data,one,two,three,four,five,six,experiment_name,tran_acc,test_acc,current_exp,iter):\n",
    "    plt.figure(figsize=(20,40))\n",
    "    G = gridspec.GridSpec(8, 6)\n",
    "\n",
    "    plt.figtext(0.5,1.0,\"Iter: \" + str(iter) + \" Histogram Per \" + experiment_name,ha=\"center\", va=\"top\", fontsize=35, color=\"black\")\n",
    "    plt.subplot(G[0, 0]).hist(main_data[0].ravel(),50,color='red');       plt.subplot(G[0, 0]).set_title(experiment_name+' 1')\n",
    "    plt.subplot(G[0, 1]).hist(main_data[1].ravel(),50,color='orange');    plt.subplot(G[0, 1]).set_title(experiment_name+' 2')\n",
    "    plt.subplot(G[0, 2]).hist(main_data[2].ravel(),50,color='yellow');  plt.subplot(G[0, 2]).set_title(experiment_name+' 3')\n",
    "    plt.subplot(G[0, 3]).hist(main_data[3].ravel(),50,color='green');    plt.subplot(G[0, 3]).set_title(experiment_name+' 4')\n",
    "    plt.subplot(G[0, 4]).hist(main_data[4].ravel(),50,color='blue');     plt.subplot(G[0, 4]).set_title(experiment_name+' 5')\n",
    "    plt.subplot(G[0, 5]).hist(main_data[5].ravel(),50,color='black');     plt.subplot(G[0, 5]).set_title(experiment_name+' 6')\n",
    "\n",
    "    plt.subplot(G[1, :]).set_title(\"Mean Per \"+ experiment_name)\n",
    "    plt.subplot(G[1, :]).plot(one[0]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[1, :]).plot(two[0]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[1, :]).plot(three[0],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[1, :]).plot(four[0],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[1, :]).plot(five[0],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[1, :]).plot(six[0],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[2, :]).set_title(\"Standard Deviation Per \"+ experiment_name)\n",
    "    plt.subplot(G[2, :]).plot(one[1]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[2, :]).plot(two[1]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[2, :]).plot(three[1],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[2, :]).plot(four[1],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[2, :]).plot(five[1],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[2, :]).plot(six[1],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[3, :]).set_title(\"Skewness Per \"+ experiment_name)\n",
    "    plt.subplot(G[3, :]).plot(one[2]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[3, :]).plot(two[2]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[3, :]).plot(three[2],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[3, :]).plot(four[2],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[3, :]).plot(five[2],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[3, :]).plot(six[2],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[4, :]).set_title(\"Kurtosis Per \"+ experiment_name)\n",
    "    plt.subplot(G[4, :]).plot(one[3]  ,c='red',alpha=0.9,label='1')\n",
    "    plt.subplot(G[4, :]).plot(two[3]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[4, :]).plot(three[3],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[4, :]).plot(four[3],c='green',alpha=0.9,label='4')\n",
    "    plt.subplot(G[4, :]).plot(five[3],c='blue',alpha=0.9,label='5')\n",
    "    plt.subplot(G[4, :]).plot(six[3],c='black',alpha=0.9,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[5, :]).set_title(\"# Non-Zero Per \"+ experiment_name)\n",
    "    plt.subplot(G[5, :]).plot(one[4]  ,c='red',alpha=0.9   ,label='1')\n",
    "    plt.subplot(G[5, :]).plot(two[4]  ,c='orange',alpha=0.9,label='2')\n",
    "    plt.subplot(G[5, :]).plot(three[4],c='yellow',alpha=0.9,label='3')\n",
    "    plt.subplot(G[5, :]).plot(four[4],c='green',alpha=0.9  ,label='4')\n",
    "    plt.subplot(G[5, :]).plot(five[4],c='blue',alpha=0.9   ,label='5')\n",
    "    plt.subplot(G[5, :]).plot(six[4],c='black',alpha=0.9   ,label='6')\n",
    "    plt.legend(bbox_to_anchor=(0., 0.95, 1., .05), loc=9,ncol=6, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "    plt.subplot(G[6, :]).set_title(\"Train/Test accuracy\")\n",
    "    plt.subplot(G[6, :]).plot(train_acc  ,c='red',alpha=0.9, label='Train')\n",
    "    plt.subplot(G[6, :]).plot(test_acc   ,c='blue',alpha=0.9,label='Test')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figtext(0.5,0,\"Correlation Matrix Per \"+ experiment_name,ha=\"center\", va=\"bottom\", fontsize=30, color=\"black\")\n",
    "    plt.subplot(G[7, 0]).imshow(np.corrcoef(transform_to_2d(main_data[0])),cmap='gray')\n",
    "    plt.subplot(G[7, 1]).imshow(np.corrcoef(transform_to_2d(main_data[1])),cmap='gray')\n",
    "    plt.subplot(G[7, 2]).imshow(np.corrcoef(transform_to_2d(main_data[2])),cmap='gray')\n",
    "    plt.subplot(G[7, 3]).imshow(np.corrcoef(transform_to_2d(main_data[3])),cmap='gray')\n",
    "    plt.subplot(G[7, 4]).imshow(np.corrcoef(transform_to_2d(main_data[4])),cmap='gray')\n",
    "    plt.subplot(G[7, 5]).imshow(np.corrcoef(transform_to_2d(main_data[5])),cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(current_exp + '/' + experiment_name + '/' + str(iter) + '.png')\n",
    "    plt.close('all')\n",
    "def plot_rotation_weight(current_layers,current_layer_number,current_batch_norm_type,current_exp_name): \n",
    "\n",
    "    def rotate(angle):ax.view_init(azim=angle)\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    colors = ['red','orange','yellow','green','blue','purple','black','gold','silver','cyan','pink']\n",
    "    number_of_eps = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax  = fig.add_subplot(111, projection='3d')\n",
    "    count = 0\n",
    "    for episode in range(num_eps+1):\n",
    "        if episode == num_eps:\n",
    "            ys   = current_layers.mean(0).flatten()\n",
    "            xmin = ys.min(); xmax = ys.max(); step = 0.005\n",
    "            hist,bins = np.histogram(ys, bins=np.linspace(xmin, xmax, (xmax-xmin)/step))\n",
    "            ax.bar(bins[:-1], hist, width=0.01,zs=episode, zdir='y', color=colors[episode], alpha=0.8)\n",
    "        else:\n",
    "            ys   = current_layers[episode].flatten()\n",
    "            xmin = ys.min(); xmax = ys.max(); step = 0.005\n",
    "            hist,bins = np.histogram(ys, bins=np.linspace(xmin, xmax, (xmax-xmin)/step))\n",
    "            ax.bar(bins[:-1], hist, width=0.01,zs=episode, zdir='y', color=colors[episode], alpha=0.4)\n",
    "    ax.set_xlabel('Values')\n",
    "    ax.set_ylabel('Episode')\n",
    "    ax.get_yaxis().set_ticks(np.arange(num_eps+1))\n",
    "    ax.set_zlabel('Histogram')\n",
    "\n",
    "    ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    # ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    animation.FuncAnimation(fig, rotate, frames=np.arange(0,362,2),interval=100) \\\n",
    "    .save(str(current_batch_norm_type)+'/'+str(current_exp_name)+'/weight_'+str(current_layer_number)+'.gif', dpi=80, writer='imagemagick')\n",
    "    plt.close('all')\n",
    "def plot_image_weight(current_layers,current_layer_number,current_batch_norm_type,current_exp_name,current_exp_train_accuracy,current_exp_test_accuracy):\n",
    "    colors = ['red','orange','yellow','green','blue','purple','black','gold','silver','cyan','pink']\n",
    "    def rt(number): return np.around(number,4)\n",
    "    plt.style.use('seaborn')\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plt.rcParams.update({'font.size': 50})\n",
    "\n",
    "    fig.add_subplot(341); plt.hist(current_layers[0].flatten(),50,color=colors[0],alpha=0.8);plt.title('EPS: 1 Mean: '+str(rt(current_layers[0].mean())) +' STD: '+str(rt(current_layers[0].std())))\n",
    "    fig.add_subplot(342); plt.hist(current_layers[1].flatten(),50,color=colors[1],alpha=0.8);plt.title('EPS: 2 Mean: '+str(rt(current_layers[1].mean())) +' STD: '+str(rt(current_layers[1].std())))\n",
    "    fig.add_subplot(343); plt.hist(current_layers[2].flatten(),50,color=colors[2],alpha=0.8);plt.title('EPS: 3 Mean: '+str(rt(current_layers[2].mean())) +' STD: '+str(rt(current_layers[2].std())))\n",
    "    fig.add_subplot(344); plt.hist(current_layers[3].flatten(),50,color=colors[3],alpha=0.8);plt.title('EPS: 4 Mean: '+str(rt(current_layers[3].mean())) +' STD: '+str(rt(current_layers[3].std())))\n",
    "    \n",
    "    fig.add_subplot(345); plt.hist(current_layers[4].flatten(),50,color=colors[4],alpha=0.8);plt.title('EPS: 5 Mean: '+str(rt(current_layers[4].mean())) +' STD: '+str(rt(current_layers[4].std())))\n",
    "    fig.add_subplot(346); plt.hist(current_layers[5].flatten(),50,color=colors[5],alpha=0.8);plt.title('EPS: 6 Mean: '+str(rt(current_layers[5].mean())) +' STD: '+str(rt(current_layers[5].std())))\n",
    "    fig.add_subplot(347); plt.hist(current_layers[6].flatten(),50,color=colors[6],alpha=0.8);plt.title('EPS: 7 Mean: '+str(rt(current_layers[6].mean())) +' STD: '+str(rt(current_layers[6].std())))\n",
    "    fig.add_subplot(348); plt.hist(current_layers[7].flatten(),50,color=colors[7],alpha=0.8);plt.title('EPS: 8 Mean: '+str(rt(current_layers[7].mean())) +' STD: '+str(rt(current_layers[7].std())))\n",
    "    \n",
    "    fig.add_subplot(3,4,9);  plt.hist(current_layers[8].flatten(),50,color=colors[8],alpha=0.8);plt.title('EPS: 9 Mean: '+str(rt(current_layers[8].mean())) +' STD: '+str(rt(current_layers[8].std())))\n",
    "    fig.add_subplot(3,4,10); plt.hist(current_layers[9].flatten(),50,color=colors[9],alpha=0.8);plt.title('EPS: 10 Mean: '+str(rt(current_layers[9].mean())) +' STD: '+str(rt(current_layers[9].std())))\n",
    "    fig.add_subplot(3,4,11); plt.hist(current_layers.mean(0).flatten(),50,color=colors[10],alpha=0.8);plt.title('EPS: All Mean: '+str(rt(current_layers.mean(0).mean())) +' STD: '+str(rt(current_layers.mean(0).std())))\n",
    "    fig.add_subplot(3,4,12); \n",
    "    plt.plot(current_exp_train_accuracy.max(0),  ' ' ,color='red')\n",
    "    plt.plot(current_exp_train_accuracy.mean(0), '-' ,color='red',label='train mean')\n",
    "    plt.plot(current_exp_train_accuracy.min(0) , ' ' ,color='red')\n",
    "    plt.fill_between(range(num_epoch),current_exp_train_accuracy.max(0),current_exp_train_accuracy.min(0),facecolor='red', alpha=0.2)\n",
    "\n",
    "    plt.plot(current_exp_test_accuracy.max(0),  ' ' ,color='blue')\n",
    "    plt.plot(current_exp_test_accuracy.mean(0), '-' ,color='blue',label='test mean')\n",
    "    plt.plot(current_exp_test_accuracy.min(0) , ' ' ,color='blue')\n",
    "    plt.fill_between(range(num_epoch),current_exp_test_accuracy.max(0),current_exp_test_accuracy.min(0),facecolor='blue', alpha=0.2)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(current_batch_norm_type)+'/'+str(current_exp_name)+'/weight_'+str(current_layer_number)+'.png')\n",
    "    plt.close('all')\n",
    "def plot_full_weight(current_weights_layer1,current_weights_layer2,current_weights_layer3,\n",
    "                     current_weights_layer4,current_weights_layer5,current_weights_layer6,\n",
    "                     current_batch_norm_type,current_exp_name,current_exp_train_accuracy,current_exp_test_accuracy):\n",
    "    \n",
    "    colors = ['red','orange','yellow','green','blue','purple','black','gold','silver','cyan','pink']\n",
    "    def rt(number): return np.around(number,4)\n",
    "    plt.style.use('seaborn')\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plt.rcParams.update({'font.size': 50})\n",
    "    gs = gridspec.GridSpec(3, 3)\n",
    "    \n",
    "    fig.add_subplot(331); plt.hist(current_weights_layer1.mean(0).flatten(),50,color=colors[0],alpha=0.8); plt.title('Layer 1 Histogram Mean :'+str(rt(current_weights_layer1.mean(0).mean()))+' STD: '+str(rt(current_weights_layer1.mean(0).std())))\n",
    "    fig.add_subplot(332); plt.hist(current_weights_layer2.mean(0).flatten(),50,color=colors[1],alpha=0.8); plt.title('Layer 2 Histogram Mean :'+str(rt(current_weights_layer2.mean(0).mean()))+' STD: '+str(rt(current_weights_layer2.mean(0).std())))\n",
    "    fig.add_subplot(333); plt.hist(current_weights_layer3.mean(0).flatten(),50,color=colors[2],alpha=0.8); plt.title('Layer 3 Histogram Mean :'+str(rt(current_weights_layer3.mean(0).mean()))+' STD: '+str(rt(current_weights_layer3.mean(0).std())))\n",
    "    \n",
    "    fig.add_subplot(334); plt.hist(current_weights_layer4.mean(0).flatten(),50,color=colors[3],alpha=0.8); plt.title('Layer 4 Histogram Mean :'+str(rt(current_weights_layer4.mean(0).mean()))+' STD: '+str(rt(current_weights_layer4.mean(0).std())))\n",
    "    fig.add_subplot(335); plt.hist(current_weights_layer5.mean(0).flatten(),50,color=colors[4],alpha=0.8); plt.title('Layer 5 Histogram Mean :'+str(rt(current_weights_layer5.mean(0).mean()))+' STD: '+str(rt(current_weights_layer5.mean(0).std())))\n",
    "    fig.add_subplot(336); plt.hist(current_weights_layer6.mean(0).flatten(),50,color=colors[5],alpha=0.8); plt.title('Layer 6 Histogram Mean :'+str(rt(current_weights_layer6.mean(0).mean()))+' STD: '+str(rt(current_weights_layer6.mean(0).std())))\n",
    "    \n",
    "    fig.add_subplot(gs[2,:]); \n",
    "    plt.plot(current_exp_train_accuracy.max(0),  ' ' ,color='red')\n",
    "    plt.plot(current_exp_train_accuracy.mean(0), '-' ,color='red',label='train mean')\n",
    "    plt.plot(current_exp_train_accuracy.min(0) , ' ' ,color='red')\n",
    "    plt.fill_between(range(num_epoch),current_exp_train_accuracy.max(0),current_exp_train_accuracy.min(0),facecolor='red', alpha=0.2)\n",
    "\n",
    "    plt.plot(current_exp_test_accuracy.max(0),  ' ' ,color='blue')\n",
    "    plt.plot(current_exp_test_accuracy.mean(0), '-' ,color='blue',label='test mean')\n",
    "    plt.plot(current_exp_test_accuracy.min(0) , ' ' ,color='blue')\n",
    "    plt.fill_between(range(num_epoch),current_exp_test_accuracy.max(0),current_exp_test_accuracy.min(0),facecolor='blue', alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(str(current_batch_norm_type)+'/'+str(current_exp_name)+'/z_all.png')\n",
    "    plt.close('all')\n",
    "def send_notification_email(letter,episode):\n",
    "    import smtplib, ssl\n",
    "\n",
    "    port = 587  # For starttls\n",
    "    smtp_server = \"smtp.gmail.com\"\n",
    "    sender_email = \"sendresultsforme@gmail.com\"\n",
    "    receiver_email = \"jae.duk.seo@gmail.com\"\n",
    "    password = \"Password123*\"\n",
    "    message = \"Subject: \" + str(letter) + \" : \"+str(episode)+\" is done!\"\n",
    "\n",
    "    context = ssl.create_default_context()\n",
    "    with smtplib.SMTP(smtp_server, port) as server:\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.starttls(context=context)\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(sender_email, receiver_email, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "num_eps   = 10; num_epoch = 350; learning_rate = 0.0008; batch_size = 50; beta1,beta2,adam_e = 0.9,0.999,1e-9; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
