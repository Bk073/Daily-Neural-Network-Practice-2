{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:20:42.901157Z",
     "start_time": "2018-12-10T14:20:39.433450Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:20:44.640534Z",
     "start_time": "2018-12-10T14:20:42.948026Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:20:48.336622Z",
     "start_time": "2018-12-10T14:20:44.826006Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:21:01.192254Z",
     "start_time": "2018-12-10T14:21:01.158385Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "# declare layer \n",
    "def tf_pca_svd(X,mmax=0.8,mmin=0.0): \n",
    "    s,U,V  = tf.svd(X,full_matrices=False)\n",
    "    smin = tf.reduce_min(s,0)\n",
    "    smax = tf.reduce_max(s,0)\n",
    "    ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "    recon_data = U @ tf.diag(s) @ tf.transpose(V) * tf.reduce_mean(tf.abs(V) * ScaledS[None,:],0,keepdims =True)\n",
    "    return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:40:04.416655Z",
     "start_time": "2018-12-10T14:40:04.113466Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,32)\n",
    "\n",
    "l4 = CNN(3,32,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,64)\n",
    "\n",
    "l7 = CNN(3,64,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:40:05.184072Z",
     "start_time": "2018-12-10T14:40:04.715364Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "def do(layer9,num=10):\n",
    "    with tf.device('/cpu:0'):\n",
    "        s,U,V = tf.svd(layer9)\n",
    "    S      = tf.matrix_diag(s)\n",
    "    layer9 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:num] \n",
    "    return layer9\n",
    "\n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,     padding='SAME',stride=1)\n",
    "layer2 = l2.feedforward(layer1,padding='SAME',stride=1)\n",
    "layer3 = l3.feedforward(layer2,padding='SAME',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='SAME',stride=1)\n",
    "layer5 = l5.feedforward(layer4,padding='SAME',stride=1)\n",
    "layer6 = l6.feedforward(layer5,padding='SAME',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID',stride=1)\n",
    "layer8 = l8.feedforward(layer7,padding='VALID',stride=1)\n",
    "layer9 = l9.feedforward(layer8,padding='VALID',stride=1)\n",
    "\n",
    "# layer9_t = tf.transpose(layer9,(1,2,0,3))\n",
    "# with tf.device('/cpu:0'):\n",
    "#     s,U,V = tf.svd(layer9_t)\n",
    "# S        = tf.matrix_diag(s)\n",
    "# layer9_2 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:10]\n",
    "# layer9_3 = tf.transpose(layer9_2,(2,0,1,3)) + layer9\n",
    "# print(U,S,V)\n",
    "# print(layer9_2)\n",
    "# print(layer9_3)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-10T14:40:04.751Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7950/8000 acc : 0.24\n",
      " Current : 0 Acc : 0.1518000001832843 Test Acc : 0.17637500031851233\n",
      "\n",
      "Current Iter : 1/50 batch : 7950/8000 acc : 0.26\n",
      " Current : 1 Acc : 0.1696000000089407 Test Acc : 0.18224999960511923\n",
      "\n",
      "Current Iter : 2/50 batch : 7950/8000 acc : 0.22\n",
      " Current : 2 Acc : 0.18619999945163726 Test Acc : 0.1991249998100102\n",
      "\n",
      "Current Iter : 3/50 batch : 7950/8000 acc : 0.32\n",
      " Current : 3 Acc : 0.224200000166893 Test Acc : 0.24187499904073775\n",
      "\n",
      "Current Iter : 4/50 batch : 7950/8000 acc : 0.32\n",
      " Current : 4 Acc : 0.264199999794364 Test Acc : 0.2761250006500632\n",
      "\n",
      "Current Iter : 5/50 batch : 7950/8000 acc : 0.46\n",
      " Current : 5 Acc : 0.3008000002801418 Test Acc : 0.32112500006332995\n",
      "\n",
      "Current Iter : 6/50 batch : 7950/8000 acc : 0.44\n",
      " Current : 6 Acc : 0.3258000011742115 Test Acc : 0.35075000105425713\n",
      "\n",
      "Current Iter : 7/50 batch : 7950/8000 acc : 0.44\n",
      " Current : 7 Acc : 0.3524000023305416 Test Acc : 0.3616250006482005\n",
      "\n",
      "Current Iter : 8/50 batch : 7950/8000 acc : 0.52\n",
      " Current : 8 Acc : 0.36560000211000443 Test Acc : 0.3998749998398125\n",
      "\n",
      "Current Iter : 9/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 9 Acc : 0.39499999925494195 Test Acc : 0.427874999307096\n",
      "\n",
      "Current Iter : 10/50 batch : 7950/8000 acc : 0.58\n",
      " Current : 10 Acc : 0.4141999988257885 Test Acc : 0.4437499983236194\n",
      "\n",
      "Current Iter : 11/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 11 Acc : 0.43839999943971636 Test Acc : 0.44649999886751174\n",
      "\n",
      "Current Iter : 12/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 12 Acc : 0.4544000005722046 Test Acc : 0.4531249988824129\n",
      "\n",
      "Current Iter : 13/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 13 Acc : 0.4657999986410141 Test Acc : 0.4581249987706542\n",
      "\n",
      "Current Iter : 14/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 14 Acc : 0.4719999992847443 Test Acc : 0.4626249983906746\n",
      "\n",
      "Current Iter : 15/50 batch : 7950/8000 acc : 0.52\n",
      " Current : 15 Acc : 0.47999999970197677 Test Acc : 0.467374998703599\n",
      "\n",
      "Current Iter : 16/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 16 Acc : 0.4945999991893768 Test Acc : 0.4728749994188547\n",
      "\n",
      "Current Iter : 17/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 17 Acc : 0.5052000012993813 Test Acc : 0.4782500000670552\n",
      "\n",
      "Current Iter : 18/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 18 Acc : 0.5108000004291534 Test Acc : 0.48025000020861625\n",
      "\n",
      "Current Iter : 19/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 19 Acc : 0.5177999985218048 Test Acc : 0.48562499936670067\n",
      "\n",
      "Current Iter : 20/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 20 Acc : 0.5257999992370606 Test Acc : 0.49162499886006117\n",
      "\n",
      "Current Iter : 21/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 21 Acc : 0.5290000009536743 Test Acc : 0.49537499733269214\n",
      "\n",
      "Current Iter : 22/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 22 Acc : 0.5339999982714653 Test Acc : 0.4994999973103404\n",
      "\n",
      "Current Iter : 23/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 23 Acc : 0.539600000679493 Test Acc : 0.5056249983608723\n",
      "\n",
      "Current Iter : 24/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 24 Acc : 0.5464000019431114 Test Acc : 0.509374999627471\n",
      "\n",
      "Current Iter : 25/50 batch : 7950/8000 acc : 0.54\n",
      " Current : 25 Acc : 0.5548000031709671 Test Acc : 0.5138750003650785\n",
      "\n",
      "Current Iter : 26/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 26 Acc : 0.5610000017285347 Test Acc : 0.519875000230968\n",
      "\n",
      "Current Iter : 27/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 27 Acc : 0.5672000020742416 Test Acc : 0.5229999994859099\n",
      "\n",
      "Current Iter : 28/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 28 Acc : 0.5776000031828881 Test Acc : 0.5303750010207295\n",
      "\n",
      "Current Iter : 29/50 batch : 7950/8000 acc : 0.58\n",
      " Current : 29 Acc : 0.5852000027894974 Test Acc : 0.5363749992102385\n",
      "\n",
      "Current Iter : 30/50 batch : 7950/8000 acc : 0.58\n",
      " Current : 30 Acc : 0.5922000020742416 Test Acc : 0.5428750012069941\n",
      "\n",
      "Current Iter : 31/50 batch : 7950/8000 acc : 0.58\n",
      " Current : 31 Acc : 0.5944000032544136 Test Acc : 0.5455000018700957\n",
      "\n",
      "Current Iter : 32/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 32 Acc : 0.6024000018835067 Test Acc : 0.5466250034049154\n",
      "\n",
      "Current Iter : 33/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 33 Acc : 0.6086000052094459 Test Acc : 0.5493750007823109\n",
      "\n",
      "Current Iter : 34/50 batch : 7950/8000 acc : 0.56\n",
      " Current : 34 Acc : 0.6136000049114227 Test Acc : 0.5463750028982759\n",
      "\n",
      "Current Iter : 35/50 batch : 2300/5000 acc : 0.52\r"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch*100):\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# build graph (batch norm)\n",
    "def do(layer9,num=10):\n",
    "    with tf.device('/cpu:0'):\n",
    "        s,U,V = tf.svd(layer9)\n",
    "    S      = tf.matrix_diag(s)\n",
    "    layer9 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:num] \n",
    "    return layer9\n",
    "\n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,     padding='SAME',stride=1)\n",
    "layer2 = l2.feedforward(layer1,padding='SAME',stride=1)\n",
    "layer3 = l3.feedforward(layer2,padding='SAME',stride=2)\n",
    "# layer3 = tf.layers.batch_normalization(layer3,training=is_training)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='SAME',stride=1)\n",
    "layer5 = l5.feedforward(layer4,padding='SAME',stride=1)\n",
    "layer6 = l6.feedforward(layer5,padding='SAME',stride=2)\n",
    "# layer6 = tf.layers.batch_normalization(layer6,training=is_training)\n",
    "\n",
    "# layer6_t = tf.transpose(layer6,(1,2,0,3))\n",
    "# with tf.device('/cpu:0'):\n",
    "#     s,U,V = tf.svd(layer6_t)\n",
    "# S        = tf.matrix_diag(s)\n",
    "# layer6_2 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:64]\n",
    "# layer6_3 = tf.transpose(layer6_2,(2,0,1,3))\n",
    "# print(U,S,V)\n",
    "# print(layer6_2)\n",
    "# print(layer6_3)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID',stride=1)\n",
    "layer8 = l8.feedforward(layer7,padding='VALID',stride=1)\n",
    "layer9 = l9.feedforward(layer8,padding='VALID',stride=1)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "# update_ops  = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:17:25.431311Z",
     "start_time": "2018-12-10T14:17:14.977Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:17:25.433341Z",
     "start_time": "2018-12-10T14:17:14.981Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels)\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels)\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:56:07.568679Z",
     "start_time": "2018-12-09T16:56:07.550727Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:17:25.434339Z",
     "start_time": "2018-12-10T14:17:15.057Z"
    }
   },
   "outputs": [],
   "source": [
    "temp   = np.random.randn(100,32,32,3)\n",
    "s,U,V  = tf.svd(temp)\n",
    "S = tf.matrix_diag(s)\n",
    "print(S)\n",
    "print(U,s,V)\n",
    "print(tf.diag(s))\n",
    "\n",
    "result = U @ S @ tf.transpose(V,(0,1,3,2))\n",
    "result = result.eval()\n",
    "\n",
    "print(np.testing.assert_allclose(temp, result))\n",
    "print(np.allclose(temp,result))\n",
    "print(np.equal(temp,result).sum())\n",
    "print(100*32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
