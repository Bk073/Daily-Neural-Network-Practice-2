{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:10.635622Z",
     "start_time": "2018-12-09T23:59:56.266197Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:12.550717Z",
     "start_time": "2018-12-10T00:00:10.638613Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.231677Z",
     "start_time": "2018-12-10T00:00:12.551681Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.274103Z",
     "start_time": "2018-12-10T00:00:16.235663Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):    return tf.nn.elu(x)\n",
    "def d_tf_elu(x):  return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) + self.b \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "# declare layer \n",
    "def tf_pca_svd(X,mmax=0.8,mmin=0.0): \n",
    "    s,U,V  = tf.svd(X,full_matrices=False)\n",
    "    smin = tf.reduce_min(s,0)\n",
    "    smax = tf.reduce_max(s,0)\n",
    "    ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "    recon_data = U @ tf.diag(s) @ tf.transpose(V) * tf.reduce_mean(tf.abs(V) * ScaledS[None,:],0,keepdims =True)\n",
    "    return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T02:07:01.989844Z",
     "start_time": "2018-12-10T02:07:01.666510Z"
    },
    "code_folding": [
     16
    ]
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "l1 = CNN(3,3,16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(2,32,128)\n",
    "\n",
    "l7 = CNN(1,64,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T02:07:10.469589Z",
     "start_time": "2018-12-10T02:07:08.931919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Svd_44:0\", shape=(25, 1, 1), dtype=float32)\n",
      "Tensor(\"Svd_44:1\", shape=(25, 1, 1, 1), dtype=float32)\n",
      "Tensor(\"transpose_96:0\", shape=(25, 1, 1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID',stride=2)\n",
    "layer6 = l6.feedforward(layer5,padding='VALID')\n",
    "\n",
    "s,U,V = tf.svd(layer6)\n",
    "\n",
    "print(s)\n",
    "print(U)\n",
    "print(tf.transpose(V,(0,1,3,2)))\n",
    "\n",
    "S    = tf.matrix_diag(s)\n",
    "smin = tf.reduce_min(s,0,keepdims=True)\n",
    "smax = tf.reduce_max(s,0,keepdims=True)\n",
    "mmax = 0.8\n",
    "mmin = 0\n",
    "ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "# *  tf.reduce_mean(tf.abs(V)[:,:,:64,:] * ScaledS[None,:],0,keepdims =True) \n",
    "layer6 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:64] \n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-10T02:07:11.330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.26\n",
      " Current : 0 Acc : 0.19699999887496233 Test Acc : 0.3043749997857958\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 1 Acc : 0.3169999997317791 Test Acc : 0.3454999994719401\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 2 Acc : 0.3602000002190471 Test Acc : 0.3715000011492521\n",
      "\n",
      "Current Iter : 3/50 batch : 4675/5000 acc : 0.36\r"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels)\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels)\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:24:40.089584Z",
     "start_time": "2018-12-10T01:24:39.532076Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:27:19.529363Z",
     "start_time": "2018-12-10T01:24:41.747172Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 0 Acc : 0.18139999855309724 Test Acc : 0.23037499892525376\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 1 Acc : 0.2577999993786216 Test Acc : 0.29962500096298755\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 2 Acc : 0.3040000008791685 Test Acc : 0.29412499961908906\n",
      "\n",
      "Current Iter : 3/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 3 Acc : 0.33220000080764295 Test Acc : 0.34125000082422047\n",
      "\n",
      "Current Iter : 4/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 4 Acc : 0.37060000136494636 Test Acc : 0.36575000116135925\n",
      "\n",
      "Current Iter : 5/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 5 Acc : 0.39500000055879353 Test Acc : 0.3934999986551702\n",
      "\n",
      "Current Iter : 6/50 batch : 7975/8000 acc : 0.52\n",
      " Current : 6 Acc : 0.4213999977707863 Test Acc : 0.3979999993694946\n",
      "\n",
      "Current Iter : 7/50 batch : 7975/8000 acc : 0.68\n",
      " Current : 7 Acc : 0.4451999981701374 Test Acc : 0.4063749992288649\n",
      "\n",
      "Current Iter : 8/50 batch : 7975/8000 acc : 0.56\n",
      " Current : 8 Acc : 0.4649999972805381 Test Acc : 0.408374999393709\n",
      "\n",
      "Current Iter : 9/50 batch : 7975/8000 acc : 0.56\n",
      " Current : 9 Acc : 0.49039999924600125 Test Acc : 0.41200000010430815\n",
      "\n",
      "Current Iter : 10/50 batch : 7975/8000 acc : 0.52\n",
      " Current : 10 Acc : 0.5007999982684851 Test Acc : 0.412375000026077\n",
      "\n",
      "Current Iter : 11/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 11 Acc : 0.5165999994426965 Test Acc : 0.41512499991804364\n",
      "\n",
      "Current Iter : 12/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 12 Acc : 0.540200001373887 Test Acc : 0.4224999998230487\n",
      "\n",
      "Current Iter : 13/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 13 Acc : 0.5734000007808209 Test Acc : 0.425749999191612\n",
      "\n",
      "Current Iter : 14/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 14 Acc : 0.5906000021100044 Test Acc : 0.4272499995538965\n",
      "\n",
      "Current Iter : 15/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 15 Acc : 0.6040000006556511 Test Acc : 0.42612499953247607\n",
      "\n",
      "Current Iter : 16/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 16 Acc : 0.6202000026404858 Test Acc : 0.4298749982845038\n",
      "\n",
      "Current Iter : 17/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 17 Acc : 0.6430000038444996 Test Acc : 0.42587499851360916\n",
      "\n",
      "Current Iter : 18/50 batch : 7975/8000 acc : 0.46\n",
      " Current : 18 Acc : 0.6564000056684017 Test Acc : 0.4238749999087304\n",
      "\n",
      "Current Iter : 19/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 19 Acc : 0.677400004118681 Test Acc : 0.41399999931454656\n",
      "\n",
      "Current Iter : 20/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 20 Acc : 0.7018000064790249 Test Acc : 0.409249999653548\n",
      "\n",
      "Current Iter : 21/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 21 Acc : 0.7226000046730041 Test Acc : 0.4077500000828877\n",
      "\n",
      "Current Iter : 22/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 22 Acc : 0.7366000029444695 Test Acc : 0.40212499964982273\n",
      "\n",
      "Current Iter : 23/50 batch : 7975/8000 acc : 0.46\n",
      " Current : 23 Acc : 0.7466000053286552 Test Acc : 0.4044999992707744\n",
      "\n",
      "Current Iter : 24/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 24 Acc : 0.761600002348423 Test Acc : 0.4093749992316589\n",
      "\n",
      "Current Iter : 25/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 25 Acc : 0.7899999994039536 Test Acc : 0.4011249995790422\n",
      "\n",
      "Current Iter : 26/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 26 Acc : 0.7939999988675117 Test Acc : 0.40312499965075405\n",
      "\n",
      "Current Iter : 27/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 27 Acc : 0.8105999982357025 Test Acc : 0.39849999942816794\n",
      "\n",
      "Current Iter : 28/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 28 Acc : 0.8179999998211861 Test Acc : 0.3947499998379499\n",
      "\n",
      "Current Iter : 29/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 29 Acc : 0.8255999961495399 Test Acc : 0.39074999978765845\n",
      "\n",
      "Current Iter : 30/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 30 Acc : 0.8391999958455563 Test Acc : 0.38999999975785615\n",
      "\n",
      "Current Iter : 31/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 31 Acc : 0.8505999958515167 Test Acc : 0.39412500001490114\n",
      "\n",
      "Current Iter : 32/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 32 Acc : 0.8585999971628189 Test Acc : 0.3926249996293336\n",
      "\n",
      "Current Iter : 33/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 33 Acc : 0.8741999965906143 Test Acc : 0.39749999993946405\n",
      "\n",
      "Current Iter : 34/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 34 Acc : 0.8885999956727028 Test Acc : 0.3939999990398064\n",
      "\n",
      "Current Iter : 35/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 35 Acc : 0.8985999953746796 Test Acc : 0.3899999995715916\n",
      "\n",
      "Current Iter : 36/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 36 Acc : 0.8931999978423119 Test Acc : 0.3769999999785796\n",
      "\n",
      "Current Iter : 37/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 37 Acc : 0.889199994802475 Test Acc : 0.3832500002114102\n",
      "\n",
      "Current Iter : 38/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 38 Acc : 0.8919999966025353 Test Acc : 0.3818750004284084\n",
      "\n",
      "Current Iter : 39/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 39 Acc : 0.901799995303154 Test Acc : 0.3853749998612329\n",
      "\n",
      "Current Iter : 40/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 40 Acc : 0.9209999951720238 Test Acc : 0.387874999945052\n",
      "\n",
      "Current Iter : 41/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 41 Acc : 0.9099999952316284 Test Acc : 0.3923750004498288\n",
      "\n",
      "Current Iter : 42/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 42 Acc : 0.9201999947428703 Test Acc : 0.3792499990668148\n",
      "\n",
      "Current Iter : 43/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 43 Acc : 0.9263999941945076 Test Acc : 0.3887500001816079\n",
      "\n",
      "Current Iter : 44/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 44 Acc : 0.9297999969124794 Test Acc : 0.3884999999776483\n",
      "\n",
      "Current Iter : 45/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 45 Acc : 0.9339999961853027 Test Acc : 0.3867499994346872\n",
      "\n",
      "Current Iter : 46/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 46 Acc : 0.938999995291233 Test Acc : 0.3889999992912635\n",
      "\n",
      "Current Iter : 47/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 47 Acc : 0.9469999954104423 Test Acc : 0.3867499990854412\n",
      "\n",
      "Current Iter : 48/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 48 Acc : 0.9503999945521354 Test Acc : 0.3826249995268881\n",
      "\n",
      "Current Iter : 49/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 49 Acc : 0.947799996137619 Test Acc : 0.38574999999254944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels)\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels)\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:56:07.568679Z",
     "start_time": "2018-12-09T16:56:07.550727Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:02:51.494724Z",
     "start_time": "2018-12-09T23:59:56.331Z"
    }
   },
   "outputs": [],
   "source": [
    "temp   = np.random.randn(100,32,32,3)\n",
    "s,U,V  = tf.svd(temp)\n",
    "S = tf.matrix_diag(s)\n",
    "print(S)\n",
    "print(U,s,V)\n",
    "print(tf.diag(s))\n",
    "\n",
    "result = U @ S @ tf.transpose(V,(0,1,3,2))\n",
    "result = result.eval()\n",
    "\n",
    "print(np.testing.assert_allclose(temp, result))\n",
    "print(np.allclose(temp,result))\n",
    "print(np.equal(temp,result).sum())\n",
    "print(100*32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
