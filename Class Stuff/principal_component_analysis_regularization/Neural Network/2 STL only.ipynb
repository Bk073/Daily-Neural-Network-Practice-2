{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-10T14:14:51.285Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-10T14:14:58.949Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T12:06:18.865572Z",
     "start_time": "2018-12-10T12:06:15.056366Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:11:43.724318Z",
     "start_time": "2018-12-10T14:11:43.693382Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):    return tf.nn.elu(x)\n",
    "def d_tf_elu(x):  return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "# declare layer \n",
    "def tf_pca_svd(X,mmax=0.8,mmin=0.0): \n",
    "    s,U,V  = tf.svd(X,full_matrices=False)\n",
    "    smin = tf.reduce_min(s,0)\n",
    "    smax = tf.reduce_max(s,0)\n",
    "    ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "    recon_data = U @ tf.diag(s) @ tf.transpose(V) * tf.reduce_mean(tf.abs(V) * ScaledS[None,:],0,keepdims =True)\n",
    "    return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:11:46.143834Z",
     "start_time": "2018-12-10T14:11:45.854605Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,32)\n",
    "\n",
    "l4 = CNN(3,32,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,64)\n",
    "\n",
    "l7 = CNN(3,64,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:13:01.993889Z",
     "start_time": "2018-12-10T14:13:01.118231Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "def do(layer9,num=10):\n",
    "    with tf.device('/cpu:0'):\n",
    "        s,U,V = tf.svd(layer9)\n",
    "    S      = tf.matrix_diag(s)\n",
    "    layer9 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:num] \n",
    "    return layer9\n",
    "\n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,     padding='SAME',stride=1)\n",
    "layer2 = l2.feedforward(layer1,padding='SAME',stride=1)\n",
    "layer3 = l3.feedforward(layer2,padding='SAME',stride=2)\n",
    "layer3 = tf.layers.batch_normalization(layer3,training=is_training)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='SAME',stride=1)\n",
    "layer5 = l5.feedforward(layer4,padding='SAME',stride=1)\n",
    "layer6 = l6.feedforward(layer5,padding='SAME',stride=2)\n",
    "layer6 = tf.layers.batch_normalization(layer6,training=is_training)\n",
    "\n",
    "# layer6_t = tf.transpose(layer6,(1,2,0,3))\n",
    "# with tf.device('/cpu:0'):\n",
    "#     s,U,V = tf.svd(layer6_t)\n",
    "# S        = tf.matrix_diag(s)\n",
    "# layer6_2 = U @ S @ tf.transpose(V,(0,1,3,2))[:,:,:,:64]\n",
    "# layer6_3 = tf.transpose(layer6_2,(2,0,1,3))\n",
    "# print(U,S,V)\n",
    "# print(layer6_2)\n",
    "# print(layer6_3)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID',stride=1)\n",
    "layer8 = l8.feedforward(layer7,padding='VALID',stride=1)\n",
    "layer9 = l9.feedforward(layer8,padding='VALID',stride=1)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "update_ops  = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:14:37.285177Z",
     "start_time": "2018-12-10T14:14:34.571452Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_122' with dtype float and shape [50,96,96,3]\n\t [[node Placeholder_122 (defined at <ipython-input-131-7ae5633a179b>:9)  = Placeholder[dtype=DT_FLOAT, shape=[50,96,96,3], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Mean_122/_1139}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3991_Mean_122\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_122', defined at:\n  File \"C:\\ProgramData\\Miniconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-131-7ae5633a179b>\", line 9, in <module>\n    x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_122' with dtype float and shape [50,96,96,3]\n\t [[node Placeholder_122 (defined at <ipython-input-131-7ae5633a179b>:9)  = Placeholder[dtype=DT_FLOAT, shape=[50,96,96,3], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Mean_122/_1139}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3991_Mean_122\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_122' with dtype float and shape [50,96,96,3]\n\t [[{{node Placeholder_122}} = Placeholder[dtype=DT_FLOAT, shape=[50,96,96,3], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Mean_122/_1139}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3991_Mean_122\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-7ad99386f9ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauto_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_122' with dtype float and shape [50,96,96,3]\n\t [[node Placeholder_122 (defined at <ipython-input-131-7ae5633a179b>:9)  = Placeholder[dtype=DT_FLOAT, shape=[50,96,96,3], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Mean_122/_1139}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3991_Mean_122\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_122', defined at:\n  File \"C:\\ProgramData\\Miniconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-131-7ae5633a179b>\", line 9, in <module>\n    x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_122' with dtype float and shape [50,96,96,3]\n\t [[node Placeholder_122 (defined at <ipython-input-131-7ae5633a179b>:9)  = Placeholder[dtype=DT_FLOAT, shape=[50,96,96,3], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Mean_122/_1139}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3991_Mean_122\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch*100):\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:24:40.089584Z",
     "start_time": "2018-12-10T01:24:39.532076Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:27:19.529363Z",
     "start_time": "2018-12-10T01:24:41.747172Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 0 Acc : 0.18139999855309724 Test Acc : 0.23037499892525376\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 1 Acc : 0.2577999993786216 Test Acc : 0.29962500096298755\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 2 Acc : 0.3040000008791685 Test Acc : 0.29412499961908906\n",
      "\n",
      "Current Iter : 3/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 3 Acc : 0.33220000080764295 Test Acc : 0.34125000082422047\n",
      "\n",
      "Current Iter : 4/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 4 Acc : 0.37060000136494636 Test Acc : 0.36575000116135925\n",
      "\n",
      "Current Iter : 5/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 5 Acc : 0.39500000055879353 Test Acc : 0.3934999986551702\n",
      "\n",
      "Current Iter : 6/50 batch : 7975/8000 acc : 0.52\n",
      " Current : 6 Acc : 0.4213999977707863 Test Acc : 0.3979999993694946\n",
      "\n",
      "Current Iter : 7/50 batch : 7975/8000 acc : 0.68\n",
      " Current : 7 Acc : 0.4451999981701374 Test Acc : 0.4063749992288649\n",
      "\n",
      "Current Iter : 8/50 batch : 7975/8000 acc : 0.56\n",
      " Current : 8 Acc : 0.4649999972805381 Test Acc : 0.408374999393709\n",
      "\n",
      "Current Iter : 9/50 batch : 7975/8000 acc : 0.56\n",
      " Current : 9 Acc : 0.49039999924600125 Test Acc : 0.41200000010430815\n",
      "\n",
      "Current Iter : 10/50 batch : 7975/8000 acc : 0.52\n",
      " Current : 10 Acc : 0.5007999982684851 Test Acc : 0.412375000026077\n",
      "\n",
      "Current Iter : 11/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 11 Acc : 0.5165999994426965 Test Acc : 0.41512499991804364\n",
      "\n",
      "Current Iter : 12/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 12 Acc : 0.540200001373887 Test Acc : 0.4224999998230487\n",
      "\n",
      "Current Iter : 13/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 13 Acc : 0.5734000007808209 Test Acc : 0.425749999191612\n",
      "\n",
      "Current Iter : 14/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 14 Acc : 0.5906000021100044 Test Acc : 0.4272499995538965\n",
      "\n",
      "Current Iter : 15/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 15 Acc : 0.6040000006556511 Test Acc : 0.42612499953247607\n",
      "\n",
      "Current Iter : 16/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 16 Acc : 0.6202000026404858 Test Acc : 0.4298749982845038\n",
      "\n",
      "Current Iter : 17/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 17 Acc : 0.6430000038444996 Test Acc : 0.42587499851360916\n",
      "\n",
      "Current Iter : 18/50 batch : 7975/8000 acc : 0.46\n",
      " Current : 18 Acc : 0.6564000056684017 Test Acc : 0.4238749999087304\n",
      "\n",
      "Current Iter : 19/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 19 Acc : 0.677400004118681 Test Acc : 0.41399999931454656\n",
      "\n",
      "Current Iter : 20/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 20 Acc : 0.7018000064790249 Test Acc : 0.409249999653548\n",
      "\n",
      "Current Iter : 21/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 21 Acc : 0.7226000046730041 Test Acc : 0.4077500000828877\n",
      "\n",
      "Current Iter : 22/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 22 Acc : 0.7366000029444695 Test Acc : 0.40212499964982273\n",
      "\n",
      "Current Iter : 23/50 batch : 7975/8000 acc : 0.46\n",
      " Current : 23 Acc : 0.7466000053286552 Test Acc : 0.4044999992707744\n",
      "\n",
      "Current Iter : 24/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 24 Acc : 0.761600002348423 Test Acc : 0.4093749992316589\n",
      "\n",
      "Current Iter : 25/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 25 Acc : 0.7899999994039536 Test Acc : 0.4011249995790422\n",
      "\n",
      "Current Iter : 26/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 26 Acc : 0.7939999988675117 Test Acc : 0.40312499965075405\n",
      "\n",
      "Current Iter : 27/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 27 Acc : 0.8105999982357025 Test Acc : 0.39849999942816794\n",
      "\n",
      "Current Iter : 28/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 28 Acc : 0.8179999998211861 Test Acc : 0.3947499998379499\n",
      "\n",
      "Current Iter : 29/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 29 Acc : 0.8255999961495399 Test Acc : 0.39074999978765845\n",
      "\n",
      "Current Iter : 30/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 30 Acc : 0.8391999958455563 Test Acc : 0.38999999975785615\n",
      "\n",
      "Current Iter : 31/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 31 Acc : 0.8505999958515167 Test Acc : 0.39412500001490114\n",
      "\n",
      "Current Iter : 32/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 32 Acc : 0.8585999971628189 Test Acc : 0.3926249996293336\n",
      "\n",
      "Current Iter : 33/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 33 Acc : 0.8741999965906143 Test Acc : 0.39749999993946405\n",
      "\n",
      "Current Iter : 34/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 34 Acc : 0.8885999956727028 Test Acc : 0.3939999990398064\n",
      "\n",
      "Current Iter : 35/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 35 Acc : 0.8985999953746796 Test Acc : 0.3899999995715916\n",
      "\n",
      "Current Iter : 36/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 36 Acc : 0.8931999978423119 Test Acc : 0.3769999999785796\n",
      "\n",
      "Current Iter : 37/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 37 Acc : 0.889199994802475 Test Acc : 0.3832500002114102\n",
      "\n",
      "Current Iter : 38/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 38 Acc : 0.8919999966025353 Test Acc : 0.3818750004284084\n",
      "\n",
      "Current Iter : 39/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 39 Acc : 0.901799995303154 Test Acc : 0.3853749998612329\n",
      "\n",
      "Current Iter : 40/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 40 Acc : 0.9209999951720238 Test Acc : 0.387874999945052\n",
      "\n",
      "Current Iter : 41/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 41 Acc : 0.9099999952316284 Test Acc : 0.3923750004498288\n",
      "\n",
      "Current Iter : 42/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 42 Acc : 0.9201999947428703 Test Acc : 0.3792499990668148\n",
      "\n",
      "Current Iter : 43/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 43 Acc : 0.9263999941945076 Test Acc : 0.3887500001816079\n",
      "\n",
      "Current Iter : 44/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 44 Acc : 0.9297999969124794 Test Acc : 0.3884999999776483\n",
      "\n",
      "Current Iter : 45/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 45 Acc : 0.9339999961853027 Test Acc : 0.3867499994346872\n",
      "\n",
      "Current Iter : 46/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 46 Acc : 0.938999995291233 Test Acc : 0.3889999992912635\n",
      "\n",
      "Current Iter : 47/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 47 Acc : 0.9469999954104423 Test Acc : 0.3867499990854412\n",
      "\n",
      "Current Iter : 48/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 48 Acc : 0.9503999945521354 Test Acc : 0.3826249995268881\n",
      "\n",
      "Current Iter : 49/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 49 Acc : 0.947799996137619 Test Acc : 0.38574999999254944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels)\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels)\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:56:07.568679Z",
     "start_time": "2018-12-09T16:56:07.550727Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:02:51.494724Z",
     "start_time": "2018-12-09T23:59:56.331Z"
    }
   },
   "outputs": [],
   "source": [
    "temp   = np.random.randn(100,32,32,3)\n",
    "s,U,V  = tf.svd(temp)\n",
    "S = tf.matrix_diag(s)\n",
    "print(S)\n",
    "print(U,s,V)\n",
    "print(tf.diag(s))\n",
    "\n",
    "result = U @ S @ tf.transpose(V,(0,1,3,2))\n",
    "result = result.eval()\n",
    "\n",
    "print(np.testing.assert_allclose(temp, result))\n",
    "print(np.allclose(temp,result))\n",
    "print(np.equal(temp,result).sum())\n",
    "print(100*32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
