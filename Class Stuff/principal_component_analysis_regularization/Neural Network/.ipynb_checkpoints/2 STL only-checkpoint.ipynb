{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:10.635622Z",
     "start_time": "2018-12-09T23:59:56.266197Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:12.550717Z",
     "start_time": "2018-12-10T00:00:10.638613Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.231677Z",
     "start_time": "2018-12-10T00:00:12.551681Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.274103Z",
     "start_time": "2018-12-10T00:00:16.235663Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):    return tf.nn.elu(x)\n",
    "def d_tf_elu(x):  return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) + self.b \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "# declare layer \n",
    "def tf_pca_svd(X,mmax=0.8,mmin=0.0): \n",
    "    s,U,V  = tf.svd(X,full_matrices=False)\n",
    "    smin = tf.reduce_min(s,0)\n",
    "    smax = tf.reduce_max(s,0)\n",
    "    ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "    recon_data = U @ tf.diag(s) @ tf.transpose(V) * tf.reduce_mean(tf.abs(V) * ScaledS[None,:],0,keepdims =True)\n",
    "    return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:44:05.389144Z",
     "start_time": "2018-12-10T00:44:05.068004Z"
    }
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "l1 = CNN(3,3,16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(1,64,10)\n",
    "l9 = CNN(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:44:06.408457Z",
     "start_time": "2018-12-10T00:44:06.332623Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 2 for 'Conv2D_68' (op: 'Conv2D') with input shapes: [25,2,2,32], [3,3,32,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'Conv2D_68' (op: 'Conv2D') with input shapes: [25,2,2,32], [3,3,32,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7136d5bb644e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlayer4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'VALID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mlayer5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'VALID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mlayer6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'VALID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtf_pca_svd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5fd2d4326b42>\u001b[0m in \u001b[0;36mfeedforward\u001b[1;34m(self, input, stride, padding)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'VALID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayerA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayerA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m    958\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'Conv2D_68' (op: 'Conv2D') with input shapes: [25,2,2,32], [3,3,32,32]."
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID',stride=2)\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "s,U,V  = tf.svd(layer6)\n",
    "S      = tf.matrix_diag(s)\n",
    "smin   = tf.reduce_min(s,0,keepdims=True)\n",
    "smax   = tf.reduce_max(s,0,keepdims=True)\n",
    "ScaledS= (1.0+1.0)*((s-smin)/(smax-smin)) + -1.0\n",
    "layer6 = U @ S @ tf.transpose(V,(0,1,3,2)) * (tf.transpose(tf.abs(V),(0,1,3,2)) * ScaledS[:,:,:,None])\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:39:11.530905Z",
     "start_time": "2018-12-10T00:32:06.763840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/5000 acc : 0.16\n",
      " Current : 0 Acc : 0.20039999850094317 Acc : 0.23999999959487467\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/5000 acc : 0.24\n",
      " Current : 1 Acc : 0.2559999990090728 Acc : 0.2437499992083758\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/5000 acc : 0.32\n",
      " Current : 2 Acc : 0.2781999996677041 Acc : 0.2741249998798594\n",
      "\n",
      "Current Iter : 3/50 batch : 4000/5000 acc : 0.36\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9d9220ed0940>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n\u001b[0;32m     24\u001b[0m                          \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:39:19.664211Z",
     "start_time": "2018-12-10T00:39:19.156538Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID')\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:43:35.113081Z",
     "start_time": "2018-12-10T00:39:20.613625Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.16\n",
      " Current : 0 Acc : 0.18559999890625478 Test Acc : 0.23149999915622174\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 1 Acc : 0.27020000003278255 Test Acc : 0.2868749999208376\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 2 Acc : 0.3077999995648861 Test Acc : 0.3188750006025657\n",
      "\n",
      "Current Iter : 3/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 3 Acc : 0.3429999999701977 Test Acc : 0.346125000086613\n",
      "\n",
      "Current Iter : 4/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 4 Acc : 0.37460000064224 Test Acc : 0.3716250000987202\n",
      "\n",
      "Current Iter : 5/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 5 Acc : 0.3963999993354082 Test Acc : 0.38637499962933364\n",
      "\n",
      "Current Iter : 6/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 6 Acc : 0.4167999990284443 Test Acc : 0.3927499997895211\n",
      "\n",
      "Current Iter : 7/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 7 Acc : 0.4339999989420176 Test Acc : 0.3931249998277053\n",
      "\n",
      "Current Iter : 8/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 8 Acc : 0.46339999720454217 Test Acc : 0.39475000025704504\n",
      "\n",
      "Current Iter : 9/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 9 Acc : 0.4899999975413084 Test Acc : 0.40049999875482173\n",
      "\n",
      "Current Iter : 10/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 10 Acc : 0.5029999983310699 Test Acc : 0.40899999979883433\n",
      "\n",
      "Current Iter : 11/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 11 Acc : 0.5247999999672175 Test Acc : 0.4157499989261851\n",
      "\n",
      "Current Iter : 12/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 12 Acc : 0.5403999998420477 Test Acc : 0.41412499884609133\n",
      "\n",
      "Current Iter : 13/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 13 Acc : 0.5574000008404255 Test Acc : 0.39787499979138374\n",
      "\n",
      "Current Iter : 14/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 14 Acc : 0.5703999997675419 Test Acc : 0.40962499876040964\n",
      "\n",
      "Current Iter : 15/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 15 Acc : 0.6026000016182661 Test Acc : 0.3998750003986061\n",
      "\n",
      "Current Iter : 16/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 16 Acc : 0.6066000016033649 Test Acc : 0.39524999891873447\n",
      "\n",
      "Current Iter : 17/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 17 Acc : 0.6332000017166137 Test Acc : 0.3982499999925494\n",
      "\n",
      "Current Iter : 18/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 18 Acc : 0.6644000041484833 Test Acc : 0.39600000057835133\n",
      "\n",
      "Current Iter : 19/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 19 Acc : 0.6814000041782856 Test Acc : 0.3837499997578561\n",
      "\n",
      "Current Iter : 20/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 20 Acc : 0.7016000032424927 Test Acc : 0.37912500023376194\n",
      "\n",
      "Current Iter : 21/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 21 Acc : 0.7048000013828277 Test Acc : 0.38075000075623394\n",
      "\n",
      "Current Iter : 22/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 22 Acc : 0.716600003093481 Test Acc : 0.38312499984167514\n",
      "\n",
      "Current Iter : 23/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 23 Acc : 0.7392000016570092 Test Acc : 0.38224999902304263\n",
      "\n",
      "Current Iter : 24/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 24 Acc : 0.7620000012218953 Test Acc : 0.38124999923165886\n",
      "\n",
      "Current Iter : 25/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 25 Acc : 0.7653999999165535 Test Acc : 0.35824999993201345\n",
      "\n",
      "Current Iter : 26/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 26 Acc : 0.7798000004887581 Test Acc : 0.3584999999962747\n",
      "\n",
      "Current Iter : 27/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 27 Acc : 0.7792000004649162 Test Acc : 0.35037500080652534\n",
      "\n",
      "Current Iter : 28/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 28 Acc : 0.792199998497963 Test Acc : 0.3438749999506399\n",
      "\n",
      "Current Iter : 29/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 29 Acc : 0.7832000011205673 Test Acc : 0.3798749997746199\n",
      "\n",
      "Current Iter : 30/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 30 Acc : 0.7967999985814095 Test Acc : 0.38312500063329935\n",
      "\n",
      "Current Iter : 31/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 31 Acc : 0.8207999980449676 Test Acc : 0.3850000001490116\n",
      "\n",
      "Current Iter : 32/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 32 Acc : 0.8431999981403351 Test Acc : 0.3776250005234033\n",
      "\n",
      "Current Iter : 33/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 33 Acc : 0.8605999976396561 Test Acc : 0.3807499994058162\n",
      "\n",
      "Current Iter : 34/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 34 Acc : 0.8741999953985214 Test Acc : 0.37699999967589976\n",
      "\n",
      "Current Iter : 35/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 35 Acc : 0.8735999950766563 Test Acc : 0.36987500051036476\n",
      "\n",
      "Current Iter : 36/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 36 Acc : 0.8853999951481819 Test Acc : 0.37324999952688814\n",
      "\n",
      "Current Iter : 37/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 37 Acc : 0.8979999965429306 Test Acc : 0.3631250007078052\n",
      "\n",
      "Current Iter : 38/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 38 Acc : 0.8909999975562095 Test Acc : 0.3723750000121072\n",
      "\n",
      "Current Iter : 39/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 39 Acc : 0.9055999958515167 Test Acc : 0.37837500011082736\n",
      "\n",
      "Current Iter : 40/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 40 Acc : 0.9007999965548515 Test Acc : 0.3712500006426126\n",
      "\n",
      "Current Iter : 41/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 41 Acc : 0.8973999947309494 Test Acc : 0.3759999998146668\n",
      "\n",
      "Current Iter : 42/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 42 Acc : 0.907599995136261 Test Acc : 0.372500000661239\n",
      "\n",
      "Current Iter : 43/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 43 Acc : 0.9155999955534935 Test Acc : 0.3720000007422641\n",
      "\n",
      "Current Iter : 44/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 44 Acc : 0.9291999971866608 Test Acc : 0.37099999936763195\n",
      "\n",
      "Current Iter : 45/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 45 Acc : 0.9313999956846237 Test Acc : 0.37600000121165067\n",
      "\n",
      "Current Iter : 46/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 46 Acc : 0.9199999952316285 Test Acc : 0.36662499972153456\n",
      "\n",
      "Current Iter : 47/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 47 Acc : 0.9367999964952469 Test Acc : 0.36587500022724273\n",
      "\n",
      "Current Iter : 48/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 48 Acc : 0.9285999971628189 Test Acc : 0.3708750002551824\n",
      "\n",
      "Current Iter : 49/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 49 Acc : 0.918799996972084 Test Acc : 0.37887500047218053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:56:07.568679Z",
     "start_time": "2018-12-09T16:56:07.550727Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:02:51.494724Z",
     "start_time": "2018-12-09T23:59:56.331Z"
    }
   },
   "outputs": [],
   "source": [
    "temp   = np.random.randn(100,32,32,3)\n",
    "s,U,V  = tf.svd(temp)\n",
    "S = tf.matrix_diag(s)\n",
    "print(S)\n",
    "print(U,s,V)\n",
    "print(tf.diag(s))\n",
    "\n",
    "result = U @ S @ tf.transpose(V,(0,1,3,2))\n",
    "result = result.eval()\n",
    "\n",
    "print(np.testing.assert_allclose(temp, result))\n",
    "print(np.allclose(temp,result))\n",
    "print(np.equal(temp,result).sum())\n",
    "print(100*32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
