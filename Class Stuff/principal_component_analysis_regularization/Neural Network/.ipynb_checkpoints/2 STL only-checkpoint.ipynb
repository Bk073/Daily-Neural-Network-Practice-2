{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:10.635622Z",
     "start_time": "2018-12-09T23:59:56.266197Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:12.550717Z",
     "start_time": "2018-12-10T00:00:10.638613Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.231677Z",
     "start_time": "2018-12-10T00:00:12.551681Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:00:16.274103Z",
     "start_time": "2018-12-10T00:00:16.235663Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):    return tf.nn.elu(x)\n",
    "def d_tf_elu(x):  return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) + self.b \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "# declare layer \n",
    "def tf_pca_svd(X,mmax=0.8,mmin=0.0): \n",
    "    s,U,V  = tf.svd(X,full_matrices=False)\n",
    "    smin = tf.reduce_min(s,0)\n",
    "    smax = tf.reduce_max(s,0)\n",
    "    ScaledS= (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "    recon_data = U @ tf.diag(s) @ tf.transpose(V) * tf.reduce_mean(tf.abs(V) * ScaledS[None,:],0,keepdims =True)\n",
    "    return recon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:10:34.233767Z",
     "start_time": "2018-12-10T01:10:33.903651Z"
    }
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "l1 = CNN(3,3,16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "\n",
    "l7 = CNN(1,32,64)\n",
    "l8 = CNN(1,64,10)\n",
    "l9 = CNN(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T01:10:35.362754Z",
     "start_time": "2018-12-10T01:10:34.597795Z"
    }
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID',stride=2)\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "s,U,V  = tf.svd(layer6)\n",
    "S      = tf.matrix_diag(s)\n",
    "smin   = tf.reduce_min(s,0,keepdims=True)\n",
    "smax   = tf.reduce_max(s,0,keepdims=True)\n",
    "ScaledS= (1.0-0.0)*((s-smin)/(smax-smin)) + 0.0\n",
    "layer6 = U @ S @ tf.transpose(V,(0,1,3,2)) * (tf.transpose(tf.abs(V),(0,1,3,2)) * ScaledS[:,:,:,None])\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-10T01:10:36.811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 0 Acc : 0.15019999828189612 Test Acc : 0.18312499839812518\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.22\n",
      " Current : 1 Acc : 0.19819999855011702 Test Acc : 0.2219999992987141\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 2 Acc : 0.2529999991506338 Test Acc : 0.2845000000204891\n",
      "\n",
      "Current Iter : 3/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 3 Acc : 0.2830000001564622 Test Acc : 0.2993749994086102\n",
      "\n",
      "Current Iter : 4/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 4 Acc : 0.3060000003129244 Test Acc : 0.31650000042282045\n",
      "\n",
      "Current Iter : 5/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 5 Acc : 0.33120000176131725 Test Acc : 0.34287499950733036\n",
      "\n",
      "Current Iter : 6/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 6 Acc : 0.3538000002130866 Test Acc : 0.35700000016950073\n",
      "\n",
      "Current Iter : 7/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 7 Acc : 0.3711999990791082 Test Acc : 0.3586250010645017\n",
      "\n",
      "Current Iter : 8/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 8 Acc : 0.3847999995201826 Test Acc : 0.3782499999506399\n",
      "\n",
      "Current Iter : 9/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 9 Acc : 0.40620000012218954 Test Acc : 0.3827499996405095\n",
      "\n",
      "Current Iter : 10/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 10 Acc : 0.43019999854266644 Test Acc : 0.38700000001117585\n",
      "\n",
      "Current Iter : 11/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 11 Acc : 0.443799998536706 Test Acc : 0.3898750005522743\n",
      "\n",
      "Current Iter : 12/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 12 Acc : 0.4667999992519617 Test Acc : 0.4024999998509884\n",
      "\n",
      "Current Iter : 13/50 batch : 850/8000 acc : 0.446\r"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels)\n",
    "    test_images,train_labels = shuffle(train_images,train_labels)\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:39:19.664211Z",
     "start_time": "2018-12-10T00:39:19.156538Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_training = tf.placeholder_with_default(input=False,shape=())\n",
    "\n",
    "layer1 = l1.feedforward(x,padding='VALID',stride=2)\n",
    "layer2 = l2.feedforward(layer1,padding='VALID')\n",
    "layer3 = l3.feedforward(layer2,padding='VALID',stride=2)\n",
    "\n",
    "layer4 = l4.feedforward(layer3,padding='VALID',stride=2)\n",
    "layer5 = l5.feedforward(layer4,padding='VALID')\n",
    "layer6 = l6.feedforward(layer5,padding='VALID',stride=2)\n",
    "\n",
    "layer7 = l7.feedforward(layer6,padding='VALID')\n",
    "layer8 = l8.feedforward(layer7,padding='VALID')\n",
    "layer9 = l9.feedforward(layer8,padding='VALID')\n",
    "final_layer   = tf.reduce_mean(layer9,axis=(1,2))\n",
    "\n",
    "cost       = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:43:35.113081Z",
     "start_time": "2018-12-10T00:39:20.613625Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/50 batch : 7975/8000 acc : 0.16\n",
      " Current : 0 Acc : 0.18559999890625478 Test Acc : 0.23149999915622174\n",
      "\n",
      "Current Iter : 1/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 1 Acc : 0.27020000003278255 Test Acc : 0.2868749999208376\n",
      "\n",
      "Current Iter : 2/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 2 Acc : 0.3077999995648861 Test Acc : 0.3188750006025657\n",
      "\n",
      "Current Iter : 3/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 3 Acc : 0.3429999999701977 Test Acc : 0.346125000086613\n",
      "\n",
      "Current Iter : 4/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 4 Acc : 0.37460000064224 Test Acc : 0.3716250000987202\n",
      "\n",
      "Current Iter : 5/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 5 Acc : 0.3963999993354082 Test Acc : 0.38637499962933364\n",
      "\n",
      "Current Iter : 6/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 6 Acc : 0.4167999990284443 Test Acc : 0.3927499997895211\n",
      "\n",
      "Current Iter : 7/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 7 Acc : 0.4339999989420176 Test Acc : 0.3931249998277053\n",
      "\n",
      "Current Iter : 8/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 8 Acc : 0.46339999720454217 Test Acc : 0.39475000025704504\n",
      "\n",
      "Current Iter : 9/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 9 Acc : 0.4899999975413084 Test Acc : 0.40049999875482173\n",
      "\n",
      "Current Iter : 10/50 batch : 7975/8000 acc : 0.48\n",
      " Current : 10 Acc : 0.5029999983310699 Test Acc : 0.40899999979883433\n",
      "\n",
      "Current Iter : 11/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 11 Acc : 0.5247999999672175 Test Acc : 0.4157499989261851\n",
      "\n",
      "Current Iter : 12/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 12 Acc : 0.5403999998420477 Test Acc : 0.41412499884609133\n",
      "\n",
      "Current Iter : 13/50 batch : 7975/8000 acc : 0.42\n",
      " Current : 13 Acc : 0.5574000008404255 Test Acc : 0.39787499979138374\n",
      "\n",
      "Current Iter : 14/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 14 Acc : 0.5703999997675419 Test Acc : 0.40962499876040964\n",
      "\n",
      "Current Iter : 15/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 15 Acc : 0.6026000016182661 Test Acc : 0.3998750003986061\n",
      "\n",
      "Current Iter : 16/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 16 Acc : 0.6066000016033649 Test Acc : 0.39524999891873447\n",
      "\n",
      "Current Iter : 17/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 17 Acc : 0.6332000017166137 Test Acc : 0.3982499999925494\n",
      "\n",
      "Current Iter : 18/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 18 Acc : 0.6644000041484833 Test Acc : 0.39600000057835133\n",
      "\n",
      "Current Iter : 19/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 19 Acc : 0.6814000041782856 Test Acc : 0.3837499997578561\n",
      "\n",
      "Current Iter : 20/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 20 Acc : 0.7016000032424927 Test Acc : 0.37912500023376194\n",
      "\n",
      "Current Iter : 21/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 21 Acc : 0.7048000013828277 Test Acc : 0.38075000075623394\n",
      "\n",
      "Current Iter : 22/50 batch : 7975/8000 acc : 0.44\n",
      " Current : 22 Acc : 0.716600003093481 Test Acc : 0.38312499984167514\n",
      "\n",
      "Current Iter : 23/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 23 Acc : 0.7392000016570092 Test Acc : 0.38224999902304263\n",
      "\n",
      "Current Iter : 24/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 24 Acc : 0.7620000012218953 Test Acc : 0.38124999923165886\n",
      "\n",
      "Current Iter : 25/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 25 Acc : 0.7653999999165535 Test Acc : 0.35824999993201345\n",
      "\n",
      "Current Iter : 26/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 26 Acc : 0.7798000004887581 Test Acc : 0.3584999999962747\n",
      "\n",
      "Current Iter : 27/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 27 Acc : 0.7792000004649162 Test Acc : 0.35037500080652534\n",
      "\n",
      "Current Iter : 28/50 batch : 7975/8000 acc : 0.24\n",
      " Current : 28 Acc : 0.792199998497963 Test Acc : 0.3438749999506399\n",
      "\n",
      "Current Iter : 29/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 29 Acc : 0.7832000011205673 Test Acc : 0.3798749997746199\n",
      "\n",
      "Current Iter : 30/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 30 Acc : 0.7967999985814095 Test Acc : 0.38312500063329935\n",
      "\n",
      "Current Iter : 31/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 31 Acc : 0.8207999980449676 Test Acc : 0.3850000001490116\n",
      "\n",
      "Current Iter : 32/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 32 Acc : 0.8431999981403351 Test Acc : 0.3776250005234033\n",
      "\n",
      "Current Iter : 33/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 33 Acc : 0.8605999976396561 Test Acc : 0.3807499994058162\n",
      "\n",
      "Current Iter : 34/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 34 Acc : 0.8741999953985214 Test Acc : 0.37699999967589976\n",
      "\n",
      "Current Iter : 35/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 35 Acc : 0.8735999950766563 Test Acc : 0.36987500051036476\n",
      "\n",
      "Current Iter : 36/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 36 Acc : 0.8853999951481819 Test Acc : 0.37324999952688814\n",
      "\n",
      "Current Iter : 37/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 37 Acc : 0.8979999965429306 Test Acc : 0.3631250007078052\n",
      "\n",
      "Current Iter : 38/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 38 Acc : 0.8909999975562095 Test Acc : 0.3723750000121072\n",
      "\n",
      "Current Iter : 39/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 39 Acc : 0.9055999958515167 Test Acc : 0.37837500011082736\n",
      "\n",
      "Current Iter : 40/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 40 Acc : 0.9007999965548515 Test Acc : 0.3712500006426126\n",
      "\n",
      "Current Iter : 41/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 41 Acc : 0.8973999947309494 Test Acc : 0.3759999998146668\n",
      "\n",
      "Current Iter : 42/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 42 Acc : 0.907599995136261 Test Acc : 0.372500000661239\n",
      "\n",
      "Current Iter : 43/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 43 Acc : 0.9155999955534935 Test Acc : 0.3720000007422641\n",
      "\n",
      "Current Iter : 44/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 44 Acc : 0.9291999971866608 Test Acc : 0.37099999936763195\n",
      "\n",
      "Current Iter : 45/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 45 Acc : 0.9313999956846237 Test Acc : 0.37600000121165067\n",
      "\n",
      "Current Iter : 46/50 batch : 7975/8000 acc : 0.32\n",
      " Current : 46 Acc : 0.9199999952316285 Test Acc : 0.36662499972153456\n",
      "\n",
      "Current Iter : 47/50 batch : 7975/8000 acc : 0.36\n",
      " Current : 47 Acc : 0.9367999964952469 Test Acc : 0.36587500022724273\n",
      "\n",
      "Current Iter : 48/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 48 Acc : 0.9285999971628189 Test Acc : 0.3708750002551824\n",
      "\n",
      "Current Iter : 49/50 batch : 7975/8000 acc : 0.28\n",
      " Current : 49 Acc : 0.918799996972084 Test Acc : 0.37887500047218053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "avg_acc_train = 0\n",
    "avg_acc_test  = 0\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_training:True})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_training:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  +\n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "        avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 \n",
    "    avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:56:07.568679Z",
     "start_time": "2018-12-09T16:56:07.550727Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T00:02:51.494724Z",
     "start_time": "2018-12-09T23:59:56.331Z"
    }
   },
   "outputs": [],
   "source": [
    "temp   = np.random.randn(100,32,32,3)\n",
    "s,U,V  = tf.svd(temp)\n",
    "S = tf.matrix_diag(s)\n",
    "print(S)\n",
    "print(U,s,V)\n",
    "print(tf.diag(s))\n",
    "\n",
    "result = U @ S @ tf.transpose(V,(0,1,3,2))\n",
    "result = result.eval()\n",
    "\n",
    "print(np.testing.assert_allclose(temp, result))\n",
    "print(np.allclose(temp,result))\n",
    "print(np.equal(temp,result).sum())\n",
    "print(100*32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
 