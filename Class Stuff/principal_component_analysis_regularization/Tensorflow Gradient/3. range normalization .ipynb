{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T03:33:35.400679Z",
     "start_time": "2018-12-17T03:33:22.784337Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-17T03:33:23.691Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-17T03:33:24.624Z"
    },
    "code_folding": [
     15,
     42,
     83,
     90,
     124
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return [self.layer,self.layerA]\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        return [grad,grad_pass]\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_min_max_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,user_max=1.0,user_min=0.0):\n",
    "        self.moving_min = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.moving_max = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.user_min   = tf.Variable(user_min,dtype=tf.float32); \n",
    "        self.user_max   = tf.Variable(user_max,dtype=tf.float32); \n",
    "        \n",
    "    def feedforward(self,input,training_phase):\n",
    "        self.input    = input\n",
    "        self.min_vec  = tf.reduce_min(input,-1)[:,None]\n",
    "        self.min_index= tf.argmin(input,-1)\n",
    "        self.max_vec  = tf.reduce_max(input,-1)[:,None]\n",
    "        self.max_index= tf.argmax(input,-1)\n",
    "        \n",
    "        def training_fn():\n",
    "            normalized_data = (self.user_max-self.user_min)  * \\\n",
    "            ((self.input - self.min_vec)/(self.max_vec - self.min_vec))          + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min * 0.9 + 0.1 * self.min_vec))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max * 0.9 + 0.1 * self.max_vec))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            normalized_data = (self.user_max-self.user_min) * \\\n",
    "            ((self.input - self.moving_min)/(self.moving_max - self.moving_min)) + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        self.output,update_min_max = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_min_max\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad1   = grad\n",
    "        \n",
    "        # Create Mask for min / max value for row\n",
    "        indices = tf.range(0, self.input.shape[0].value,dtype=tf.int64)\n",
    "        min_indices = tf.stack([indices, self.min_index], axis=1)\n",
    "        max_indices = tf.stack([indices, self.max_index], axis=1)\n",
    "        grad_min = tf.cast(tf.sparse_to_dense(min_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        grad_max = tf.cast(tf.sparse_to_dense(max_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        \n",
    "        grad_max_min = 1.0/(self.max_vec-self.min_vec)\n",
    "        grad_pass    = grad1 * (self.user_max-self.user_min) * (\n",
    "            grad_max_min + \\\n",
    "            (self.input - self.max_vec)/tf.square(grad_max_min) * grad_min + \\\n",
    "            (self.min_vec - self.input)/tf.square(grad_max_min) * grad_max\n",
    "        )\n",
    "        \n",
    "        return grad_pass\n",
    "    \n",
    "def show_histogram(layer1,layer1a,grad1w,grad1p):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(141); plt.hist(layer1. ravel(),batch_size); plt.title('layer')\n",
    "    plt.subplot(142); plt.hist(layer1a.ravel(),batch_size); plt.title('layer a')\n",
    "    plt.subplot(143); plt.hist(grad1w.ravel(),batch_size); plt.title('grad w')\n",
    "    plt.subplot(144); plt.hist(grad1p.ravel(),batch_size); plt.title('grad p')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-17T03:33:28.335Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# declare layers and the data \n",
    "sess = tf.InteractiveSession()\n",
    "batch_size = 20 \n",
    "x_data     = train_images[:batch_size].astype(np.float32)\n",
    "x_label    = train_labels[:batch_size].astype(np.float32)\n",
    "\n",
    "l1 = CNN(3,3, 16); l1n = tf_min_max_layer(batch_size,user_max=0.5,user_min=-0.5)\n",
    "l2 = CNN(3,16,16); l2n = tf_min_max_layer(batch_size,user_max=0.5,user_min=-0.5)\n",
    "l3 = CNN(3,16,16); l3n = tf_min_max_layer(batch_size,user_max=0.5,user_min=-0.5)\n",
    "l4 = CNN(3,16,16); l4n = tf_min_max_layer(batch_size,user_max=0.5,user_min=-0.5)\n",
    "l5 = CNN(3,16,16); l5n = tf_min_max_layer(batch_size,user_max=0.5,user_min=-0.5)\n",
    "l6 = CNN(3,16,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-17T03:33:34.246Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ranged norm\n",
    "sess.run(tf.global_variables_initializer())\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "layer1,layer1a = l1.feedforward(x_data, stride=2)\n",
    "layer1a   = tf.reshape(layer1a,(batch_size,-1))\n",
    "layer1b,_ = l1n.feedforward(layer1a,is_train)\n",
    "layer1b   = tf.reshape(layer1b,(batch_size,48,48,16))\n",
    "\n",
    "layer2,layer2a = l2.feedforward(layer1b,stride=2)\n",
    "layer2a   = tf.reshape(layer2a,(batch_size,-1))\n",
    "layer2b,_ = l2n.feedforward(layer2a,is_train)\n",
    "layer2b   = tf.reshape(layer2b,(batch_size,24,24,16))\n",
    "\n",
    "layer3,layer3a = l3.feedforward(layer2b,stride=2)\n",
    "layer3a   = tf.reshape(layer3a,(batch_size,-1))\n",
    "layer3b,_ = l3n.feedforward(layer3a,is_train)\n",
    "layer3b   = tf.reshape(layer3b,(batch_size,12,12,16))\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3b,stride=2)\n",
    "layer4a   = tf.reshape(layer4a,(batch_size,-1))\n",
    "layer4b,_ = l4n.feedforward(layer4a,is_train)\n",
    "layer4b   = tf.reshape(layer4b,(batch_size,6,6,16))\n",
    "\n",
    "layer5,layer5a = l5.feedforward(layer4b,stride=2)\n",
    "layer5a   = tf.reshape(layer5a,(batch_size,-1))\n",
    "layer5b,_ = l5n.feedforward(layer5a,is_train)\n",
    "layer5b   = tf.reshape(layer5b,(batch_size,3,3,16))\n",
    "\n",
    "layer6,layer6a = l6.feedforward(layer5b,stride=1,padding='VALID')\n",
    "\n",
    "final_softmax  = tf_softmax(tf.squeeze(layer6a))\n",
    "cost  = - tf.reduce_mean(x_label * tf.log(final_softmax + 1e-8))\n",
    "dcost = (tf.squeeze(layer6a) - x_label)[:,None,None,:]\n",
    "\n",
    "grad6w,grad6p = l6.backprop(dcost,stride=1,padding='VALID')\n",
    "grad6p  = tf.reshape(grad6p,(batch_size,-1))\n",
    "grad6pb = l5n.backprop(grad6p)\n",
    "grad6pb = tf.reshape(grad6pb,(batch_size,3,3,16))\n",
    "\n",
    "grad5w,grad5p = l5.backprop(grad6pb,stride=2)\n",
    "grad5p  = tf.reshape(grad5p,(batch_size,-1))\n",
    "grad5pb = l4n.backprop(grad5p)\n",
    "grad5pb = tf.reshape(grad5pb,(batch_size,6,6,16))\n",
    "\n",
    "grad4w,grad4p = l4.backprop(grad5pb,stride=2)\n",
    "grad4p  = tf.reshape(grad4p,(batch_size,-1))\n",
    "grad4pb = l3n.backprop(grad4p)\n",
    "grad4pb = tf.reshape(grad4pb,(batch_size,12,12,16))\n",
    "\n",
    "grad3w,grad3p = l3.backprop(grad4pb,stride=2)\n",
    "grad3p  = tf.reshape(grad3p,(batch_size,-1))\n",
    "grad3pb = l2n.backprop(grad3p)\n",
    "grad3pb = tf.reshape(grad3pb,(batch_size,24,24,16))\n",
    "\n",
    "grad2w,grad2p = l2.backprop(grad3pb,stride=2)\n",
    "grad2p  = tf.reshape(grad2p,(batch_size,-1))\n",
    "grad2pb = l1n.backprop(grad2p)\n",
    "grad2pb = tf.reshape(grad2pb,(batch_size,48,48,16))\n",
    "\n",
    "grad1w,grad1p = l1.backprop(grad2pb,stride=2)\n",
    "\n",
    "# evaluate all of the layers\n",
    "layer1,layer1a=layer1.eval(),layer1a.eval()\n",
    "layer2,layer2a=layer2.eval(),layer2a.eval()\n",
    "layer3,layer3a=layer3.eval(),layer3a.eval()\n",
    "layer4,layer4a=layer4.eval(),layer4a.eval()\n",
    "layer5,layer5a=layer5.eval(),layer5a.eval()\n",
    "layer6,layer6a=layer6.eval(),layer6a.eval()\n",
    "\n",
    "grad6w,grad6p = grad6w.eval(),grad6p.eval()\n",
    "grad5w,grad5p = grad5w.eval(),grad5p.eval()\n",
    "grad4w,grad4p = grad4w.eval(),grad4p.eval()\n",
    "grad3w,grad3p = grad3w.eval(),grad3p.eval()\n",
    "grad2w,grad2p = grad2w.eval(),grad2p.eval()\n",
    "grad1w,grad1p = grad1w.eval(),grad1p.eval()\n",
    "\n",
    "show_histogram(layer1,layer1a,grad1w,grad1p)\n",
    "show_histogram(layer2,layer2a,grad2w,grad2p)\n",
    "show_histogram(layer3,layer3a,grad3w,grad3p)\n",
    "show_histogram(layer4,layer4a,grad4w,grad4p)\n",
    "show_histogram(layer5,layer5a,grad5w,grad5p)\n",
    "show_histogram(layer6,layer6a,grad6w,grad6p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T16:46:48.255187Z",
     "start_time": "2018-12-14T16:46:48.250225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T20:18:06.761198Z",
     "start_time": "2018-12-15T20:18:02.663286Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple\n",
    "random_distribution = 0.06 * np.random.randn(1,1000000).astype(np.float32) + 100\n",
    "temp_layer          = tf_min_max_layer(1,-0.5,0.5)\n",
    "\n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "changed,_      = temp_layer.feedforward(random_distribution,is_train)\n",
    "changed        = changed.eval()\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121); plt.hist(random_distribution.ravel(),batch_size); plt.title('Random')\n",
    "plt.subplot(122); plt.hist(changed.ravel(),batch_size); plt.title('After')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T19:05:26.087958Z",
     "start_time": "2018-12-14T19:05:25.618214Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. generator, B. (2018). Bernoulli random number generator. Stack Overflow. Retrieved 14 December 2018, from https://stackoverflow.com/questions/47012474/bernoulli-random-number-generator\n",
    "2. right?, D. (2018). Derivative of Binary Cross Entropy - why are my signs not right?. Mathematics Stack Exchange. Retrieved 14 December 2018, from https://math.stackexchange.com/questions/2503428/derivative-of-binary-cross-entropy-why-are-my-signs-not-right\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
