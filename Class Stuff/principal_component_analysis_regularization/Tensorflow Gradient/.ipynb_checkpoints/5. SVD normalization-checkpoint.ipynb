{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T03:30:33.889085Z",
     "start_time": "2018-12-16T03:30:27.419589Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T05:22:09.343538Z",
     "start_time": "2018-12-16T05:22:07.009627Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T05:22:09.966895Z",
     "start_time": "2018-12-16T05:22:09.877112Z"
    },
    "code_folding": [
     42,
     83,
     90,
     124,
     165,
     185,
     241,
     272
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return [self.layer,self.layerA]\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        return [grad,grad_pass]\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self,lmbda=2.0):\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = (tf.pow((data + 1.0),self.lmbda) - 1.0)/self.lmbda\n",
    "        return self.layer \n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad_input = tf.pow((self.input + 1),self.lmbda-1.0)\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda = tf.pow((self.input+1),self.lmbda) * \\\n",
    "        (tf.log(self.input+1)*self.lmbda -1) + 1\n",
    "        grad_lmbda = grad_lmbda / (self.lmbda ** 2)\n",
    "        \n",
    "        return grad_input * grad\n",
    "\n",
    "class tf_min_max_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,user_max=1.0,user_min=0.0):\n",
    "        self.moving_min = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.moving_max = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.user_min   = tf.Variable(user_min,dtype=tf.float32); \n",
    "        self.user_max   = tf.Variable(user_max,dtype=tf.float32); \n",
    "        \n",
    "    def feedforward(self,input,training_phase):\n",
    "        self.input    = input\n",
    "        self.min_vec  = tf.reduce_min(input,-1)[:,None]\n",
    "        self.min_index= tf.argmin(input,-1)\n",
    "        self.max_vec  = tf.reduce_max(input,-1)[:,None]\n",
    "        self.max_index= tf.argmax(input,-1)\n",
    "        \n",
    "        def training_fn():\n",
    "            normalized_data = (self.user_max-self.user_min)  * \\\n",
    "            ((self.input - self.min_vec)/(self.max_vec - self.min_vec))          + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min * 0.9 + 0.1 * self.min_vec))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max * 0.9 + 0.1 * self.max_vec))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            normalized_data = (self.user_max-self.user_min) * \\\n",
    "            ((self.input - self.moving_min)/(self.moving_max - self.moving_min)) + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        self.output,update_min_max = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_min_max\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad1   = grad\n",
    "        \n",
    "        # Create Mask for min / max value for row\n",
    "        indices = tf.range(0, self.input.shape[0].value,dtype=tf.int64)\n",
    "        min_indices = tf.stack([indices, self.min_index], axis=1)\n",
    "        max_indices = tf.stack([indices, self.max_index], axis=1)\n",
    "        grad_min = tf.cast(tf.sparse_to_dense(min_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        grad_max = tf.cast(tf.sparse_to_dense(max_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        \n",
    "        grad_max_min = 1.0/(self.max_vec-self.min_vec)\n",
    "        grad_pass    = grad1 * (self.user_max-self.user_min) * (\n",
    "            grad_max_min + \\\n",
    "            (self.input - self.max_vec)/tf.square(grad_max_min) * grad_min + \\\n",
    "            (self.min_vec - self.input)/tf.square(grad_max_min) * grad_max\n",
    "        )\n",
    "        \n",
    "        return grad_pass\n",
    "\n",
    "class tf_svd_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,channel_size):\n",
    "        self.moving_s = tf.Variable(tf.zeros((batch_size,channel_size),dtype=tf.float32))\n",
    "    \n",
    "    def feedforward(self,data,training_phase):\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            s,U,V = tf.svd(data)\n",
    "\n",
    "        smean,sstd = tf.nn.moments(s, axes=(-1))\n",
    "\n",
    "        def training_fn():\n",
    "            snorm  = (s-smean[:,None])/sstd[:,None] + smean[:,None]\n",
    "            data   = U @ tf.matrix_diag(snorm) @ tf.transpose(V,(0,2,1))\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_s,self.moving_s*0.9 + 0.1 * snorm))\n",
    "            return data,update\n",
    "            \n",
    "        def testing_fn():\n",
    "            data   = U @ tf.matrix_diag(self.moving_s) @ tf.transpose(V,(0,2,1))\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_s,self.moving_s))\n",
    "            return data,update\n",
    "        \n",
    "        data,update  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return data,update\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        raise NotImplemented('Do not rely on Auto Differentiation')\n",
    "    \n",
    "def show_histogram(layer1,layer1a,grad1w,grad1p):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(141); plt.hist(layer1. ravel(),batch_size); plt.title('layer')\n",
    "    plt.subplot(142); plt.hist(layer1a.ravel(),batch_size); plt.title('layer a')\n",
    "    plt.subplot(143); plt.hist(grad1w.ravel(),batch_size); plt.title('grad w')\n",
    "    plt.subplot(144); plt.hist(grad1p.ravel(),batch_size); plt.title('grad p')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T05:28:10.848976Z",
     "start_time": "2018-12-16T05:28:10.690171Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# declare layers and the data \n",
    "# sess = tf.InteractiveSession()\n",
    "batch_size = 20 \n",
    "x_data     = train_images[:batch_size].astype(np.float32)\n",
    "x_label    = train_labels[:batch_size].astype(np.float32)\n",
    "\n",
    "l1 = CNN(3,3, 16); l1bc = tf_svd_layer(batch_size,16)\n",
    "l2 = CNN(3,16,16); l2bc = tf_svd_layer(batch_size,16)\n",
    "l3 = CNN(3,16,16); l3bc = tf_svd_layer(batch_size,16)\n",
    "l4 = CNN(3,16,16); l4bc = tf_svd_layer(batch_size,16)\n",
    "l5 = CNN(3,16,16); l5bc = tf_svd_layer(batch_size,9)\n",
    "l6 = CNN(3,16,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T05:29:07.293672Z",
     "start_time": "2018-12-16T05:29:02.102890Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# svd\n",
    "sess.run(tf.global_variables_initializer())\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x_data, stride=2)\n",
    "layer1a = tf.reshape(layer1a,(batch_size,48*48,16))\n",
    "layer1b,_       = l1bc.feedforward(layer1a,is_train)\n",
    "layer1b = tf.reshape(layer1b,(batch_size,48,48,16))\n",
    "\n",
    "layer2,layer2a = l2.feedforward(layer1b,stride=2)\n",
    "layer2a = tf.reshape(layer2a,(batch_size,24*24,16))\n",
    "layer2b,_        = l2bc.feedforward(layer2a,is_train)\n",
    "layer2b = tf.reshape(layer2b,(batch_size,24,24,16))\n",
    "\n",
    "layer3,layer3a = l3.feedforward(layer2b,stride=2)\n",
    "layer3a = tf.reshape(layer3a,(batch_size,12*12,16))\n",
    "layer3b,_        = l3bc.feedforward(layer3a,is_train)\n",
    "layer3b = tf.reshape(layer3b,(batch_size,12,12,16))\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3b,stride=2)\n",
    "layer4a = tf.reshape(layer4a,(batch_size,6*6,16))\n",
    "layer4b,_        = l4bc.feedforward(layer4a,is_train)\n",
    "layer4b = tf.reshape(layer4b,(batch_size,6,6,16))\n",
    "\n",
    "layer5,layer5a = l5.feedforward(layer4b,stride=2)\n",
    "layer5a = tf.reshape(layer5,(batch_size,3*3,16))\n",
    "layer5a = tf.transpose(layer5a,(0,2,1))\n",
    "layer5b,_        = l5bc.feedforward(layer5a,is_train)\n",
    "layer5b = tf.transpose(layer5b,(0,2,1))\n",
    "layer5b = tf.reshape(layer5b,(batch_size,3,3,16))\n",
    "\n",
    "layer6,layer6a = l6.feedforward(layer5b,stride=1,padding='VALID')\n",
    "\n",
    "final_softmax  = tf_softmax(tf.squeeze(layer6a))\n",
    "cost  = - tf.reduce_mean(x_label * tf.log(final_softmax + 1e-8))\n",
    "dcost = (tf.squeeze(layer6a) - x_label)[:,None,None,:]\n",
    "\n",
    "# grad6w,grad6p = l6.backprop(dcost,stride=1,padding='VALID')\n",
    "# grad6pb = l5bc.backprop(grad6p)\n",
    "# grad5w,grad5p = l5.backprop(grad6pb,stride=2)\n",
    "# grad5pb = l4bc.backprop(grad5p)\n",
    "# grad4w,grad4p = l4.backprop(grad5pb,stride=2)\n",
    "# grad4pb = l3bc.backprop(grad4p)\n",
    "# grad3w,grad3p = l3.backprop(grad4pb,stride=2)\n",
    "# grad3pb = l2bc.backprop(grad3p)\n",
    "# grad2w,grad2p = l2.backprop(grad3pb,stride=2)\n",
    "# grad2pb = l1bc.backprop(grad2p)\n",
    "# grad1w,grad1p = l1.backprop(grad2pb,stride=2)\n",
    "\n",
    "# evaluate all of the layers\n",
    "layer1,layer1a=layer1.eval(),layer1a.eval()\n",
    "layer2,layer2a=layer2.eval(),layer2a.eval()\n",
    "layer3,layer3a=layer3.eval(),layer3a.eval()\n",
    "layer4,layer4a=layer4.eval(),layer4a.eval()\n",
    "layer5,layer5a=layer5.eval(),layer5a.eval()\n",
    "layer6,layer6a=layer6.eval(),layer6a.eval()\n",
    "\n",
    "# grad6w,grad6p = grad6w.eval(),grad6p.eval()\n",
    "# grad5w,grad5p = grad5w.eval(),grad5p.eval()\n",
    "# grad4w,grad4p = grad4w.eval(),grad4p.eval()\n",
    "# grad3w,grad3p = grad3w.eval(),grad3p.eval()\n",
    "# grad2w,grad2p = grad2w.eval(),grad2p.eval()\n",
    "# grad1w,grad1p = grad1w.eval(),grad1p.eval()\n",
    "\n",
    "# show_histogram(layer1,layer1a,grad1w,grad1p)\n",
    "# show_histogram(layer2,layer2a,grad1w,grad2p)\n",
    "# show_histogram(layer3,layer3a,grad2w,grad3p)\n",
    "# show_histogram(layer4,layer4a,grad3w,grad4p)\n",
    "# show_histogram(layer5,layer5a,grad4w,grad5p)\n",
    "# show_histogram(layer6,layer6a,grad5w,grad6p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T16:46:48.255187Z",
     "start_time": "2018-12-14T16:46:48.250225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T05:14:25.793854Z",
     "start_time": "2018-12-16T05:14:24.716935Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15827622 0.2785311\n",
      "-5.585176e-08 1.0\n"
     ]
    }
   ],
   "source": [
    "# reconstruct using norm svd\n",
    "layert = tf_svd_layer(batch_size,3)\n",
    "temp   = np.reshape(x_data,(batch_size,96*96,3))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "results,_ = layert.feedforward(temp,tf.placeholder_with_default(True,()))\n",
    "results   = np.reshape(results.eval(),(batch_size,96,96,3))\n",
    "\n",
    "x_std = (x_data-x_data.mean((1,2),keepdims=True))/x_data.std((1,2),keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131); plt.hist(x_data.ravel(),batch_size); plt.title('Original')\n",
    "plt.subplot(132); plt.hist(recon.ravel(), batch_size); plt.title('Recon')\n",
    "plt.subplot(133); plt.hist(x_std.ravel(), batch_size); plt.title('STD')\n",
    "plt.show()   \n",
    "\n",
    "print(recon.mean(),recon.std())\n",
    "print(x_std.mean(),x_std.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T04:50:59.316183Z",
     "start_time": "2018-12-16T04:50:59.300228Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T00:32:05.749486Z",
     "start_time": "2018-12-16T00:32:05.449256Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. generator, B. (2018). Bernoulli random number generator. Stack Overflow. Retrieved 14 December 2018, from https://stackoverflow.com/questions/47012474/bernoulli-random-number-generator\n",
    "2. right?, D. (2018). Derivative of Binary Cross Entropy - why are my signs not right?. Mathematics Stack Exchange. Retrieved 14 December 2018, from https://math.stackexchange.com/questions/2503428/derivative-of-binary-cross-entropy-why-are-my-signs-not-right\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
