{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:07:40.886877Z",
     "start_time": "2018-12-14T17:07:40.879898Z"
    }
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:07:43.239150Z",
     "start_time": "2018-12-14T17:07:43.219231Z"
    },
    "code_folding": [
     38
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class FNN():\n",
    "    \n",
    "    def __init__(self,inc,outc,act,dact):\n",
    "        self.w = tf.Variable(tf.random_normal((inc,outc),stddev=0.01))\n",
    "        self.act = act \n",
    "        self.dact= dact\n",
    "        \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = data @ self.w\n",
    "        self.layera= self.act(self.layer)\n",
    "        return [self.layer,self.layera]\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad1 = grad\n",
    "        grad2 = self.dact(self.layer)\n",
    "        grad3 = self.input\n",
    "        grad_middle = grad1 * grad2\n",
    "        \n",
    "        gradw = tf.transpose(self.input) @ grad_middle\n",
    "        gradp = grad_middle @ tf.transpose(self.w)\n",
    "        \n",
    "        return [gradw,gradp]\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,axis):\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.c = self.input_size[0].value,self.input_size[1].value\n",
    "\n",
    "        self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "        self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "        centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "        \n",
    "        return centered_data\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:07:46.423802Z",
     "start_time": "2018-12-14T17:07:46.369948Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare layers and the data \n",
    "# sess = tf.InteractiveSession()\n",
    "batch_size = 20 \n",
    "x_data     = np.random.uniform(0,1,(batch_size,100)).astype(np.float32)\n",
    "x_label    = np.random.binomial(size=(batch_size,1), n=1, p= 0.5)\n",
    "\n",
    "l1 = FNN(100,64,tf_relu,d_tf_relu)\n",
    "l1b= tf_batch_norm_layer(0)\n",
    "l2 = FNN(64,32,tf_relu,d_tf_relu)\n",
    "l2b= tf_batch_norm_layer(0)\n",
    "l3 = FNN(32,16,tf_relu,d_tf_relu)\n",
    "l3b= tf_batch_norm_layer(0)\n",
    "l4 = FNN(16,1,tf_sigmoid,d_tf_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-14T17:07:46.753Z"
    }
   },
   "outputs": [],
   "source": [
    "# feed forwward operation without batch norm\n",
    "sess.run(tf.global_variables_initializer())\n",
    "layer1,layer1a = l1.feedforward(x_data)\n",
    "layer2,layer2a = l2.feedforward(layer1a)\n",
    "layer3,layer3a = l3.feedforward(layer2a)\n",
    "layer4,layer4a = l4.feedforward(layer3a)\n",
    "\n",
    "cost  = - tf.reduce_mean(x_label * tf.log(layer4a+1e-8) + (1-x_label) * tf.log(1-layer4a + 1e-8))\n",
    "dcost = ((x_label-layer4a)/(layer4a-layer4a * layer4a))/batch_size\n",
    "\n",
    "grad4w,grad4p = l4.backprop(dcost)\n",
    "grad3w,grad3p = l3.backprop(grad4p)\n",
    "grad2w,grad2p = l2.backprop(grad3p)\n",
    "grad1w,grad1p = l1.backprop(grad2p)\n",
    "\n",
    "# evaluate all of the layers\n",
    "layer1,layer1a=layer1.eval(),layer1a.eval()\n",
    "layer2,layer2a=layer2.eval(),layer2a.eval()\n",
    "layer3,layer3a=layer3.eval(),layer3a.eval()\n",
    "layer4,layer4a=layer4.eval(),layer4a.eval()\n",
    "\n",
    "grad4w,grad4p = grad4w.eval(),grad4p.eval()\n",
    "grad3w,grad3p = grad3w.eval(),grad3p.eval()\n",
    "grad2w,grad2p = grad2w.eval(),grad2p.eval()\n",
    "grad1w,grad1p = grad1w.eval(),grad1p.eval()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121); plt.hist(layer1. ravel(),batch_size); plt.title('layer')\n",
    "plt.subplot(122); plt.hist(layer1a.ravel(),batch_size); plt.title('layer a')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121); plt.hist(layer2. ravel(),batch_size); plt.title('layer')\n",
    "plt.subplot(122); plt.hist(layer2a.ravel(),batch_size); plt.title('layer a')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121); plt.hist(layer3. ravel(),batch_size); plt.title('layer')\n",
    "plt.subplot(122); plt.hist(layer3a.ravel(),batch_size); plt.title('layer a')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121); plt.hist(layer4. ravel(),batch_size); plt.title('layer')\n",
    "plt.subplot(122); plt.hist(layer4a.ravel(),batch_size); plt.title('layer a')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:05:48.402938Z",
     "start_time": "2018-12-14T17:05:48.203471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T17:05:44.893570Z",
     "start_time": "2018-12-14T17:05:44.887585Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T16:46:48.255187Z",
     "start_time": "2018-12-14T16:46:48.250225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. generator, B. (2018). Bernoulli random number generator. Stack Overflow. Retrieved 14 December 2018, from https://stackoverflow.com/questions/47012474/bernoulli-random-number-generator\n",
    "2. right?, D. (2018). Derivative of Binary Cross Entropy - why are my signs not right?. Mathematics Stack Exchange. Retrieved 14 December 2018, from https://math.stackexchange.com/questions/2503428/derivative-of-binary-cross-entropy-why-are-my-signs-not-right\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
