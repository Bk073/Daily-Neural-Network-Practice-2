{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:23:18.736997Z",
     "start_time": "2018-12-15T23:23:15.273119Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:23:21.163561Z",
     "start_time": "2018-12-15T23:23:18.746728Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:34:12.931417Z",
     "start_time": "2018-12-15T23:34:12.785247Z"
    },
    "code_folding": [
     15,
     42,
     83,
     90,
     124,
     165,
     179,
     235
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return [self.layer,self.layerA]\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "        \n",
    "        return [grad,grad_pass]\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self,lmbda=2.0):\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = (tf.pow((data + 1.0),self.lmbda) - 1.0)/self.lmbda\n",
    "        return self.layer \n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad_input = tf.pow((self.input + 1),self.lmbda-1.0)\n",
    "        return grad_input * grad\n",
    "\n",
    "class tf_min_max_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,user_max=1.0,user_min=0.0):\n",
    "        self.moving_min = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.moving_max = tf.Variable(tf.zeros(shape=(vector_shape,1),dtype=tf.float32))\n",
    "        self.user_min   = tf.Variable(user_min,dtype=tf.float32); \n",
    "        self.user_max   = tf.Variable(user_max,dtype=tf.float32); \n",
    "        \n",
    "    def feedforward(self,input,training_phase):\n",
    "        self.input    = input\n",
    "        self.min_vec  = tf.reduce_min(input,-1)[:,None]\n",
    "        self.min_index= tf.argmin(input,-1)\n",
    "        self.max_vec  = tf.reduce_max(input,-1)[:,None]\n",
    "        self.max_index= tf.argmax(input,-1)\n",
    "        \n",
    "        def training_fn():\n",
    "            normalized_data = (self.user_max-self.user_min)  * \\\n",
    "            ((self.input - self.min_vec)/(self.max_vec - self.min_vec))          + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min * 0.9 + 0.1 * self.min_vec))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max * 0.9 + 0.1 * self.max_vec))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            normalized_data = (self.user_max-self.user_min) * \\\n",
    "            ((self.input - self.moving_min)/(self.moving_max - self.moving_min)) + self.user_min\n",
    "            \n",
    "            update_min_max = []\n",
    "            update_min_max.append(tf.assign(self.moving_min,self.moving_min))\n",
    "            update_min_max.append(tf.assign(self.moving_max,self.moving_max))\n",
    "            return normalized_data,update_min_max\n",
    "        \n",
    "        self.output,update_min_max = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_min_max\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad1   = grad\n",
    "        \n",
    "        # Create Mask for min / max value for row\n",
    "        indices = tf.range(0, self.input.shape[0].value,dtype=tf.int64)\n",
    "        min_indices = tf.stack([indices, self.min_index], axis=1)\n",
    "        max_indices = tf.stack([indices, self.max_index], axis=1)\n",
    "        grad_min = tf.cast(tf.sparse_to_dense(min_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        grad_max = tf.cast(tf.sparse_to_dense(max_indices, self.input.shape, sparse_values=1, default_value=0),dtype=tf.float32)\n",
    "        \n",
    "        grad_max_min = 1.0/(self.max_vec-self.min_vec)\n",
    "        grad_pass    = grad1 * (self.user_max-self.user_min) * (\n",
    "            grad_max_min + \\\n",
    "            (self.input - self.max_vec)/tf.square(grad_max_min) * grad_min + \\\n",
    "            (self.min_vec - self.input)/tf.square(grad_max_min) * grad_max\n",
    "        )\n",
    "        \n",
    "        return grad_pass\n",
    "\n",
    "def show_histogram(layer1,layer1a,grad1w,grad1p):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(141); plt.hist(layer1. ravel(),batch_size); plt.title('layer')\n",
    "    plt.subplot(142); plt.hist(layer1a.ravel(),batch_size); plt.title('layer a')\n",
    "    plt.subplot(143); plt.hist(grad1w.ravel(),batch_size); plt.title('grad w')\n",
    "    plt.subplot(144); plt.hist(grad1p.ravel(),batch_size); plt.title('grad p')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:38:59.804455Z",
     "start_time": "2018-12-15T23:38:59.675544Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# declare layers and the data \n",
    "# sess = tf.InteractiveSession()\n",
    "batch_size = 20 \n",
    "x_data     = train_images[:batch_size].astype(np.float32)\n",
    "x_label    = train_labels[:batch_size].astype(np.float32)\n",
    "\n",
    "l1 = CNN(3,3, 16); l1bc = tf_box_cox()\n",
    "l2 = CNN(3,16,16); l2bc = tf_box_cox()\n",
    "l3 = CNN(3,16,16); l3bc = tf_box_cox()\n",
    "l4 = CNN(3,16,16); l4bc = tf_box_cox()\n",
    "l5 = CNN(3,16,16); l5bc = tf_box_cox()\n",
    "l6 = CNN(3,16,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T23:38:34.473138Z",
     "start_time": "2018-12-15T23:38:34.088167Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tf_min_max_layer' object has no attribute 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-332166f3252c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mgrad2w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad2p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad3pb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mgrad2p\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad2p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mgrad2pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad2p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mgrad2pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad2pb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-eec46c0e7f5e>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# Create Mask for min / max value for row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         \u001b[0mmin_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mmax_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tf_min_max_layer' object has no attribute 'input'"
     ]
    }
   ],
   "source": [
    "# box cox\n",
    "sess.run(tf.global_variables_initializer())\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "layer1,layer1a = l1.feedforward(x_data, stride=2)\n",
    "layer1b        = box_cox_layer.feedforward(layer1a)\n",
    "\n",
    "layer2,layer2a = l2.feedforward(layer1b,stride=2)\n",
    "layer2b        = box_cox_layer.feedforward(layer2a)\n",
    "\n",
    "layer3,layer3a = l3.feedforward(layer2b,stride=2)\n",
    "layer3b        = box_cox_layer.feedforward(layer3a)\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3b,stride=2)\n",
    "layer4b        = box_cox_layer.feedforward(layer4a)\n",
    "\n",
    "layer5,layer5a = l5.feedforward(layer4b,stride=2)\n",
    "layer5b        = box_cox_layer.feedforward(layer5a)\n",
    "\n",
    "layer6,layer6a = l6.feedforward(layer5b,stride=1,padding='VALID')\n",
    "\n",
    "final_softmax  = tf_softmax(tf.squeeze(layer6a))\n",
    "cost  = - tf.reduce_mean(x_label * tf.log(final_softmax + 1e-8))\n",
    "dcost = (tf.squeeze(layer6a) - x_label)[:,None,None,:]\n",
    "\n",
    "grad6w,grad6p = l6.backprop(dcost,stride=1,padding='VALID')\n",
    "grad6p  = tf.reshape(grad6p,(batch_size,-1))\n",
    "grad6pb = l5n.backprop(grad6p)\n",
    "grad6pb = tf.reshape(grad6pb,(batch_size,3,3,16))\n",
    "\n",
    "grad5w,grad5p = l5.backprop(grad6pb,stride=2)\n",
    "grad5p  = tf.reshape(grad5p,(batch_size,-1))\n",
    "grad5pb = l4n.backprop(grad5p)\n",
    "grad5pb = tf.reshape(grad5pb,(batch_size,6,6,16))\n",
    "\n",
    "grad4w,grad4p = l4.backprop(grad5pb,stride=2)\n",
    "grad4p  = tf.reshape(grad4p,(batch_size,-1))\n",
    "grad4pb = l3n.backprop(grad4p)\n",
    "grad4pb = tf.reshape(grad4pb,(batch_size,12,12,16))\n",
    "\n",
    "grad3w,grad3p = l3.backprop(grad4pb,stride=2)\n",
    "grad3p  = tf.reshape(grad3p,(batch_size,-1))\n",
    "grad3pb = l2n.backprop(grad3p)\n",
    "grad3pb = tf.reshape(grad3pb,(batch_size,24,24,16))\n",
    "\n",
    "grad2w,grad2p = l2.backprop(grad3pb,stride=2)\n",
    "grad2p  = tf.reshape(grad2p,(batch_size,-1))\n",
    "grad2pb = l1n.backprop(grad2p)\n",
    "grad2pb = tf.reshape(grad2pb,(batch_size,48,48,16))\n",
    "\n",
    "grad1w,grad1p = l1.backprop(grad2pb,stride=2)\n",
    "\n",
    "# evaluate all of the layers\n",
    "layer1,layer1a=layer1.eval(),layer1a.eval()\n",
    "layer2,layer2a=layer2.eval(),layer2a.eval()\n",
    "layer3,layer3a=layer3.eval(),layer3a.eval()\n",
    "layer4,layer4a=layer4.eval(),layer4a.eval()\n",
    "layer5,layer5a=layer5.eval(),layer5a.eval()\n",
    "layer6,layer6a=layer6.eval(),layer6a.eval()\n",
    "\n",
    "grad6w,grad6p = grad6w.eval(),grad6p.eval()\n",
    "grad5w,grad5p = grad5w.eval(),grad5p.eval()\n",
    "grad4w,grad4p = grad4w.eval(),grad4p.eval()\n",
    "grad3w,grad3p = grad3w.eval(),grad3p.eval()\n",
    "grad2w,grad2p = grad2w.eval(),grad2p.eval()\n",
    "grad1w,grad1p = grad1w.eval(),grad1p.eval()\n",
    "\n",
    "show_histogram(layer1,layer1a,grad1w,grad1p)\n",
    "show_histogram(layer2,layer2a,grad1w,grad2p)\n",
    "show_histogram(layer3,layer3a,grad2w,grad3p)\n",
    "show_histogram(layer4,layer4a,grad3w,grad4p)\n",
    "show_histogram(layer5,layer5a,grad4w,grad5p)\n",
    "show_histogram(layer6,layer6a,grad5w,grad6p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T16:46:48.255187Z",
     "start_time": "2018-12-14T16:46:48.250225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T21:06:11.358086Z",
     "start_time": "2018-12-15T21:06:10.970090Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# power law \n",
    "random_distribution = np.random.power(0.2, size=(10000)) \n",
    "\n",
    "def box1(x,lmbda): return (np.power(x,lmbda) - 1)/lmbda\n",
    "def box2(x,lmbda): return (np.power((x+1),lmbda) - 1) / lmbda\n",
    "box_cox1 = box2(random_distribution,2)\n",
    "box_cox2 = box2(random_distribution,-2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131); plt.hist(random_distribution.ravel(),batch_size); plt.title('Random')\n",
    "plt.subplot(132); plt.hist(box_cox1.ravel(),batch_size); plt.title('Greater One')\n",
    "plt.subplot(133); plt.hist(box_cox2.ravel(),batch_size); plt.title('Smaller One')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T19:05:26.087958Z",
     "start_time": "2018-12-14T19:05:25.618214Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. generator, B. (2018). Bernoulli random number generator. Stack Overflow. Retrieved 14 December 2018, from https://stackoverflow.com/questions/47012474/bernoulli-random-number-generator\n",
    "2. right?, D. (2018). Derivative of Binary Cross Entropy - why are my signs not right?. Mathematics Stack Exchange. Retrieved 14 December 2018, from https://math.stackexchange.com/questions/2503428/derivative-of-binary-cross-entropy-why-are-my-signs-not-right\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
