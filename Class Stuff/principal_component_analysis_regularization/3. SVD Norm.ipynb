{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:13.834409Z",
     "start_time": "2018-12-11T20:31:10.536400Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:21.251700Z",
     "start_time": "2018-12-11T20:31:19.198087Z"
    },
    "code_folding": [
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:29.419455Z",
     "start_time": "2018-12-11T20:31:25.705387Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T03:57:53.571627Z",
     "start_time": "2018-12-12T03:57:53.537710Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.moving_w   = tf.Variable(tf.zeros_like(self.w))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "    def updatew(self):\n",
    "        w,h,inc,outc = self.w.shape\n",
    "        \n",
    "        tempw = tf.reshape(self.w,(w*h,inc,outc))\n",
    "        tempw = tf.transpose(tempw,(2,1,0))\n",
    "        s,U,V = tf.svd(tempw)\n",
    "        print(s)\n",
    "        print(tf.reduce_min(s,1,True))\n",
    "        scaleds = (s-tf.reduce_min(s,1,True))/(tf.reduce_max(s,1,True)-tf.reduce_min(s,1,True)+1e-8)\n",
    "        _,n   = s.shape\n",
    "        n     = n//3\n",
    "        print(n)\n",
    "        neww  = U[:,:,:n] @ tf.matrix_diag(scaleds)[:,:n,:n] @ tf.transpose(V,(0,2,1))[:,:n,:]\n",
    "        neww  = tf.transpose(neww,(2,1,0))\n",
    "        neww  = tf.reshape(neww,(w,h,inc,outc))\n",
    "        \n",
    "        update = []\n",
    "#         update.append(tf.assign(self.moving_w,self.moving_w * 0.9 + 0.1 * neww))\n",
    "#         tempww = self.moving_w/(1-0.9)\n",
    "        update.append(tf.assign(self.w,neww))\n",
    "        return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T03:57:53.930917Z",
     "start_time": "2018-12-12T03:57:53.916918Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# create the svd layer\n",
    "class svd_layer():\n",
    "    \n",
    "    def __init__(self,batch,size,width):\n",
    "        self.n = size\n",
    "        self.moving_s = tf.Variable(tf.zeros((batch_size,size),dtype=tf.float32))\n",
    "        self.moving_u = tf.Variable(tf.zeros((batch_size,width**2,size),dtype=tf.float32))\n",
    "        self.moving_v = tf.Variable(tf.zeros((batch_size,size,size),dtype=tf.float32))\n",
    "    \n",
    "    def feedforward(self,data,training_phase):\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            s,U,V = tf.svd(data)\n",
    "        print(s)\n",
    "        print(U)\n",
    "        print(V)\n",
    "        smin = tf.reduce_min(s,1,keepdims=True)\n",
    "        smax = tf.reduce_max(s,1,keepdims=True)\n",
    "        scaleds = (s - smin)/(smax-smin + 1e-8)\n",
    "        def training_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            data = data  * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u*0.9 + 0.1 * U))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v*0.9 + 0.1 * V))\n",
    "            return data,update\n",
    "            \n",
    "        def testing_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v))\n",
    "            return data,update\n",
    "        \n",
    "        data,update  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return data,update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T03:57:54.946049Z",
     "start_time": "2018-12-12T03:57:54.584022Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "learning_rate = 0.0008; batch_size = 100\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "l3_svd = svd_layer(100,16,24)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "l6_svd = svd_layer(100,32,6)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(3,64,64)\n",
    "l9 = CNN(3,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T03:57:56.482390Z",
     "start_time": "2018-12-12T03:57:55.255414Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Svd_327:0\", shape=(16, 3), dtype=float32)\n",
      "Tensor(\"Min_223:0\", shape=(16, 1), dtype=float32)\n",
      "1\n",
      "Tensor(\"Svd_328:0\", shape=(16, 9), dtype=float32)\n",
      "Tensor(\"Min_226:0\", shape=(16, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_329:0\", shape=(16, 9), dtype=float32)\n",
      "Tensor(\"Min_229:0\", shape=(16, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_330:0\", shape=(32, 9), dtype=float32)\n",
      "Tensor(\"Min_232:0\", shape=(32, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_331:0\", shape=(32, 9), dtype=float32)\n",
      "Tensor(\"Min_235:0\", shape=(32, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_332:0\", shape=(32, 9), dtype=float32)\n",
      "Tensor(\"Min_238:0\", shape=(32, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_333:0\", shape=(64, 9), dtype=float32)\n",
      "Tensor(\"Min_241:0\", shape=(64, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_334:0\", shape=(64, 9), dtype=float32)\n",
      "Tensor(\"Min_244:0\", shape=(64, 1), dtype=float32)\n",
      "3\n",
      "Tensor(\"Svd_335:0\", shape=(10, 9), dtype=float32)\n",
      "Tensor(\"Min_247:0\", shape=(10, 1), dtype=float32)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_train = tf.placeholder_with_default(False,())\n",
    "\n",
    "layer1 = l1.feedforward(x       ,padding='SAME',stride=2)\n",
    "layer2 = l2.feedforward(layer1  ,padding='SAME',stride=2) \n",
    "layer3 = l3.feedforward(layer2  ,padding='SAME',stride=1)\n",
    "\n",
    "layer4 = l4.feedforward(layer3  ,padding='SAME',stride=2) \n",
    "layer5 = l5.feedforward(layer4  ,padding='SAME',stride=2)\n",
    "layer6 = l6.feedforward(layer5  ,padding='SAME',stride=1)\n",
    "\n",
    "layer7 = l7.feedforward(layer6  ,padding='SAME',stride=1)\n",
    "layer8 = l8.feedforward(layer7  ,padding='SAME',stride=1) \n",
    "layer9 = l9.feedforward(layer8  ,padding='SAME',stride=1)\n",
    "\n",
    "all_update = l1.updatew() + l2.updatew() + l3.updatew() + \\\n",
    "             l4.updatew() + l5.updatew() + l6.updatew() + \\\n",
    "             l7.updatew() + l8.updatew() + l9.updatew() \n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T03:58:00.976Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7900/8000 acc : 0.1515\n",
      " Current : 0 Acc : 0.1622000002115965 Test Acc : 0.18212500046938657\n",
      "\n",
      "Current Iter : 1/300 batch : 7900/8000 acc : 0.2721\n",
      " Current : 1 Acc : 0.23360000044107437 Test Acc : 0.2718749998137355\n",
      "\n",
      "Current Iter : 2/300 batch : 7900/8000 acc : 0.3626\n",
      " Current : 2 Acc : 0.2766000020503998 Test Acc : 0.2795000007376075\n",
      "\n",
      "Current Iter : 3/300 batch : 7900/8000 acc : 0.2926\n",
      " Current : 3 Acc : 0.28400000095367434 Test Acc : 0.3003750005736947\n",
      "\n",
      "Current Iter : 4/300 batch : 7900/8000 acc : 0.3636\n",
      " Current : 4 Acc : 0.3084000039100647 Test Acc : 0.31725000143051146\n",
      "\n",
      "Current Iter : 5/300 batch : 7900/8000 acc : 0.3535\n",
      " Current : 5 Acc : 0.3302000004053116 Test Acc : 0.34249999895691874\n",
      "\n",
      "Current Iter : 6/300 batch : 7900/8000 acc : 0.2436\n",
      " Current : 6 Acc : 0.341600002348423 Test Acc : 0.32762500140815976\n",
      "\n",
      "Current Iter : 7/300 batch : 7900/8000 acc : 0.2946\n",
      " Current : 7 Acc : 0.3522000017762184 Test Acc : 0.3542500017210841\n",
      "\n",
      "Current Iter : 8/300 batch : 7900/8000 acc : 0.4534\n",
      " Current : 8 Acc : 0.37740000247955324 Test Acc : 0.37550000138580797\n",
      "\n",
      "Current Iter : 9/300 batch : 7900/8000 acc : 0.3241\n",
      " Current : 9 Acc : 0.3927999985218048 Test Acc : 0.366249999217689\n",
      "\n",
      "Current Iter : 10/300 batch : 7900/8000 acc : 0.4248\n",
      " Current : 10 Acc : 0.4191999977827072 Test Acc : 0.3893749974668026\n",
      "\n",
      "Current Iter : 11/300 batch : 7900/8000 acc : 0.4242\n",
      " Current : 11 Acc : 0.4215999978780747 Test Acc : 0.417749996855855\n",
      "\n",
      "Current Iter : 12/300 batch : 7900/8000 acc : 0.4244\n",
      " Current : 12 Acc : 0.4509999978542328 Test Acc : 0.40974999852478505\n",
      "\n",
      "Current Iter : 13/300 batch : 7900/8000 acc : 0.4847\n",
      " Current : 13 Acc : 0.4557999974489212 Test Acc : 0.41924999803304674\n",
      "\n",
      "Current Iter : 14/300 batch : 7900/8000 acc : 0.3844\n",
      " Current : 14 Acc : 0.4685999971628189 Test Acc : 0.43462499789893627\n",
      "\n",
      "Current Iter : 15/300 batch : 7900/8000 acc : 0.4248\n",
      " Current : 15 Acc : 0.4865999948978424 Test Acc : 0.426249997317791\n",
      "\n",
      "Current Iter : 16/300 batch : 7900/8000 acc : 0.5642\n",
      " Current : 16 Acc : 0.4895999950170517 Test Acc : 0.43937499783933165\n",
      "\n",
      "Current Iter : 17/300 batch : 7900/8000 acc : 0.3954\n",
      " Current : 17 Acc : 0.5125999945402145 Test Acc : 0.4291249975562096\n",
      "\n",
      "Current Iter : 18/300 batch : 7900/8000 acc : 0.5146\n",
      " Current : 18 Acc : 0.5313999956846237 Test Acc : 0.4372499957680702\n",
      "\n",
      "Current Iter : 19/300 batch : 7900/8000 acc : 0.5254\n",
      " Current : 19 Acc : 0.5249999970197677 Test Acc : 0.4499999973922968\n",
      "\n",
      "Current Iter : 20/300 batch : 7900/8000 acc : 0.4153\n",
      " Current : 20 Acc : 0.544999994635582 Test Acc : 0.4478749979287386\n",
      "\n",
      "Current Iter : 21/300 batch : 7900/8000 acc : 0.4259\n",
      " Current : 21 Acc : 0.5703999960422516 Test Acc : 0.4537499979138374\n",
      "\n",
      "Current Iter : 22/300 batch : 7900/8000 acc : 0.4456\n",
      " Current : 22 Acc : 0.5736000037193298 Test Acc : 0.4537499982863665\n",
      "\n",
      "Current Iter : 23/300 batch : 7900/8000 acc : 0.4358\n",
      " Current : 23 Acc : 0.5931999969482422 Test Acc : 0.4553749978542328\n",
      "\n",
      "Current Iter : 24/300 batch : 7900/8000 acc : 0.4664\n",
      " Current : 24 Acc : 0.6129999959468841 Test Acc : 0.44499999582767485\n",
      "\n",
      "Current Iter : 25/300 batch : 7900/8000 acc : 0.5462\n",
      " Current : 25 Acc : 0.6286000001430512 Test Acc : 0.4627499971538782\n",
      "\n",
      "Current Iter : 26/300 batch : 7900/8000 acc : 0.4164\n",
      " Current : 26 Acc : 0.6388000011444092 Test Acc : 0.46337499730288984\n",
      "\n",
      "Current Iter : 27/300 batch : 7900/8000 acc : 0.5267\n",
      " Current : 27 Acc : 0.6594000029563903 Test Acc : 0.4518749974668026\n",
      "\n",
      "Current Iter : 28/300 batch : 7900/8000 acc : 0.4264\n",
      " Current : 28 Acc : 0.6666000008583068 Test Acc : 0.44699999801814555\n",
      "\n",
      "Current Iter : 29/300 batch : 7900/8000 acc : 0.4567\n",
      " Current : 29 Acc : 0.6877999985218048 Test Acc : 0.4331249974668026\n",
      "\n",
      "Current Iter : 30/300 batch : 7900/8000 acc : 0.3461\n",
      " Current : 30 Acc : 0.7056000006198883 Test Acc : 0.4619999971240759\n",
      "\n",
      "Current Iter : 31/300 batch : 7900/8000 acc : 0.4174\n",
      " Current : 31 Acc : 0.7327999985218048 Test Acc : 0.44912499859929084\n",
      "\n",
      "Current Iter : 32/300 batch : 7900/8000 acc : 0.3567\n",
      " Current : 32 Acc : 0.7431999981403351 Test Acc : 0.44749999716877936\n",
      "\n",
      "Current Iter : 33/300 batch : 7900/8000 acc : 0.5878\n",
      " Current : 33 Acc : 0.7519999980926514 Test Acc : 0.4533749982714653\n",
      "\n",
      "Current Iter : 34/300 batch : 7900/8000 acc : 0.5374\n",
      " Current : 34 Acc : 0.7797999966144562 Test Acc : 0.450749996304512\n",
      "\n",
      "Current Iter : 35/300 batch : 7900/8000 acc : 0.4371\n",
      " Current : 35 Acc : 0.8129999971389771 Test Acc : 0.44174999706447127\n",
      "\n",
      "Current Iter : 36/300 batch : 7900/8000 acc : 0.4477\n",
      " Current : 36 Acc : 0.8231999945640563 Test Acc : 0.4482499983161688\n",
      "\n",
      "Current Iter : 37/300 batch : 7900/8000 acc : 0.4784\n",
      " Current : 37 Acc : 0.8470000004768372 Test Acc : 0.42224999628961085\n",
      "\n",
      "Current Iter : 38/300 batch : 7900/8000 acc : 0.3982\n",
      " Current : 38 Acc : 0.831599999666214 Test Acc : 0.44112499728798865\n",
      "\n",
      "Current Iter : 39/300 batch : 7900/8000 acc : 0.4288\n",
      " Current : 39 Acc : 0.8648000025749206 Test Acc : 0.4436249975115061\n",
      "\n",
      "Current Iter : 40/300 batch : 7900/8000 acc : 0.4484\n",
      " Current : 40 Acc : 0.881199996471405 Test Acc : 0.4433749973773956\n",
      "\n",
      "Current Iter : 41/300 batch : 7900/8000 acc : 0.4993\n",
      "-----------reset\n",
      "\n",
      " Current : 41 Acc : 0.9092000031471252 Test Acc : 0.4486249964684248\n",
      "\n",
      "Current Iter : 42/300 batch : 7900/8000 acc : 0.4351\n",
      " Current : 42 Acc : 0.3384000018239021 Test Acc : 0.37500000223517416\n",
      "\n",
      "Current Iter : 43/300 batch : 7900/8000 acc : 0.4243\n",
      " Current : 43 Acc : 0.46999999821186067 Test Acc : 0.4088749997317791\n",
      "\n",
      "Current Iter : 44/300 batch : 7900/8000 acc : 0.3857\n",
      " Current : 44 Acc : 0.5289999967813492 Test Acc : 0.4246249973773956\n",
      "\n",
      "Current Iter : 45/300 batch : 7900/8000 acc : 0.4659\n",
      " Current : 45 Acc : 0.5789999967813492 Test Acc : 0.4343749962747097\n",
      "\n",
      "Current Iter : 46/300 batch : 7900/8000 acc : 0.4662\n",
      " Current : 46 Acc : 0.6230000019073486 Test Acc : 0.4336249969899654\n",
      "\n",
      "Current Iter : 47/300 batch : 7900/8000 acc : 0.4863\n",
      " Current : 47 Acc : 0.6538000011444092 Test Acc : 0.4441249992698431\n",
      "\n",
      "Current Iter : 48/300 batch : 7900/8000 acc : 0.4969\n",
      " Current : 48 Acc : 0.6814000034332275 Test Acc : 0.4457499973475933\n",
      "\n",
      "Current Iter : 49/300 batch : 7900/8000 acc : 0.4673\n",
      " Current : 49 Acc : 0.717999997138977 Test Acc : 0.4358749970793724\n",
      "\n",
      "Current Iter : 50/300 batch : 7900/8000 acc : 0.4774\n",
      " Current : 50 Acc : 0.7410000061988831 Test Acc : 0.44787499867379665\n",
      "\n",
      "Current Iter : 51/300 batch : 7900/8000 acc : 0.4273\n",
      " Current : 51 Acc : 0.7759999978542328 Test Acc : 0.43987499848008155\n",
      "\n",
      "Current Iter : 52/300 batch : 7900/8000 acc : 0.3773\n",
      " Current : 52 Acc : 0.802799996137619 Test Acc : 0.4436249990016222\n",
      "\n",
      "Current Iter : 53/300 batch : 7900/8000 acc : 0.4682\n",
      " Current : 53 Acc : 0.8113999962806702 Test Acc : 0.4421249970793724\n",
      "\n",
      "Current Iter : 54/300 batch : 7900/8000 acc : 0.4288\n",
      " Current : 54 Acc : 0.8499999988079071 Test Acc : 0.43937499783933165\n",
      "\n",
      "Current Iter : 55/300 batch : 7900/8000 acc : 0.4381\n",
      " Current : 55 Acc : 0.8595999968051911 Test Acc : 0.43087499812245367\n",
      "\n",
      "Current Iter : 56/300 batch : 7900/8000 acc : 0.3798\n",
      " Current : 56 Acc : 0.8826000022888184 Test Acc : 0.4307499974966049\n",
      "\n",
      "Current Iter : 57/300 batch : 7900/8000 acc : 0.5683\n",
      " Current : 57 Acc : 0.8989999961853027 Test Acc : 0.43137499764561654\n",
      "\n",
      "Current Iter : 58/300 batch : 7900/8000 acc : 0.4991\n",
      "-----------reset\n",
      "\n",
      " Current : 58 Acc : 0.9258000040054322 Test Acc : 0.43037499822676184\n",
      "\n",
      "Current Iter : 59/300 batch : 7900/8000 acc : 0.3672\n",
      " Current : 59 Acc : 0.7160000026226043 Test Acc : 0.4378749970346689\n",
      "\n",
      "Current Iter : 60/300 batch : 7900/8000 acc : 0.4285\n",
      " Current : 60 Acc : 0.833600001335144 Test Acc : 0.4352499980479479\n",
      "\n",
      "Current Iter : 61/300 batch : 7900/8000 acc : 0.3984\n",
      " Current : 61 Acc : 0.8814000010490417 Test Acc : 0.4274999976158142\n",
      "\n",
      "Current Iter : 62/300 batch : 7900/8000 acc : 0.4488\n",
      " Current : 62 Acc : 0.8842000007629395 Test Acc : 0.42937499694526193\n",
      "\n",
      "Current Iter : 63/300 batch : 7900/8000 acc : 0.3685\n",
      "-----------reset\n",
      "\n",
      " Current : 63 Acc : 0.902000002861023 Test Acc : 0.42737499810755253\n",
      "\n",
      "Current Iter : 64/300 batch : 7900/8000 acc : 0.4481\n",
      " Current : 64 Acc : 0.8439999997615815 Test Acc : 0.4206249974668026\n",
      "\n",
      "Current Iter : 65/300 batch : 7900/8000 acc : 0.3283\n",
      " Current : 65 Acc : 0.8833999979496002 Test Acc : 0.4273749962449074\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 66/300 batch : 7900/8000 acc : 0.4195\n",
      "-----------reset\n",
      "\n",
      " Current : 66 Acc : 0.9228000032901764 Test Acc : 0.4180000007152557\n",
      "\n",
      "Current Iter : 67/300 batch : 7900/8000 acc : 0.3684\n",
      " Current : 67 Acc : 0.8916000008583069 Test Acc : 0.4243749979883432\n",
      "\n",
      "Current Iter : 68/300 batch : 7900/8000 acc : 0.4389\n",
      "-----------reset\n",
      "\n",
      " Current : 68 Acc : 0.9005999994277955 Test Acc : 0.4248749978840351\n",
      "\n",
      "Current Iter : 69/300 batch : 7900/8000 acc : 0.4786\n",
      "-----------reset\n",
      "\n",
      " Current : 69 Acc : 0.9120000028610229 Test Acc : 0.42712499722838404\n",
      "\n",
      "Current Iter : 70/300 batch : 7900/8000 acc : 0.4992\n",
      "-----------reset\n",
      "\n",
      " Current : 70 Acc : 0.9279999983310699 Test Acc : 0.42237499840557574\n",
      "\n",
      "Current Iter : 71/300 batch : 7900/8000 acc : 0.3998\n",
      "-----------reset\n",
      "\n",
      " Current : 71 Acc : 0.9324000024795532 Test Acc : 0.41724999733269214\n",
      "\n",
      "Current Iter : 72/300 batch : 7900/8000 acc : 0.4186\n",
      "-----------reset\n",
      "\n",
      " Current : 72 Acc : 0.9144000041484833 Test Acc : 0.4007500000298023\n",
      "\n",
      "Current Iter : 73/300 batch : 7900/8000 acc : 0.3387\n",
      "-----------reset\n",
      "\n",
      " Current : 73 Acc : 0.9048000013828278 Test Acc : 0.4207499988377094\n",
      "\n",
      "Current Iter : 74/300 batch : 7900/8000 acc : 0.3397\n",
      "-----------reset\n",
      "\n",
      " Current : 74 Acc : 0.9640000033378601 Test Acc : 0.4264999985694885\n",
      "\n",
      "Current Iter : 75/300 batch : 7900/8000 acc : 0.4694\n",
      "-----------reset\n",
      "\n",
      " Current : 75 Acc : 0.965400003194809 Test Acc : 0.42649999894201757\n",
      "\n",
      "Current Iter : 76/300 batch : 7900/8000 acc : 0.4494\n",
      "-----------reset\n",
      "\n",
      " Current : 76 Acc : 0.9582000064849854 Test Acc : 0.4169999994337559\n",
      "\n",
      "Current Iter : 77/300 batch : 7900/8000 acc : 0.3391\n",
      "-----------reset\n",
      "\n",
      " Current : 77 Acc : 0.9648000025749206 Test Acc : 0.42712499760091305\n",
      "\n",
      "Current Iter : 78/300 batch : 7900/8000 acc : 0.3894\n",
      "-----------reset\n",
      "\n",
      " Current : 78 Acc : 0.9594000041484833 Test Acc : 0.4238749958574772\n",
      "\n",
      "Current Iter : 79/300 batch : 7900/8000 acc : 0.2987\n",
      "-----------reset\n",
      "\n",
      " Current : 79 Acc : 0.9288000023365021 Test Acc : 0.40224999785423277\n",
      "\n",
      "Current Iter : 80/300 batch : 7900/8000 acc : 0.3692\n",
      "-----------reset\n",
      "\n",
      " Current : 80 Acc : 0.9089999973773957 Test Acc : 0.41874999962747095\n",
      "\n",
      "Current Iter : 81/300 batch : 7900/8000 acc : 0.5194\n",
      "-----------reset\n",
      "\n",
      " Current : 81 Acc : 0.9526000034809112 Test Acc : 0.4306249976158142\n",
      "\n",
      "Current Iter : 82/300 batch : 7900/8000 acc : 0.3589\n",
      "-----------reset\n",
      "\n",
      " Current : 82 Acc : 0.9752000057697296 Test Acc : 0.4258749965578318\n",
      "\n",
      "Current Iter : 83/300 batch : 7900/8000 acc : 0.4697\n",
      "-----------reset\n",
      "\n",
      " Current : 83 Acc : 0.9802000081539154 Test Acc : 0.4257499989122152\n",
      "\n",
      "Current Iter : 84/300 batch : 7900/8000 acc : 0.4899\n",
      "-----------reset\n",
      "\n",
      " Current : 84 Acc : 0.9850000095367432 Test Acc : 0.42412499971687795\n",
      "\n",
      "Current Iter : 85/300 batch : 7900/8000 acc : 0.4609\n",
      "-----------reset\n",
      "\n",
      " Current : 85 Acc : 0.9962000036239624 Test Acc : 0.4291249975562096\n",
      "\n",
      "Current Iter : 86/300 batch : 7900/8000 acc : 0.3892\n",
      "-----------reset\n",
      "\n",
      " Current : 86 Acc : 0.9800000059604644 Test Acc : 0.4216249991208315\n",
      "\n",
      "Current Iter : 87/300 batch : 7900/8000 acc : 0.5177\n",
      "-----------reset\n",
      "\n",
      " Current : 87 Acc : 0.9148000049591064 Test Acc : 0.39874999821186063\n",
      "\n",
      "Current Iter : 88/300 batch : 7900/8000 acc : 0.3893\n",
      "-----------reset\n",
      "\n",
      " Current : 88 Acc : 0.9130000042915344 Test Acc : 0.42887499928474426\n",
      "\n",
      "Current Iter : 89/300 batch : 7900/8000 acc : 0.3799\n",
      "-----------reset\n",
      "\n",
      " Current : 89 Acc : 0.9820000112056733 Test Acc : 0.42949999757111074\n",
      "\n",
      "Current Iter : 90/300 batch : 7900/8000 acc : 0.3998\n",
      "-----------reset\n",
      "\n",
      " Current : 90 Acc : 0.9950000047683716 Test Acc : 0.4298749979585409\n",
      "\n",
      "Current Iter : 91/300 batch : 7900/8000 acc : 0.3909\n",
      "-----------reset\n",
      "\n",
      " Current : 91 Acc : 0.9988000011444091 Test Acc : 0.42812499813735483\n",
      "\n",
      "Current Iter : 92/300 batch : 7900/8000 acc : 0.4799\n",
      "-----------reset\n",
      "\n",
      " Current : 92 Acc : 0.9994000005722046 Test Acc : 0.43237499743700025\n",
      "\n",
      "0 Current Iter : 93/300 batch : 0/5000 acc : 1.0\r"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 300 ; avg_acc_train = 0; avg_acc_test  = 0; train_more = 1\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    test_images,test_labels   = shuffle(test_images,test_labels);\n",
    "\n",
    "    for i in range(train_more):\n",
    "        train_images,train_labels = shuffle(train_images,train_labels);\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label})\n",
    "            sys.stdout.write(str(i) + ' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "\n",
    "    if avg_acc_train/(len(train_images)/batch_size)/train_more > 0.9 and avg_acc_test/(len(test_images)/batch_size) < 0.5 :  \n",
    "        print('\\n-----------reset')\n",
    "        sess.run(all_update)\n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)/train_more) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T21:03:17.629751Z",
     "start_time": "2018-12-10T21:03:16.795967Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
