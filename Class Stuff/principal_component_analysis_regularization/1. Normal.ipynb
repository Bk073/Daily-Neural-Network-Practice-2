{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:06.952925Z",
     "start_time": "2018-12-11T18:11:53.489090Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:29.753180Z",
     "start_time": "2018-12-11T18:12:27.960830Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:35.051154Z",
     "start_time": "2018-12-11T18:12:31.458752Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:35.127948Z",
     "start_time": "2018-12-11T18:12:35.101021Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:35.596699Z",
     "start_time": "2018-12-11T18:12:35.256605Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "learning_rate = 0.0008; batch_size = 100\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:12:37.223276Z",
     "start_time": "2018-12-11T18:12:36.852961Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "n = tf.placeholder(shape=(),dtype=tf.int32)\n",
    "mmax = tf.placeholder_with_default(1.0,())\n",
    "mmin = tf.placeholder_with_default(0.0,())\n",
    "\n",
    "layer1 = l1.feedforward(x       ,padding='SAME',stride=2)\n",
    "layer2 = l2.feedforward(layer1  ,padding='SAME',stride=2) \n",
    "layer3 = l3.feedforward(layer2  ,padding='SAME',stride=1)\n",
    "\n",
    "layer4 = l4.feedforward(layer3  ,padding='SAME',stride=2) \n",
    "layer5 = l5.feedforward(layer4  ,padding='SAME',stride=2)\n",
    "layer6 = l6.feedforward(layer5  ,padding='SAME',stride=1)\n",
    "\n",
    "layer7 = l7.feedforward(layer6  ,padding='SAME',stride=1)\n",
    "layer8 = l8.feedforward(layer7  ,padding='SAME',stride=1) \n",
    "layer9 = l9.feedforward(layer8  ,padding='SAME',stride=1)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:18:40.423334Z",
     "start_time": "2018-12-11T18:13:07.082619Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7900/8000 acc : 0.16\n",
      " Current : 0 Acc : 0.1394000004976988 Test Acc : 0.18099999958649277\n",
      "\n",
      "Current Iter : 1/300 batch : 7900/8000 acc : 0.13\n",
      " Current : 1 Acc : 0.17139999970793723 Test Acc : 0.17962499968707563\n",
      "\n",
      "Current Iter : 2/300 batch : 7900/8000 acc : 0.22\n",
      " Current : 2 Acc : 0.20659999966621398 Test Acc : 0.2294999983161688\n",
      "\n",
      "Current Iter : 3/300 batch : 7900/8000 acc : 0.26\n",
      " Current : 3 Acc : 0.2255999991297722 Test Acc : 0.22875000052154065\n",
      "\n",
      "Current Iter : 4/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 4 Acc : 0.25840000092983245 Test Acc : 0.2770000007003546\n",
      "\n",
      "Current Iter : 5/300 batch : 7900/8000 acc : 0.27\n",
      " Current : 5 Acc : 0.2870000022649765 Test Acc : 0.2816250013187528\n",
      "\n",
      "Current Iter : 6/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 6 Acc : 0.3088000011444092 Test Acc : 0.3105000004172325\n",
      "\n",
      "Current Iter : 7/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 7 Acc : 0.32180000334978104 Test Acc : 0.33212500158697367\n",
      "\n",
      "Current Iter : 8/300 batch : 7900/8000 acc : 0.35\n",
      " Current : 8 Acc : 0.33120000004768374 Test Acc : 0.350874999910593\n",
      "\n",
      "Current Iter : 9/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 9 Acc : 0.35160000175237655 Test Acc : 0.34675000198185446\n",
      "\n",
      "Current Iter : 10/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 10 Acc : 0.36440000087022784 Test Acc : 0.358500000461936\n",
      "\n",
      "Current Iter : 11/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 11 Acc : 0.3858000010251999 Test Acc : 0.3703749986365438\n",
      "\n",
      "Current Iter : 12/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 12 Acc : 0.38700000047683714 Test Acc : 0.3822499975562096\n",
      "\n",
      "Current Iter : 13/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 13 Acc : 0.3989999979734421 Test Acc : 0.39012499880045653\n",
      "\n",
      "Current Iter : 14/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 14 Acc : 0.4083999991416931 Test Acc : 0.39787499979138374\n",
      "\n",
      "Current Iter : 15/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 15 Acc : 0.4145999974012375 Test Acc : 0.39987499825656414\n",
      "\n",
      "Current Iter : 16/300 batch : 7900/8000 acc : 0.32\n",
      " Current : 16 Acc : 0.41979999899864195 Test Acc : 0.397749999165535\n",
      "\n",
      "Current Iter : 17/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 17 Acc : 0.4261999976634979 Test Acc : 0.3954999988898635\n",
      "\n",
      "Current Iter : 18/300 batch : 7900/8000 acc : 0.32\n",
      " Current : 18 Acc : 0.4333999973535538 Test Acc : 0.41074999757111075\n",
      "\n",
      "Current Iter : 19/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 19 Acc : 0.4451999980211258 Test Acc : 0.4104999989271164\n",
      "\n",
      "Current Iter : 20/300 batch : 7900/8000 acc : 0.53\n",
      " Current : 20 Acc : 0.45459999680519103 Test Acc : 0.4117499977350235\n",
      "\n",
      "Current Iter : 21/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 21 Acc : 0.46459999680519104 Test Acc : 0.41474999859929085\n",
      "\n",
      "Current Iter : 22/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 22 Acc : 0.4619999974966049 Test Acc : 0.4167499979957938\n",
      "\n",
      "Current Iter : 23/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 23 Acc : 0.4801999986171722 Test Acc : 0.4092499990016222\n",
      "\n",
      "Current Iter : 24/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 24 Acc : 0.47859999656677243 Test Acc : 0.42399999760091306\n",
      "\n",
      "Current Iter : 25/300 batch : 7900/8000 acc : 0.51\n",
      " Current : 25 Acc : 0.49039999485015867 Test Acc : 0.4349999975413084\n",
      "\n",
      "Current Iter : 26/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 26 Acc : 0.5079999953508377 Test Acc : 0.4419999971985817\n",
      "\n",
      "Current Iter : 27/300 batch : 7900/8000 acc : 0.51\n",
      " Current : 27 Acc : 0.5143999963998794 Test Acc : 0.4464999958872795\n",
      "\n",
      "Current Iter : 28/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 28 Acc : 0.5212000000476837 Test Acc : 0.4334999967366457\n",
      "\n",
      "Current Iter : 29/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 29 Acc : 0.5267999964952469 Test Acc : 0.432499996945262\n",
      "\n",
      "Current Iter : 30/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.5405999952554703 Test Acc : 0.4423749979585409\n",
      "\n",
      "Current Iter : 31/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 31 Acc : 0.5425999927520752 Test Acc : 0.4418749984353781\n",
      "\n",
      "Current Iter : 32/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 32 Acc : 0.5481999969482422 Test Acc : 0.42362499982118607\n",
      "\n",
      "Current Iter : 33/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 33 Acc : 0.5728000009059906 Test Acc : 0.45662499479949475\n",
      "\n",
      "Current Iter : 34/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 34 Acc : 0.5801999992132187 Test Acc : 0.45637499652802943\n",
      "\n",
      "Current Iter : 35/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 35 Acc : 0.5815999984741211 Test Acc : 0.4514999967068434\n",
      "\n",
      "Current Iter : 36/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 36 Acc : 0.5758000004291535 Test Acc : 0.4553749989718199\n",
      "\n",
      "Current Iter : 37/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 37 Acc : 0.6002000004053116 Test Acc : 0.43062499947845934\n",
      "\n",
      "Current Iter : 38/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 38 Acc : 0.6078000009059906 Test Acc : 0.4497499976307154\n",
      "\n",
      "Current Iter : 39/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 39 Acc : 0.6191999971866607 Test Acc : 0.4487499978393316\n",
      "\n",
      "Current Iter : 40/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 40 Acc : 0.6393999993801117 Test Acc : 0.4662499953061342\n",
      "\n",
      "Current Iter : 41/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 41 Acc : 0.6465999960899353 Test Acc : 0.4533749967813492\n",
      "\n",
      "Current Iter : 42/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 42 Acc : 0.6374000000953675 Test Acc : 0.44637499898672106\n",
      "\n",
      "Current Iter : 43/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 43 Acc : 0.668199999332428 Test Acc : 0.4579999953508377\n",
      "\n",
      "Current Iter : 44/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 44 Acc : 0.6815999984741211 Test Acc : 0.45387499667704106\n",
      "\n",
      "Current Iter : 45/300 batch : 7900/8000 acc : 0.57\n",
      " Current : 45 Acc : 0.68200000166893 Test Acc : 0.45087499618530275\n",
      "\n",
      "Current Iter : 46/300 batch : 7900/8000 acc : 0.53\n",
      " Current : 46 Acc : 0.6936000037193298 Test Acc : 0.456249999627471\n",
      "\n",
      "Current Iter : 47/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 47 Acc : 0.7056000053882598 Test Acc : 0.43799999691545966\n",
      "\n",
      "Current Iter : 48/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 48 Acc : 0.714799998998642 Test Acc : 0.4491249989718199\n",
      "\n",
      "Current Iter : 49/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 49 Acc : 0.7114000010490418 Test Acc : 0.4447499979287386\n",
      "\n",
      "Current Iter : 50/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 50 Acc : 0.7272000014781952 Test Acc : 0.4534999990835786\n",
      "\n",
      "Current Iter : 51/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 51 Acc : 0.7493999993801117 Test Acc : 0.45537499487400057\n",
      "\n",
      "Current Iter : 52/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 52 Acc : 0.7432000041007996 Test Acc : 0.46187499687075617\n",
      "\n",
      "Current Iter : 53/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 53 Acc : 0.7529999983310699 Test Acc : 0.44499999545514585\n",
      "\n",
      "Current Iter : 54/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 54 Acc : 0.7664000010490417 Test Acc : 0.44299999736249446\n",
      "\n",
      "Current Iter : 55/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 55 Acc : 0.7733999991416931 Test Acc : 0.45087499879300597\n",
      "\n",
      "Current Iter : 56/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 56 Acc : 0.7939999985694886 Test Acc : 0.4407499976456165\n",
      "\n",
      "Current Iter : 57/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 57 Acc : 0.8087999963760376 Test Acc : 0.4423749968409538\n",
      "\n",
      "Current Iter : 58/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 58 Acc : 0.8207999980449676 Test Acc : 0.44587499648332596\n",
      "\n",
      "Current Iter : 59/300 batch : 7900/8000 acc : 0.35\n",
      " Current : 59 Acc : 0.820200001001358 Test Acc : 0.4268749963492155\n",
      "\n",
      "Current Iter : 60/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 60 Acc : 0.8269999980926513 Test Acc : 0.4511249989271164\n",
      "\n",
      "Current Iter : 61/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 61 Acc : 0.8282000005245209 Test Acc : 0.43112499713897706\n",
      "\n",
      "Current Iter : 62/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 62 Acc : 0.8447999966144562 Test Acc : 0.4348749976605177\n",
      "\n",
      "Current Iter : 63/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 63 Acc : 0.845400002002716 Test Acc : 0.43487499579787253\n",
      "\n",
      "Current Iter : 64/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 64 Acc : 0.8741999971866607 Test Acc : 0.433374997228384\n",
      "\n",
      "Current Iter : 65/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 65 Acc : 0.8807999980449677 Test Acc : 0.4329999975860119\n",
      "\n",
      "Current Iter : 66/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 66 Acc : 0.8944000017642975 Test Acc : 0.4282499969005585\n",
      "\n",
      "Current Iter : 67/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 67 Acc : 0.8757999980449677 Test Acc : 0.42424999810755254\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 68 Acc : 0.8839999973773957 Test Acc : 0.43187499716877936\n",
      "\n",
      "Current Iter : 69/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 69 Acc : 0.9200000035762786 Test Acc : 0.42637499757111075\n",
      "\n",
      "Current Iter : 70/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 70 Acc : 0.9174000024795532 Test Acc : 0.4381249971687794\n",
      "\n",
      "Current Iter : 71/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 71 Acc : 0.9113999962806701 Test Acc : 0.4238749984651804\n",
      "\n",
      "Current Iter : 72/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 72 Acc : 0.9114000010490417 Test Acc : 0.4348749965429306\n",
      "\n",
      "Current Iter : 73/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 73 Acc : 0.9180000007152558 Test Acc : 0.434249996393919\n",
      "\n",
      "Current Iter : 74/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 74 Acc : 0.9389999997615814 Test Acc : 0.4297499965876341\n",
      "\n",
      "Current Iter : 75/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 75 Acc : 0.9406000018119812 Test Acc : 0.41474999897181986\n",
      "\n",
      "Current Iter : 76/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 76 Acc : 0.9191999983787537 Test Acc : 0.42349999509751796\n",
      "\n",
      "Current Iter : 77/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 77 Acc : 0.9042000043392181 Test Acc : 0.4343749977648258\n",
      "\n",
      "Current Iter : 78/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 78 Acc : 0.9323999953269958 Test Acc : 0.43862499818205836\n",
      "\n",
      "Current Iter : 79/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 79 Acc : 0.9742000102996826 Test Acc : 0.4324999988079071\n",
      "\n",
      "Current Iter : 80/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 80 Acc : 0.9726000034809112 Test Acc : 0.4291249968111515\n",
      "\n",
      "Current Iter : 81/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.9730000102519989 Test Acc : 0.42962499633431434\n",
      "\n",
      "Current Iter : 82/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 82 Acc : 0.9468000030517578 Test Acc : 0.43774999789893626\n",
      "\n",
      "Current Iter : 83/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 83 Acc : 0.9636000049114227 Test Acc : 0.4359999977052212\n",
      "\n",
      "Current Iter : 84/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 84 Acc : 0.9682000064849854 Test Acc : 0.42524999789893625\n",
      "\n",
      "Current Iter : 85/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 85 Acc : 0.9628000056743622 Test Acc : 0.4227499969303608\n",
      "\n",
      "Current Iter : 86/300 batch : 7900/8000 acc : 0.58\n",
      " Current : 86 Acc : 0.898400001525879 Test Acc : 0.4251249972730875\n",
      "\n",
      "Current Iter : 87/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 87 Acc : 0.940600004196167 Test Acc : 0.4377499967813492\n",
      "\n",
      "Current Iter : 88/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 88 Acc : 0.9106000030040741 Test Acc : 0.41574999764561654\n",
      "\n",
      "Current Iter : 89/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 89 Acc : 0.9344000017642975 Test Acc : 0.42212499864399433\n",
      "\n",
      "Current Iter : 90/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 90 Acc : 0.9714000022411347 Test Acc : 0.4391249980777502\n",
      "\n",
      "Current Iter : 91/300 batch : 1600/5000 acc : 0.98\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-108ddd0eeb71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauto_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mavg_acc_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_acc_train\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 300 ; avg_acc_train = 0; avg_acc_test  = 0; train_more = 1\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels);\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels);\n",
    "\n",
    "    for i in range(train_more):\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,n:2})\n",
    "            sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,n:1,mmax:1.0,mmin:0})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)/train_more) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T21:03:17.629751Z",
     "start_time": "2018-12-10T21:03:16.795967Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
