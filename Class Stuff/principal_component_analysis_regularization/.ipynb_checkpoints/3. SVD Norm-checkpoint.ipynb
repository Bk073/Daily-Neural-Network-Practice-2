{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:13.834409Z",
     "start_time": "2018-12-11T20:31:10.536400Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:21.251700Z",
     "start_time": "2018-12-11T20:31:19.198087Z"
    },
    "code_folding": [
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T20:31:29.419455Z",
     "start_time": "2018-12-11T20:31:25.705387Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T04:13:45.839332Z",
     "start_time": "2018-12-12T04:13:45.807392Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.moving_w   = tf.Variable(tf.zeros_like(self.w))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "    def updatew(self):\n",
    "        w,h,inc,outc = self.w.shape\n",
    "        \n",
    "        tempw = tf.reshape(self.w,(w*h,inc,outc))\n",
    "        tempw = tf.transpose(tempw,(1,2,0))\n",
    "        s,U,V = tf.svd(tempw)\n",
    "        print(s)\n",
    "        print(tf.reduce_min(s,1,True))\n",
    "        scaleds = (s-tf.reduce_min(s,1,True))/(tf.reduce_max(s,1,True)-tf.reduce_min(s,1,True)+1e-8)\n",
    "        _,n   = s.shape\n",
    "        n     = n//2\n",
    "        print(n)\n",
    "        neww  = U[:,:,:n] @ tf.matrix_diag(scaleds)[:,:n,:n] @ tf.transpose(V,(0,2,1))[:,:n,:]\n",
    "        neww  = tf.transpose(neww,(2,0,1))\n",
    "        neww  = tf.reshape(neww,(w,h,inc,outc))\n",
    "        \n",
    "        update = []\n",
    "#         update.append(tf.assign(self.moving_w,self.moving_w * 0.9 + 0.1 * neww))\n",
    "#         tempww = self.moving_w/(1-0.9)\n",
    "        update.append(tf.assign(self.w,neww))\n",
    "        return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T04:13:46.146757Z",
     "start_time": "2018-12-12T04:13:46.130800Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# create the svd layer\n",
    "class svd_layer():\n",
    "    \n",
    "    def __init__(self,batch,size,width):\n",
    "        self.n = size\n",
    "        self.moving_s = tf.Variable(tf.zeros((batch_size,size),dtype=tf.float32))\n",
    "        self.moving_u = tf.Variable(tf.zeros((batch_size,width**2,size),dtype=tf.float32))\n",
    "        self.moving_v = tf.Variable(tf.zeros((batch_size,size,size),dtype=tf.float32))\n",
    "    \n",
    "    def feedforward(self,data,training_phase):\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            s,U,V = tf.svd(data)\n",
    "        print(s)\n",
    "        print(U)\n",
    "        print(V)\n",
    "        smin = tf.reduce_min(s,1,keepdims=True)\n",
    "        smax = tf.reduce_max(s,1,keepdims=True)\n",
    "        scaleds = (s - smin)/(smax-smin + 1e-8)\n",
    "        def training_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            data = data  * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u*0.9 + 0.1 * U))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v*0.9 + 0.1 * V))\n",
    "            return data,update\n",
    "            \n",
    "        def testing_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v))\n",
    "            return data,update\n",
    "        \n",
    "        data,update  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return data,update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T04:13:46.899121Z",
     "start_time": "2018-12-12T04:13:46.510920Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "learning_rate = 0.0008; batch_size = 100\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "l3_svd = svd_layer(100,16,24)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "l6_svd = svd_layer(100,32,6)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(3,64,64)\n",
    "l9 = CNN(3,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T04:13:48.382018Z",
     "start_time": "2018-12-12T04:13:47.117710Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Svd_346:0\", shape=(3, 3, 3), dtype=float32)\n",
      "Tensor(\"Min_280:0\", shape=(3, 1, 3), dtype=float32)\n",
      "1\n",
      "Tensor(\"Svd_347:0\", shape=(3, 3, 16), dtype=float32)\n",
      "Tensor(\"Min_283:0\", shape=(3, 1, 16), dtype=float32)\n",
      "8\n",
      "Tensor(\"Svd_348:0\", shape=(3, 3, 16), dtype=float32)\n",
      "Tensor(\"Min_286:0\", shape=(3, 1, 16), dtype=float32)\n",
      "8\n",
      "Tensor(\"Svd_349:0\", shape=(3, 3, 16), dtype=float32)\n",
      "Tensor(\"Min_289:0\", shape=(3, 1, 16), dtype=float32)\n",
      "8\n",
      "Tensor(\"Svd_350:0\", shape=(3, 3, 32), dtype=float32)\n",
      "Tensor(\"Min_292:0\", shape=(3, 1, 32), dtype=float32)\n",
      "16\n",
      "Tensor(\"Svd_351:0\", shape=(3, 3, 32), dtype=float32)\n",
      "Tensor(\"Min_295:0\", shape=(3, 1, 32), dtype=float32)\n",
      "16\n",
      "Tensor(\"Svd_352:0\", shape=(3, 3, 32), dtype=float32)\n",
      "Tensor(\"Min_298:0\", shape=(3, 1, 32), dtype=float32)\n",
      "16\n",
      "Tensor(\"Svd_353:0\", shape=(3, 3, 64), dtype=float32)\n",
      "Tensor(\"Min_301:0\", shape=(3, 1, 64), dtype=float32)\n",
      "32\n",
      "Tensor(\"Svd_354:0\", shape=(3, 3, 10), dtype=float32)\n",
      "Tensor(\"Min_304:0\", shape=(3, 1, 10), dtype=float32)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_train = tf.placeholder_with_default(False,())\n",
    "\n",
    "layer1 = l1.feedforward(x       ,padding='SAME',stride=2)\n",
    "layer2 = l2.feedforward(layer1  ,padding='SAME',stride=2) \n",
    "layer3 = l3.feedforward(layer2  ,padding='SAME',stride=1)\n",
    "\n",
    "layer4 = l4.feedforward(layer3  ,padding='SAME',stride=2) \n",
    "layer5 = l5.feedforward(layer4  ,padding='SAME',stride=2)\n",
    "layer6 = l6.feedforward(layer5  ,padding='SAME',stride=1)\n",
    "\n",
    "layer7 = l7.feedforward(layer6  ,padding='SAME',stride=1)\n",
    "layer8 = l8.feedforward(layer7  ,padding='SAME',stride=1) \n",
    "layer9 = l9.feedforward(layer8  ,padding='SAME',stride=1)\n",
    "\n",
    "all_update = l1.updatew() + l2.updatew() + l3.updatew() + \\\n",
    "             l4.updatew() + l5.updatew() + l6.updatew() + \\\n",
    "             l7.updatew() + l8.updatew() + l9.updatew() \n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T04:20:40.103767Z",
     "start_time": "2018-12-12T04:13:49.293988Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7900/8000 acc : 0.1427\n",
      " Current : 0 Acc : 0.14899999976158143 Test Acc : 0.2022499991580844\n",
      "\n",
      "Current Iter : 1/300 batch : 7900/8000 acc : 0.1825\n",
      " Current : 1 Acc : 0.22260000169277191 Test Acc : 0.2182499997317791\n",
      "\n",
      "Current Iter : 2/300 batch : 7900/8000 acc : 0.2833\n",
      " Current : 2 Acc : 0.25959999948740003 Test Acc : 0.29337500166147945\n",
      "\n",
      "Current Iter : 3/300 batch : 7900/8000 acc : 0.3328\n",
      " Current : 3 Acc : 0.281000000834465 Test Acc : 0.29662500116974116\n",
      "\n",
      "Current Iter : 4/300 batch : 7900/8000 acc : 0.3827\n",
      " Current : 4 Acc : 0.2958000022172928 Test Acc : 0.2990000002086163\n",
      "\n",
      "Current Iter : 5/300 batch : 7900/8000 acc : 0.3731\n",
      " Current : 5 Acc : 0.31460000276565553 Test Acc : 0.32087500374764205\n",
      "\n",
      "Current Iter : 6/300 batch : 7900/8000 acc : 0.3829\n",
      " Current : 6 Acc : 0.33860000312328337 Test Acc : 0.3488750014454126\n",
      "\n",
      "Current Iter : 7/300 batch : 7900/8000 acc : 0.3945\n",
      " Current : 7 Acc : 0.35159999966621397 Test Acc : 0.3361250003799796\n",
      "\n",
      "Current Iter : 8/300 batch : 7900/8000 acc : 0.4139\n",
      " Current : 8 Acc : 0.35920000046491624 Test Acc : 0.3480000032112002\n",
      "\n",
      "Current Iter : 9/300 batch : 7900/8000 acc : 0.3838\n",
      " Current : 9 Acc : 0.3768000024557114 Test Acc : 0.3542499985545874\n",
      "\n",
      "Current Iter : 10/300 batch : 7900/8000 acc : 0.3143\n",
      " Current : 10 Acc : 0.3928000009059906 Test Acc : 0.3723750002682209\n",
      "\n",
      "Current Iter : 11/300 batch : 7900/8000 acc : 0.4324\n",
      " Current : 11 Acc : 0.4019999960064888 Test Acc : 0.3806249998509884\n",
      "\n",
      "Current Iter : 12/300 batch : 7900/8000 acc : 0.3745\n",
      " Current : 12 Acc : 0.4221999990940094 Test Acc : 0.40975000001490114\n",
      "\n",
      "Current Iter : 13/300 batch : 7900/8000 acc : 0.4633\n",
      " Current : 13 Acc : 0.4423999983072281 Test Acc : 0.4038750004023314\n",
      "\n",
      "Current Iter : 14/300 batch : 7900/8000 acc : 0.4146\n",
      " Current : 14 Acc : 0.44559999704360964 Test Acc : 0.4155000004917383\n",
      "\n",
      "Current Iter : 15/300 batch : 7900/8000 acc : 0.3746\n",
      " Current : 15 Acc : 0.46139999508857726 Test Acc : 0.4264999981969595\n",
      "\n",
      "Current Iter : 16/300 batch : 7900/8000 acc : 0.4944\n",
      " Current : 16 Acc : 0.47639999747276307 Test Acc : 0.4104999974370003\n",
      "\n",
      "Current Iter : 17/300 batch : 7900/8000 acc : 0.5544\n",
      " Current : 17 Acc : 0.47659999907016753 Test Acc : 0.4326249983161688\n",
      "\n",
      "Current Iter : 18/300 batch : 7900/8000 acc : 0.4246\n",
      " Current : 18 Acc : 0.4875999975204468 Test Acc : 0.42924999706447126\n",
      "\n",
      "Current Iter : 19/300 batch : 7900/8000 acc : 0.4648\n",
      " Current : 19 Acc : 0.5131999969482421 Test Acc : 0.4348749965429306\n",
      "\n",
      "Current Iter : 20/300 batch : 7900/8000 acc : 0.4657\n",
      " Current : 20 Acc : 0.5175999969244003 Test Acc : 0.4326249983161688\n",
      "\n",
      "Current Iter : 21/300 batch : 7900/8000 acc : 0.3748\n",
      " Current : 21 Acc : 0.5321999943256378 Test Acc : 0.4433749973773956\n",
      "\n",
      "Current Iter : 22/300 batch : 7900/8000 acc : 0.4854\n",
      " Current : 22 Acc : 0.5385999989509582 Test Acc : 0.44649999774992466\n",
      "\n",
      "Current Iter : 23/300 batch : 7900/8000 acc : 0.4549\n",
      " Current : 23 Acc : 0.5543999963998795 Test Acc : 0.4599999986588955\n",
      "\n",
      "Current Iter : 24/300 batch : 7900/8000 acc : 0.4963\n",
      " Current : 24 Acc : 0.5711999976634979 Test Acc : 0.4573749978095293\n",
      "\n",
      "Current Iter : 25/300 batch : 7900/8000 acc : 0.4852\n",
      " Current : 25 Acc : 0.5879999941587448 Test Acc : 0.447749999165535\n",
      "\n",
      "Current Iter : 26/300 batch : 7900/8000 acc : 0.5565\n",
      " Current : 26 Acc : 0.6007999980449676 Test Acc : 0.4582499969750643\n",
      "\n",
      "Current Iter : 27/300 batch : 7900/8000 acc : 0.4965\n",
      " Current : 27 Acc : 0.6280000030994415 Test Acc : 0.45624999739229677\n",
      "\n",
      "Current Iter : 28/300 batch : 7900/8000 acc : 0.4664\n",
      " Current : 28 Acc : 0.6302000045776367 Test Acc : 0.45962499678134916\n",
      "\n",
      "Current Iter : 29/300 batch : 7900/8000 acc : 0.5569\n",
      " Current : 29 Acc : 0.6572000014781952 Test Acc : 0.4464999955147505\n",
      "\n",
      "Current Iter : 30/300 batch : 7900/8000 acc : 0.5151\n",
      " Current : 30 Acc : 0.6695999991893768 Test Acc : 0.4671249967068434\n",
      "\n",
      "Current Iter : 31/300 batch : 7900/8000 acc : 0.4871\n",
      " Current : 31 Acc : 0.6748000025749207 Test Acc : 0.4556249979883432\n",
      "\n",
      "Current Iter : 32/300 batch : 7900/8000 acc : 0.4274\n",
      " Current : 32 Acc : 0.7042000031471253 Test Acc : 0.4333749983459711\n",
      "\n",
      "Current Iter : 33/300 batch : 7900/8000 acc : 0.5966\n",
      " Current : 33 Acc : 0.712200002670288 Test Acc : 0.4539999976754189\n",
      "\n",
      "Current Iter : 34/300 batch : 7900/8000 acc : 0.4465\n",
      " Current : 34 Acc : 0.7467999994754791 Test Acc : 0.44337499849498274\n",
      "\n",
      "Current Iter : 35/300 batch : 7900/8000 acc : 0.3872\n",
      " Current : 35 Acc : 0.7649999988079071 Test Acc : 0.45137499570846557\n",
      "\n",
      "Current Iter : 36/300 batch : 7900/8000 acc : 0.4974\n",
      " Current : 36 Acc : 0.7748000001907349 Test Acc : 0.43812499940395355\n",
      "\n",
      "Current Iter : 37/300 batch : 7900/8000 acc : 0.4573\n",
      " Current : 37 Acc : 0.7927999997138977 Test Acc : 0.4454999968409538\n",
      "\n",
      "Current Iter : 38/300 batch : 7900/8000 acc : 0.4486\n",
      " Current : 38 Acc : 0.8037999987602233 Test Acc : 0.44862499721348287\n",
      "\n",
      "Current Iter : 39/300 batch : 7900/8000 acc : 0.4878\n",
      " Current : 39 Acc : 0.8439999985694885 Test Acc : 0.44474999494850637\n",
      "\n",
      "Current Iter : 40/300 batch : 7900/8000 acc : 0.4785\n",
      " Current : 40 Acc : 0.857799996137619 Test Acc : 0.4394999958574772\n",
      "\n",
      "Current Iter : 41/300 batch : 7900/8000 acc : 0.4887\n",
      " Current : 41 Acc : 0.8625999999046325 Test Acc : 0.42949999757111074\n",
      "\n",
      "Current Iter : 42/300 batch : 7900/8000 acc : 0.3991\n",
      " Current : 42 Acc : 0.8958000028133393 Test Acc : 0.4386249970644712\n",
      "\n",
      "Current Iter : 43/300 batch : 7900/8000 acc : 0.5491\n",
      " Current : 43 Acc : 0.8762000012397766 Test Acc : 0.43037499859929085\n",
      "\n",
      "Current Iter : 44/300 batch : 7900/8000 acc : 0.4191\n",
      "-----------reset\n",
      "\n",
      " Current : 44 Acc : 0.9022000026702881 Test Acc : 0.45337499752640725\n",
      "\n",
      "Current Iter : 45/300 batch : 7900/8000 acc : 0.4642\n",
      " Current : 45 Acc : 0.3188000002503395 Test Acc : 0.3904999990016222\n",
      "\n",
      "Current Iter : 46/300 batch : 7900/8000 acc : 0.3946\n",
      " Current : 46 Acc : 0.44779999911785123 Test Acc : 0.4196249973028898\n",
      "\n",
      "Current Iter : 47/300 batch : 7900/8000 acc : 0.4744\n",
      " Current : 47 Acc : 0.486999996304512 Test Acc : 0.4349999982863665\n",
      "\n",
      "Current Iter : 48/300 batch : 7900/8000 acc : 0.4155\n",
      " Current : 48 Acc : 0.5227999949455261 Test Acc : 0.4366249978542328\n",
      "\n",
      "Current Iter : 49/300 batch : 7900/8000 acc : 0.4257\n",
      " Current : 49 Acc : 0.550999995470047 Test Acc : 0.46337499767541884\n",
      "\n",
      "Current Iter : 50/300 batch : 7900/8000 acc : 0.5452\n",
      " Current : 50 Acc : 0.5853999996185303 Test Acc : 0.4563749980181456\n",
      "\n",
      "Current Iter : 51/300 batch : 7900/8000 acc : 0.4858\n",
      " Current : 51 Acc : 0.6041999983787537 Test Acc : 0.4584999971091747\n",
      "\n",
      "Current Iter : 52/300 batch : 7900/8000 acc : 0.5452\n",
      " Current : 52 Acc : 0.6437999987602234 Test Acc : 0.45624999664723875\n",
      "\n",
      "Current Iter : 53/300 batch : 7900/8000 acc : 0.4668\n",
      " Current : 53 Acc : 0.6704000008106231 Test Acc : 0.46212499886751174\n",
      "\n",
      "Current Iter : 54/300 batch : 7900/8000 acc : 0.4766\n",
      " Current : 54 Acc : 0.6790000021457672 Test Acc : 0.45862499810755253\n",
      "\n",
      "Current Iter : 55/300 batch : 7900/8000 acc : 0.4969\n",
      " Current : 55 Acc : 0.7082000029087067 Test Acc : 0.4437499973922968\n",
      "\n",
      "Current Iter : 56/300 batch : 7900/8000 acc : 0.4172\n",
      " Current : 56 Acc : 0.7392000019550323 Test Acc : 0.4546249959617853\n",
      "\n",
      "Current Iter : 57/300 batch : 7900/8000 acc : 0.5275\n",
      " Current : 57 Acc : 0.7522000002861023 Test Acc : 0.44737499617040155\n",
      "\n",
      "Current Iter : 58/300 batch : 7900/8000 acc : 0.4984\n",
      " Current : 58 Acc : 0.7786000001430512 Test Acc : 0.45862499959766867\n",
      "\n",
      "Current Iter : 59/300 batch : 7900/8000 acc : 0.4978\n",
      " Current : 59 Acc : 0.824199994802475 Test Acc : 0.44187499955296516\n",
      "\n",
      "Current Iter : 60/300 batch : 7900/8000 acc : 0.5375\n",
      " Current : 60 Acc : 0.8330000007152557 Test Acc : 0.4603749953210354\n",
      "\n",
      "Current Iter : 61/300 batch : 7900/8000 acc : 0.4584\n",
      " Current : 61 Acc : 0.8535999953746796 Test Acc : 0.44974999874830246\n",
      "\n",
      "Current Iter : 62/300 batch : 7900/8000 acc : 0.5293\n",
      " Current : 62 Acc : 0.88700000166893 Test Acc : 0.4416249956935644\n",
      "\n",
      "Current Iter : 63/300 batch : 7900/8000 acc : 0.4388\n",
      " Current : 63 Acc : 0.8820000004768371 Test Acc : 0.43924999944865706\n",
      "\n",
      "Current Iter : 64/300 batch : 7900/8000 acc : 0.4387\n",
      " Current : 64 Acc : 0.8970000004768371 Test Acc : 0.43449999690055846\n",
      "\n",
      "Current Iter : 65/300 batch : 7900/8000 acc : 0.4593\n",
      "-----------reset\n",
      "\n",
      " Current : 65 Acc : 0.9224000012874604 Test Acc : 0.4348749961704016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 66/300 batch : 7900/8000 acc : 0.4455\n",
      " Current : 66 Acc : 0.441799995303154 Test Acc : 0.43687499724328516\n",
      "\n",
      "Current Iter : 67/300 batch : 7900/8000 acc : 0.5268\n",
      " Current : 67 Acc : 0.5545999962091446 Test Acc : 0.4509999956935644\n",
      "\n",
      "Current Iter : 68/300 batch : 7900/8000 acc : 0.4857\n",
      " Current : 68 Acc : 0.6217999970912933 Test Acc : 0.455249996855855\n",
      "\n",
      "Current Iter : 69/300 batch : 7900/8000 acc : 0.4265\n",
      " Current : 69 Acc : 0.6713999998569489 Test Acc : 0.46137499772012236\n",
      "\n",
      "Current Iter : 70/300 batch : 7900/8000 acc : 0.4471\n",
      " Current : 70 Acc : 0.7048000013828277 Test Acc : 0.45624999776482583\n",
      "\n",
      "Current Iter : 71/300 batch : 7900/8000 acc : 0.4574\n",
      " Current : 71 Acc : 0.7458000004291534 Test Acc : 0.4393749989569187\n",
      "\n",
      "Current Iter : 72/300 batch : 7900/8000 acc : 0.4774\n",
      " Current : 72 Acc : 0.7779999995231628 Test Acc : 0.4454999979585409\n",
      "\n",
      "Current Iter : 73/300 batch : 7900/8000 acc : 0.4881\n",
      " Current : 73 Acc : 0.8041999995708465 Test Acc : 0.45949999764561655\n",
      "\n",
      "Current Iter : 74/300 batch : 7900/8000 acc : 0.3868\n",
      " Current : 74 Acc : 0.8363999938964843 Test Acc : 0.4442499987781048\n",
      "\n",
      "Current Iter : 75/300 batch : 7900/8000 acc : 0.4983\n",
      " Current : 75 Acc : 0.841199997663498 Test Acc : 0.44824999682605265\n",
      "\n",
      "Current Iter : 76/300 batch : 7900/8000 acc : 0.4193\n",
      " Current : 76 Acc : 0.8857999968528748 Test Acc : 0.4444999974220991\n",
      "\n",
      "Current Iter : 77/300 batch : 7900/8000 acc : 0.5792\n",
      "-----------reset\n",
      "\n",
      " Current : 77 Acc : 0.9058000004291534 Test Acc : 0.4492499966174364\n",
      "\n",
      "Current Iter : 78/300 batch : 7900/8000 acc : 0.3563\n",
      " Current : 78 Acc : 0.49539999902248383 Test Acc : 0.4463749974966049\n",
      "\n",
      "Current Iter : 79/300 batch : 7900/8000 acc : 0.4274\n",
      " Current : 79 Acc : 0.6366000008583069 Test Acc : 0.44737499877810477\n",
      "\n",
      "Current Iter : 80/300 batch : 7900/8000 acc : 0.3679\n",
      " Current : 80 Acc : 0.700800005197525 Test Acc : 0.4579999975860119\n",
      "\n",
      "Current Iter : 81/300 batch : 7900/8000 acc : 0.3766\n",
      " Current : 81 Acc : 0.7556000030040741 Test Acc : 0.45387499779462814\n",
      "\n",
      "Current Iter : 82/300 batch : 7900/8000 acc : 0.4776\n",
      " Current : 82 Acc : 0.7875999975204467 Test Acc : 0.444999997317791\n",
      "\n",
      "Current Iter : 83/300 batch : 7900/8000 acc : 0.4483\n",
      " Current : 83 Acc : 0.8279999947547912 Test Acc : 0.4383749976754189\n",
      "\n",
      "Current Iter : 84/300 batch : 7900/8000 acc : 0.4395\n",
      " Current : 84 Acc : 0.8401999962329865 Test Acc : 0.4429999962449074\n",
      "\n",
      "Current Iter : 85/300 batch : 7900/8000 acc : 0.4286\n",
      " Current : 85 Acc : 0.8704000008106232 Test Acc : 0.4341249972581863\n",
      "\n",
      "Current Iter : 86/300 batch : 7900/8000 acc : 0.3891\n",
      " Current : 86 Acc : 0.8977999997138977 Test Acc : 0.4518749978393316\n",
      "\n",
      "Current Iter : 87/300 batch : 7900/8000 acc : 0.4693\n",
      "-----------reset\n",
      "\n",
      " Current : 87 Acc : 0.9193999993801117 Test Acc : 0.4417499966919422\n",
      "\n",
      "Current Iter : 88/300 batch : 7900/8000 acc : 0.4766\n",
      " Current : 88 Acc : 0.575 Test Acc : 0.4494999971240759\n",
      "\n",
      "Current Iter : 89/300 batch : 7900/8000 acc : 0.5184\n",
      " Current : 89 Acc : 0.7090000033378601 Test Acc : 0.46449999772012235\n",
      "\n",
      "Current Iter : 90/300 batch : 7900/8000 acc : 0.4777\n",
      " Current : 90 Acc : 0.7745999968051911 Test Acc : 0.45212499909102916\n",
      "\n",
      "Current Iter : 91/300 batch : 7900/8000 acc : 0.4981\n",
      " Current : 91 Acc : 0.788199998140335 Test Acc : 0.441874997317791\n",
      "\n",
      "Current Iter : 92/300 batch : 7900/8000 acc : 0.4489\n",
      " Current : 92 Acc : 0.8489999997615815 Test Acc : 0.447624996304512\n",
      "\n",
      "Current Iter : 93/300 batch : 7900/8000 acc : 0.4289\n",
      " Current : 93 Acc : 0.8651999998092651 Test Acc : 0.44162499718368053\n",
      "\n",
      "Current Iter : 94/300 batch : 7900/8000 acc : 0.4887\n",
      " Current : 94 Acc : 0.891599999666214 Test Acc : 0.44199999757111075\n",
      "\n",
      "Current Iter : 95/300 batch : 7900/8000 acc : 0.3783\n",
      " Current : 95 Acc : 0.8948000025749206 Test Acc : 0.45062499567866326\n",
      "\n",
      "Current Iter : 96/300 batch : 7900/8000 acc : 0.5195\n",
      "-----------reset\n",
      "\n",
      " Current : 96 Acc : 0.9063999998569489 Test Acc : 0.4449999965727329\n",
      "\n",
      "Current Iter : 97/300 batch : 7900/8000 acc : 0.4382\n",
      " Current : 97 Acc : 0.6033999991416931 Test Acc : 0.4537499971687794\n",
      "\n",
      "Current Iter : 98/300 batch : 7900/8000 acc : 0.5475\n",
      " Current : 98 Acc : 0.7362000024318696 Test Acc : 0.4533749997615814\n",
      "\n",
      "Current Iter : 99/300 batch : 7900/8000 acc : 0.4674\n",
      " Current : 99 Acc : 0.8146000027656555 Test Acc : 0.44237499721348283\n",
      "\n",
      "Current Iter : 100/300 batch : 7900/8000 acc : 0.4683\n",
      " Current : 100 Acc : 0.8303999972343444 Test Acc : 0.43799999766051767\n",
      "\n",
      "Current Iter : 101/300 batch : 7900/8000 acc : 0.3682\n",
      " Current : 101 Acc : 0.8805999970436096 Test Acc : 0.4439999986439943\n",
      "\n",
      "Current Iter : 102/300 batch : 7900/8000 acc : 0.4287\n",
      "-----------reset\n",
      "\n",
      " Current : 102 Acc : 0.9144000017642975 Test Acc : 0.43874999731779096\n",
      "\n",
      "Current Iter : 103/300 batch : 7900/8000 acc : 0.5665\n",
      " Current : 103 Acc : 0.6325999987125397 Test Acc : 0.4567499965429306\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-344-0be228c2d0e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_more\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \"\"\"\n\u001b[0;32m    402\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mresampled_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mresampled_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[0;32m    215\u001b[0m             \u001b[1;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 300 ; avg_acc_train = 0; avg_acc_test  = 0; train_more = 1\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    test_images,test_labels   = shuffle(test_images,test_labels);\n",
    "\n",
    "    for i in range(train_more):\n",
    "        train_images,train_labels = shuffle(train_images,train_labels);\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label})\n",
    "            sys.stdout.write(str(i) + ' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "\n",
    "    if avg_acc_train/(len(train_images)/batch_size)/train_more > 0.9 and avg_acc_test/(len(test_images)/batch_size) < 0.5 :  \n",
    "        print('\\n-----------reset')\n",
    "        sess.run(all_update)\n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)/train_more) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T21:03:17.629751Z",
     "start_time": "2018-12-10T21:03:16.795967Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
