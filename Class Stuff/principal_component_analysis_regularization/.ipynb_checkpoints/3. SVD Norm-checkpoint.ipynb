{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:28:19.338871Z",
     "start_time": "2018-12-11T18:28:19.333883Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:28:45.410902Z",
     "start_time": "2018-12-11T18:28:43.468129Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:28:49.908336Z",
     "start_time": "2018-12-11T18:28:46.446594Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:28:49.995103Z",
     "start_time": "2018-12-11T18:28:49.963189Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:12:25.951904Z",
     "start_time": "2018-12-11T19:12:25.941930Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the svd layer\n",
    "class svd_layer():\n",
    "    \n",
    "    def __init__(self,batch,channel,size):\n",
    "        self.n = size\n",
    "        self.moving_s = tf.Variable(tf.zeros((batch_size,channel,size),dtype=tf.float32))\n",
    "    \n",
    "    def feedforward(self,data,training_phase):\n",
    "        \n",
    "        batch,width,height,channel = data.shape\n",
    "#         data = tf.transpose(data,(0,3,1,2))\n",
    "        with tf.device('/cpu:0'):\n",
    "            s,U,V = tf.svd(data)\n",
    "        number_of_element = self.n\n",
    "        s         = s[:,:,:number_of_element]\n",
    "        # smin      = tf.reduce_min(s,(2),keepdims=True)\n",
    "        # smax      = tf.reduce_max(s,(2),keepdims=True)\n",
    "        # s         = (mmax-mmin)*((s-smin)/(smax-smin)) + mmin\n",
    "        \n",
    "        def training_fn():\n",
    "            data      = U[:,:,:,:number_of_element] @ tf.matrix_diag(s) @ tf.transpose(V,(0,1,3,2))[:,:,:number_of_element,:]\n",
    "            return data\n",
    "            \n",
    "        def testing_fn():\n",
    "            data      = U[:,:,:,:number_of_element] @ tf.matrix_diag(self.moving_s) @ tf.transpose(V,(0,1,3,2))[:,:,:number_of_element,:]\n",
    "            return data\n",
    "        \n",
    "        data  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "#         data  = tf.transpose(data,(0,2,3,1))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:12:58.401258Z",
     "start_time": "2018-12-11T19:12:58.081115Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "learning_rate = 0.0008; batch_size = 100\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:39:34.908152Z",
     "start_time": "2018-12-11T19:39:34.823378Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Svd_97:0\", shape=(100, 16), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"Svd_97:1\", shape=(100, 576, 16), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"Svd_97:2\", shape=(100, 16, 16), dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"matmul_47:0\", shape=(100, 576, 16), dtype=float32)\n",
      "Tensor(\"Elu_518:0\", shape=(100, 6, 6, 32), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot reshape a tensor with 115200 elements to shape [100,576,16] (921600 elements) for 'Reshape_19' (op: 'Reshape') with input shapes: [100,6,6,32], [3] and with input tensors computed as partial shapes: input[1] = [100,576,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot reshape a tensor with 115200 elements to shape [100,576,16] (921600 elements) for 'Reshape_19' (op: 'Reshape') with input shapes: [100,6,6,32], [3] and with input tensors computed as partial shapes: input[1] = [100,576,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-90d5e0bba5ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mlayer6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer5\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mlayer6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   6480\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6481\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6482\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   6483\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6484\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot reshape a tensor with 115200 elements to shape [100,576,16] (921600 elements) for 'Reshape_19' (op: 'Reshape') with input shapes: [100,6,6,32], [3] and with input tensors computed as partial shapes: input[1] = [100,576,16]."
     ]
    }
   ],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "n = tf.placeholder(shape=(),dtype=tf.int32)\n",
    "is_train = tf.placeholder_with_default(False,())\n",
    "\n",
    "layer1 = l1.feedforward(x       ,padding='SAME',stride=2)\n",
    "layer2 = l2.feedforward(layer1  ,padding='SAME',stride=2) \n",
    "layer3 = l3.feedforward(layer2  ,padding='SAME',stride=1)\n",
    "\n",
    "# have to do this\n",
    "layer3 = tf.reshape(layer3,(batch_size,24*24,16))\n",
    "with tf.device('/cpu:0'):\n",
    "    s,U,V = tf.svd(layer3,False)\n",
    "print(s)\n",
    "print(U)\n",
    "print(V)\n",
    "layer3 = U[:,:,:n] @ tf.matrix_diag(s)[:,:n,:n] @ tf.transpose(V,(0,2,1))[:,:n,:]\n",
    "print(layer3)\n",
    "layer3 = tf.reshape(layer3,(batch_size,24,24,16))\n",
    "\n",
    "layer4 = l4.feedforward(layer3  ,padding='SAME',stride=2) \n",
    "layer5 = l5.feedforward(layer4  ,padding='SAME',stride=2)\n",
    "layer6 = l6.feedforward(layer5  ,padding='SAME',stride=1)\n",
    "\n",
    "layer6 = tf.reshape(layer6,(batch_size,6*6,32))\n",
    "with tf.device('/cpu:0'):\n",
    "    s1,U1,V1 = tf.svd(layer6,False)\n",
    "layer6 = U1[:,:,:n] @ tf.matrix_diag(s1)[:,:n,:n] @ tf.transpose(V1,(0,2,1))[:,:n,:]\n",
    "layer6 = tf.reshape(layer6,(batch_size,24,24,16))\n",
    "\n",
    "layer7 = l7.feedforward(layer6  ,padding='SAME',stride=1)\n",
    "layer8 = l8.feedforward(layer7  ,padding='SAME',stride=1) \n",
    "layer9 = l9.feedforward(layer8  ,padding='SAME',stride=1)\n",
    "print(layer9)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "auto_train  = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:38:36.772547Z",
     "start_time": "2018-12-11T19:27:26.074429Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7900/8000 acc : 0.13\n",
      " Current : 0 Acc : 0.11579999953508377 Test Acc : 0.1361250003334135\n",
      "\n",
      "Current Iter : 1/300 batch : 7900/8000 acc : 0.18\n",
      " Current : 1 Acc : 0.16240000002086163 Test Acc : 0.18162500075995922\n",
      "\n",
      "Current Iter : 2/300 batch : 7900/8000 acc : 0.23\n",
      " Current : 2 Acc : 0.2088000002503395 Test Acc : 0.24950000010430812\n",
      "\n",
      "Current Iter : 3/300 batch : 7900/8000 acc : 0.22\n",
      " Current : 3 Acc : 0.2497999992966652 Test Acc : 0.26075000055134295\n",
      "\n",
      "Current Iter : 4/300 batch : 7900/8000 acc : 0.32\n",
      " Current : 4 Acc : 0.27760000109672545 Test Acc : 0.2850000005215406\n",
      "\n",
      "Current Iter : 5/300 batch : 7900/8000 acc : 0.26\n",
      " Current : 5 Acc : 0.29680000007152557 Test Acc : 0.29450000124052167\n",
      "\n",
      "Current Iter : 6/300 batch : 7900/8000 acc : 0.33\n",
      " Current : 6 Acc : 0.31520000159740447 Test Acc : 0.32150000259280204\n",
      "\n",
      "Current Iter : 7/300 batch : 7900/8000 acc : 0.31\n",
      " Current : 7 Acc : 0.3370000010728836 Test Acc : 0.3450000027194619\n",
      "\n",
      "Current Iter : 8/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 8 Acc : 0.35579999923706057 Test Acc : 0.359124999679625\n",
      "\n",
      "Current Iter : 9/300 batch : 7900/8000 acc : 0.28\n",
      " Current : 9 Acc : 0.3652000033855438 Test Acc : 0.3580000003799796\n",
      "\n",
      "Current Iter : 10/300 batch : 7900/8000 acc : 0.31\n",
      " Current : 10 Acc : 0.3768000000715256 Test Acc : 0.3673750013113022\n",
      "\n",
      "Current Iter : 11/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 11 Acc : 0.38779999792575837 Test Acc : 0.367875000834465\n",
      "\n",
      "Current Iter : 12/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 12 Acc : 0.395799999833107 Test Acc : 0.386999998614192\n",
      "\n",
      "Current Iter : 13/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 13 Acc : 0.40340000092983247 Test Acc : 0.3885000001639128\n",
      "\n",
      "Current Iter : 14/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 14 Acc : 0.4155999970436096 Test Acc : 0.38512500040233133\n",
      "\n",
      "Current Iter : 15/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 15 Acc : 0.42359999716281893 Test Acc : 0.397749999538064\n",
      "\n",
      "Current Iter : 16/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 16 Acc : 0.43560000002384186 Test Acc : 0.4077500008046627\n",
      "\n",
      "Current Iter : 17/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 17 Acc : 0.4443999981880188 Test Acc : 0.39549999833106997\n",
      "\n",
      "Current Iter : 18/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 18 Acc : 0.4543999969959259 Test Acc : 0.40899999886751176\n",
      "\n",
      "Current Iter : 19/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 19 Acc : 0.4527999985218048 Test Acc : 0.40912500135600566\n",
      "\n",
      "Current Iter : 20/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 20 Acc : 0.46739999353885653 Test Acc : 0.4184999976307154\n",
      "\n",
      "Current Iter : 21/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 21 Acc : 0.4775999993085861 Test Acc : 0.42112499587237834\n",
      "\n",
      "Current Iter : 22/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 22 Acc : 0.49259999573230745 Test Acc : 0.43174999840557576\n",
      "\n",
      "Current Iter : 23/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 23 Acc : 0.49440000057220457 Test Acc : 0.43199999667704103\n",
      "\n",
      "Current Iter : 24/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 24 Acc : 0.5133999931812286 Test Acc : 0.44424999691545963\n",
      "\n",
      "Current Iter : 25/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 25 Acc : 0.5033999949693679 Test Acc : 0.4437499973922968\n",
      "\n",
      "Current Iter : 26/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 26 Acc : 0.5179999995231629 Test Acc : 0.4384999983012676\n",
      "\n",
      "Current Iter : 27/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 27 Acc : 0.528399994969368 Test Acc : 0.4252499986439943\n",
      "\n",
      "Current Iter : 28/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 28 Acc : 0.5169999986886978 Test Acc : 0.4537499971687794\n",
      "\n",
      "Current Iter : 29/300 batch : 7900/8000 acc : 0.58\n",
      " Current : 29 Acc : 0.5267999964952469 Test Acc : 0.44862499795854094\n",
      "\n",
      "Current Iter : 30/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.5493999975919723 Test Acc : 0.44649999849498273\n",
      "\n",
      "Current Iter : 31/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 31 Acc : 0.5507999980449676 Test Acc : 0.43799999691545966\n",
      "\n",
      "Current Iter : 32/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 32 Acc : 0.5625999999046326 Test Acc : 0.41949999816715716\n",
      "\n",
      "Current Iter : 33/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 33 Acc : 0.5613999950885773 Test Acc : 0.4464999955147505\n",
      "\n",
      "Current Iter : 34/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 34 Acc : 0.5797999995946884 Test Acc : 0.4442499987781048\n",
      "\n",
      "Current Iter : 35/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 35 Acc : 0.5845999985933303 Test Acc : 0.4421249970793724\n",
      "\n",
      "Current Iter : 36/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 36 Acc : 0.5820000004768372 Test Acc : 0.43974999710917473\n",
      "\n",
      "Current Iter : 37/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 37 Acc : 0.6062000024318696 Test Acc : 0.4515000004321337\n",
      "\n",
      "Current Iter : 38/300 batch : 7900/8000 acc : 0.51\n",
      " Current : 38 Acc : 0.6204000020027161 Test Acc : 0.4422499995678663\n",
      "\n",
      "Current Iter : 39/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 39 Acc : 0.612999997138977 Test Acc : 0.43024999685585497\n",
      "\n",
      "Current Iter : 40/300 batch : 7900/8000 acc : 0.53\n",
      " Current : 40 Acc : 0.63200000166893 Test Acc : 0.45137499645352364\n",
      "\n",
      "Current Iter : 41/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 41 Acc : 0.6337999987602234 Test Acc : 0.44799999706447124\n",
      "\n",
      "Current Iter : 42/300 batch : 7900/8000 acc : 0.55\n",
      " Current : 42 Acc : 0.65 Test Acc : 0.44037499837577343\n",
      "\n",
      "Current Iter : 43/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 43 Acc : 0.6574000012874603 Test Acc : 0.44449999891221526\n",
      "\n",
      "Current Iter : 44/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 44 Acc : 0.6770000004768372 Test Acc : 0.4471249967813492\n",
      "\n",
      "Current Iter : 45/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 45 Acc : 0.6758000063896179 Test Acc : 0.4438749972730875\n",
      "\n",
      "Current Iter : 46/300 batch : 7900/8000 acc : 0.59\n",
      " Current : 46 Acc : 0.6897999942302704 Test Acc : 0.4381249979138374\n",
      "\n",
      "Current Iter : 47/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 47 Acc : 0.7090000033378601 Test Acc : 0.4279999975115061\n",
      "\n",
      "Current Iter : 48/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 48 Acc : 0.6960000050067902 Test Acc : 0.4308749992400408\n",
      "\n",
      "Current Iter : 49/300 batch : 7900/8000 acc : 0.54\n",
      " Current : 49 Acc : 0.7124000036716461 Test Acc : 0.448124997317791\n",
      "\n",
      "Current Iter : 50/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 50 Acc : 0.7321999967098236 Test Acc : 0.45162499845027926\n",
      "\n",
      "Current Iter : 51/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 51 Acc : 0.7432000005245208 Test Acc : 0.4329999998211861\n",
      "\n",
      "Current Iter : 52/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 52 Acc : 0.7357999992370605 Test Acc : 0.4401249963790178\n",
      "\n",
      "Current Iter : 53/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 53 Acc : 0.7635999989509582 Test Acc : 0.44274999797344206\n",
      "\n",
      "Current Iter : 54/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 54 Acc : 0.7651999998092651 Test Acc : 0.4344999972730875\n",
      "\n",
      "Current Iter : 55/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 55 Acc : 0.7741999983787536 Test Acc : 0.43949999697506426\n",
      "\n",
      "Current Iter : 56/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 56 Acc : 0.7755999982357025 Test Acc : 0.4298749975860119\n",
      "\n",
      "Current Iter : 57/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 57 Acc : 0.7582000017166137 Test Acc : 0.4338749974966049\n",
      "\n",
      "Current Iter : 58/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 58 Acc : 0.8203999996185303 Test Acc : 0.43937499485909937\n",
      "\n",
      "Current Iter : 59/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 59 Acc : 0.8373999965190887 Test Acc : 0.43824999816715715\n",
      "\n",
      "Current Iter : 60/300 batch : 7900/8000 acc : 0.61\n",
      " Current : 60 Acc : 0.8353999972343444 Test Acc : 0.42824999913573264\n",
      "\n",
      "Current Iter : 61/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 61 Acc : 0.8344000005722045 Test Acc : 0.4309999976307154\n",
      "\n",
      "Current Iter : 62/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 62 Acc : 0.8257999980449676 Test Acc : 0.43074999563395977\n",
      "\n",
      "Current Iter : 63/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 63 Acc : 0.8620000016689301 Test Acc : 0.42674999833106997\n",
      "\n",
      "Current Iter : 64/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 64 Acc : 0.8478000020980835 Test Acc : 0.4348749976605177\n",
      "\n",
      "Current Iter : 65/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 65 Acc : 0.8695999979972839 Test Acc : 0.4228749990463257\n",
      "\n",
      "Current Iter : 66/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 66 Acc : 0.8623999953269958 Test Acc : 0.42037499882280827\n",
      "\n",
      "Current Iter : 67/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 67 Acc : 0.883400000333786 Test Acc : 0.43249999955296514\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 68 Acc : 0.8854000008106232 Test Acc : 0.4256249967962503\n",
      "\n",
      "Current Iter : 69/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 69 Acc : 0.8880000019073486 Test Acc : 0.4174999989569187\n",
      "\n",
      "Current Iter : 70/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 70 Acc : 0.8894000005722046 Test Acc : 0.4291249975562096\n",
      "\n",
      "Current Iter : 71/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 71 Acc : 0.9230000054836274 Test Acc : 0.4236249964684248\n",
      "\n",
      "Current Iter : 72/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 72 Acc : 0.9034000051021576 Test Acc : 0.42499999776482583\n",
      "\n",
      "Current Iter : 73/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 73 Acc : 0.9075999999046326 Test Acc : 0.4199999988079071\n",
      "\n",
      "Current Iter : 74/300 batch : 7900/8000 acc : 0.36\n",
      " Current : 74 Acc : 0.9145999991893768 Test Acc : 0.4181249991059303\n",
      "\n",
      "Current Iter : 75/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 75 Acc : 0.9151999998092651 Test Acc : 0.4324999962002039\n",
      "\n",
      "Current Iter : 76/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 76 Acc : 0.953800003528595 Test Acc : 0.420874997228384\n",
      "\n",
      "Current Iter : 77/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 77 Acc : 0.9434000039100647 Test Acc : 0.4158749975264072\n",
      "\n",
      "Current Iter : 78/300 batch : 7900/8000 acc : 0.33\n",
      " Current : 78 Acc : 0.9342000019550324 Test Acc : 0.4177499979734421\n",
      "\n",
      "Current Iter : 79/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 79 Acc : 0.9344000005722046 Test Acc : 0.4191249992698431\n",
      "\n",
      "Current Iter : 80/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 80 Acc : 0.9390000057220459 Test Acc : 0.41424999944865704\n",
      "\n",
      "Current Iter : 81/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 81 Acc : 0.9448000001907348 Test Acc : 0.4206249974668026\n",
      "\n",
      "Current Iter : 82/300 batch : 7900/8000 acc : 0.52\n",
      " Current : 82 Acc : 0.9372000050544739 Test Acc : 0.4241249978542328\n",
      "\n",
      "Current Iter : 83/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 83 Acc : 0.9590000057220459 Test Acc : 0.4229999970644712\n",
      "\n",
      "Current Iter : 84/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 84 Acc : 0.9786000108718872 Test Acc : 0.4254999976605177\n",
      "\n",
      "Current Iter : 85/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 85 Acc : 0.963600002527237 Test Acc : 0.424874996393919\n",
      "\n",
      "Current Iter : 86/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 86 Acc : 0.968000009059906 Test Acc : 0.4272499967366457\n",
      "\n",
      "Current Iter : 87/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 87 Acc : 0.9754000079631805 Test Acc : 0.4228749979287386\n",
      "\n",
      "Current Iter : 88/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 88 Acc : 0.9792000067234039 Test Acc : 0.4192499976605177\n",
      "\n",
      "Current Iter : 89/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 89 Acc : 0.9718000090122223 Test Acc : 0.41362499855458734\n",
      "\n",
      "Current Iter : 90/300 batch : 7900/8000 acc : 0.59\n",
      " Current : 90 Acc : 0.9620000052452088 Test Acc : 0.41899999752640726\n",
      "\n",
      "Current Iter : 91/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 91 Acc : 0.9294000041484832 Test Acc : 0.4141249995678663\n",
      "\n",
      "Current Iter : 92/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 92 Acc : 0.9381999969482422 Test Acc : 0.4202499981969595\n",
      "\n",
      "Current Iter : 93/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 93 Acc : 0.9267999982833862 Test Acc : 0.41712500117719176\n",
      "\n",
      "Current Iter : 94/300 batch : 7900/8000 acc : 0.33\n",
      " Current : 94 Acc : 0.9730000066757202 Test Acc : 0.42737499959766867\n",
      "\n",
      "Current Iter : 95/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 95 Acc : 0.9884000098705292 Test Acc : 0.42062499932944775\n",
      "\n",
      "Current Iter : 96/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 96 Acc : 0.9968000030517579 Test Acc : 0.42749999836087227\n",
      "\n",
      "Current Iter : 97/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 97 Acc : 1.0 Test Acc : 0.42899999767541885\n",
      "\n",
      "Current Iter : 98/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 98 Acc : 1.0 Test Acc : 0.43037499822676184\n",
      "\n",
      "Current Iter : 99/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 99 Acc : 1.0 Test Acc : 0.43174999915063383\n",
      "\n",
      "Current Iter : 100/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 100 Acc : 1.0 Test Acc : 0.42987499833106996\n",
      "\n",
      "Current Iter : 101/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 101 Acc : 1.0 Test Acc : 0.4327499967068434\n",
      "\n",
      "Current Iter : 102/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 102 Acc : 1.0 Test Acc : 0.4299999974668026\n",
      "\n",
      "Current Iter : 103/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 103 Acc : 1.0 Test Acc : 0.4312499973922968\n",
      "\n",
      "Current Iter : 104/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 104 Acc : 1.0 Test Acc : 0.43087499737739565\n",
      "\n",
      "Current Iter : 105/300 batch : 7900/8000 acc : 0.34\n",
      " Current : 105 Acc : 1.0 Test Acc : 0.43149999603629113\n",
      "\n",
      "Current Iter : 106/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 106 Acc : 1.0 Test Acc : 0.4304999988526106\n",
      "\n",
      "Current Iter : 107/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 107 Acc : 1.0 Test Acc : 0.4302499987185001\n",
      "\n",
      "Current Iter : 108/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 108 Acc : 1.0 Test Acc : 0.43212499655783176\n",
      "\n",
      "Current Iter : 109/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 109 Acc : 1.0 Test Acc : 0.42974999770522115\n",
      "\n",
      "Current Iter : 110/300 batch : 7900/8000 acc : 0.53\n",
      " Current : 110 Acc : 1.0 Test Acc : 0.43062499798834325\n",
      "\n",
      "Current Iter : 111/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 111 Acc : 1.0 Test Acc : 0.4307499978691339\n",
      "\n",
      "Current Iter : 112/300 batch : 7900/8000 acc : 0.48\n",
      " Current : 112 Acc : 1.0 Test Acc : 0.4309999976307154\n",
      "\n",
      "Current Iter : 113/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 113 Acc : 1.0 Test Acc : 0.43024999760091304\n",
      "\n",
      "Current Iter : 114/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 114 Acc : 1.0 Test Acc : 0.4298749972134829\n",
      "\n",
      "Current Iter : 115/300 batch : 7900/8000 acc : 0.47\n",
      " Current : 115 Acc : 1.0 Test Acc : 0.43087499886751174\n",
      "\n",
      "Current Iter : 116/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 116 Acc : 1.0 Test Acc : 0.4312499985098839\n",
      "\n",
      "Current Iter : 117/300 batch : 7900/8000 acc : 0.39\n",
      " Current : 117 Acc : 1.0 Test Acc : 0.4303749997168779\n",
      "\n",
      "Current Iter : 118/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 118 Acc : 1.0 Test Acc : 0.4289999969303608\n",
      "\n",
      "Current Iter : 119/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 119 Acc : 1.0 Test Acc : 0.4303749971091747\n",
      "\n",
      "Current Iter : 120/300 batch : 7900/8000 acc : 0.42\n",
      " Current : 120 Acc : 1.0 Test Acc : 0.4312499962747097\n",
      "\n",
      "Current Iter : 121/300 batch : 7900/8000 acc : 0.34\n",
      " Current : 121 Acc : 1.0 Test Acc : 0.43087499774992466\n",
      "\n",
      "Current Iter : 122/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 122 Acc : 1.0 Test Acc : 0.4291249968111515\n",
      "\n",
      "Current Iter : 123/300 batch : 7900/8000 acc : 0.45\n",
      " Current : 123 Acc : 1.0 Test Acc : 0.42887500002980233\n",
      "\n",
      "Current Iter : 124/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 124 Acc : 1.0 Test Acc : 0.4297499980777502\n",
      "\n",
      "Current Iter : 125/300 batch : 7900/8000 acc : 0.38\n",
      " Current : 125 Acc : 1.0 Test Acc : 0.4307499974966049\n",
      "\n",
      "Current Iter : 126/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 126 Acc : 1.0 Test Acc : 0.4306249987334013\n",
      "\n",
      "Current Iter : 127/300 batch : 7900/8000 acc : 0.44\n",
      " Current : 127 Acc : 1.0 Test Acc : 0.43037499822676184\n",
      "\n",
      "Current Iter : 128/300 batch : 7900/8000 acc : 0.43\n",
      " Current : 128 Acc : 1.0 Test Acc : 0.4307499974966049\n",
      "\n",
      "Current Iter : 129/300 batch : 7900/8000 acc : 0.46\n",
      " Current : 129 Acc : 1.0 Test Acc : 0.4301249969750643\n",
      "\n",
      "Current Iter : 130/300 batch : 7900/8000 acc : 0.58\n",
      " Current : 130 Acc : 1.0 Test Acc : 0.43037499859929085\n",
      "\n",
      "Current Iter : 131/300 batch : 7900/8000 acc : 0.58\n",
      " Current : 131 Acc : 1.0 Test Acc : 0.4304999992251396\n",
      "\n",
      "Current Iter : 132/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 132 Acc : 1.0 Test Acc : 0.4293749984353781\n",
      "\n",
      "Current Iter : 133/300 batch : 7900/8000 acc : 0.41\n",
      " Current : 133 Acc : 1.0 Test Acc : 0.43137499913573263\n",
      "\n",
      "Current Iter : 134/300 batch : 7900/8000 acc : 0.49\n",
      " Current : 134 Acc : 1.0 Test Acc : 0.4298749979585409\n",
      "\n",
      "Current Iter : 135/300 batch : 7900/8000 acc : 0.37\n",
      " Current : 135 Acc : 1.0 Test Acc : 0.42987499870359897\n",
      "\n",
      "Current Iter : 136/300 batch : 6000/8000 acc : 0.42\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-c44f422c0c13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 300 ; avg_acc_train = 0; avg_acc_test  = 0; train_more = 1\n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    train_images,train_labels = shuffle(train_images,train_labels);\n",
    "    test_images,test_labels   = shuffle(test_images,test_labels);\n",
    "\n",
    "    for i in range(train_more):\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "            sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label,is_train:True,n:8})\n",
    "            sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False,n:16})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)/train_more) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T21:03:17.629751Z",
     "start_time": "2018-12-10T21:03:16.795967Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
