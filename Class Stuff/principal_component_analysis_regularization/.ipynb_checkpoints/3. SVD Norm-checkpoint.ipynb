{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:30:31.213021Z",
     "start_time": "2018-12-12T17:30:16.905306Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import lib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys, os,cv2\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.misc import imread,imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:30:33.123538Z",
     "start_time": "2018-12-12T17:30:31.289821Z"
    },
    "code_folding": [
     0,
     1,
     28
    ]
   },
   "outputs": [],
   "source": [
    "# read all of the data\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "    \n",
    "train_images = read_all_images(\"../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:30:37.024277Z",
     "start_time": "2018-12-12T17:30:33.380085Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [0. 0. 0.] [0.44671062 0.43980984 0.40664645] [0.26034098 0.25657727 0.27126738]\n",
      "(5000, 96, 96, 3)\n",
      "(5000, 10)\n",
      "[1. 1. 1.] [0. 0. 0.] [0.44723063 0.43964247 0.40495725] [0.2605645  0.25666146 0.26997382]\n",
      "(8000, 96, 96, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "# some basic statistic of train and test image // hyper\n",
    "print(train_images.max((0,1,2)),train_images.min((0,1,2)),train_images.mean((0,1,2)),train_images.std((0,1,2)) )\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.max((0,1,2)),test_images.min((0,1,2)),test_images.mean((0,1,2)),test_images.std((0,1,2)) )\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "num_epoch = 50 ; learning_rate = 0.0008; batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:45:27.702385Z",
     "start_time": "2018-12-12T17:45:27.658458Z"
    },
    "code_folding": [
     26,
     82
    ]
   },
   "outputs": [],
   "source": [
    "# import layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_elu(x):     return tf.nn.elu(x)\n",
    "def d_tf_elu(x):   return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "def tf_relu(x):    return tf.nn.relu(x)\n",
    "def d_tf_relu(x):  return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x): return x\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_elu,d_act=d_tf_elu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.moving_w   = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.b          = tf.Variable(tf.zeros(out,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.mb,self.vb = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return [self.w,self.b]\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding)\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad_b      = tf.reduce_mean(grad_middle,(0,1,2))/batch_size\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        \n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        update_w.append(tf.assign( self.mb,self.mb*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign( self.vb,self.vb*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hatb = self.mb / (1-beta1) ; v_hatb = self.vb / (1-beta2)\n",
    "        adam_middleb = m_hatb * learning_rate/(tf.sqrt(v_hatb) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middleb  )))\n",
    "        \n",
    "        return grad_pass,update_w\n",
    "    \n",
    "    def updatew(self):\n",
    "        w,h,inc,outc = self.w.shape\n",
    "        \n",
    "        tempw = tf.reshape(self.w,(w*h,inc,outc))\n",
    "        tempw = tf.transpose(tempw,(1,2,0))\n",
    "        s,U,V = tf.svd(tempw)\n",
    "\n",
    "        scaleds = (s-tf.reduce_min(s,1,True))/(tf.reduce_max(s,1,True)-tf.reduce_min(s,1,True) + 1e-8 )\n",
    "        _,n     = s.shape\n",
    "        n       = 2\n",
    "\n",
    "        neww   = U[:,:,n:n+3] @ tf.matrix_diag(scaleds)[:,n:n+3,n:n+3] @ tf.transpose(V,(0,2,1))[:,n:n+3,:]\n",
    "        neww   = tf.transpose(neww,(2,0,1))\n",
    "        neww   = tf.reshape(neww,(w,h,inc,outc))\n",
    "        \n",
    "        update = []\n",
    "        # update.append(tf.assign(self.moving_w,self.moving_w * 0.5 + 0.5 * neww))\n",
    "        update.append(tf.assign(self.w,neww))\n",
    "        return update\n",
    "    \n",
    "# create the svd layer\n",
    "class svd_layer():\n",
    "    \n",
    "    def __init__(self,batch,size,width):\n",
    "        self.n = size\n",
    "        self.moving_s = tf.Variable(tf.zeros((batch_size,size),dtype=tf.float32))\n",
    "        self.moving_u = tf.Variable(tf.zeros((batch_size,width**2,size),dtype=tf.float32))\n",
    "        self.moving_v = tf.Variable(tf.zeros((batch_size,size,size),dtype=tf.float32))\n",
    "    \n",
    "    def feedforward(self,data,training_phase):\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            s,U,V = tf.svd(data)\n",
    "        print(s)\n",
    "        print(U)\n",
    "        print(V)\n",
    "        smin = tf.reduce_min(s,1,keepdims=True)\n",
    "        smax = tf.reduce_max(s,1,keepdims=True)\n",
    "        scaleds = (s - smin)/(smax-smin + 1e-8)\n",
    "        def training_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            data = data  * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u*0.9 + 0.1 * U))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v*0.9 + 0.1 * V))\n",
    "            return data,update\n",
    "            \n",
    "        def testing_fn():\n",
    "            data      = U[:,:,:] @ tf.matrix_diag(s)[:,:,:] @ tf.transpose(V,(0,2,1))[:,:,:]\n",
    "            # data      = data * tf.reduce_mean(tf.transpose(tf.abs(V),(0,2,1)) * scaleds[:,:,None] ,(1),keepdims=True)\n",
    "            update = []\n",
    "            update.append(tf.assign(self.moving_u,self.moving_u))\n",
    "            update.append(tf.assign(self.moving_v,self.moving_v))\n",
    "            return data,update\n",
    "        \n",
    "        data,update  = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return data,update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:45:28.446350Z",
     "start_time": "2018-12-12T17:45:28.106260Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# restart the graph \n",
    "# sess.close()\n",
    "# tf.reset_default_graph()\n",
    "learning_rate = 0.0008; batch_size = 100\n",
    "\n",
    "l1 = CNN(3,3, 16)\n",
    "l2 = CNN(3,16,16)\n",
    "l3 = CNN(3,16,16)\n",
    "\n",
    "l4 = CNN(3,16,32)\n",
    "l5 = CNN(3,32,32)\n",
    "l6 = CNN(3,32,32)\n",
    "\n",
    "l7 = CNN(3,32,64)\n",
    "l8 = CNN(3,64,64)\n",
    "l9 = CNN(3,64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:45:29.408779Z",
     "start_time": "2018-12-12T17:45:28.817358Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build graph \n",
    "x = tf.placeholder(shape=(batch_size,96,96,3),dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(batch_size,10),dtype=tf.float32)\n",
    "is_train = tf.placeholder_with_default(False,())\n",
    "\n",
    "layer1 = l1.feedforward(x       ,padding='SAME',stride=2)\n",
    "layer2 = l2.feedforward(layer1  ,padding='SAME',stride=2) \n",
    "layer3 = l3.feedforward(layer2  ,padding='SAME',stride=1)\n",
    "layer3 = tf.layers.batch_normalization(layer3,training=is_train)\n",
    "\n",
    "layer4 = l4.feedforward(layer3  ,padding='SAME',stride=2) \n",
    "layer5 = l5.feedforward(layer4  ,padding='SAME',stride=2)\n",
    "layer6 = l6.feedforward(layer5  ,padding='SAME',stride=1)\n",
    "layer6 = tf.layers.batch_normalization(layer6,training=is_train)\n",
    "\n",
    "layer7 = l7.feedforward(layer6  ,padding='SAME',stride=1)\n",
    "layer8 = l8.feedforward(layer7  ,padding='SAME',stride=1) \n",
    "layer9 = l9.feedforward(layer8  ,padding='SAME',stride=1)\n",
    "\n",
    "all_update  = l1.updatew() + l2.updatew() + l3.updatew() + l4.updatew() + l5.updatew() + l6.updatew() + l7.updatew() + l8.updatew() + l9.updatew() \n",
    "final_layer = tf.reduce_mean(layer9,axis=(1,2))\n",
    "cost        = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y)\n",
    "optimizer   = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "reset_optimizer_op = tf.variables_initializer(optimizer.variables())\n",
    "auto_train  = optimizer.minimize(cost)\n",
    "\n",
    "final_softmax      = tf_softmax(final_layer)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T17:50:31.490Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : 0 Acc : 0.14179999984800815 Test Acc : 0.1877500002272427\n",
      "Current : 1 Acc : 0.21279999986290932 Test Acc : 0.24812500085681677\n",
      "Current : 2 Acc : 0.25740000039339067 Test Acc : 0.27800000067800285\n",
      "Current : 3 Acc : 0.2812000003457069 Test Acc : 0.2796250004321337\n",
      "Current : 4 Acc : 0.2898000007867813 Test Acc : 0.3018750002607703\n",
      "Current : 5 Acc : 0.3252000018954277 Test Acc : 0.3335000041872263\n",
      "Current : 6 Acc : 0.3437999990582466 Test Acc : 0.33750000279396775\n",
      "Current : 7 Acc : 0.3551999992132187 Test Acc : 0.34249999970197675\n",
      "Current : 8 Acc : 0.36520000010728837 Test Acc : 0.3506250001490116\n",
      "Current : 9 Acc : 0.37679999828338623 Test Acc : 0.36162499971687795\n",
      "Current : 10 Acc : 0.3917999976873398 Test Acc : 0.3657500000670552\n",
      "Current : 11 Acc : 0.41079999566078185 Test Acc : 0.3980000000447035\n",
      "Current : 12 Acc : 0.4160000002384186 Test Acc : 0.3855000000447035\n",
      "Current : 13 Acc : 0.4283999979496002 Test Acc : 0.4061249990016222\n",
      "Current : 14 Acc : 0.43419999837875367 Test Acc : 0.396374998986721\n",
      "Current : 15 Acc : 0.4525999981164932 Test Acc : 0.42399999760091306\n",
      "Current : 16 Acc : 0.47740000128746035 Test Acc : 0.4363749984651804\n",
      "Current : 17 Acc : 0.4931999975442886 Test Acc : 0.42999999672174455\n",
      "Current : 18 Acc : 0.12800000011920928 Test Acc : 0.16412500003352762\n",
      "Current : 19 Acc : 0.1623999997228384 Test Acc : 0.1988749999552965\n",
      "Current : 20 Acc : 0.2328000009059906 Test Acc : 0.24224999994039537\n",
      "Current : 21 Acc : 0.26239999920129775 Test Acc : 0.25150000024586916\n",
      "Current : 22 Acc : 0.2902000007033348 Test Acc : 0.29475000146776437\n",
      "Current : 23 Acc : 0.3030000016093254 Test Acc : 0.2863750014454126\n",
      "Current : 24 Acc : 0.3258000022172928 Test Acc : 0.33200000170618293\n",
      "Current : 25 Acc : 0.35439999878406525 Test Acc : 0.32762500178068876\n",
      "Current : 26 Acc : 0.36280000060796735 Test Acc : 0.3473750000819564\n",
      "Current : 27 Acc : 0.37919999957084655 Test Acc : 0.37150000035762787\n",
      "Current : 28 Acc : 0.3955999970436096 Test Acc : 0.3942500002682209\n",
      "Current : 29 Acc : 0.4159999966621399 Test Acc : 0.3913750000298023\n",
      "Current : 30 Acc : 0.42679999887943265 Test Acc : 0.402250000089407\n",
      "Current : 31 Acc : 0.44679999589920044 Test Acc : 0.3972500003874302\n",
      "Current : 32 Acc : 0.44959999799728395 Test Acc : 0.4123749990016222\n",
      "Current : 33 Acc : 0.4703999972343445 Test Acc : 0.42374999932944774\n",
      "Current : 34 Acc : 0.4741999977827072 Test Acc : 0.4423749979585409\n",
      "Current : 35 Acc : 0.46779999673366546 Test Acc : 0.434749998152256\n",
      "Current : 36 Acc : 0.4995999962091446 Test Acc : 0.4326249975711107\n",
      "Current : 37 Acc : 0.13840000003576278 Test Acc : 0.1778749999590218\n",
      "Current : 38 Acc : 0.19719999939203262 Test Acc : 0.1944999996572733\n",
      "Current : 39 Acc : 0.23440000027418137 Test Acc : 0.27987500056624415\n",
      "Current : 40 Acc : 0.2856000018119812 Test Acc : 0.27562500033527615\n",
      "Current : 41 Acc : 0.3000000002980232 Test Acc : 0.3057500025257468\n",
      "Current : 42 Acc : 0.32860000103712084 Test Acc : 0.3437500011175871\n",
      "Current : 43 Acc : 0.3612000024318695 Test Acc : 0.3226250022649765\n",
      "Current : 44 Acc : 0.38439999997615815 Test Acc : 0.36487499959766867\n",
      "Current : 45 Acc : 0.3968000012636185 Test Acc : 0.3742499999701977\n",
      "Current : 46 Acc : 0.41580000162124636 Test Acc : 0.38462499864399435\n",
      "Current : 47 Acc : 0.43499999701976777 Test Acc : 0.3979999989271164\n",
      "Current : 48 Acc : 0.4387999999523163 Test Acc : 0.40762499868869784\n",
      "Current : 49 Acc : 0.46279999673366545 Test Acc : 0.40949999783188107\n",
      "Current : 50 Acc : 0.10299999974668025 Test Acc : 0.1037499999627471\n",
      "Current : 51 Acc : 0.10299999974668025 Test Acc : 0.10599999958649278\n",
      "Current : 52 Acc : 0.11060000035911799 Test Acc : 0.12050000010058284\n",
      "Current : 53 Acc : 0.12919999971985818 Test Acc : 0.13725000009872018\n",
      "Current : 54 Acc : 0.13700000040233135 Test Acc : 0.13987500010989606\n",
      "Current : 55 Acc : 0.13419999986886977 Test Acc : 0.1328750004991889\n",
      "Current : 56 Acc : 0.1373999997973442 Test Acc : 0.1513749998062849\n",
      "Current : 57 Acc : 0.14380000039935112 Test Acc : 0.1487500007264316\n",
      "Current : 58 Acc : 0.15179999977350234 Test Acc : 0.11687499969266354\n",
      "Current : 59 Acc : 0.10019999898970128 Test Acc : 0.1\n",
      "Current : 60 Acc : 0.09999999992549419 Test Acc : 0.1\n",
      "Current : 61 Acc : 0.1 Test Acc : 0.18000 acc : 0.082\n",
      "Current : 62 Acc : 0.12059999998658895 Test Acc : 0.16412500077858566\n",
      "Current : 63 Acc : 0.15680000007152559 Test Acc : 0.17487500058487057\n",
      "Current : 64 Acc : 0.17160000085830687 Test Acc : 0.1773750003427267\n",
      "Current : 65 Acc : 0.18300000011920928 Test Acc : 0.1981249999254942\n",
      "Current : 66 Acc : 0.21599999994039534 Test Acc : 0.23737500067800282\n",
      "Current : 67 Acc : 0.26 Test Acc : 0.2577500009909272\n",
      "Current : 68 Acc : 0.27259999781847 Test Acc : 0.2755000006407499\n",
      "Current : 69 Acc : 0.29580000042915344 Test Acc : 0.2871250003576279\n",
      "Current : 70 Acc : 0.31340000212192537 Test Acc : 0.31850000098347664\n",
      "Current : 71 Acc : 0.3216000017523766 Test Acc : 0.31987500190734863\n",
      "Current : 72 Acc : 0.32920000195503235 Test Acc : 0.3316250009462237\n",
      "Current : 73 Acc : 0.3529999998211861 Test Acc : 0.3404999999329448\n",
      "Current : 74 Acc : 0.3597999995946884 Test Acc : 0.36587499883025887\n",
      "Current : 75 Acc : 0.3837999975681305 Test Acc : 0.3813749998807907\n",
      "Current : 76 Acc : 0.3970000010728836 Test Acc : 0.39112499859184024\n",
      "Current : 77 Acc : 0.40340000033378604 Test Acc : 0.3749999998137355\n",
      "Current : 78 Acc : 0.42560000002384185 Test Acc : 0.4036249991506338\n",
      "Current : 79 Acc : 0.43479999899864197 Test Acc : 0.40549999959766864\n",
      "Current : 80 Acc : 0.4427999973297119 Test Acc : 0.39500000029802323\n",
      "Current : 81 Acc : 0.45219999849796294 Test Acc : 0.419124998524785\n",
      "Current : 82 Acc : 0.46219999611377716 Test Acc : 0.4251249983906746\n",
      "Current : 83 Acc : 0.4743999981880188 Test Acc : 0.41874999888241293\n",
      "Current : 84 Acc : 0.09339999962598085 Test Acc : 0.09949999996460974\n",
      "Current : 85 Acc : 0.1001999993622303 Test Acc : 0.09987499993294477\n",
      "Current : 86 Acc : 0.09999999959021806 Test Acc : 0.09999999990686774\n",
      "Current : 87 Acc : 0.09999999959021806 Test Acc : 0.09999999990686774\n",
      "Current : 88 Acc : 0.10000000018626451 Test Acc : 0.09999999990686774\n",
      "Current : 89 Acc : 0.10719999998807907 Test Acc : 0.1008749998640269\n",
      "Current : 90 Acc : 0.12379999995231629 Test Acc : 0.1681249998509884\n",
      "Current : 91 Acc : 0.17180000007152557 Test Acc : 0.1601250003091991\n",
      "Current : 92 Acc : 0.18900000020861626 Test Acc : 0.2168750001117587\n",
      "Current : 93 Acc : 0.24659999936819077 Test Acc : 0.26312500014901163\n",
      "Current : 94 Acc : 0.2748000019788742 Test Acc : 0.2950000012293458\n",
      "Current : 95 Acc : 0.3062000024318695 Test Acc : 0.3126250009983778\n",
      "Current : 96 Acc : 0.31880000203847886 Test Acc : 0.32837500143796206\n",
      "Current : 97 Acc : 0.34100000143051146 Test Acc : 0.3401250008493662\n",
      "Current : 98 Acc : 0.3554000017046928 Test Acc : 0.3300000008195639\n",
      "Current : 99 Acc : 0.3802000004053116 Test Acc : 0.3665000002831221\n",
      "Current : 100 Acc : 0.37639999866485596 Test Acc : 0.3717500001192093\n",
      "Current : 101 Acc : 0.4011999976634979 Test Acc : 0.39724999815225603\n",
      "Current : 102 Acc : 0.4223999983072281 Test Acc : 0.39012499935925005\n",
      "Current : 103 Acc : 0.42439999580383303 Test Acc : 0.4037499975413084\n",
      "Current : 104 Acc : 0.4369999980926514 Test Acc : 0.4169999957084656\n",
      "Current : 105 Acc : 0.45779999732971194 Test Acc : 0.42212499752640725\n",
      "Current : 106 Acc : 0.4653999948501587 Test Acc : 0.42212499752640725\n",
      "Current : 107 Acc : 0.4701999962329865 Test Acc : 0.42399999797344207\n",
      "Current : 108 Acc : 0.4877999997138977 Test Acc : 0.4292499989271164\n",
      "Current : 109 Acc : 0.10140000030398369 Test Acc : 0.10137500008568168\n",
      "Current : 110 Acc : 0.10079999953508377 Test Acc : 0.12199999997392297\n",
      "Current : 111 Acc : 0.11920000068843364 Test Acc : 0.15687500005587934\n",
      "Current : 112 Acc : 0.20400000005960464 Test Acc : 0.23700000001117588\n",
      "Current : 113 Acc : 0.2750000011920929 Test Acc : 0.2568749997764826\n",
      "Current : 114 Acc : 0.3146000015735626 Test Acc : 0.31950000058859584\n",
      "Current : 115 Acc : 0.3316000008583069 Test Acc : 0.3441249992698431\n",
      "Current : 116 Acc : 0.36780000030994414 Test Acc : 0.3622500002384186\n",
      "Current : 117 Acc : 0.38420000225305556 Test Acc : 0.36400000005960464\n",
      "Current : 118 Acc : 0.39999999940395353 Test Acc : 0.3697500007227063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : 119 Acc : 0.4139999973773956 Test Acc : 0.37887500002980234\n",
      "Current : 120 Acc : 0.42859999895095824 Test Acc : 0.39812499955296515\n",
      "Current : 121 Acc : 0.44039999961853027 Test Acc : 0.4193749979138374\n",
      "Current : 122 Acc : 0.45879999935626986 Test Acc : 0.4208749957382679\n",
      "Current : 123 Acc : 0.47339999735355376 Test Acc : 0.4294999986886978\n",
      "Current : 124 Acc : 0.4977999991178513 Test Acc : 0.42624999918043616\n",
      "Current : 125 Acc : 0.10979999989271164 Test Acc : 0.09962499989196658\n",
      "Current : 126 Acc : 0.10599999986588955 Test Acc : 0.13549999948590993\n",
      "Current : 127 Acc : 0.14799999989569187 Test Acc : 0.17750000013038517\n",
      "Current : 128 Acc : 0.17740000054240226 Test Acc : 0.21137499902397394\n",
      "Current : 129 Acc : 0.21300000086426735 Test Acc : 0.2248749990016222\n",
      "Current : 130 Acc : 0.2338000002503395 Test Acc : 0.2641250007785857\n",
      "Current : 131 Acc : 0.30280000030994414 Test Acc : 0.32087500151246784\n",
      "Current : 132 Acc : 0.3366000032424927 Test Acc : 0.34900000132620335\n",
      "Current : 133 Acc : 0.35459999918937685 Test Acc : 0.3681249987334013\n",
      "Current : 134 Acc : 0.3805999979376793 Test Acc : 0.38262500185519455\n",
      "Current : 135 Acc : 0.39439999997615816 Test Acc : 0.3993749987334013\n",
      "Current : 136 Acc : 0.4147999978065491 Test Acc : 0.39762500002980233\n",
      "Current : 137 Acc : 0.4353999978303909 Test Acc : 0.425374997779727\n",
      "Current : 138 Acc : 0.4625999957323074 Test Acc : 0.43575000017881393\n",
      "Current : 139 Acc : 0.4713999980688095 Test Acc : 0.44374999664723874\n",
      "Current : 140 Acc : 0.4749999964237213 Test Acc : 0.4408749982714653\n",
      "Current : 141 Acc : 0.4923999959230423 Test Acc : 0.4316249996423721\n",
      "Current : 142 Acc : 0.10639999963343144 Test Acc : 0.10037499978207051\n",
      "Current : 143 Acc : 0.11800000041723252 Test Acc : 0.1620000010356307\n",
      "Current : 144 Acc : 0.14580000020563602 Test Acc : 0.14325000010430813\n",
      "Current : 145 Acc : 0.17420000106096267 Test Acc : 0.1735000006854534\n",
      "Current : 146 Acc : 0.19239999935030938 Test Acc : 0.23825000058859586\n",
      "Current : 147 Acc : 0.23380000084638597 Test Acc : 0.27249999884516\n",
      "Current : 148 Acc : 0.2780000001192093 Test Acc : 0.2767500013113022\n",
      "Current : 149 Acc : 0.2898000028729439 Test Acc : 0.3333750024437904\n",
      "Current : 150 Acc : 0.33500000059604645 Test Acc : 0.34400000162422656\n",
      "Current : 151 Acc : 0.368199999332428 Test Acc : 0.35049999952316285\n",
      "Current : 152 Acc : 0.3740000009536743 Test Acc : 0.3677500009536743\n",
      "Current : 153 Acc : 0.39379999876022337 Test Acc : 0.38362500034272673\n",
      "Current : 154 Acc : 0.40079999923706056 Test Acc : 0.4042499974370003\n",
      "Current : 155 Acc : 0.42799999594688415 Test Acc : 0.3974999986588955\n",
      "Current : 156 Acc : 0.4391999965906143 Test Acc : 0.4086249988526106\n",
      "Current : 157 Acc : 0.44879999697208406 Test Acc : 0.41412500105798244\n",
      "Current : 158 Acc : 0.45659999787807465 Test Acc : 0.4228749979287386\n",
      "Current : 159 Acc : 0.46999999940395354 Test Acc : 0.42337499782443044\n",
      "Current : 160 Acc : 0.4801999986171722 Test Acc : 0.437499999627471\n",
      "Current : 161 Acc : 0.49499999403953554 Test Acc : 0.43487499803304674\n",
      "Current : 162 Acc : 0.10180000014603138 Test Acc : 0.10000000023283065\n",
      "Current : 163 Acc : 0.10000000044703483 Test Acc : 0.10050000012852252\n",
      "Current : 164 Acc : 0.10299999974668025 Test Acc : 0.09925000004004687\n",
      "Current : 165 Acc : 0.1002000005915761 Test Acc : 0.19\n",
      "Current : 166 Acc : 0.09999999977648258 Test Acc : 0.1\n",
      "Current : 167 Acc : 0.09999999985098838 Test Acc : 0.1\n",
      "Current : 168 Acc : 0.1019999997317791 Test Acc : 0.11\n",
      "Current : 169 Acc : 0.10099999949336053 Test Acc : 0.10824999962933361\n",
      "Current : 170 Acc : 0.14919999971985817 Test Acc : 0.1715000013820827\n",
      "Current : 171 Acc : 0.19899999991059303 Test Acc : 0.22612499920651316\n",
      "Current : 172 Acc : 0.2510000014305115 Test Acc : 0.2349999975413084\n",
      "Current : 173 Acc : 0.26799999982118605 Test Acc : 0.2890000019222498\n",
      "Current : 174 Acc : 0.2948000001907349 Test Acc : 0.29362500123679636\n",
      "Current : 175 Acc : 0.3179999986290932 Test Acc : 0.3031250011175871\n",
      "Current : 176 Acc : 0.32720000147819517 Test Acc : 0.3298750001937151\n",
      "Current : 177 Acc : 0.34940000116825104 Test Acc : 0.3561249999329448\n",
      "Current : 178 Acc : 0.36659999907016755 Test Acc : 0.36700000129640103\n",
      "Current : 179 Acc : 0.3855999982357025 Test Acc : 0.35750000141561034\n",
      "Current : 180 Acc : 0.39879999935626986 Test Acc : 0.3917500000447035\n",
      "Current : 181 Acc : 0.4219999986886978 Test Acc : 0.4088749971240759\n",
      "Current : 182 Acc : 0.4395999985933304 Test Acc : 0.4122499983757734\n",
      "Current : 183 Acc : 0.45519999563694 Test Acc : 0.42487499862909317\n",
      "Current : 184 Acc : 0.4605999976396561 Test Acc : 0.4384999983012676\n",
      "Current : 185 Acc : 0.4805999970436096 Test Acc : 0.43949999697506426\n",
      "Current : 186 Acc : 0.5053999978303909 Test Acc : 0.4393749997019768\n",
      "Current : 187 Acc : 0.09659999992698431 Test Acc : 0.1\n",
      "Current : 188 Acc : 0.10560000069439411 Test Acc : 0.14400000004097818\n",
      "Current : 189 Acc : 0.1519999997317791 Test Acc : 0.15637499978765845\n",
      "Current : 190 Acc : 0.17519999980926515 Test Acc : 0.18962500067427754\n",
      "Current : 191 Acc : 0.22180000066757202 Test Acc : 0.23737499825656413\n",
      "Current : 192 Acc : 0.28340000063180926 Test Acc : 0.2943750018253922\n",
      "Current : 193 Acc : 0.3128000015020371 Test Acc : 0.33450000267475843\n",
      "Current : 194 Acc : 0.3648000031709671 Test Acc : 0.3742500014603138\n",
      "Current : 195 Acc : 0.37520000100135803 Test Acc : 0.36425000093877313\n",
      "Current : 196 Acc : 0.386000000834465 Test Acc : 0.3951249998062849\n",
      "Current : 197 Acc : 0.4247999978065491 Test Acc : 0.41012499779462813\n",
      "Current : 198 Acc : 0.4265999972820282 Test Acc : 0.41137499883770945\n",
      "Current : 199 Acc : 0.4449999976158142 Test Acc : 0.4227499980479479\n",
      "Current : 200 Acc : 0.4483999997377396 Test Acc : 0.44062499776482583\n",
      "Current : 201 Acc : 0.46599999487400057 Test Acc : 0.4439999978989363\n",
      "Current : 202 Acc : 0.4811999976634979 Test Acc : 0.4327499967068434\n",
      "Current : 203 Acc : 0.5027999979257584 Test Acc : 0.453499998152256\n",
      "Current : 204 Acc : 0.5011999976634979 Test Acc : 0.43887499906122684\n",
      "Current : 205 Acc : 0.12340000048279762 Test Acc : 0.1182500003837049\n",
      "Current : 206 Acc : 0.12379999995231629 Test Acc : 0.11962500018998981\n",
      "Current : 207 Acc : 0.13379999995231628 Test Acc : 0.15225000027567148\n",
      "Current : 208 Acc : 0.15440000012516975 Test Acc : 0.18487499943003058\n",
      "Current : 209 Acc : 0.18720000073313714 Test Acc : 0.2181250002235174\n",
      "Current : 210 Acc : 0.24119999915361404 Test Acc : 0.22412499887868761\n",
      "Current : 211 Acc : 0.25480000019073484 Test Acc : 0.26025000102818013\n",
      "Current : 212 Acc : 0.2812000012397766 Test Acc : 0.28950000163167716\n",
      "Current : 213 Acc : 0.2942000013589859 Test Acc : 0.284875001758337\n",
      "Current : 214 Acc : 0.3056000012159348 Test Acc : 0.3168750021606684\n",
      "Current : 215 Acc : 0.3338000014424324 Test Acc : 0.30862500201910736\n",
      "Current : 216 Acc : 0.35240000069141386 Test Acc : 0.3583750005811453\n",
      "Current : 217 Acc : 0.38419999957084655 Test Acc : 0.37062499988824127\n",
      "Current : 218 Acc : 0.399200000166893 Test Acc : 0.37087500020861625\n",
      "Current : 219 Acc : 0.41179999768733977 Test Acc : 0.4077499993145466\n",
      "Current : 220 Acc : 0.41779999911785126 Test Acc : 0.4032499983906746\n",
      "Current : 221 Acc : 0.44599999725818634 Test Acc : 0.4172499991953373\n",
      "Current : 222 Acc : 0.4607999974489212 Test Acc : 0.42137499861419203\n",
      "Current : 223 Acc : 0.4605999976396561 Test Acc : 0.4381249986588955\n",
      "Current : 224 Acc : 0.4775999993085861 Test Acc : 0.44549999609589575\n",
      "Current : 225 Acc : 0.488599995970726 Test Acc : 0.4402499977499247\n",
      "Current : 226 Acc : 0.5101999986171722 Test Acc : 0.4457499966025352\n",
      "Current : 227 Acc : 0.072799999602139 Test Acc : 0.1029999997233972\n",
      "Current : 228 Acc : 0.10000000074505806 Test Acc : 0.09975000016856939\n",
      "Current : 229 Acc : 0.10020000025629998 Test Acc : 0.1\n",
      "Current : 230 Acc : 0.09999999977648258 Test Acc : 0.1\n",
      "Current : 231 Acc : 0.10000000029802322 Test Acc : 0.10100000051315874\n",
      "Current : 232 Acc : 0.14479999981820582 Test Acc : 0.17650000033900143\n",
      "Current : 233 Acc : 0.17740000035613776 Test Acc : 0.19050000039860607\n",
      "Current : 234 Acc : 0.1956000007688999 Test Acc : 0.22575000040233134\n",
      "Current : 235 Acc : 0.25219999939203264 Test Acc : 0.2726250015199184\n",
      "Current : 236 Acc : 0.28839999973773955 Test Acc : 0.3012500010430813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : 237 Acc : 0.31040000200271606 Test Acc : 0.2921249998733401\n",
      "Current : 238 Acc : 0.3260000011324882 Test Acc : 0.3318750005215406\n",
      "Current : 239 Acc : 0.33820000231266023 Test Acc : 0.33987499978393315\n",
      "Current : 240 Acc : 0.3668000003695488 Test Acc : 0.3398750001564622\n",
      "Current : 241 Acc : 0.37640000104904175 Test Acc : 0.3512500010430813\n",
      "Current : 242 Acc : 0.3885999992489815 Test Acc : 0.35049999970942736\n",
      "Current : 243 Acc : 0.38759999960660935 Test Acc : 0.3866249993443489\n",
      "Current : 244 Acc : 0.412399999499321 Test Acc : 0.3882500004023314\n",
      "Current : 245 Acc : 0.42279999792575834 Test Acc : 0.37787499986588957\n",
      "Current : 246 Acc : 0.43059999763965606 Test Acc : 0.3824999988079071\n",
      "Current : 247 Acc : 0.4453999948501587 Test Acc : 0.37262499909847974\n",
      "Current : 248 Acc : 0.10980000011622906 Test Acc : 0.10212500016205013\n",
      "Current : 249 Acc : 0.10140000030398369 Test Acc : 0.10499999965541065\n",
      "Current : 250 Acc : 0.12100000109523534 Test Acc : 0.14287500036880374\n",
      "Current : 251 Acc : 0.15120000079274176 Test Acc : 0.19012500066310167\n",
      "Current : 252 Acc : 0.22179999977350234 Test Acc : 0.234375\n",
      "Current : 253 Acc : 0.27660000026226045 Test Acc : 0.27524999994784594\n",
      "Current : 254 Acc : 0.2766000020503998 Test Acc : 0.2715000009164214\n",
      "Current : 255 Acc : 0.3006000009179115 Test Acc : 0.2859999999403954\n",
      "Current : 256 Acc : 0.32680000066757203 Test Acc : 0.3306250018998981\n",
      "Current : 257 Acc : 0.34819999992847445 Test Acc : 0.33987500090152023\n",
      "Current : 258 Acc : 0.35500000059604647 Test Acc : 0.34050000105053185\n",
      "Current : 259 Acc : 0.3806000030040741 Test Acc : 0.3701249998062849\n",
      "Current : 260 Acc : 0.39199999868869784 Test Acc : 0.3813749995082617\n",
      "Current : 261 Acc : 0.41159999907016753 Test Acc : 0.379874998703599\n",
      "Current : 262 Acc : 0.4226000016927719 Test Acc : 0.3859999986365438\n",
      "Current : 263 Acc : 0.4333999979496002 Test Acc : 0.4044999998062849\n",
      "Current : 264 Acc : 0.4567999970912933 Test Acc : 0.4111249968409538\n",
      "Current : 265 Acc : 0.47159999668598174 Test Acc : 0.41199999749660493\n",
      "Current : 266 Acc : 0.10159999988973141 Test Acc : 0.10050000003539025\n",
      "Current : 267 Acc : 0.104599999897182 Test Acc : 0.1029999997932464\n",
      "Current : 268 Acc : 0.11059999935328961 Test Acc : 0.11649999991059304\n",
      "Current : 269 Acc : 0.1043999994546175 Test Acc : 0.10100000014062971\n",
      "Current : 270 Acc : 0.10839999973773956 Test Acc : 0.1627500005066395\n",
      "Current : 271 Acc : 0.14940000027418138 Test Acc : 0.17800000086426734\n",
      "Current : 272 Acc : 0.20579999804496765 Test Acc : 0.2305000001564622\n",
      "Current : 273 Acc : 0.2546000011265278 Test Acc : 0.27750000115483997\n",
      "Current : 274 Acc : 0.28099999904632567 Test Acc : 0.30012500267475845\n",
      "Current : 275 Acc : 0.3136000019311905 Test Acc : 0.3202500011771917\n",
      "Current : 276 Acc : 0.3336000025272369 Test Acc : 0.28750000037252904\n",
      "Current : 277 Acc : 0.34060000002384183 Test Acc : 0.35137500017881396\n",
      "Current : 278 Acc : 0.38200000166893006 Test Acc : 0.37887500002980234\n",
      "Current : 279 Acc : 0.40299999713897705 Test Acc : 0.3904999990016222\n",
      "Current : 280 Acc : 0.41499999940395355 Test Acc : 0.3962499987334013\n",
      "Current : 281 Acc : 0.4325999963283539 Test Acc : 0.41449999883770944\n",
      "Current : 282 Acc : 0.4437999975681305 Test Acc : 0.4206249978393316\n",
      "Current : 283 Acc : 0.46019999384880067 Test Acc : 0.43162499777972696\n",
      "Current : 284 Acc : 0.47019999504089355 Test Acc : 0.44037499837577343\n",
      "Current : 285 Acc : 0.490999995470047 Test Acc : 0.4454999968409538\n",
      "Current : 286 Acc : 0.5025999969244004 Test Acc : 0.4404999975115061\n",
      "Current : 287 Acc : 0.09059999987483025 Test Acc : 0.09337500035762787\n",
      "Current : 288 Acc : 0.09279999997466802 Test Acc : 0.09599999957717956\n",
      "Current : 289 Acc : 0.08959999956190585 Test Acc : 0.09087500018067658\n",
      "Current : 290 Acc : 0.09259999983012676 Test Acc : 0.1\n",
      "Current : 291 Acc : 0.10039999954402447 Test Acc : 0.1248750001192093\n",
      "Current : 292 Acc : 0.13260000064969063 Test Acc : 0.16075000073760748\n",
      "Current : 293 Acc : 0.16500000014901162 Test Acc : 0.1848750002682209\n",
      "Current : 294 Acc : 0.23080000087618827 Test Acc : 0.25337500013411046\n",
      "Current : 295 Acc : 0.27299999952316284 Test Acc : 0.2913750009611249\n",
      "Current : 296 Acc : 0.2943999999761581 Test Acc : 0.2841250000521541\n",
      "Current : 297 Acc : 0.3102000033855438 Test Acc : 0.32362500093877317\n",
      "Current : 298 Acc : 0.3366000020503998 Test Acc : 0.3437500009313226\n",
      "Current : 299 Acc : 0.35060000121593476 Test Acc : 0.3616250013932586\n",
      "Current : 300 Acc : 0.38160000085830686 Test Acc : 0.37425000220537186\n",
      "Current : 301 Acc : 0.39839999973773954 Test Acc : 0.3808749983087182\n",
      "Current : 302 Acc : 0.409200000166893 Test Acc : 0.38999999947845937\n",
      "Current : 303 Acc : 0.4257999974489212 Test Acc : 0.4078750003129244\n",
      "Current : 304 Acc : 0.4397999972105026 Test Acc : 0.41549999788403513\n",
      "Current : 305 Acc : 0.4547999995946884 Test Acc : 0.43087499774992466\n",
      "Current : 306 Acc : 0.4817999964952469 Test Acc : 0.43599999956786634\n",
      "Current : 307 Acc : 0.49859999656677245 Test Acc : 0.45112499706447123\n",
      "Current : 308 Acc : 0.5047999948263169 Test Acc : 0.4356249988079071\n",
      "Current : 309 Acc : 0.09480000033974648 Test Acc : 0.09187500004190952\n",
      "Current : 310 Acc : 0.09300000008195639 Test Acc : 0.09274999992921948\n",
      "Current : 311 Acc : 0.09360000006854534 Test Acc : 0.09299999934155494\n",
      "Current : 312 Acc : 0.08799999978393316 Test Acc : 0.08362500013317913\n",
      "Current : 313 Acc : 0.09719999998807907 Test Acc : 0.1\n",
      "Current : 314 Acc : 0.10519999951124191 Test Acc : 0.15749999922700225\n",
      "Current : 315 Acc : 0.15199999950826168 Test Acc : 0.18562500067055226\n",
      "Current : 316 Acc : 0.16940000027418137 Test Acc : 0.17887500105425716\n",
      "Current : 317 Acc : 0.21619999945163726 Test Acc : 0.2242500003427267\n",
      "Current : 318 Acc : 0.2464000004529953 Test Acc : 0.2681250000372529\n",
      "Current : 319 Acc : 0.27020000129938126 Test Acc : 0.273875000141561\n",
      "Current : 320 Acc : 0.27819999992847444 Test Acc : 0.2892500007525086\n",
      "Current : 321 Acc : 0.30940000265836715 Test Acc : 0.2838750021532178\n",
      "Current : 322 Acc : 0.3106000006198883 Test Acc : 0.32062500175088643\n",
      "Current : 323 Acc : 0.33240000128746033 Test Acc : 0.3323750013485551\n",
      "Current : 324 Acc : 0.3565999999642372 Test Acc : 0.3330000014975667\n",
      "Current : 325 Acc : 0.37259999811649325 Test Acc : 0.3548750005662441\n",
      "Current : 326 Acc : 0.38159999847412107 Test Acc : 0.38412499874830247\n",
      "Current : 327 Acc : 0.4115999984741211 Test Acc : 0.38087499905377625\n",
      "Current : 328 Acc : 0.41360000014305115 Test Acc : 0.39862499870359897\n",
      "Current : 329 Acc : 0.4315999984741211 Test Acc : 0.41874999813735486\n",
      "Current : 330 Acc : 0.4609999984502792 Test Acc : 0.408374997228384\n",
      "Current : 331 Acc : 0.09479999985545874 Test Acc : 0.1\n",
      "Current : 332 Acc : 0.1334000004082918 Test Acc : 0.16274999994784595\n",
      "Current : 333 Acc : 0.16179999947547913 Test Acc : 0.19399999985471367\n",
      "Current : 334 Acc : 0.22439999893307686 Test Acc : 0.25274999942630527\n",
      "Current : 335 Acc : 0.2762000009417534 Test Acc : 0.2890000009909272\n",
      "Current : 336 Acc : 0.301800000667572 Test Acc : 0.3133750017732382\n",
      "Current : 337 Acc : 0.31820000112056734 Test Acc : 0.3271250020712614\n",
      "Current : 338 Acc : 0.3438000023365021 Test Acc : 0.3338749995455146\n",
      "Current : 339 Acc : 0.36040000289678575 Test Acc : 0.358249999769032\n",
      "Current : 340 Acc : 0.3781999999284744 Test Acc : 0.36387500204145906\n",
      "Current : 341 Acc : 0.39119999945163725 Test Acc : 0.3918749988079071\n",
      "Current : 342 Acc : 0.41219999849796296 Test Acc : 0.39574999921023846\n",
      "Current : 343 Acc : 0.42379999816417696 Test Acc : 0.41962499879300597\n",
      "Current : 344 Acc : 0.43659999668598176 Test Acc : 0.41812499724328517\n",
      "Current : 345 Acc : 0.46280000030994417 Test Acc : 0.430375000089407\n",
      "Current : 346 Acc : 0.4751999962329865 Test Acc : 0.4414999969303608\n",
      "Current : 347 Acc : 0.4981999951601028 Test Acc : 0.41049999818205835\n",
      "Current : 348 Acc : 0.09799999952316284 Test Acc : 0.1242499998304993\n",
      "Current : 349 Acc : 0.1131999996304512 Test Acc : 0.10400000009685754\n",
      "Current : 350 Acc : 0.10039999946951866 Test Acc : 0.10112500018440188\n",
      "Current : 351 Acc : 0.12859999999403954 Test Acc : 0.16550000058487058\n",
      "Current : 352 Acc : 0.153400000333786 Test Acc : 0.15087500060908496\n",
      "Current : 353 Acc : 0.1662000012397766 Test Acc : 0.18899999968707562\n"
     ]
    }
   ],
   "source": [
    "# start the training \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 10000 ; avg_acc_train = 0; avg_acc_test  = 0; \n",
    "\n",
    "for iter in range(num_epoch):\n",
    "    train_images,train_labels = shuffle(train_images,train_labels);\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,auto_train],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]        \n",
    "    print(\"Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) )\n",
    "    if np.abs(avg_acc_train/(len(train_images)/batch_size)-avg_acc_test/(len(test_images)/batch_size))>0.05 and avg_acc_train/(len(train_images)/batch_size)>avg_acc_test/(len(test_images)/batch_size): \n",
    "        sess.run([all_update,reset_optimizer_op]);   \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Optimizer : Optimizer, R. (2018). Reset tensorflow Optimizer. Stack Overflow. Retrieved 12 December 2018, from https://stackoverflow.com/questions/39607566/reset-tensorflow-optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "1. Brownlee, J. (2017). How to One Hot Encode Sequence Data in Python. Machine Learning Mastery. Retrieved 9 December 2018, from https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "2. tf.placeholder_with_default | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default\n",
    "3. tf.nn.softmax_cross_entropy_with_logits | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits\n",
    "4. line, O. (2018). Output without new line. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2623470/output-without-new-line\n",
    "5. shell?, H. (2018). How to tell if tensorflow is using gpu acceleration from inside python shell?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "6. GPU?, H. (2018). How to use TensorFlow GPU?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/51306862/how-to-use-tensorflow-gpu\n",
    "7. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "8. Batch normalization: theory and how to use it with Tensorflow. (2018). Towards Data Science. Retrieved 9 December 2018, from https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad\n",
    "9. tf.reset_default_graph | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/reset_default_graph\n",
    "10. tf.Session | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "11. tf.nn.moments | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "12. CMD?, H. (2018). How do I run two commands in one line in Windows CMD?. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/8055371/how-do-i-run-two-commands-in-one-line-in-windows-cmd\n",
    "13. loop, B. (2018). Batch script loop. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/2591758/batch-script-loop\n",
    "14. tf.train.MomentumOptimizer | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "15. Test if two numpy arrays are (close to) equal, i. (2018). Test if two numpy arrays are (close to) equal, including shape. Stack Overflow. Retrieved 9 December 2018, from https://stackoverflow.com/questions/32874840/test-if-two-numpy-arrays-are-close-to-equal-including-shape\n",
    "16. tf.linalg.diag | TensorFlow. (2018). TensorFlow. Retrieved 9 December 2018, from https://www.tensorflow.org/api_docs/python/tf/linalg/diag\n",
    "17. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "18. tf.layers.batch_normalization | TensorFlow. (2018). TensorFlow. Retrieved 10 December 2018, from https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization\n",
    "19. error, t. (2018). tf.layers.batch_normalization large test error. Stack Overflow. Retrieved 10 December 2018, from https://stackoverflow.com/questions/43234667/tf-layers-batch-normalization-large-test-error\n",
    "20. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
