{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:42.564610Z",
     "start_time": "2018-12-20T07:57:39.629309Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:50.528979Z",
     "start_time": "2018-12-20T07:57:48.468510Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T08:14:38.171257Z",
     "start_time": "2018-12-20T08:14:38.099467Z"
    },
    "code_folding": [
     15,
     58,
     99,
     140
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return [self.layer,self.layerA]\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        return (self.layer - 1.0)/(self.lmbda + 1e-8)\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        \n",
    "        # Gradient that gets passed along\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0) * grad\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda1 =   (self.layer * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda2 = - (self.layer - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean((grad_lmbda1 + grad_lmbda2)*grad)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:21:04.871403Z",
     "start_time": "2018-12-20T06:21:04.769676Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "num_epoch = 300; learning_rate = 0.0008; batch_size = 20\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-9\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:07:37.013560Z",
     "start_time": "2018-12-20T06:07:36.830997Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,32); \n",
    "l5 = CNN(3,32,32); \n",
    "l6 = CNN(3,32,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:08:47.504461Z",
     "start_time": "2018-12-20T06:08:47.299795Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x,stride=2)      ;          \n",
    "layer2,layer2a = l2.feedforward(layer1a,stride=2);         \n",
    "layer3,layer3a = l3.feedforward(layer2a,stride=2); \n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3a,stride=2);          \n",
    "layer5,layer5a = l5.feedforward(layer4a,stride=1);         \n",
    "layer6,layer6a = l6.feedforward(layer5a,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6w,grad6p,grad6_up = l6.backprop(gradient)\n",
    "grad5w,grad5p,grad5_up = l5.backprop(grad6p)\n",
    "grad4w,grad4p,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "\n",
    "grad3w,grad3p,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2w,grad2p,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1w,grad1p,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + \\\n",
    "                   grad5_up + \\\n",
    "                   grad4_up + \\\n",
    "                   grad3_up + \\\n",
    "                   grad2_up + \\\n",
    "                   grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:09:14.239248Z",
     "start_time": "2018-12-20T06:08:54.084190Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.12840000288188458 Test Acc : 0.21200000332668423\n",
      "\n",
      "Current Iter : 1/300 batch : 7980/8000 acc : 0.45\n",
      " Current : 1 Acc : 0.22900000382959843 Test Acc : 0.25975000286474825\n",
      "\n",
      "Current Iter : 2/300 batch : 7980/8000 acc : 0.55\n",
      " Current : 2 Acc : 0.2868000023066998 Test Acc : 0.3093750014156103\n",
      "\n",
      "Current Iter : 3/300 batch : 900/8000 acc : 0.455\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fbb428fac211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc     = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test/(len(test_images)/batch_size)  )\n",
    "    \n",
    "    \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T08:14:44.699298Z",
     "start_time": "2018-12-20T08:14:44.473825Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "num_epoch = 350; learning_rate = 0.001; batch_size = 50\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "tf.reset_default_graph(); sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "l1 = CNN(3,3, 16); l1n = tf_box_cox()\n",
    "l2 = CNN(3,16,16); l2n = tf_box_cox()\n",
    "l3 = CNN(3,16,16); l3n = tf_box_cox()\n",
    "\n",
    "l4 = CNN(3,16,32); l4n = tf_box_cox()\n",
    "l5 = CNN(3,32,32); l5n = tf_box_cox()\n",
    "l6 = CNN(3,32,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T08:14:45.821531Z",
     "start_time": "2018-12-20T08:14:44.984546Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x,stride=2)      ;          \n",
    "layer1n = l1n.feedforward(layer1a)\n",
    "layer2,layer2a = l2.feedforward(layer1n,stride=2);          \n",
    "layer2n = l2n.feedforward(layer2a)\n",
    "layer3,layer3a = l3.feedforward(layer2n,stride=2); \n",
    "layer3n = l3n.feedforward(layer3a)\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3n,stride=2);          \n",
    "layer4n = l4n.feedforward(layer4a)\n",
    "layer5,layer5a = l5.feedforward(layer4n,stride=1);          \n",
    "layer5n = l5n.feedforward(layer5a)\n",
    "layer6,layer6a = l6.feedforward(layer5n,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up  = l6.backprop(gradient)\n",
    "grad5n,grad5l,grad5n_up = l5n.backprop(grad6p); \n",
    "grad5p,grad5w,grad5_up  = l5.backprop(grad5n)\n",
    "grad4n,grad4l,grad4n_up = l4n.backprop(grad5p); \n",
    "grad4p,grad4w,grad4_up  = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n,grad3l,grad3n_up = l3n.backprop(grad4p);\n",
    "grad3p,grad3w,grad3_up  = l3.backprop(grad3n,stride=2)\n",
    "grad2n,grad2l,grad2n_up = l2n.backprop(grad3p); \n",
    "grad2p,grad2w,grad2_up  = l2.backprop(grad2n,stride=2)\n",
    "grad1n,grad1l,grad1n_up = l1n.backprop(grad2p); \n",
    "grad1p,grad1w,grad1_up  = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + \\\n",
    "                  grad5n_up + grad5_up + \\\n",
    "                  grad4n_up + grad4_up + \\\n",
    "                  grad3n_up + grad3_up + \\\n",
    "                  grad2n_up + grad2_up + \\\n",
    "                  grad1n_up + grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-20T08:14:45.579Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/350 batch : 7950/8000 acc : 0.12\n",
      " Current : 0 Acc : 0.11139999970793724 Test Acc : 0.100499999220483\n",
      "\n",
      "Current Iter : 1/350 batch : 7950/8000 acc : 0.18\n",
      " Current : 1 Acc : 0.12339999999850988 Test Acc : 0.1567499997559935\n",
      "\n",
      "Current Iter : 2/350 batch : 7950/8000 acc : 0.32\n",
      " Current : 2 Acc : 0.16959999959915875 Test Acc : 0.24862499958835543\n",
      "\n",
      "Current Iter : 3/350 batch : 7950/8000 acc : 0.32\n",
      " Current : 3 Acc : 0.2497999992966652 Test Acc : 0.25024999971501527\n",
      "\n",
      "Current Iter : 4/350 batch : 7950/8000 acc : 0.34\n",
      " Current : 4 Acc : 0.27319999851286414 Test Acc : 0.29525000173598526\n",
      "\n",
      "Current Iter : 5/350 batch : 7950/8000 acc : 0.32\n",
      " Current : 5 Acc : 0.29860000006854537 Test Acc : 0.3281249998137355\n",
      "\n",
      "Current Iter : 6/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 6 Acc : 0.3214000004529953 Test Acc : 0.34262500079348684\n",
      "\n",
      "Current Iter : 7/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 7 Acc : 0.3292000010609627 Test Acc : 0.35275000082328917\n",
      "\n",
      "Current Iter : 8/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 8 Acc : 0.3454000014066696 Test Acc : 0.36075000194832685\n",
      "\n",
      "Current Iter : 9/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 9 Acc : 0.3568000023066997 Test Acc : 0.36737500159069897\n",
      "\n",
      "Current Iter : 10/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 10 Acc : 0.3642000012099743 Test Acc : 0.37324999887496235\n",
      "\n",
      "Current Iter : 11/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 11 Acc : 0.36940000250935556 Test Acc : 0.3780000003054738\n",
      "\n",
      "Current Iter : 12/350 batch : 7950/8000 acc : 0.32\n",
      " Current : 12 Acc : 0.376800000667572 Test Acc : 0.38687500096857547\n",
      "\n",
      "Current Iter : 13/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 13 Acc : 0.38800000116229055 Test Acc : 0.3926249995827675\n",
      "\n",
      "Current Iter : 14/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 14 Acc : 0.39240000024437904 Test Acc : 0.39700000174343586\n",
      "\n",
      "Current Iter : 15/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 15 Acc : 0.3913999989628792 Test Acc : 0.3926250008866191\n",
      "\n",
      "Current Iter : 16/350 batch : 7950/8000 acc : 0.36\n",
      " Current : 16 Acc : 0.3938000002503395 Test Acc : 0.3953750003129244\n",
      "\n",
      "Current Iter : 17/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 17 Acc : 0.40859999984502793 Test Acc : 0.3882500000298023\n",
      "\n",
      "Current Iter : 18/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 18 Acc : 0.4094000005722046 Test Acc : 0.39637500047683716\n",
      "\n",
      "Current Iter : 19/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 19 Acc : 0.4173999986052513 Test Acc : 0.3989999990910292\n",
      "\n",
      "Current Iter : 20/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 20 Acc : 0.42359999895095823 Test Acc : 0.40775000089779495\n",
      "\n",
      "Current Iter : 21/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 21 Acc : 0.4304000002145767 Test Acc : 0.4141249994747341\n",
      "\n",
      "Current Iter : 22/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 22 Acc : 0.4363999971747398 Test Acc : 0.4168749998323619\n",
      "\n",
      "Current Iter : 23/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 23 Acc : 0.44119999825954437 Test Acc : 0.41675000041723254\n",
      "\n",
      "Current Iter : 24/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 24 Acc : 0.44419999808073046 Test Acc : 0.41187499929219484\n",
      "\n",
      "Current Iter : 25/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 25 Acc : 0.4499999991059303 Test Acc : 0.4201250002719462\n",
      "\n",
      "Current Iter : 26/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 26 Acc : 0.45399999916553496 Test Acc : 0.43100000051781534\n",
      "\n",
      "Current Iter : 27/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 27 Acc : 0.448199999332428 Test Acc : 0.42937499899417164\n",
      "\n",
      "Current Iter : 28/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 28 Acc : 0.4606000000238419 Test Acc : 0.43974999971687795\n",
      "\n",
      "Current Iter : 29/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 29 Acc : 0.4677999982237816 Test Acc : 0.4402499979361892\n",
      "\n",
      "Current Iter : 30/350 batch : 7950/8000 acc : 0.38\n",
      " Current : 30 Acc : 0.47819999754428866 Test Acc : 0.44174999874085186\n",
      "\n",
      "Current Iter : 31/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 31 Acc : 0.48539999932050704 Test Acc : 0.44724999777972696\n",
      "\n",
      "Current Iter : 32/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 32 Acc : 0.4937999966740608 Test Acc : 0.4556249984540045\n",
      "\n",
      "Current Iter : 33/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 33 Acc : 0.4865999978780746 Test Acc : 0.4592499994672835\n",
      "\n",
      "Current Iter : 34/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 34 Acc : 0.49439999848604205 Test Acc : 0.4597499975003302\n",
      "\n",
      "Current Iter : 35/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 35 Acc : 0.49999999821186064 Test Acc : 0.4547499995678663\n",
      "\n",
      "Current Iter : 36/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 36 Acc : 0.49999999910593035 Test Acc : 0.454624998383224\n",
      "\n",
      "Current Iter : 37/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 37 Acc : 0.5098000007867813 Test Acc : 0.46899999883025884\n",
      "\n",
      "Current Iter : 38/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 38 Acc : 0.521800000667572 Test Acc : 0.47237499691545964\n",
      "\n",
      "Current Iter : 39/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 39 Acc : 0.5148000001907349 Test Acc : 0.47099999859929087\n",
      "\n",
      "Current Iter : 40/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 40 Acc : 0.5225999996066093 Test Acc : 0.4729999995790422\n",
      "\n",
      "Current Iter : 41/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 41 Acc : 0.521999998986721 Test Acc : 0.47949999775737523\n",
      "\n",
      "Current Iter : 42/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 42 Acc : 0.5272000020742417 Test Acc : 0.46812499929219487\n",
      "\n",
      "Current Iter : 43/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 43 Acc : 0.5330000013113022 Test Acc : 0.4817499998956919\n",
      "\n",
      "Current Iter : 44/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 44 Acc : 0.5442000013589859 Test Acc : 0.4803750006482005\n",
      "\n",
      "Current Iter : 45/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 45 Acc : 0.544600002169609 Test Acc : 0.48499999940395355\n",
      "\n",
      "Current Iter : 46/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 46 Acc : 0.5446000015735626 Test Acc : 0.48012500144541265\n",
      "\n",
      "Current Iter : 47/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 47 Acc : 0.5510000002384186 Test Acc : 0.48712499905377626\n",
      "\n",
      "Current Iter : 48/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 48 Acc : 0.5524000000953674 Test Acc : 0.4831250011920929\n",
      "\n",
      "Current Iter : 49/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 49 Acc : 0.5626000013947486 Test Acc : 0.483624997921288\n",
      "\n",
      "Current Iter : 50/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 50 Acc : 0.5637999993562698 Test Acc : 0.4824999986216426\n",
      "\n",
      "Current Iter : 51/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 51 Acc : 0.5686000022292137 Test Acc : 0.48249999787658454\n",
      "\n",
      "Current Iter : 52/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 52 Acc : 0.5625999996066093 Test Acc : 0.4907500000670552\n",
      "\n",
      "Current Iter : 53/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 53 Acc : 0.5676000016927719 Test Acc : 0.4801249986514449\n",
      "\n",
      "Current Iter : 54/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 54 Acc : 0.5662000045180321 Test Acc : 0.4909999996423721\n",
      "\n",
      "Current Iter : 55/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 55 Acc : 0.5780000013113021 Test Acc : 0.4876249998807907\n",
      "\n",
      "Current Iter : 56/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 56 Acc : 0.5838000020384788 Test Acc : 0.4726249987259507\n",
      "\n",
      "Current Iter : 57/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 57 Acc : 0.5924000045657158 Test Acc : 0.4787499999627471\n",
      "\n",
      "Current Iter : 58/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 58 Acc : 0.5864000019431114 Test Acc : 0.4771249985322356\n",
      "\n",
      "Current Iter : 59/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 59 Acc : 0.5904000040888786 Test Acc : 0.48474999871104957\n",
      "\n",
      "Current Iter : 60/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 60 Acc : 0.5822000014781952 Test Acc : 0.489874997921288\n",
      "\n",
      "Current Iter : 61/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 61 Acc : 0.5860000047087669 Test Acc : 0.5013749994337559\n",
      "\n",
      "Current Iter : 62/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 62 Acc : 0.5920000025629997 Test Acc : 0.49137499928474426\n",
      "\n",
      "Current Iter : 63/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 63 Acc : 0.5838000002503395 Test Acc : 0.4908749973401427\n",
      "\n",
      "Current Iter : 64/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 64 Acc : 0.6032000038027764 Test Acc : 0.494875000230968\n",
      "\n",
      "Current Iter : 65/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 65 Acc : 0.6054000023007393 Test Acc : 0.49512499794363973\n",
      "\n",
      "Current Iter : 66/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 66 Acc : 0.6084000042080879 Test Acc : 0.5003749996423721\n",
      "\n",
      "Current Iter : 67/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 67 Acc : 0.6094000044465065 Test Acc : 0.4889999995008111\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 68 Acc : 0.5938000023365021 Test Acc : 0.4948749991133809\n",
      "\n",
      "Current Iter : 69/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 69 Acc : 0.6104000049829483 Test Acc : 0.4888750001788139\n",
      "\n",
      "Current Iter : 70/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 70 Acc : 0.621400004029274 Test Acc : 0.48775000032037497\n",
      "\n",
      "Current Iter : 71/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 71 Acc : 0.6248000082373619 Test Acc : 0.47224999889731406\n",
      "\n",
      "Current Iter : 72/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 72 Acc : 0.6276000052690506 Test Acc : 0.4862499987706542\n",
      "\n",
      "Current Iter : 73/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 73 Acc : 0.6250000044703483 Test Acc : 0.4747499994933605\n",
      "\n",
      "Current Iter : 74/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 74 Acc : 0.6286000052094459 Test Acc : 0.4963749984279275\n",
      "\n",
      "Current Iter : 75/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 75 Acc : 0.6262000074982643 Test Acc : 0.4847500005736947\n",
      "\n",
      "Current Iter : 76/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 76 Acc : 0.6302000030875206 Test Acc : 0.49112499952316285\n",
      "\n",
      "Current Iter : 77/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 77 Acc : 0.6022000035643578 Test Acc : 0.47612499743700026\n",
      "\n",
      "Current Iter : 78/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 78 Acc : 0.6220000064373017 Test Acc : 0.47974999975413085\n",
      "\n",
      "Current Iter : 79/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 79 Acc : 0.6252000030875206 Test Acc : 0.4810000007972121\n",
      "\n",
      "Current Iter : 80/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 80 Acc : 0.6214000016450882 Test Acc : 0.48162500057369473\n",
      "\n",
      "Current Iter : 81/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 81 Acc : 0.6138000044226647 Test Acc : 0.47099999748170374\n",
      "\n",
      "Current Iter : 82/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 82 Acc : 0.6052000027894974 Test Acc : 0.4699999995529652\n",
      "\n",
      "Current Iter : 83/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 83 Acc : 0.613800003528595 Test Acc : 0.4787499994039536\n",
      "\n",
      "Current Iter : 84/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 84 Acc : 0.625600006878376 Test Acc : 0.47925000060349704\n",
      "\n",
      "Current Iter : 85/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 85 Acc : 0.6346000054478645 Test Acc : 0.48150000013411043\n",
      "\n",
      "Current Iter : 86/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 86 Acc : 0.6416000074148178 Test Acc : 0.4773749984800816\n",
      "\n",
      "Current Iter : 87/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 87 Acc : 0.6454000055789948 Test Acc : 0.48062499780207874\n",
      "\n",
      "Current Iter : 88/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 88 Acc : 0.6530000051856041 Test Acc : 0.47799999695271256\n",
      "\n",
      "Current Iter : 89/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 89 Acc : 0.6574000063538551 Test Acc : 0.47599999941885474\n",
      "\n",
      "Current Iter : 90/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 90 Acc : 0.6614000046253204 Test Acc : 0.47649999912828206\n",
      "\n",
      "Current Iter : 91/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 91 Acc : 0.6652000045776367 Test Acc : 0.4768749991431832\n",
      "\n",
      "Current Iter : 92/350 batch : 7950/8000 acc : 0.44\n",
      " Current : 92 Acc : 0.661600005030632 Test Acc : 0.4721249992027879\n",
      "\n",
      "Current Iter : 93/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 93 Acc : 0.6644000062346458 Test Acc : 0.46999999806284903\n",
      "\n",
      "Current Iter : 94/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 94 Acc : 0.6572000050544738 Test Acc : 0.4857499975711107\n",
      "\n",
      "Current Iter : 95/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 95 Acc : 0.6520000085234642 Test Acc : 0.4823749979957938\n",
      "\n",
      "Current Iter : 96/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 96 Acc : 0.6426000067591667 Test Acc : 0.47287499979138375\n",
      "\n",
      "Current Iter : 97/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 97 Acc : 0.6372000023722648 Test Acc : 0.4852500006556511\n",
      "\n",
      "Current Iter : 98/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 98 Acc : 0.6572000041604042 Test Acc : 0.48099999949336053\n",
      "\n",
      "Current Iter : 99/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 99 Acc : 0.6690000003576279 Test Acc : 0.4834999982267618\n",
      "\n",
      "Current Iter : 100/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 100 Acc : 0.6658000037074089 Test Acc : 0.4818749981001019\n",
      "\n",
      "Current Iter : 101/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 101 Acc : 0.6724000018835068 Test Acc : 0.48912499845027924\n",
      "\n",
      "Current Iter : 102/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 102 Acc : 0.68280000269413 Test Acc : 0.4919999992474914\n",
      "\n",
      "Current Iter : 103/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 103 Acc : 0.6960000026226044 Test Acc : 0.4827499967068434\n",
      "\n",
      "Current Iter : 104/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 104 Acc : 0.702200003862381 Test Acc : 0.4805000001564622\n",
      "\n",
      "Current Iter : 105/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 105 Acc : 0.7052000004053116 Test Acc : 0.47787499874830247\n",
      "\n",
      "Current Iter : 106/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 106 Acc : 0.7064000028371811 Test Acc : 0.4736249985173345\n",
      "\n",
      "Current Iter : 107/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 107 Acc : 0.7026000016927719 Test Acc : 0.48262499999254943\n",
      "\n",
      "Current Iter : 108/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 108 Acc : 0.6766000044345856 Test Acc : 0.4772499997168779\n",
      "\n",
      "Current Iter : 109/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 109 Acc : 0.6976000040769577 Test Acc : 0.4813749985769391\n",
      "\n",
      "Current Iter : 110/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 110 Acc : 0.7012000012397767 Test Acc : 0.4874999992549419\n",
      "\n",
      "Current Iter : 111/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 111 Acc : 0.6982000073790551 Test Acc : 0.4812499973922968\n",
      "\n",
      "Current Iter : 112/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 112 Acc : 0.6846000051498413 Test Acc : 0.4780000001192093\n",
      "\n",
      "Current Iter : 113/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 113 Acc : 0.7026000040769577 Test Acc : 0.4806249987334013\n",
      "\n",
      "Current Iter : 114/350 batch : 7950/8000 acc : 0.56\n",
      " Current : 114 Acc : 0.7055999994277954 Test Acc : 0.4810000011697412\n",
      "\n",
      "Current Iter : 115/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 115 Acc : 0.7044000032544137 Test Acc : 0.4819999972358346\n",
      "\n",
      "Current Iter : 116/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 116 Acc : 0.6902000015974045 Test Acc : 0.4846249995753169\n",
      "\n",
      "Current Iter : 117/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 117 Acc : 0.7004000049829483 Test Acc : 0.48124999813735486\n",
      "\n",
      "Current Iter : 118/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 118 Acc : 0.707200002670288 Test Acc : 0.47262499704957006\n",
      "\n",
      "Current Iter : 119/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 119 Acc : 0.7146000033617019 Test Acc : 0.47799999825656414\n",
      "\n",
      "Current Iter : 120/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 120 Acc : 0.7184000009298325 Test Acc : 0.4742499988526106\n",
      "\n",
      "Current Iter : 121/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 121 Acc : 0.7010000026226044 Test Acc : 0.49362500067800286\n",
      "\n",
      "Current Iter : 122/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 122 Acc : 0.7216000038385392 Test Acc : 0.4989999981597066\n",
      "\n",
      "Current Iter : 123/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 123 Acc : 0.7206000000238418 Test Acc : 0.4954999988898635\n",
      "\n",
      "Current Iter : 124/350 batch : 7950/8000 acc : 0.52\n",
      " Current : 124 Acc : 0.7166000038385392 Test Acc : 0.4967499988153577\n",
      "\n",
      "Current Iter : 125/350 batch : 7950/8000 acc : 0.54\n",
      " Current : 125 Acc : 0.7208000057935715 Test Acc : 0.4886249991133809\n",
      "\n",
      "Current Iter : 126/350 batch : 7950/8000 acc : 0.58\n",
      " Current : 126 Acc : 0.7242000037431717 Test Acc : 0.49449999872595074\n",
      "\n",
      "Current Iter : 127/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 127 Acc : 0.7240000015497208 Test Acc : 0.49662499967962503\n",
      "\n",
      "Current Iter : 128/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 128 Acc : 0.7262000000476837 Test Acc : 0.4957499988377094\n",
      "\n",
      "Current Iter : 129/350 batch : 7950/8000 acc : 0.46\n",
      " Current : 129 Acc : 0.7260000038146973 Test Acc : 0.493499999307096\n",
      "\n",
      "Current Iter : 130/350 batch : 7950/8000 acc : 0.42\n",
      " Current : 130 Acc : 0.7206000033020973 Test Acc : 0.4952499981969595\n",
      "\n",
      "Current Iter : 131/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 131 Acc : 0.740599998831749 Test Acc : 0.4853749979287386\n",
      "\n",
      "Current Iter : 132/350 batch : 7950/8000 acc : 0.48\n",
      " Current : 132 Acc : 0.7479999959468842 Test Acc : 0.49137499909847976\n",
      "\n",
      "Current Iter : 133/350 batch : 6850/8000 acc : 0.56\r"
     ]
    }
   ],
   "source": [
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc     = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test/(len(test_images)/batch_size)  )\n",
    "    \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T08:13:22.470763Z",
     "start_time": "2018-12-20T08:13:22.448827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7192458, 1.7283884, 1.7490733, 1.8224932, 1.9920293]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([l1n.getw(),l2n.getw(),l3n.getw(),l4n.getw(),l5n.getw()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:39:51.379493Z",
     "start_time": "2018-12-20T07:39:51.079050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:43:08.033249Z",
     "start_time": "2018-12-20T07:43:06.719715Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:07.576480Z",
     "start_time": "2018-12-20T07:51:47.829257Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:51:37.093685Z",
     "start_time": "2018-12-20T07:51:37.016902Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:11.376556Z",
     "start_time": "2018-12-20T07:57:11.370596Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
