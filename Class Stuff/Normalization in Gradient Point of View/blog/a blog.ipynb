{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:25:48.211729Z",
     "start_time": "2018-12-20T06:25:44.682125Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:25:53.354955Z",
     "start_time": "2018-12-20T06:25:50.789791Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:47:31.439630Z",
     "start_time": "2018-12-20T06:47:31.251857Z"
    },
    "code_folding": [
     58,
     99,
     140
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w          = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v   = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg  = which_reg\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return [self.layer,self.layerA]\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.which_reg == 0:   grad = grad\n",
    "        if self.which_reg == 0.5: grad = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "        if self.which_reg == 1:   grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.which_reg == 1.5: grad = grad + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "        if self.which_reg == 2:   grad = grad + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "        if self.which_reg == 2.5: grad = grad + lamda * 2.0 * self.w\n",
    "        if self.which_reg == 3:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "        if self.which_reg == 4:   grad = grad + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self,channel):\n",
    "#         self.lmbda    = tf.Variable(tf.ones([1,1,1,channel],tf.float32)* 2.0) \n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = (tf.pow((self.input + 1.0),self.lmbda) - 1.0)/self.lmbda\n",
    "        return self.layer \n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0)\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmdba1 = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        grad_lmbda2 =   (grad_lmdba1 * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda3 = - (grad_lmdba1 - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean(grad_lmbda2 + grad_lmbda3)\n",
    "        print(grad_lmbda)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        # update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        update_w.append(tf.assign(self.lmbda,self.lmbda))\n",
    "\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:21:04.871403Z",
     "start_time": "2018-12-20T06:21:04.769676Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "num_epoch = 300; learning_rate = 0.0008; batch_size = 20\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-9\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:07:37.013560Z",
     "start_time": "2018-12-20T06:07:36.830997Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,32); \n",
    "l5 = CNN(3,32,32); \n",
    "l6 = CNN(3,32,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:08:47.504461Z",
     "start_time": "2018-12-20T06:08:47.299795Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x,stride=2)      ;          \n",
    "layer2,layer2a = l2.feedforward(layer1a,stride=2);         \n",
    "layer3,layer3a = l3.feedforward(layer2a,stride=2); \n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3a,stride=2);          \n",
    "layer5,layer5a = l5.feedforward(layer4a,stride=1);         \n",
    "layer6,layer6a = l6.feedforward(layer5a,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6w,grad6p,grad6_up = l6.backprop(gradient)\n",
    "grad5w,grad5p,grad5_up = l5.backprop(grad6p)\n",
    "grad4w,grad4p,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "\n",
    "grad3w,grad3p,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2w,grad2p,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1w,grad1p,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + \\\n",
    "                   grad5_up + \\\n",
    "                   grad4_up + \\\n",
    "                   grad3_up + \\\n",
    "                   grad2_up + \\\n",
    "                   grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:09:14.239248Z",
     "start_time": "2018-12-20T06:08:54.084190Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.12840000288188458 Test Acc : 0.21200000332668423\n",
      "\n",
      "Current Iter : 1/300 batch : 7980/8000 acc : 0.45\n",
      " Current : 1 Acc : 0.22900000382959843 Test Acc : 0.25975000286474825\n",
      "\n",
      "Current Iter : 2/300 batch : 7980/8000 acc : 0.55\n",
      " Current : 2 Acc : 0.2868000023066998 Test Acc : 0.3093750014156103\n",
      "\n",
      "Current Iter : 3/300 batch : 900/8000 acc : 0.455\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fbb428fac211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc     = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test/(len(test_images)/batch_size)  )\n",
    "    \n",
    "    \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:47:34.104427Z",
     "start_time": "2018-12-20T06:47:33.881812Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "num_epoch = 300; learning_rate = 0.001; batch_size = 50\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "tf.reset_default_graph(); sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "l1 = CNN(3,3, 16); l1n = tf_box_cox(16)\n",
    "l2 = CNN(3,16,16); l2n = tf_box_cox(16)\n",
    "l3 = CNN(3,16,16); l3n = tf_box_cox(16)\n",
    "\n",
    "l4 = CNN(3,16,32); l4n = tf_box_cox(32)\n",
    "l5 = CNN(3,32,32); l5n = tf_box_cox(32)\n",
    "l6 = CNN(3,32,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:47:35.513077Z",
     "start_time": "2018-12-20T06:47:34.721194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Mean_5:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Mean_6:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Mean_7:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x,stride=2)      ;          \n",
    "layer1n = l1n.feedforward(layer1a)\n",
    "layer2,layer2a = l2.feedforward(layer1n,stride=2);          \n",
    "layer2n = l2n.feedforward(layer2a)\n",
    "layer3,layer3a = l3.feedforward(layer2n,stride=2); \n",
    "layer3n = l3n.feedforward(layer3a)\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3n,stride=2);          \n",
    "layer4n = l4n.feedforward(layer4a)\n",
    "layer5,layer5a = l5.feedforward(layer4n,stride=1);          \n",
    "layer5n = l5n.feedforward(layer5a)\n",
    "layer6,layer6a = l6.feedforward(layer5n,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up  = l6.backprop(gradient)\n",
    "grad5n,grad5l,grad5n_up = l5n.backprop(grad6p); \n",
    "grad5p,grad5w,grad5_up  = l5.backprop(grad5n)\n",
    "grad4n,grad4l,grad4n_up = l4n.backprop(grad5p); \n",
    "grad4p,grad4w,grad4_up  = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n,grad3l,grad3n_up = l3n.backprop(grad4p);\n",
    "grad3p,grad3w,grad3_up  = l3.backprop(grad3n,stride=2)\n",
    "grad2n,grad2l,grad2n_up = l2n.backprop(grad3p); \n",
    "grad2p,grad2w,grad2_up  = l2.backprop(grad2n,stride=2)\n",
    "grad1n,grad1l,grad1n_up = l1n.backprop(grad2p); \n",
    "grad1p,grad1w,grad1_up  = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + \\\n",
    "                  grad5n_up + grad5_up + \\\n",
    "                  grad4n_up + grad4_up + \\\n",
    "                  grad3n_up + grad3_up + \\\n",
    "                  grad2n_up + grad2_up + \\\n",
    "                  grad1n_up + grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:47:46.579481Z",
     "start_time": "2018-12-20T06:47:35.822251Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/300 batch : 7950/8000 acc : 0.12\n",
      " Current : 0 Acc : 0.10599999938160182 Test Acc : 0.1033749993890524\n",
      "\n",
      "[2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "Current Iter : 1/300 batch : 7950/8000 acc : 0.12\n",
      " Current : 1 Acc : 0.1059999992325902 Test Acc : 0.10237499920185655\n",
      "\n",
      "[2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "Current Iter : 2/300 batch : 2800/8000 acc : 0.12\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-05fa7af0baa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcurrent_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0msess_results\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current Iter : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' acc : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_acc_test\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msess_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc     = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test/(len(test_images)/batch_size)  )\n",
    "    \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    print(sess.run([l1n.getw(),l2n.getw(),l3n.getw(),l4n.getw(),l5n.getw()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T06:49:14.167942Z",
     "start_time": "2018-12-20T06:49:14.083170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 2.83646933e-03,  1.11323840e-04, -3.17374617e-03, ...,\n",
       "           -4.50299820e-04,  1.97324040e-03, -1.71105145e-03],\n",
       "          [ 4.26819082e-03, -1.09096873e-03, -4.64794692e-03, ...,\n",
       "            1.85834698e-03,  5.04207425e-03, -3.25885322e-03],\n",
       "          [ 1.85944652e-03, -1.44804560e-03, -4.07405244e-03, ...,\n",
       "            1.19430432e-03,  4.88950033e-03, -2.66293623e-03],\n",
       "          [ 3.77269043e-03, -1.20721583e-03, -3.33881238e-03, ...,\n",
       "            2.67794658e-03,  1.96452066e-03, -1.09356770e-03],\n",
       "          [ 3.29670758e-04, -2.70206336e-04, -1.49826496e-03, ...,\n",
       "           -4.50462132e-04,  3.67337093e-03, -1.67844805e-03],\n",
       "          [-3.97419972e-05, -3.20637337e-04, -5.48983575e-04, ...,\n",
       "            2.48057744e-03,  1.48572400e-03, -7.39831303e-04]],\n",
       " \n",
       "         [[ 3.53838457e-03,  1.22925104e-03, -7.17498246e-04, ...,\n",
       "           -2.22815410e-03,  8.23972863e-04, -1.17475027e-03],\n",
       "          [ 2.56787450e-03, -4.01223399e-04, -2.34427792e-03, ...,\n",
       "           -5.87051909e-04,  2.82928138e-03, -4.09772294e-03],\n",
       "          [ 2.27877777e-03, -1.03758147e-03, -3.89658473e-03, ...,\n",
       "            1.99242402e-03,  5.09895803e-03, -4.93494794e-03],\n",
       "          [ 4.89442085e-04,  3.05186695e-04, -9.72871727e-04, ...,\n",
       "            5.64194866e-04,  3.94211151e-03, -2.28884607e-03],\n",
       "          [ 2.13801599e-04, -1.01058744e-03, -1.95048703e-03, ...,\n",
       "            1.72519241e-03,  3.85252922e-03, -1.64118106e-03],\n",
       "          [-1.00189541e-03, -1.83781813e-04,  2.46225507e-04, ...,\n",
       "           -1.36966977e-04,  3.78315075e-04, -1.48336496e-03]],\n",
       " \n",
       "         [[ 2.06762063e-03,  1.34100462e-03,  2.71203025e-04, ...,\n",
       "           -1.53070909e-03, -4.37980489e-04, -1.18735142e-03],\n",
       "          [ 1.88447163e-03,  9.44291474e-04, -2.79328809e-03, ...,\n",
       "            2.48195691e-04,  4.12879419e-03, -5.42412186e-03],\n",
       "          [ 2.18800525e-03,  5.40686131e-04, -1.78326573e-03, ...,\n",
       "            8.22520698e-04,  2.10965564e-03, -4.01446363e-03],\n",
       "          [ 1.44087244e-03, -2.12463317e-03, -3.38647724e-03, ...,\n",
       "            9.60936712e-04,  6.02968782e-03, -4.53097606e-03],\n",
       "          [ 1.10122259e-03, -2.03383667e-03, -2.84202490e-03, ...,\n",
       "            1.38186954e-03,  2.82444712e-03, -2.26743938e-03],\n",
       "          [ 1.09362090e-03, -4.94122214e-04, -1.94540119e-03, ...,\n",
       "           -1.40522956e-04,  2.01710919e-03, -1.12937138e-04]],\n",
       " \n",
       "         [[ 4.64244113e-05,  1.90084940e-03, -4.43568533e-05, ...,\n",
       "           -2.49168812e-03,  1.09070016e-03, -1.35253253e-03],\n",
       "          [ 1.72216084e-03,  1.42132887e-03,  2.94314814e-04, ...,\n",
       "            6.73595525e-04,  7.02266505e-07, -1.75181916e-03],\n",
       "          [ 2.47340929e-03,  8.04721087e-04, -1.34538161e-03, ...,\n",
       "           -2.46235332e-03,  2.45633698e-03, -2.24474003e-03],\n",
       "          [ 2.27227039e-03, -1.66562269e-04, -2.24161847e-03, ...,\n",
       "            1.59529527e-03,  2.77062156e-03, -4.97862324e-03],\n",
       "          [-4.30345273e-04, -1.97726698e-03, -2.49246461e-03, ...,\n",
       "            1.38771231e-03,  5.00751706e-03, -3.01991450e-03],\n",
       "          [ 9.23724787e-04, -1.11325551e-03, -2.70733819e-03, ...,\n",
       "            2.28541950e-03,  3.58434930e-03, -1.26478297e-03]],\n",
       " \n",
       "         [[ 1.98864192e-03, -2.69264885e-04,  4.52709683e-05, ...,\n",
       "            6.50166126e-04, -6.15136058e-04, -7.60238559e-04],\n",
       "          [-1.18610484e-03,  1.17165467e-03,  1.42990018e-03, ...,\n",
       "           -1.56608701e-03,  4.59063362e-04, -1.19238533e-03],\n",
       "          [ 1.25124957e-03,  1.12172740e-03,  9.11792740e-04, ...,\n",
       "            1.42237078e-03, -7.98644382e-04, -7.80220318e-04],\n",
       "          [ 4.47539671e-04,  1.96493091e-03,  6.68084307e-04, ...,\n",
       "           -1.09560625e-03,  2.31631333e-04, -2.29569082e-03],\n",
       "          [-2.26375554e-03, -7.32844230e-04, -2.14447515e-04, ...,\n",
       "            1.74520258e-03,  3.50139616e-03, -3.54454736e-03],\n",
       "          [-1.32431695e-03, -1.04365149e-03, -4.70893137e-04, ...,\n",
       "            2.49959226e-03,  1.62358594e-03, -2.03465205e-03]],\n",
       " \n",
       "         [[ 6.88956527e-04,  9.46079905e-04,  1.11154548e-03, ...,\n",
       "           -1.31836243e-03, -1.00349670e-03,  8.15080828e-04],\n",
       "          [-6.72579277e-04, -2.11847218e-04,  2.07338016e-04, ...,\n",
       "            1.43539990e-04, -9.38317608e-05, -4.65852645e-04],\n",
       "          [-6.13444019e-04,  1.17284036e-03,  1.19768688e-03, ...,\n",
       "           -1.67138129e-03, -9.53757612e-04, -8.46234092e-04],\n",
       "          [-1.80982552e-05,  1.16508966e-03,  1.15691661e-03, ...,\n",
       "           -1.82430004e-03, -1.59323134e-03, -3.69171903e-04],\n",
       "          [-1.18781743e-03, -4.29233129e-04,  3.50821210e-04, ...,\n",
       "           -5.41363843e-04,  4.80867631e-04, -1.51607359e-03],\n",
       "          [-1.22765824e-03, -7.98564695e-04, -1.33380483e-04, ...,\n",
       "           -3.13797529e-04,  1.30144384e-04, -1.10733323e-03]]],\n",
       " \n",
       " \n",
       "        [[[-8.68216273e-04,  2.29457364e-04,  5.45413408e-04, ...,\n",
       "           -3.50624090e-04, -8.33975151e-04,  1.08076364e-03],\n",
       "          [ 3.46969435e-04,  1.05339545e-03,  1.37517380e-03, ...,\n",
       "           -4.78673319e-04,  6.49148424e-04,  1.17035001e-03],\n",
       "          [ 5.80948719e-04,  9.17423866e-04, -1.80423856e-04, ...,\n",
       "           -1.61468657e-03,  2.82616168e-03,  9.33384115e-04],\n",
       "          [ 1.49635063e-03,  6.17220285e-05, -9.64805542e-04, ...,\n",
       "           -2.08940124e-03,  2.52267253e-03,  3.04784579e-03],\n",
       "          [ 9.97717609e-04,  2.06855615e-03,  1.15452625e-03, ...,\n",
       "           -5.18435729e-04,  1.92834967e-04, -4.04495047e-04],\n",
       "          [ 1.78696716e-03, -2.46242678e-04, -1.61291810e-03, ...,\n",
       "           -1.98108749e-03,  2.00800225e-03,  2.12416681e-03]],\n",
       " \n",
       "         [[-6.78192300e-04,  3.09567986e-04,  4.32628207e-04, ...,\n",
       "            1.35606824e-04, -8.21524183e-04, -8.19496927e-04],\n",
       "          [-1.42150000e-03,  1.79602718e-03, -5.48582466e-04, ...,\n",
       "           -2.19767797e-03,  2.79588014e-04,  7.40343239e-04],\n",
       "          [ 1.04378234e-03,  1.54975499e-03, -8.58967600e-04, ...,\n",
       "           -3.41924047e-03,  3.56842327e-04,  2.22457037e-03],\n",
       "          [ 3.54443706e-04, -1.89652806e-03, -1.60911202e-03, ...,\n",
       "           -1.73405639e-03,  1.53897703e-03,  5.44361724e-03],\n",
       "          [ 1.30518118e-03,  1.56630203e-03,  9.49616428e-04, ...,\n",
       "           -2.33555399e-03,  2.22642650e-03, -5.11905935e-04],\n",
       "          [ 2.32100603e-03, -7.40485615e-04, -1.44510670e-03, ...,\n",
       "           -2.95199314e-03,  1.19583646e-03,  3.90376989e-03]],\n",
       " \n",
       "         [[-2.68729375e-04, -7.30544096e-04,  2.21444890e-04, ...,\n",
       "           -1.47199244e-04, -6.85088919e-04,  2.23130279e-04],\n",
       "          [ 1.45272963e-04,  4.22136654e-04,  9.92824425e-05, ...,\n",
       "            7.39026145e-05, -1.69093866e-04, -6.76512311e-04],\n",
       "          [ 3.32276715e-04,  9.10738949e-04, -7.47578888e-05, ...,\n",
       "           -2.97350599e-03,  8.33315309e-04,  3.06315138e-04],\n",
       "          [ 2.76380510e-04, -3.72717215e-04,  1.01102842e-03, ...,\n",
       "           -1.40227098e-03, -3.72016337e-04,  3.68677801e-03],\n",
       "          [-2.11494931e-04,  3.05810384e-03,  1.79851530e-04, ...,\n",
       "           -2.60801287e-03, -1.66075974e-04,  6.87382824e-04],\n",
       "          [ 1.56154542e-03, -6.75264979e-04, -1.67360506e-03, ...,\n",
       "           -3.33185028e-03,  1.30641263e-03,  3.76436277e-03]],\n",
       " \n",
       "         [[-3.91443959e-04, -6.18042715e-04,  1.50528460e-04, ...,\n",
       "            2.96809158e-04, -1.00462930e-04, -6.12709118e-05],\n",
       "          [ 7.90938648e-05,  4.81492452e-06, -7.50422214e-06, ...,\n",
       "            2.91222852e-04, -4.16011579e-04, -2.72871373e-04],\n",
       "          [ 6.64904917e-07, -6.25631656e-04,  1.05479936e-04, ...,\n",
       "            3.94742849e-04, -2.25306358e-04, -6.31728792e-04],\n",
       "          [-2.52253540e-05,  4.07379266e-04,  8.62970192e-04, ...,\n",
       "            3.17019236e-04,  6.48005866e-04,  3.96320283e-05],\n",
       "          [-3.03994573e-04,  3.30721936e-03, -2.29594589e-04, ...,\n",
       "           -2.11160793e-03,  1.15776667e-03, -3.13490920e-04],\n",
       "          [ 1.29441184e-03, -4.63177625e-04, -4.07562405e-03, ...,\n",
       "           -5.44816069e-03,  1.33154541e-03,  4.62801242e-03]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-7.43296870e-04,  1.17262558e-03,  1.35115362e-04, ...,\n",
       "            2.54524377e-04, -1.22141023e-03,  2.28289617e-04],\n",
       "          [ 6.21354440e-04,  1.63208798e-03,  1.92741441e-04, ...,\n",
       "           -2.17833021e-03,  1.57800585e-03, -3.02963424e-04],\n",
       "          [ 6.88796281e-04, -2.30760849e-03, -1.97418500e-03, ...,\n",
       "           -1.99847994e-03,  1.92830712e-03,  4.71558748e-03]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-4.78255039e-04,  5.38414810e-04,  1.03385093e-04, ...,\n",
       "            2.81537301e-04, -5.70486241e-04, -6.04036439e-04],\n",
       "          [ 2.47300952e-04,  2.06173514e-04, -7.88135920e-04, ...,\n",
       "           -1.47352228e-03,  3.14161152e-04, -7.19931617e-04],\n",
       "          [ 1.66890430e-04, -1.85129233e-03, -4.70988511e-04, ...,\n",
       "           -1.38458179e-03, -7.87357742e-04,  2.32969434e-03]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([grad5l],feed_dict={x:current_data,y:current_label})\n",
    "grad_temp = sess.run([grad6p],feed_dict={x:current_data,y:current_label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
