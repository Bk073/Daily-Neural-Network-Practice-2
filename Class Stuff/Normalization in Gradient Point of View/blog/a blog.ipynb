{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T07:26:26.651964Z",
     "start_time": "2018-12-21T07:26:23.474276Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 35})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T07:26:28.657211Z",
     "start_time": "2018-12-21T07:26:26.653954Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T07:26:28.727533Z",
     "start_time": "2018-12-21T07:26:28.659208Z"
    },
    "code_folding": [
     48,
     88,
     128,
     168,
     199
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer,self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        return (self.layer - 1.0)/(self.lmbda + 1e-8)\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        \n",
    "        # Gradient that gets passed along\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0) * grad\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda1 =   (self.layer * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda2 = - (self.layer - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean((grad_lmbda1 + grad_lmbda2)*grad)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w\n",
    "    \n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T07:26:28.740495Z",
     "start_time": "2018-12-21T07:26:28.729523Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "num_epoch = 150; learning_rate = 0.0008; batch_size = 20; beta1,beta2,adam_e = 0.9,0.999,1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.487Z"
    },
    "code_folding": [
     0,
     45,
     58
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.12900000227987765 Test Acc : 0.1987500031851232\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 1 Acc : 0.2002000028192997 Test Acc : 0.19487500333227217\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 2 Acc : 0.25800000259280204 Test Acc : 0.2747500031534582\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.30100000256299975 Test Acc : 0.324500001296401\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Acc : 0.3272000018209219 Test Acc : 0.3463750016503036\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 5 Acc : 0.33460000103712084 Test Acc : 0.358000001963228\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 6 Acc : 0.34200000193715097 Test Acc : 0.3641250016726553\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 7 Acc : 0.3526000015437603 Test Acc : 0.3663750013988465\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 8 Acc : 0.3604000017940998 Test Acc : 0.3708750011399388\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 9 Acc : 0.3666000015437603 Test Acc : 0.37525000117719176\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 10 Acc : 0.3692000012397766 Test Acc : 0.3771250018198043\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 11 Acc : 0.37460000175237657 Test Acc : 0.380250001186505\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 12 Acc : 0.38020000129938125 Test Acc : 0.3826250007841736\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 13 Acc : 0.38480000108480455 Test Acc : 0.3855000017024577\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 14 Acc : 0.38760000085830687 Test Acc : 0.38775000182911756\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 15 Acc : 0.3894000016450882 Test Acc : 0.390500001963228\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 16 Acc : 0.3950000023841858 Test Acc : 0.39225000141188504\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Acc : 0.39900000166893007 Test Acc : 0.39250000117346645\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 18 Acc : 0.40100000154972076 Test Acc : 0.3953750011511147\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 19 Acc : 0.4032000015974045 Test Acc : 0.3985000008158386\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 20 Acc : 0.4068000011444092 Test Acc : 0.3985000008158386\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 21 Acc : 0.4122000011205673 Test Acc : 0.3985000010207295\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 22 Acc : 0.41500000160932543 Test Acc : 0.40187500037252905\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Acc : 0.41900000131130216 Test Acc : 0.4046250005811453\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Acc : 0.42340000182390214 Test Acc : 0.4056250005587935\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Acc : 0.42600000208616257 Test Acc : 0.4083749998360872\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 26 Acc : 0.4274000012278557 Test Acc : 0.4109999997541308\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Acc : 0.4278000015616417 Test Acc : 0.414875000230968\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 28 Acc : 0.43240000057220457 Test Acc : 0.41712500020861626\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 29 Acc : 0.4360000007748604 Test Acc : 0.4177500005438924\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 30 Acc : 0.4406000009179115 Test Acc : 0.42300000090152023\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Acc : 0.4416000010371208 Test Acc : 0.42375000085681674\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Acc : 0.44400000137090684 Test Acc : 0.42300000075250865\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.4460000019073486 Test Acc : 0.42550000082701445\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.4490000016093254 Test Acc : 0.4280000006780028\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.45280000203847887 Test Acc : 0.42875000089406967\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.4580000014901161 Test Acc : 0.43100000081583856\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.4594000012278557 Test Acc : 0.43325000094249844\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.461400001347065 Test Acc : 0.4355000010691583\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.4638000019788742 Test Acc : 0.4355000006593764\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 40 Acc : 0.4674000009894371 Test Acc : 0.437250000257045\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 41 Acc : 0.4684000012278557 Test Acc : 0.4397500001266599\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 42 Acc : 0.46920000076293944 Test Acc : 0.443250000718981\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 43 Acc : 0.4728000011444092 Test Acc : 0.44287500070407987\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 44 Acc : 0.47680000168085096 Test Acc : 0.4442500010691583\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Acc : 0.47840000146627426 Test Acc : 0.44625000124797226\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Acc : 0.48240000134706496 Test Acc : 0.44812500147148965\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 47 Acc : 0.48500000149011613 Test Acc : 0.448250001873821\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 48 Acc : 0.4864000015854836 Test Acc : 0.4517500019259751\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 49 Acc : 0.4880000013709068 Test Acc : 0.45325000217184425\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 50 Acc : 0.491800001680851 Test Acc : 0.4567500016279519\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Acc : 0.49300000101327895 Test Acc : 0.4613750018365681\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Acc : 0.49440000075101853 Test Acc : 0.46312500139698387\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 53 Acc : 0.4972000013589859 Test Acc : 0.4657500013522804\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 54 Acc : 0.5008000014424324 Test Acc : 0.4688750009797513\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Acc : 0.5034000014662743 Test Acc : 0.47000000154599547\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 56 Acc : 0.5098000014424324 Test Acc : 0.47300000229850414\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 57 Acc : 0.5090000013709068 Test Acc : 0.4756250017695129\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 58 Acc : 0.5128000018000602 Test Acc : 0.47562500106170774\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 59 Acc : 0.5136000017523765 Test Acc : 0.4777500017173588\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 60 Acc : 0.5152000016570091 Test Acc : 0.47762500116601586\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Acc : 0.514600000679493 Test Acc : 0.4797500011511147\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Acc : 0.5166000007987023 Test Acc : 0.4808750011585653\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 63 Acc : 0.5194000012278557 Test Acc : 0.48112500078976156\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 64 Acc : 0.5200000010132789 Test Acc : 0.48350000120699405\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 65 Acc : 0.5224000011086464 Test Acc : 0.48362500123679636\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 66 Acc : 0.5274000006318093 Test Acc : 0.48537500109523535\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Acc : 0.5276000006198883 Test Acc : 0.48737500127404926\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 68 Acc : 0.5310000005960465 Test Acc : 0.48862500086426736\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Acc : 0.5320000007152558 Test Acc : 0.48962500158697364\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Acc : 0.5318000012636185 Test Acc : 0.49037500225007535\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Acc : 0.5342000021934509 Test Acc : 0.4921250016614795\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Acc : 0.5346000024080276 Test Acc : 0.4942500014230609\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Acc : 0.5380000025033951 Test Acc : 0.49562500197440384\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 74 Acc : 0.5372000023126602 Test Acc : 0.4991250016540289\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Acc : 0.5402000019550324 Test Acc : 0.5008750011026859\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Acc : 0.5420000019669533 Test Acc : 0.5030000010505319\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 77 Acc : 0.5432000018954277 Test Acc : 0.5022500012814999\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 78 Acc : 0.5460000019669533 Test Acc : 0.5067500010877848\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 79 Acc : 0.5494000019431114 Test Acc : 0.5043750010803342\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 80 Acc : 0.5488000015616417 Test Acc : 0.5043750014528632\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 81 Acc : 0.5500000010728836 Test Acc : 0.506375001706183\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 82 Acc : 0.5542000017762184 Test Acc : 0.5065000013634563\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 83 Acc : 0.5552000008225441 Test Acc : 0.5085000013187527\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 84 Acc : 0.5584000012278557 Test Acc : 0.5088750007376075\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 85 Acc : 0.5592000014185905 Test Acc : 0.5107500014826656\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 86 Acc : 0.5616000016331673 Test Acc : 0.512875001579523\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 87 Acc : 0.5628000021576881 Test Acc : 0.5120000014826656\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 88 Acc : 0.5638000014424324 Test Acc : 0.51550000179559\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 89 Acc : 0.56440000218153 Test Acc : 0.514125002026558\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 90 Acc : 0.5630000016093254 Test Acc : 0.5146250019222498\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 91 Acc : 0.5648000020384788 Test Acc : 0.518875002078712\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 92 Acc : 0.5656000017523766 Test Acc : 0.5180000019446015\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 93 Acc : 0.5668000020384788 Test Acc : 0.5197500026598573\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 94 Acc : 0.5656000021100044 Test Acc : 0.519875002913177\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 95 Acc : 0.5670000023245811 Test Acc : 0.5203750018402934\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 96 Acc : 0.5678000019192696 Test Acc : 0.5205000020191073\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 97 Acc : 0.5686000027060508 Test Acc : 0.5228750022500753\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 98 Acc : 0.5688000013232231 Test Acc : 0.5253750021010637\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 99 Acc : 0.5702000027298927 Test Acc : 0.5265000024437905\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 100 Acc : 0.5724000018835068 Test Acc : 0.5260000026226044\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 101 Acc : 0.5730000020265579 Test Acc : 0.5275000020861625\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Acc : 0.572600002169609 Test Acc : 0.5268750025331974\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 103 Acc : 0.5730000022649765 Test Acc : 0.5276250021159649\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 104 Acc : 0.575600002527237 Test Acc : 0.5286250017210841\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Acc : 0.5772000036239624 Test Acc : 0.5312500016763806\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 106 Acc : 0.577200003027916 Test Acc : 0.5292500014603138\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 107 Acc : 0.5818000025749207 Test Acc : 0.5317500016093254\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 108 Acc : 0.5820000032186509 Test Acc : 0.5337500016763806\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 109 Acc : 0.5830000027418136 Test Acc : 0.5346250019967556\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 110 Acc : 0.5852000020742416 Test Acc : 0.5355000014975667\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 111 Acc : 0.5850000013113021 Test Acc : 0.5361250023543834\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 112 Acc : 0.5858000023365021 Test Acc : 0.5361250024288893\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Acc : 0.586800001859665 Test Acc : 0.5381250018998981\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Acc : 0.586800001859665 Test Acc : 0.5360000021010637\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Acc : 0.5922000020742416 Test Acc : 0.5401250022277236\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Acc : 0.5908000011444092 Test Acc : 0.5413750015571713\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Acc : 0.5934000006914139 Test Acc : 0.5402500019967555\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Acc : 0.5954000016450882 Test Acc : 0.5426250013336539\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Acc : 0.5974000008106232 Test Acc : 0.5403750014305114\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 120 Acc : 0.5968000013828277 Test Acc : 0.5412500013038516\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Acc : 0.5988000001907349 Test Acc : 0.543250002078712\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Acc : 0.6022000010013581 Test Acc : 0.5462500019744039\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Acc : 0.6038000010251999 Test Acc : 0.5451250021532178\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Acc : 0.6050000010728837 Test Acc : 0.5443750019744038\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Acc : 0.6056000001430512 Test Acc : 0.545375002399087\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Acc : 0.608200000166893 Test Acc : 0.5436250026896596\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Acc : 0.6090000001192093 Test Acc : 0.5471250024437905\n",
      "\n",
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Acc : 0.6110000010728837 Test Acc : 0.5457500024139881\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Acc : 0.6110000009536743 Test Acc : 0.5470000022649765\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Acc : 0.6120000004768371 Test Acc : 0.546875001937151\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Acc : 0.6122000008821488 Test Acc : 0.5472500019520521\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Acc : 0.6122000005245208 Test Acc : 0.5486250018328428\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Acc : 0.6152000013589859 Test Acc : 0.5503750023245811\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 134 Acc : 0.6152000008821488 Test Acc : 0.5510000021755695\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Acc : 0.6180000009536744 Test Acc : 0.5530000016838312\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Acc : 0.6192000008821488 Test Acc : 0.5522500019520521\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 137 Acc : 0.619599999666214 Test Acc : 0.5535000019520521\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Acc : 0.6226000006198883 Test Acc : 0.5552500026673078\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 139 Acc : 0.6216000000238419 Test Acc : 0.5541250020265579\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Acc : 0.6238000003099442 Test Acc : 0.5546250025182963\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Acc : 0.6240000010728836 Test Acc : 0.5567500019818544\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 142 Acc : 0.6254000005722046 Test Acc : 0.5550000018626452\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 143 Acc : 0.6250000002384186 Test Acc : 0.5558750017732382\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 144 Acc : 0.6266000003814697 Test Acc : 0.5558750019222498\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 145 Acc : 0.6274000005722046 Test Acc : 0.5577500023692846\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 146 Acc : 0.6289999997615814 Test Acc : 0.558125001937151\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 147 Acc : 0.6297999995946885 Test Acc : 0.5573750023543834\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Acc : 0.6317999993562698 Test Acc : 0.5582500024139881\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 149 Acc : 0.6319999994039536 Test Acc : 0.5581250020861626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Normal CNN \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,16); \n",
    "l5 = CNN(3,16,16); \n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Normal/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Normal/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Normal/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Normal/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save('Normal/train.npy',train_acc)\n",
    "np.save('Normal/test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.491Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.2912000026255846 Test Acc : 0.34337500234134494\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.36260000175237656 Test Acc : 0.3870000005699694\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 2 Acc : 0.39380000191926956 Test Acc : 0.4041250008158386\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.42120000106096267 Test Acc : 0.4147500023432076\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Acc : 0.4457999997735024 Test Acc : 0.4216250019706786\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 5 Acc : 0.46980000096559527 Test Acc : 0.41412500104866923\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 6 Acc : 0.49180000203847885 Test Acc : 0.4360000008717179\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 7 Acc : 0.5106000022888184 Test Acc : 0.44900000140070917\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 8 Acc : 0.5230000023841858 Test Acc : 0.4557500014454126\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 9 Acc : 0.5384000033140183 Test Acc : 0.4575000016763806\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 10 Acc : 0.5480000021457672 Test Acc : 0.4606250024959445\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 11 Acc : 0.5610000009536743 Test Acc : 0.4522500019520521\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 12 Acc : 0.572800000667572 Test Acc : 0.46325000170618297\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 13 Acc : 0.5850000017881394 Test Acc : 0.4675000016018748\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 14 Acc : 0.5958000005483627 Test Acc : 0.46487500201910736\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 15 Acc : 0.6043999992609024 Test Acc : 0.45875000121071935\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 16 Acc : 0.6117999993562698 Test Acc : 0.4668750014901161\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 17 Acc : 0.6205999989509583 Test Acc : 0.46637500083073974\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 18 Acc : 0.6307999995946885 Test Acc : 0.46450000066310165\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 19 Acc : 0.6402000013589859 Test Acc : 0.46725000023841856\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 20 Acc : 0.6493999999761582 Test Acc : 0.4680000001192093\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 21 Acc : 0.6605999997854233 Test Acc : 0.47312500070780517\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 22 Acc : 0.6677999974489212 Test Acc : 0.46712500136345625\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 23 Acc : 0.677600000500679 Test Acc : 0.47000000040978196\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 24 Acc : 0.6823999990224838 Test Acc : 0.4670000009983778\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 25 Acc : 0.6887999987602234 Test Acc : 0.46675000138580797\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 26 Acc : 0.6969999989271164 Test Acc : 0.46112500119954347\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Acc : 0.700999999165535 Test Acc : 0.46112500101327897\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 28 Acc : 0.7065999985933303 Test Acc : 0.46612500105053184\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 29 Acc : 0.715399999499321 Test Acc : 0.4651250011101365\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 30 Acc : 0.7231999998092651 Test Acc : 0.4670000008866191\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Acc : 0.7306000007390976 Test Acc : 0.4673750014230609\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Acc : 0.7380000010728837 Test Acc : 0.4527500015683472\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.7462000000476837 Test Acc : 0.4546250008046627\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.7518000009059906 Test Acc : 0.45150000041350724\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.7544000009298325 Test Acc : 0.42675000093877313\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.75800000166893 Test Acc : 0.40587500043213365\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.7646000018119812 Test Acc : 0.40062500091269615\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.7726000008583069 Test Acc : 0.40700000135228037\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.7739999997615814 Test Acc : 0.39100000059232115\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 40 Acc : 0.7795999999046326 Test Acc : 0.399875001385808\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 41 Acc : 0.7844000012874603 Test Acc : 0.363625001758337\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 42 Acc : 0.7892000014781952 Test Acc : 0.38362500121816995\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Acc : 0.7964000015258789 Test Acc : 0.3996250015310943\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.7982000021934509 Test Acc : 0.41262500116601586\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Acc : 0.8028000016212463 Test Acc : 0.42700000064447524\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Acc : 0.8120000021457672 Test Acc : 0.4392500006407499\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Acc : 0.8152000019550324 Test Acc : 0.4431250014156103\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 48 Acc : 0.8206000020503997 Test Acc : 0.43562500128522513\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.825200001001358 Test Acc : 0.44500000175088644\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 50 Acc : 0.8292000031471253 Test Acc : 0.45437500078231097\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 51 Acc : 0.8344000024795533 Test Acc : 0.45425000093877316\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Acc : 0.8382000024318695 Test Acc : 0.4595000009611249\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 53 Acc : 0.8438000016212464 Test Acc : 0.4612500018253922\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 54 Acc : 0.8466000022888184 Test Acc : 0.46137500140815974\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Acc : 0.8486000006198883 Test Acc : 0.45637500174343587\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 56 Acc : 0.8494000008106232 Test Acc : 0.4588750021532178\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 57 Acc : 0.8522000000476837 Test Acc : 0.45650000162422655\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 58 Acc : 0.8544000008106232 Test Acc : 0.4566250014305115\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 59 Acc : 0.8588000009059906 Test Acc : 0.45837500162422656\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 60 Acc : 0.8614000024795532 Test Acc : 0.4575000011175871\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Acc : 0.8644000022411347 Test Acc : 0.45487500097602607\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Acc : 0.8686000006198883 Test Acc : 0.4525000014901161\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 63 Acc : 0.8698000001907349 Test Acc : 0.44575000179931523\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 64 Acc : 0.877399998664856 Test Acc : 0.43950000176206233\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 65 Acc : 0.8823999967575074 Test Acc : 0.4428750018775463\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 66 Acc : 0.8827999970912933 Test Acc : 0.4347500006109476\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Acc : 0.887599997997284 Test Acc : 0.4375000004842877\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 68 Acc : 0.8905999970436096 Test Acc : 0.44412500197067856\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Acc : 0.8899999966621399 Test Acc : 0.44150000121444466\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Acc : 0.8955999963283539 Test Acc : 0.4416250013560057\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Acc : 0.8967999958992005 Test Acc : 0.44537500098347665\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Acc : 0.9005999944210052 Test Acc : 0.44275000158697364\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Acc : 0.9041999948024749 Test Acc : 0.43725000113248824\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 74 Acc : 0.9021999933719635 Test Acc : 0.44037500146776437\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Acc : 0.9049999947547913 Test Acc : 0.43050000090152024\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Acc : 0.9089999935626983 Test Acc : 0.4330000011622906\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 77 Acc : 0.9105999932289124 Test Acc : 0.43487500127404927\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 78 Acc : 0.9093999936580658 Test Acc : 0.4351250006817281\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 79 Acc : 0.9101999931335449 Test Acc : 0.4250000009685755\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 80 Acc : 0.9127999942302704 Test Acc : 0.4333750007674098\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.9149999949932098 Test Acc : 0.4313750008493662\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.9231999943256378 Test Acc : 0.43400000128895044\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.9223999943733215 Test Acc : 0.4365000008046627\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 84 Acc : 0.9229999933242797 Test Acc : 0.4356250013411045\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Acc : 0.9255999937057495 Test Acc : 0.43412500143051147\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 86 Acc : 0.9275999929904938 Test Acc : 0.430500001385808\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 87 Acc : 0.9259999940395355 Test Acc : 0.4307500019855797\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 88 Acc : 0.9331999928951263 Test Acc : 0.43062500115484\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 89 Acc : 0.9297999927997589 Test Acc : 0.4261250006221235\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 90 Acc : 0.9389999930858612 Test Acc : 0.4276250009983778\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 91 Acc : 0.9397999947071075 Test Acc : 0.4268750011175871\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 92 Acc : 0.940199991941452 Test Acc : 0.43225000163540245\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 93 Acc : 0.943199993133545 Test Acc : 0.4296250017546117\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 94 Acc : 0.9485999937057495 Test Acc : 0.42887500097975134\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 95 Acc : 0.9475999934673309 Test Acc : 0.4286250019259751\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 96 Acc : 0.945599993944168 Test Acc : 0.42437500165775416\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 97 Acc : 0.9511999936103821 Test Acc : 0.41400000095367434\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Acc : 0.946999993801117 Test Acc : 0.4205000014230609\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 99 Acc : 0.9447999927997589 Test Acc : 0.42550000028684737\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Acc : 0.9447999920845032 Test Acc : 0.41937500158324836\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Acc : 0.9513999934196472 Test Acc : 0.41187500081956385\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 102 Acc : 0.9477999923229218 Test Acc : 0.41662500154227017\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.9521999914646149 Test Acc : 0.4281250013783574\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 104 Acc : 0.946399992465973 Test Acc : 0.42975000068545344\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 105 Acc : 0.949799993276596 Test Acc : 0.42800000190734866\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 106 Acc : 0.9561999926567077 Test Acc : 0.42837500147521496\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Acc : 0.9599999933242798 Test Acc : 0.4306250008940697\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.9653999934196472 Test Acc : 0.4333750021085143\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.9601999933719635 Test Acc : 0.4337500024959445\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 110 Acc : 0.9641999933719635 Test Acc : 0.43400000102818015\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 111 Acc : 0.951199993133545 Test Acc : 0.4436250015348196\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 112 Acc : 0.9595999934673309 Test Acc : 0.4366250011697412\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 113 Acc : 0.9593999927043915 Test Acc : 0.43450000178068876\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 114 Acc : 0.9595999939441681 Test Acc : 0.43800000166520475\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 115 Acc : 0.9637999942302704 Test Acc : 0.43737500090152026\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 116 Acc : 0.9563999931812286 Test Acc : 0.4402500010840595\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Acc : 0.9677999947071075 Test Acc : 0.4317500006593764\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 118 Acc : 0.9667999937534332 Test Acc : 0.4331250015646219\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 119 Acc : 0.9655999937057496 Test Acc : 0.4332500010356307\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 120 Acc : 0.9669999947547913 Test Acc : 0.4350000016391277\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Acc : 0.9687999939918518 Test Acc : 0.4370000012405217\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 122 Acc : 0.973199994802475 Test Acc : 0.43100000178441406\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 123 Acc : 0.9729999952316284 Test Acc : 0.43300000170245767\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 124 Acc : 0.9741999955177307 Test Acc : 0.42737500166520476\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 125 Acc : 0.975199994802475 Test Acc : 0.4331250013038516\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 126 Acc : 0.9709999942779541 Test Acc : 0.4263750013150275\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 127 Acc : 0.9803999955654145 Test Acc : 0.4256250013783574\n",
      "\n",
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 128 Acc : 0.9805999960899353 Test Acc : 0.4253750010766089\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 129 Acc : 0.9787999963760377 Test Acc : 0.4296250017546117\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 130 Acc : 0.9809999957084655 Test Acc : 0.4312500006146729\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 131 Acc : 0.9691999945640564 Test Acc : 0.43125000135973096\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 132 Acc : 0.9777999954223633 Test Acc : 0.42925000097602606\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 133 Acc : 0.9775999960899353 Test Acc : 0.43062500171363355\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 134 Acc : 0.9713999943733216 Test Acc : 0.42337500140070916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Acc : 0.975999995470047 Test Acc : 0.43000000093132257\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 136 Acc : 0.9755999960899353 Test Acc : 0.43324999989941715\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 137 Acc : 0.9723999960422516 Test Acc : 0.4373750016093254\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 138 Acc : 0.9735999953746796 Test Acc : 0.42787500120699407\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.65\n",
      " Current : 139 Acc : 0.9805999960899353 Test Acc : 0.43662500094622375\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Acc : 0.981399995803833 Test Acc : 0.4312500008940697\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 141 Acc : 0.985399996995926 Test Acc : 0.4330000003799796\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 142 Acc : 0.9837999966144562 Test Acc : 0.4341250006109476\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 143 Acc : 0.9805999963283539 Test Acc : 0.4336250011622906\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 144 Acc : 0.9849999966621399 Test Acc : 0.4388750006631017\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 145 Acc : 0.9785999960899353 Test Acc : 0.430875000692904\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 146 Acc : 0.981399995803833 Test Acc : 0.42625000163912774\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 147 Acc : 0.9809999957084655 Test Acc : 0.4232500003650784\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Acc : 0.9815999958515167 Test Acc : 0.42475000156089665\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 149 Acc : 0.9759999947547913 Test Acc : 0.42875000078231096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. batch normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'batch Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'batch Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('batch Norm/train.npy',train_acc)\n",
    "np.save('batch Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.496Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Acc : 0.2362000032067299 Test Acc : 0.2541250028740615\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 1 Acc : 0.31260000233352186 Test Acc : 0.23525000294670462\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 2 Acc : 0.3676000007390976 Test Acc : 0.24912500320002437\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.3982000014185905 Test Acc : 0.2648750030901283\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Acc : 0.42420000123977664 Test Acc : 0.28925000262446704\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 5 Acc : 0.4446000022292137 Test Acc : 0.29662500238977374\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 6 Acc : 0.46440000158548356 Test Acc : 0.3077500025276095\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 7 Acc : 0.4790000013709068 Test Acc : 0.32000000146217644\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 8 Acc : 0.48940000182390214 Test Acc : 0.32987500150687993\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 9 Acc : 0.4962000018358231 Test Acc : 0.3362500006891787\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 10 Acc : 0.5034000002145768 Test Acc : 0.3423750014975667\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 11 Acc : 0.5136000009775161 Test Acc : 0.348250001128763\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 12 Acc : 0.5212000012397766 Test Acc : 0.35187500150874257\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 13 Acc : 0.5290000019073486 Test Acc : 0.3530000018328428\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 14 Acc : 0.5362000019550324 Test Acc : 0.3552500014565885\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 15 Acc : 0.5460000002384185 Test Acc : 0.354000000897795\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 16 Acc : 0.5537999995946884 Test Acc : 0.3530000015348196\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Acc : 0.5640000007152557 Test Acc : 0.35262500112876294\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 18 Acc : 0.5694000006914138 Test Acc : 0.3538750012218952\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 19 Acc : 0.5774000010490418 Test Acc : 0.35112500151619314\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 20 Acc : 0.582000000834465 Test Acc : 0.35675000175833704\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 21 Acc : 0.5913999997377396 Test Acc : 0.35200000198557974\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 22 Acc : 0.6009999991655349 Test Acc : 0.35075000243261456\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Acc : 0.608799999833107 Test Acc : 0.348375001642853\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Acc : 0.6182000008821488 Test Acc : 0.3460000016912818\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Acc : 0.6291999992132187 Test Acc : 0.34487500103190544\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 26 Acc : 0.634599997997284 Test Acc : 0.3410000016912818\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Acc : 0.6405999983549118 Test Acc : 0.3405000016465783\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Acc : 0.6461999974250794 Test Acc : 0.34062500147148966\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Acc : 0.6557999974489213 Test Acc : 0.3378750020172447\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.6597999979257584 Test Acc : 0.33262500196695327\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Acc : 0.6669999979734421 Test Acc : 0.3323750021122396\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 32 Acc : 0.6702000007629395 Test Acc : 0.3360000019520521\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.6752000008821487 Test Acc : 0.3301250021532178\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.6833999997377396 Test Acc : 0.3310000021569431\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 35 Acc : 0.6928000007867813 Test Acc : 0.32862500139512124\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.7019999997615815 Test Acc : 0.32762500170618297\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.706600001335144 Test Acc : 0.32937500197440384\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.7064000000953674 Test Acc : 0.3276250017341226\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.710600001335144 Test Acc : 0.3260000016260892\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 40 Acc : 0.7174000000953674 Test Acc : 0.3253750022593886\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 41 Acc : 0.7250000017881394 Test Acc : 0.3240000027511269\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 42 Acc : 0.7300000013113022 Test Acc : 0.3278750023152679\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 43 Acc : 0.7380000007152557 Test Acc : 0.3281250023748726\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 44 Acc : 0.7437999997138977 Test Acc : 0.3262500026170164\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Acc : 0.7478000004291534 Test Acc : 0.3285000021662563\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Acc : 0.7557999985218048 Test Acc : 0.32887500160373745\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Acc : 0.7591999986171722 Test Acc : 0.3282500018551946\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.7643999998569488 Test Acc : 0.32775000179186464\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.7667999989986419 Test Acc : 0.32912500196136535\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 50 Acc : 0.769199999332428 Test Acc : 0.3316250015236437\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 51 Acc : 0.7709999995231629 Test Acc : 0.32875000169500707\n",
      "\n",
      "Current Iter : 52/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 52 Acc : 0.7792000000476837 Test Acc : 0.3270000017993152\n",
      "\n",
      "Current Iter : 53/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 53 Acc : 0.7805999991893768 Test Acc : 0.32575000160373746\n",
      "\n",
      "Current Iter : 54/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 54 Acc : 0.7808000009059906 Test Acc : 0.3176250022929162\n",
      "\n",
      "Current Iter : 55/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Acc : 0.7834000005722046 Test Acc : 0.31700000221841035\n",
      "\n",
      "Current Iter : 56/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 56 Acc : 0.7902000005245209 Test Acc : 0.3178750022593886\n",
      "\n",
      "Current Iter : 57/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 57 Acc : 0.7936000022888183 Test Acc : 0.3190000018198043\n",
      "\n",
      "Current Iter : 58/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 58 Acc : 0.7992000012397766 Test Acc : 0.3203750021290034\n",
      "\n",
      "Current Iter : 59/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 59 Acc : 0.7996000020503998 Test Acc : 0.3187500021327287\n",
      "\n",
      "Current Iter : 60/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 60 Acc : 0.8044000012874604 Test Acc : 0.31687500156462195\n",
      "\n",
      "Current Iter : 61/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Acc : 0.8070000009536743 Test Acc : 0.3182500025164336\n",
      "\n",
      "Current Iter : 62/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Acc : 0.8134000022411346 Test Acc : 0.31825000184588137\n",
      "\n",
      "Current Iter : 63/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 63 Acc : 0.8180000011920929 Test Acc : 0.3193750020954758\n",
      "\n",
      "Current Iter : 64/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 64 Acc : 0.8243999993801117 Test Acc : 0.32312500164844093\n",
      "\n",
      "Current Iter : 65/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 65 Acc : 0.8196000010967255 Test Acc : 0.32387500192038715\n",
      "\n",
      "Current Iter : 66/150 batch : 7980/8000 acc : 0.55\n",
      " Current : 66 Acc : 0.8208000009059906 Test Acc : 0.32087500172667205\n",
      "\n",
      "Current Iter : 67/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 67 Acc : 0.8242000019550324 Test Acc : 0.32025000170804563\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 68 Acc : 0.8250000011920929 Test Acc : 0.31900000154040753\n",
      "\n",
      "Current Iter : 69/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 69 Acc : 0.8260000011920929 Test Acc : 0.31825000166893\n",
      "\n",
      "Current Iter : 70/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 70 Acc : 0.8328000013828277 Test Acc : 0.31937500219792125\n",
      "\n",
      "Current Iter : 71/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 71 Acc : 0.8394000005722045 Test Acc : 0.3211250021029264\n",
      "\n",
      "Current Iter : 72/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 72 Acc : 0.841800000667572 Test Acc : 0.3236250018142164\n",
      "\n",
      "Current Iter : 73/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 73 Acc : 0.8484000000953674 Test Acc : 0.3251250013336539\n",
      "\n",
      "Current Iter : 74/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 74 Acc : 0.8505999999046325 Test Acc : 0.3242500016558915\n",
      "\n",
      "Current Iter : 75/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 75 Acc : 0.8518000004291535 Test Acc : 0.3216250014025718\n",
      "\n",
      "Current Iter : 76/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 76 Acc : 0.8575999991893768 Test Acc : 0.3252500016614795\n",
      "\n",
      "Current Iter : 77/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 77 Acc : 0.8599999990463257 Test Acc : 0.32662500157020985\n",
      "\n",
      "Current Iter : 78/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 78 Acc : 0.86499999833107 Test Acc : 0.3263750017527491\n",
      "\n",
      "Current Iter : 79/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Acc : 0.8661999986171722 Test Acc : 0.3266250015422702\n",
      "\n",
      "Current Iter : 80/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Acc : 0.8685999991893768 Test Acc : 0.32587500194087626\n",
      "\n",
      "Current Iter : 81/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.8683999998569488 Test Acc : 0.32262500215321777\n",
      "\n",
      "Current Iter : 82/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.8643999989032746 Test Acc : 0.32237500194460156\n",
      "\n",
      "Current Iter : 83/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.8667999980449677 Test Acc : 0.3192500010691583\n",
      "\n",
      "Current Iter : 84/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 84 Acc : 0.8737999982833863 Test Acc : 0.3128750015888363\n",
      "\n",
      "Current Iter : 85/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 85 Acc : 0.8711999988555909 Test Acc : 0.31237500180490313\n",
      "\n",
      "Current Iter : 86/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 86 Acc : 0.877199996471405 Test Acc : 0.3132500018551946\n",
      "\n",
      "Current Iter : 87/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 87 Acc : 0.8759999973773956 Test Acc : 0.31400000195018946\n",
      "\n",
      "Current Iter : 88/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 88 Acc : 0.8753999969959259 Test Acc : 0.319500001994893\n",
      "\n",
      "Current Iter : 89/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 89 Acc : 0.8793999989032746 Test Acc : 0.31587500182911754\n",
      "\n",
      "Current Iter : 90/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 90 Acc : 0.8789999973773956 Test Acc : 0.31712500177323816\n",
      "\n",
      "Current Iter : 91/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 91 Acc : 0.8861999967098236 Test Acc : 0.31837500191293655\n",
      "\n",
      "Current Iter : 92/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 92 Acc : 0.8931999940872193 Test Acc : 0.31812500147148964\n",
      "\n",
      "Current Iter : 93/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 93 Acc : 0.8959999942779541 Test Acc : 0.31225000220350924\n",
      "\n",
      "Current Iter : 94/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 94 Acc : 0.9041999936103821 Test Acc : 0.3125000012665987\n",
      "\n",
      "Current Iter : 95/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 95 Acc : 0.9043999948501587 Test Acc : 0.308625001180917\n",
      "\n",
      "Current Iter : 96/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 96 Acc : 0.9093999950885773 Test Acc : 0.30962500205263493\n",
      "\n",
      "Current Iter : 97/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 97 Acc : 0.9175999941825866 Test Acc : 0.30900000215508044\n",
      "\n",
      "Current Iter : 98/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Acc : 0.9199999942779541 Test Acc : 0.308125001648441\n",
      "\n",
      "Current Iter : 99/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Acc : 0.9233999948501587 Test Acc : 0.30862500191666187\n",
      "\n",
      "Current Iter : 100/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Acc : 0.9237999925613404 Test Acc : 0.30750000179745257\n",
      "\n",
      "Current Iter : 101/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Acc : 0.9269999930858612 Test Acc : 0.3073750016372651\n",
      "\n",
      "Current Iter : 102/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 102 Acc : 0.928799993276596 Test Acc : 0.31112500129267573\n",
      "\n",
      "Current Iter : 103/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.9209999933242797 Test Acc : 0.3051250024326146\n",
      "\n",
      "Current Iter : 104/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 104 Acc : 0.9193999936580658 Test Acc : 0.3087500024959445\n",
      "\n",
      "Current Iter : 105/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 105 Acc : 0.9199999926090241 Test Acc : 0.3087500019930303\n",
      "\n",
      "Current Iter : 106/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 106 Acc : 0.9257999918460846 Test Acc : 0.31337500183843076\n",
      "\n",
      "Current Iter : 107/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 107 Acc : 0.9289999916553497 Test Acc : 0.31387500174343586\n",
      "\n",
      "Current Iter : 108/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.9305999920368194 Test Acc : 0.3197500016633421\n",
      "\n",
      "Current Iter : 109/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.9297999935150146 Test Acc : 0.31387500210665165\n",
      "\n",
      "Current Iter : 110/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 110 Acc : 0.9275999927520752 Test Acc : 0.32012500184588133\n",
      "\n",
      "Current Iter : 111/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 111 Acc : 0.9313999931812287 Test Acc : 0.31975000190548597\n",
      "\n",
      "Current Iter : 112/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 112 Acc : 0.933599992275238 Test Acc : 0.3211250021960586\n",
      "\n",
      "Current Iter : 113/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 113 Acc : 0.9295999920368194 Test Acc : 0.320000002104789\n",
      "\n",
      "Current Iter : 114/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 114 Acc : 0.9353999919891357 Test Acc : 0.3213750015944242\n",
      "\n",
      "Current Iter : 115/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 115 Acc : 0.9415999913215637 Test Acc : 0.32212500223889945\n",
      "\n",
      "Current Iter : 116/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 116 Acc : 0.9419999921321869 Test Acc : 0.32162500215694306\n",
      "\n",
      "Current Iter : 117/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Acc : 0.9337999913692474 Test Acc : 0.32425000143237415\n",
      "\n",
      "Current Iter : 118/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 118 Acc : 0.9417999920845032 Test Acc : 0.3267500019352883\n",
      "\n",
      "Current Iter : 119/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 119 Acc : 0.943399992465973 Test Acc : 0.3235000020638108\n",
      "\n",
      "Current Iter : 120/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.9431999912261962 Test Acc : 0.3195000015199184\n",
      "\n",
      "Current Iter : 121/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Acc : 0.9353999922275543 Test Acc : 0.31875000172294676\n",
      "\n",
      "Current Iter : 122/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 122 Acc : 0.9367999925613403 Test Acc : 0.32150000211782753\n",
      "\n",
      "Current Iter : 123/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 123 Acc : 0.9387999925613403 Test Acc : 0.32212500187568366\n",
      "\n",
      "Current Iter : 124/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 124 Acc : 0.942999992609024 Test Acc : 0.32450000119395556\n",
      "\n",
      "Current Iter : 125/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 125 Acc : 0.9443999929428101 Test Acc : 0.32525000176392493\n",
      "\n",
      "Current Iter : 126/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 126 Acc : 0.945799993276596 Test Acc : 0.32612500140443446\n",
      "\n",
      "Current Iter : 127/150 batch : 7980/8000 acc : 0.35\n",
      " Current : 127 Acc : 0.9455999937057495 Test Acc : 0.32775000200606885\n",
      "\n",
      "Current Iter : 128/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 128 Acc : 0.9421999933719635 Test Acc : 0.32425000173039736\n",
      "\n",
      "Current Iter : 129/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 129 Acc : 0.9441999921798706 Test Acc : 0.326250002104789\n",
      "\n",
      "Current Iter : 130/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 130 Acc : 0.9429999921321869 Test Acc : 0.3255000019818544\n",
      "\n",
      "Current Iter : 131/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 131 Acc : 0.9473999936580658 Test Acc : 0.3185000015888363\n",
      "\n",
      "Current Iter : 132/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 132 Acc : 0.9443999931812287 Test Acc : 0.31937500145286324\n",
      "\n",
      "Current Iter : 133/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 133 Acc : 0.9475999934673309 Test Acc : 0.3241250015236437\n",
      "\n",
      "Current Iter : 134/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 134 Acc : 0.9511999926567077 Test Acc : 0.33300000090152027\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 135 Acc : 0.9545999929904938 Test Acc : 0.33725000103004277\n",
      "\n",
      "Current Iter : 136/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 136 Acc : 0.9541999936103821 Test Acc : 0.3288750019762665\n",
      "\n",
      "Current Iter : 137/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 137 Acc : 0.9569999938011169 Test Acc : 0.3317500018607825\n",
      "\n",
      "Current Iter : 138/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 138 Acc : 0.960399994134903 Test Acc : 0.32750000193715095\n",
      "\n",
      "Current Iter : 139/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 139 Acc : 0.9631999938488006 Test Acc : 0.3250000016018748\n",
      "\n",
      "Current Iter : 140/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 140 Acc : 0.9567999942302704 Test Acc : 0.32300000155344605\n",
      "\n",
      "Current Iter : 141/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 141 Acc : 0.9577999935150147 Test Acc : 0.3217500017490238\n",
      "\n",
      "Current Iter : 142/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 142 Acc : 0.9567999939918518 Test Acc : 0.32325000195764003\n",
      "\n",
      "Current Iter : 143/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 143 Acc : 0.9523999927043915 Test Acc : 0.3238750016596168\n",
      "\n",
      "Current Iter : 144/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 144 Acc : 0.9481999940872192 Test Acc : 0.3266250011604279\n",
      "\n",
      "Current Iter : 145/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 145 Acc : 0.9509999933242798 Test Acc : 0.32425000085495415\n",
      "\n",
      "Current Iter : 146/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 146 Acc : 0.955799994468689 Test Acc : 0.31350000156089664\n",
      "\n",
      "Current Iter : 147/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 147 Acc : 0.9655999953746796 Test Acc : 0.31712500141002237\n",
      "\n",
      "Current Iter : 148/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Acc : 0.9637999954223633 Test Acc : 0.32150000117719174\n",
      "\n",
      "Current Iter : 149/150 batch : 7980/8000 acc : 0.45\n",
      " Current : 149 Acc : 0.9689999949932099 Test Acc : 0.32437500153668225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. layer normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l2 = CNN(3,16,16); l2n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l3 = CNN(3,16,16); l3n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l4 = CNN(3,16,16); l4n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l5 = CNN(3,16,16); l5n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Layer Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('Layer Norm/train.npy',train_acc)\n",
    "np.save('Layer Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.498Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 0 Acc : 0.21720000338554382 Test Acc : 0.1950000035762787\n",
      "\n",
      "Current Iter : 1/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 1 Acc : 0.31700000254809857 Test Acc : 0.20887500301934778\n",
      "\n",
      "Current Iter : 2/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 2 Acc : 0.362800000667572 Test Acc : 0.2205000027269125\n",
      "\n",
      "Current Iter : 3/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 3 Acc : 0.39800000116229056 Test Acc : 0.2173750031646341\n",
      "\n",
      "Current Iter : 4/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 4 Acc : 0.4152000014781952 Test Acc : 0.21525000302121045\n",
      "\n",
      "Current Iter : 5/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 5 Acc : 0.4276000012755394 Test Acc : 0.22037500308826566\n",
      "\n",
      "Current Iter : 6/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 6 Acc : 0.4418000018596649 Test Acc : 0.21962500334717333\n",
      "\n",
      "Current Iter : 7/150 batch : 7980/8000 acc : 0.25\n",
      " Current : 7 Acc : 0.45660000026226044 Test Acc : 0.22387500337325036\n",
      "\n",
      "Current Iter : 8/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 8 Acc : 0.47600000190734865 Test Acc : 0.2220000028796494\n",
      "\n",
      "Current Iter : 9/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 9 Acc : 0.4928000023961067 Test Acc : 0.22250000319443644\n",
      "\n",
      "Current Iter : 10/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 10 Acc : 0.5038000025749206 Test Acc : 0.2202500030118972\n",
      "\n",
      "Current Iter : 11/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 11 Acc : 0.5178000023961067 Test Acc : 0.2213750032801181\n",
      "\n",
      "Current Iter : 12/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 12 Acc : 0.5304000024199486 Test Acc : 0.22762500315904619\n",
      "\n",
      "Current Iter : 13/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 13 Acc : 0.5406000019311905 Test Acc : 0.2271250030118972\n",
      "\n",
      "Current Iter : 14/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 14 Acc : 0.5512000014781951 Test Acc : 0.2287500030361116\n",
      "\n",
      "Current Iter : 15/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 15 Acc : 0.5572000023126602 Test Acc : 0.22887500314041972\n",
      "\n",
      "Current Iter : 16/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 16 Acc : 0.5710000029206276 Test Acc : 0.22875000324100256\n",
      "\n",
      "Current Iter : 17/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 17 Acc : 0.579400002360344 Test Acc : 0.22787500276230277\n",
      "\n",
      "Current Iter : 18/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 18 Acc : 0.5864000006914138 Test Acc : 0.22675000279210508\n",
      "\n",
      "Current Iter : 19/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 19 Acc : 0.5937999998331069 Test Acc : 0.2268750028591603\n",
      "\n",
      "Current Iter : 20/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 20 Acc : 0.6054000004529952 Test Acc : 0.22812500308267772\n",
      "\n",
      "Current Iter : 21/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 21 Acc : 0.608400000333786 Test Acc : 0.22525000279769303\n",
      "\n",
      "Current Iter : 22/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 22 Acc : 0.6169999996423722 Test Acc : 0.22637500314973294\n",
      "\n",
      "Current Iter : 23/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 23 Acc : 0.6277999995946885 Test Acc : 0.22700000337325035\n",
      "\n",
      "Current Iter : 24/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 24 Acc : 0.6366000006198883 Test Acc : 0.2275000030361116\n",
      "\n",
      "Current Iter : 25/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 25 Acc : 0.6398000018596649 Test Acc : 0.2276250031683594\n",
      "\n",
      "Current Iter : 26/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 26 Acc : 0.649600000500679 Test Acc : 0.226375003317371\n",
      "\n",
      "Current Iter : 27/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 27 Acc : 0.6538000011444092 Test Acc : 0.22787500319071113\n",
      "\n",
      "Current Iter : 28/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 28 Acc : 0.6607999999523163 Test Acc : 0.22612500339746475\n",
      "\n",
      "Current Iter : 29/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 29 Acc : 0.6657999999523163 Test Acc : 0.22575000290758906\n",
      "\n",
      "Current Iter : 30/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 30 Acc : 0.6736000001430511 Test Acc : 0.22187500339001417\n",
      "\n",
      "Current Iter : 31/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 31 Acc : 0.6812000005245209 Test Acc : 0.219250003201887\n",
      "\n",
      "Current Iter : 32/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 32 Acc : 0.6848000004291535 Test Acc : 0.22037500315345823\n",
      "\n",
      "Current Iter : 33/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 33 Acc : 0.6944000017642975 Test Acc : 0.221875002970919\n",
      "\n",
      "Current Iter : 34/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 34 Acc : 0.6992000011205673 Test Acc : 0.21975000312551857\n",
      "\n",
      "Current Iter : 35/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 35 Acc : 0.7032000008821487 Test Acc : 0.21412500261329115\n",
      "\n",
      "Current Iter : 36/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 36 Acc : 0.7074000005722045 Test Acc : 0.20975000300444663\n",
      "\n",
      "Current Iter : 37/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 37 Acc : 0.7132000005245209 Test Acc : 0.20962500296533107\n",
      "\n",
      "Current Iter : 38/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 38 Acc : 0.7172000008821487 Test Acc : 0.2127500027883798\n",
      "\n",
      "Current Iter : 39/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 39 Acc : 0.7209999997615815 Test Acc : 0.21250000298023225\n",
      "\n",
      "Current Iter : 40/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 40 Acc : 0.7258000011444092 Test Acc : 0.20812500298954548\n",
      "\n",
      "Current Iter : 41/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 41 Acc : 0.7304000000953674 Test Acc : 0.20475000279955566\n",
      "\n",
      "Current Iter : 42/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 42 Acc : 0.7420000016689301 Test Acc : 0.2015000026114285\n",
      "\n",
      "Current Iter : 43/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 43 Acc : 0.7480000011920929 Test Acc : 0.2011250029038638\n",
      "\n",
      "Current Iter : 44/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 44 Acc : 0.7516000024080276 Test Acc : 0.19850000262260437\n",
      "\n",
      "Current Iter : 45/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 45 Acc : 0.7534000017642974 Test Acc : 0.19650000317953528\n",
      "\n",
      "Current Iter : 46/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 46 Acc : 0.7586000027656555 Test Acc : 0.19562500318512321\n",
      "\n",
      "Current Iter : 47/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 47 Acc : 0.7678000010251999 Test Acc : 0.19850000321865083\n",
      "\n",
      "Current Iter : 48/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 48 Acc : 0.772200001835823 Test Acc : 0.1925000030454248\n",
      "\n",
      "Current Iter : 49/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 49 Acc : 0.7698000025749206 Test Acc : 0.19450000333599746\n",
      "\n",
      "Current Iter : 50/150 batch : 7980/8000 acc : 0.15\n",
      " Current : 50 Acc : 0.7780000030994415 Test Acc : 0.1916250030696392\n",
      "\n",
      "Current Iter : 51/150 batch : 7980/8000 acc : 0.05\n",
      " Current : 51 Acc : 0.7810000026226044 Test Acc : 0.19412500305101277\n",
      "\n",
      "Current Iter : 52/150 batch : 2320/5000 acc : 0.85\r"
     ]
    }
   ],
   "source": [
    "# 4. Instance normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Instace Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('Instace Norm/train.npy',train_acc)\n",
    "np.save('Instace Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.502Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 5. box cox \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_box_cox()\n",
    "l2 = CNN(3,16,16); l2n = tf_box_cox()\n",
    "l3 = CNN(3,16,16); l3n = tf_box_cox()\n",
    "\n",
    "l4 = CNN(3,16,16); l4n = tf_box_cox()\n",
    "l5 = CNN(3,16,16); l5n = tf_box_cox()\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1a = l1n.feedforward(layer1a)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer2a = l2n.feedforward(layer2a)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer3a = l3n.feedforward(layer3a)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer4a = l4n.feedforward(layer4a)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer5a = l5n.feedforward(layer5a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up  = l6.backprop(gradient)\n",
    "grad5n,grad5l,grad5n_up = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up  = l5.backprop(grad5n)\n",
    "grad4n,grad4l,grad4n_up = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up  = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n,grad3l,grad3n_up = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up  = l3.backprop(grad3n,stride=2)\n",
    "grad2n,grad2l,grad2n_up = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up  = l2.backprop(grad2n,stride=2)\n",
    "grad1n,grad1l,grad1n_up = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up  = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5n_up + grad5_up + grad4n_up +  grad4_up + grad3n_up + grad3_up + grad2n_up + grad2_up + grad1n_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Box Cox/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Box Cox/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Box Cox/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Box Cox/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save('Box Cox/train.npy',train_acc)\n",
    "np.save('Box Cox/test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.504Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# read and plot all accuracy\n",
    "normal = np.load('Normal/train.npy')\n",
    "batch  = np.load(\"batch Norm/train.npy\")\n",
    "layer  = np.load(\"Layer Norm/train.npy\")\n",
    "instace= np.load(\"Instace Norm/train.npy\")\n",
    "boxcox = np.load(\"Box Cox/train.npy\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(normal); plt.plot(batch); plt.plot(layer); plt.plot(instace); plt.plot(boxcox); \n",
    "plt.show()\n",
    "\n",
    "normal = np.load('Normal/test.npy')\n",
    "batch  = np.load(\"batch Norm/test.npy\")\n",
    "layer  = np.load(\"Layer Norm/test.npy\")\n",
    "instace= np.load(\"Instace Norm/test.npy\")\n",
    "boxcox = np.load(\"Box Cox/test.npy\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(normal); plt.plot(batch); plt.plot(layer); plt.plot(instace); plt.plot(boxcox); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-21T07:26:23.506Z"
    }
   },
   "outputs": [],
   "source": [
    "%%notify\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly\n",
    "3. plot, H. (2010). How to change the font size on a matplotlib plot. Stack Overflow. Retrieved 20 December 2018, from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n",
    "4. ShopRunner/jupyter-notify. (2018). GitHub. Retrieved 20 December 2018, from https://github.com/ShopRunner/jupyter-notify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
