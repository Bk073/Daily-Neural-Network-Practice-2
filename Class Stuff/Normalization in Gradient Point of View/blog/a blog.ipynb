{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:01:19.410253Z",
     "start_time": "2018-12-20T21:01:19.405232Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 35})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:00:18.567808Z",
     "start_time": "2018-12-20T21:00:16.491815Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:02:00.227446Z",
     "start_time": "2018-12-20T21:02:00.144670Z"
    },
    "code_folding": [
     15,
     89,
     130,
     171,
     202
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=4,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer,self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        return (self.layer - 1.0)/(self.lmbda + 1e-8)\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        \n",
    "        # Gradient that gets passed along\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0) * grad\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda1 =   (self.layer * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda2 = - (self.layer - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean((grad_lmbda1 + grad_lmbda2)*grad)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w\n",
    "    \n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:49:36.669478Z",
     "start_time": "2018-12-20T21:49:36.663494Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "num_epoch = 200; learning_rate = 0.0008; batch_size = 20; beta1,beta2,adam_e = 0.9,0.999,1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:49:35.661396Z",
     "start_time": "2018-12-20T21:19:25.928419Z"
    },
    "code_folding": [
     47,
     60
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Acc : 0.10820000241696835 Test Acc : 0.17150000302121043\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.17420000280439854 Test Acc : 0.24750000319443644\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 2 Acc : 0.22760000275075434 Test Acc : 0.28162500261329115\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.26160000275075435 Test Acc : 0.2953750019427389\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 4 Acc : 0.2766000027805567 Test Acc : 0.30250000215135514\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 5 Acc : 0.29040000224113466 Test Acc : 0.3280000017210841\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 6 Acc : 0.3174000021219254 Test Acc : 0.3348750017769635\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Acc : 0.3352000017762184 Test Acc : 0.34287500208243726\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 8 Acc : 0.3446000021249056 Test Acc : 0.3446250020340085\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 9 Acc : 0.35319999954104425 Test Acc : 0.352875001821667\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Acc : 0.3571999998986721 Test Acc : 0.3576250019669533\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 11 Acc : 0.3621999996453524 Test Acc : 0.3651250016503036\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 12 Acc : 0.37080000016093256 Test Acc : 0.367125001559034\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 13 Acc : 0.3726000011265278 Test Acc : 0.37100000145845113\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 14 Acc : 0.37700000128149985 Test Acc : 0.3745000007655472\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 15 Acc : 0.3828000011146069 Test Acc : 0.3771250011771917\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 16 Acc : 0.38360000106692316 Test Acc : 0.3797500009648502\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 17 Acc : 0.38700000140070917 Test Acc : 0.3823750014230609\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 18 Acc : 0.39340000170469286 Test Acc : 0.38462500140070915\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 19 Acc : 0.3974000008702278 Test Acc : 0.38825000083073974\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Acc : 0.3982000013589859 Test Acc : 0.3902500014193356\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 21 Acc : 0.4028000012636185 Test Acc : 0.3912500010803342\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Acc : 0.40680000150203705 Test Acc : 0.39487500112503765\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 23 Acc : 0.4082000009417534 Test Acc : 0.3976250010728836\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 24 Acc : 0.4132000012993813 Test Acc : 0.3975000010803342\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 25 Acc : 0.4124000009298325 Test Acc : 0.4006250010058284\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Acc : 0.41660000157356264 Test Acc : 0.40175000090152024\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 27 Acc : 0.4212000018954277 Test Acc : 0.40525000045076015\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Acc : 0.4202000014781952 Test Acc : 0.4073750005103648\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Acc : 0.4224000009894371 Test Acc : 0.41012500097975135\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.42720000094175337 Test Acc : 0.4118750006519258\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 31 Acc : 0.43020000112056733 Test Acc : 0.41412500085309145\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 32 Acc : 0.4290000022649765 Test Acc : 0.4156250006891787\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 33 Acc : 0.43480000174045563 Test Acc : 0.41887500079348683\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 34 Acc : 0.4342000014781952 Test Acc : 0.42100000055506825\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 35 Acc : 0.4392000015377998 Test Acc : 0.4226250003837049\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 36 Acc : 0.4482000007033348 Test Acc : 0.4387500012293458\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 37 Acc : 0.46440000158548356 Test Acc : 0.4402500008791685\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 38 Acc : 0.46980000120401383 Test Acc : 0.4425000011920929\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 39 Acc : 0.4778000012636185 Test Acc : 0.4465000008791685\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 40 Acc : 0.47840000194311144 Test Acc : 0.44712500093504787\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 41 Acc : 0.48160000163316724 Test Acc : 0.45225000124424697\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 42 Acc : 0.48540000170469283 Test Acc : 0.45562500137835743\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Acc : 0.48600000208616256 Test Acc : 0.4545000013895333\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.4878000020980835 Test Acc : 0.46050000116229056\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 45 Acc : 0.48900000232458113 Test Acc : 0.46100000143051145\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 46 Acc : 0.4906000028252602 Test Acc : 0.4630000011995435\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 47 Acc : 0.49220000207424164 Test Acc : 0.4620000011473894\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.49480000138282776 Test Acc : 0.46700000036507844\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.5006000016331673 Test Acc : 0.4680000006407499\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 50 Acc : 0.49980000185966494 Test Acc : 0.4682500005885959\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 51 Acc : 0.5048000020980835 Test Acc : 0.47162500116974115\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 52 Acc : 0.5038000020980835 Test Acc : 0.4743750014156103\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 53 Acc : 0.5044000024795532 Test Acc : 0.47500000178813934\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 54 Acc : 0.5080000027418137 Test Acc : 0.47762500181794165\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 55 Acc : 0.5062000030279159 Test Acc : 0.47937500178813935\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 56 Acc : 0.5044000015258789 Test Acc : 0.48037500109523534\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 57 Acc : 0.5078000012636185 Test Acc : 0.4798750012740493\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 58 Acc : 0.508600000500679 Test Acc : 0.47937500055879356\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 59 Acc : 0.5092000006437302 Test Acc : 0.47775000039488075\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 60 Acc : 0.5120000004768371 Test Acc : 0.4791250005736947\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 61 Acc : 0.5124000001549721 Test Acc : 0.47987500071525574\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 62 Acc : 0.5162000007033348 Test Acc : 0.483125\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 63 Acc : 0.5162000008225441 Test Acc : 0.4838750000298023\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 64 Acc : 0.5188000007271767 Test Acc : 0.48512499980628493\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 65 Acc : 0.5196000002026558 Test Acc : 0.4856250000745058\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 66 Acc : 0.5222000007033348 Test Acc : 0.4891250002384186\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 67 Acc : 0.525200001001358 Test Acc : 0.4905000002682209\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 68 Acc : 0.5258000010251999 Test Acc : 0.4910000006109476\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 69 Acc : 0.5268000018596649 Test Acc : 0.49149999998509886\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 70 Acc : 0.5314000012874603 Test Acc : 0.4916250002011657\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 71 Acc : 0.5352000008821487 Test Acc : 0.4928750002011657\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 72 Acc : 0.5358000005483627 Test Acc : 0.4956249999254942\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 73 Acc : 0.5368000009059906 Test Acc : 0.4951250002160668\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 74 Acc : 0.5396000001430511 Test Acc : 0.4948750001937151\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 75 Acc : 0.5392000013589859 Test Acc : 0.49875000096857547\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 76 Acc : 0.5426000009775162 Test Acc : 0.49862500071525573\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 77 Acc : 0.5458000013828278 Test Acc : 0.5001250007003546\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 78 Acc : 0.5456000012159348 Test Acc : 0.5021250016614794\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Acc : 0.5466000015735626 Test Acc : 0.5015000016614795\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Acc : 0.5488000020980836 Test Acc : 0.502000001333654\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.5506000012159348 Test Acc : 0.5032500005885958\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.5542000018358231 Test Acc : 0.503374999947846\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.5524000010490417 Test Acc : 0.5027500003576278\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 84 Acc : 0.5534000009298324 Test Acc : 0.5037500009685755\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Acc : 0.5552000018358231 Test Acc : 0.5060000012814999\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 86 Acc : 0.5574000014066696 Test Acc : 0.506500000655651\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 87 Acc : 0.5604000010490418 Test Acc : 0.5068750005215407\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 88 Acc : 0.5602000008821487 Test Acc : 0.504750000834465\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 89 Acc : 0.5606000000238418 Test Acc : 0.505750000923872\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 90 Acc : 0.5650000010728836 Test Acc : 0.5065000005811453\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 91 Acc : 0.563600000500679 Test Acc : 0.5080000008270145\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 92 Acc : 0.5667999995946884 Test Acc : 0.5072500010207296\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 93 Acc : 0.5681999992132187 Test Acc : 0.5067500003054738\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 94 Acc : 0.5687999993562698 Test Acc : 0.5070000007376074\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 95 Acc : 0.5711999983787537 Test Acc : 0.5072500006482005\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 96 Acc : 0.573799999833107 Test Acc : 0.5103750007972121\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 97 Acc : 0.5759999980926513 Test Acc : 0.5091250004991889\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Acc : 0.5753999990224838 Test Acc : 0.5088750002905726\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Acc : 0.5778000000715255 Test Acc : 0.5083750008419156\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Acc : 0.5816000000238418 Test Acc : 0.509125000871718\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Acc : 0.5809999986886978 Test Acc : 0.5097500003129244\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 102 Acc : 0.5862000002861023 Test Acc : 0.508500000871718\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.5856000003814698 Test Acc : 0.5111250009387731\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 104 Acc : 0.5866000003814698 Test Acc : 0.5131250006705522\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 105 Acc : 0.5884000004529953 Test Acc : 0.5131250002980232\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 106 Acc : 0.5886000009775162 Test Acc : 0.5131250004470348\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Acc : 0.5900000003576279 Test Acc : 0.5123750007152558\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.5914000002145767 Test Acc : 0.514250001013279\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.5934000000953674 Test Acc : 0.5145000006258488\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 110 Acc : 0.5936000012159347 Test Acc : 0.5151250005513429\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 111 Acc : 0.5958000004291535 Test Acc : 0.515625000745058\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 112 Acc : 0.5970000005960464 Test Acc : 0.517000001296401\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Acc : 0.5964000014066696 Test Acc : 0.5176250008493661\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Acc : 0.5998000001907349 Test Acc : 0.5173750007152558\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Acc : 0.6008000012636184 Test Acc : 0.5173750004172325\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Acc : 0.5992000002861023 Test Acc : 0.5181250009685755\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Acc : 0.6008000005483627 Test Acc : 0.5202500015497208\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Acc : 0.5994000005722045 Test Acc : 0.5203750013560057\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Acc : 0.6012000007629394 Test Acc : 0.5203750015050173\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.603200001835823 Test Acc : 0.5232500015199184\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Acc : 0.6040000007152557 Test Acc : 0.5243750016391278\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Acc : 0.6044000014066696 Test Acc : 0.5236250019073486\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Acc : 0.607600000500679 Test Acc : 0.5228750013560056\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Acc : 0.6072000007629395 Test Acc : 0.5252500009164214\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Acc : 0.6108000003099442 Test Acc : 0.5243750011175871\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Acc : 0.6116000000238418 Test Acc : 0.5247500014305114\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Acc : 0.609600000500679 Test Acc : 0.5245000011473894\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Acc : 0.611399999499321 Test Acc : 0.5252500009536744\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Acc : 0.6119999986886978 Test Acc : 0.524875001385808\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Acc : 0.6147999991178512 Test Acc : 0.526750001385808\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Acc : 0.6157999995946885 Test Acc : 0.5278750013560056\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Acc : 0.6173999987840653 Test Acc : 0.528375001475215\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Acc : 0.617399999499321 Test Acc : 0.5283750014007091\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 134 Acc : 0.6199999991655349 Test Acc : 0.5281250009685755\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Acc : 0.6223999996185303 Test Acc : 0.5276250011846423\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Acc : 0.6236000002622605 Test Acc : 0.5272500010952353\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 137 Acc : 0.6237999994754791 Test Acc : 0.5281250010803342\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Acc : 0.6251999995708466 Test Acc : 0.52750000115484\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 139 Acc : 0.6261999998092651 Test Acc : 0.52812500115484\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Acc : 0.6255999991893768 Test Acc : 0.5285000010207296\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Acc : 0.6283999992609024 Test Acc : 0.5295000013336539\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 142 Acc : 0.6303999989032746 Test Acc : 0.5280000016465783\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 143 Acc : 0.6310000003576278 Test Acc : 0.5268750016018748\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 144 Acc : 0.6299999992847443 Test Acc : 0.527625001333654\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 145 Acc : 0.6325999999046326 Test Acc : 0.5283750015869737\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 146 Acc : 0.6323999991416931 Test Acc : 0.529125001616776\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 147 Acc : 0.6334000000953675 Test Acc : 0.5295000017061829\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Acc : 0.6349999997615814 Test Acc : 0.5292500017210842\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 149 Acc : 0.6355999997854233 Test Acc : 0.5287500012293458\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 150 Acc : 0.6361999998092651 Test Acc : 0.5297500013187527\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 151 Acc : 0.6372000004053116 Test Acc : 0.5305000017955899\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 152 Acc : 0.6377999997138977 Test Acc : 0.5301250017806888\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 153 Acc : 0.6402000004053116 Test Acc : 0.5313750018551946\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 154 Acc : 0.6376000002622605 Test Acc : 0.5312500020489097\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 155 Acc : 0.638200000166893 Test Acc : 0.5318750025704503\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 156 Acc : 0.6387999997138977 Test Acc : 0.5320000018924474\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 157 Acc : 0.637999999165535 Test Acc : 0.5330000018328428\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 158 Acc : 0.6403999990224838 Test Acc : 0.5327500019222497\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 159 Acc : 0.6431999996900558 Test Acc : 0.5337500021606684\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 160 Acc : 0.6435999985933304 Test Acc : 0.5342500016093255\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 161 Acc : 0.6475999994277954 Test Acc : 0.5328750012442469\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 162 Acc : 0.6485999991893768 Test Acc : 0.5332500012218953\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 163 Acc : 0.648999999165535 Test Acc : 0.5323750014230609\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 164 Acc : 0.651199999332428 Test Acc : 0.5321250016987323\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 165 Acc : 0.6525999999046326 Test Acc : 0.5326250012218953\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 166 Acc : 0.6531999990940094 Test Acc : 0.5330000015720725\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 167 Acc : 0.6561999998092651 Test Acc : 0.5315000015124679\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 168 Acc : 0.6571999998092651 Test Acc : 0.5327500024437904\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 169 Acc : 0.6589999994039536 Test Acc : 0.5335000022128225\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 170 Acc : 0.6625999993085862 Test Acc : 0.5337500020489097\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 171 Acc : 0.6613999994993209 Test Acc : 0.5343750020489096\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 172 Acc : 0.6655999995470047 Test Acc : 0.5352500023320317\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 173 Acc : 0.6643999987840652 Test Acc : 0.5351250023767352\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 174 Acc : 0.6641999988555908 Test Acc : 0.5356250027194619\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 175 Acc : 0.6671999995708465 Test Acc : 0.5342500021681189\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 176 Acc : 0.6669999985694886 Test Acc : 0.534875002540648\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 177 Acc : 0.6679999992847443 Test Acc : 0.5341250025853514\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 178 Acc : 0.6705999999046326 Test Acc : 0.5357500026747585\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 179 Acc : 0.6669999988079071 Test Acc : 0.5351250018551945\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 180 Acc : 0.6689999990463257 Test Acc : 0.5365000025555492\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 181 Acc : 0.6703999997377396 Test Acc : 0.5375000031664967\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 182 Acc : 0.6697999997138977 Test Acc : 0.5373750024661422\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 183 Acc : 0.6703999989032745 Test Acc : 0.5373750038817525\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 184 Acc : 0.6741999983787537 Test Acc : 0.5361250028386713\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 185 Acc : 0.6759999995231628 Test Acc : 0.5367500029876828\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 186 Acc : 0.6733999991416931 Test Acc : 0.5377500034496188\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 187 Acc : 0.6767999987602233 Test Acc : 0.537875003144145\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 188 Acc : 0.675799998998642 Test Acc : 0.5375000036880374\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 189 Acc : 0.6763999977111816 Test Acc : 0.5373750024661422\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 190 Acc : 0.6769999988079071 Test Acc : 0.5375000026449561\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 191 Acc : 0.6785999989509582 Test Acc : 0.5380000032484531\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 192 Acc : 0.6797999987602233 Test Acc : 0.537500002682209\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 193 Acc : 0.6805999987125396 Test Acc : 0.5376250033080577\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 194 Acc : 0.6817999985218048 Test Acc : 0.5380000030994415\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 195 Acc : 0.6835999994277954 Test Acc : 0.5391250036656856\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 196 Acc : 0.6857999992370606 Test Acc : 0.5387500029057264\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 197 Acc : 0.6853999991416931 Test Acc : 0.5370000029355287\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 198 Acc : 0.6823999984264374 Test Acc : 0.5383750024437904\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 199 Acc : 0.6847999987602233 Test Acc : 0.5395000026375055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Normal CNN \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,16); \n",
    "l5 = CNN(3,16,16); \n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "normal_train_acc = [];normal_test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Normal/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Normal/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Normal/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Normal/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    normal_train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    normal_test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T20:46:08.775107Z",
     "start_time": "2018-12-20T20:46:08.745151Z"
    },
    "code_folding": [
     48,
     61
    ]
   },
   "outputs": [],
   "source": [
    "# 2. batch normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1.feedforward(x,stride=2)      ;    \n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "\n",
    "layer2,layer2a = l2.feedforward(layer1b,stride=2); \n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "\n",
    "layer3,layer3a = l3.feedforward(layer2b,stride=2); \n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3b,stride=2);  \n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "\n",
    "layer5,layer5a = l5.feedforward(layer4b,stride=1); \n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "\n",
    "layer6,layer6a = l6.feedforward(layer5b,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'batch Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'batch Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('batch Norm/train.npy',train_acc)\n",
    "np.save('batch Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:15:40.774701Z",
     "start_time": "2018-12-20T22:15:40.752771Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:15:43.828650Z",
     "start_time": "2018-12-20T22:15:43.552111Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T09:22:32.728296Z",
     "start_time": "2018-12-20T09:22:32.507642Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "num_epoch = 150; learning_rate = 0.001; batch_size = 100\n",
    "beta1,beta2,adam_e = 0.9,0.999,1e-8\n",
    "sess = tf.InteractiveSession()\n",
    "l1 = CNN(3,3, 16); l1n = tf_box_cox()\n",
    "l2 = CNN(3,16,16); l2n = tf_box_cox()\n",
    "l3 = CNN(3,16,16); l3n = tf_box_cox()\n",
    "\n",
    "l4 = CNN(3,16,32); l4n = tf_box_cox()\n",
    "l5 = CNN(3,32,32); l5n = tf_box_cox()\n",
    "l6 = CNN(3,32,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T09:22:33.995782Z",
     "start_time": "2018-12-20T09:22:33.036092Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,[batch_size,96,96,3])\n",
    "y = tf.placeholder(tf.float32,[batch_size,10])\n",
    "\n",
    "layer1,layer1a = l1.feedforward(x,stride=2)      ;          \n",
    "layer1n = l1n.feedforward(layer1a)\n",
    "layer2,layer2a = l2.feedforward(layer1n,stride=2);          \n",
    "layer2n = l2n.feedforward(layer2a)\n",
    "layer3,layer3a = l3.feedforward(layer2n,stride=2); \n",
    "layer3n = l3n.feedforward(layer3a)\n",
    "\n",
    "layer4,layer4a = l4.feedforward(layer3n,stride=2);          \n",
    "layer4n = l4n.feedforward(layer4a)\n",
    "layer5,layer5a = l5.feedforward(layer4n,stride=1);          \n",
    "layer5n = l5n.feedforward(layer5a)\n",
    "layer6,layer6a = l6.feedforward(layer5n,stride=1); \n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "auto_train = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up  = l6.backprop(gradient)\n",
    "grad5n,grad5l,grad5n_up = l5n.backprop(grad6p); \n",
    "grad5p,grad5w,grad5_up  = l5.backprop(grad5n,stride=1)\n",
    "grad4n,grad4l,grad4n_up = l4n.backprop(grad5p); \n",
    "grad4p,grad4w,grad4_up  = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n,grad3l,grad3n_up = l3n.backprop(grad4p);\n",
    "grad3p,grad3w,grad3_up  = l3.backprop(grad3n,stride=2)\n",
    "grad2n,grad2l,grad2n_up = l2n.backprop(grad3p); \n",
    "grad2p,grad2w,grad2_up  = l2.backprop(grad2n,stride=2)\n",
    "grad1n,grad1l,grad1n_up = l1n.backprop(grad2p); \n",
    "grad1p,grad1w,grad1_up  = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + \\\n",
    "                  grad5n_up + grad5_up + \\\n",
    "                  grad4n_up + grad4_up + \\\n",
    "                  grad3n_up + grad3_up + \\\n",
    "                  grad2n_up + grad2_up + \\\n",
    "                  grad1n_up + grad1_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T09:31:30.028152Z",
     "start_time": "2018-12-20T09:22:34.190006Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/150 batch : 7900/8000 acc : 0.15\n",
      " Current : 0 Acc : 0.10639999989420175 Test Acc : 0.12137499949894845\n",
      "\n",
      "Current Iter : 1/150 batch : 7900/8000 acc : 0.21\n",
      " Current : 1 Acc : 0.11419999979436397 Test Acc : 0.14175000037066637\n",
      "\n",
      "Current Iter : 2/150 batch : 7900/8000 acc : 0.14\n",
      " Current : 2 Acc : 0.11979999981820583 Test Acc : 0.10049999975599348\n",
      "\n",
      "Current Iter : 3/150 batch : 7900/8000 acc : 0.14\n",
      " Current : 3 Acc : 0.11179999962449073 Test Acc : 0.09999999976716936\n",
      "\n",
      "Current Iter : 4/150 batch : 7900/8000 acc : 0.11\n",
      " Current : 4 Acc : 0.12080000028014183 Test Acc : 0.12437499961815775\n",
      "\n",
      "Current Iter : 5/150 batch : 7900/8000 acc : 0.12\n",
      " Current : 5 Acc : 0.15379999995231627 Test Acc : 0.158500000461936\n",
      "\n",
      "Current Iter : 6/150 batch : 7900/8000 acc : 0.16\n",
      " Current : 6 Acc : 0.17820000007748604 Test Acc : 0.1642500003799796\n",
      "\n",
      "Current Iter : 7/150 batch : 7900/8000 acc : 0.25\n",
      " Current : 7 Acc : 0.2115999987721443 Test Acc : 0.21212499951943756\n",
      "\n",
      "Current Iter : 8/150 batch : 7900/8000 acc : 0.34\n",
      " Current : 8 Acc : 0.23819999873638154 Test Acc : 0.23000000063329934\n",
      "\n",
      "Current Iter : 9/150 batch : 7900/8000 acc : 0.32\n",
      " Current : 9 Acc : 0.247600000500679 Test Acc : 0.25125000029802325\n",
      "\n",
      "Current Iter : 10/150 batch : 7900/8000 acc : 0.33\n",
      " Current : 10 Acc : 0.264399998486042 Test Acc : 0.2599999999627471\n",
      "\n",
      "Current Iter : 11/150 batch : 7900/8000 acc : 0.32\n",
      " Current : 11 Acc : 0.27479999989271164 Test Acc : 0.28787500113248826\n",
      "\n",
      "Current Iter : 12/150 batch : 7900/8000 acc : 0.39\n",
      " Current : 12 Acc : 0.29060000002384184 Test Acc : 0.30837500039488075\n",
      "\n",
      "Current Iter : 13/150 batch : 7900/8000 acc : 0.37\n",
      " Current : 13 Acc : 0.3015999999642372 Test Acc : 0.3076250026002526\n",
      "\n",
      "Current Iter : 14/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 14 Acc : 0.3059999996423721 Test Acc : 0.3325000017881393\n",
      "\n",
      "Current Iter : 15/150 batch : 7900/8000 acc : 0.36\n",
      " Current : 15 Acc : 0.31920000046491626 Test Acc : 0.33862500060349704\n",
      "\n",
      "Current Iter : 16/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 16 Acc : 0.34560000240802763 Test Acc : 0.3528750021010637\n",
      "\n",
      "Current Iter : 17/150 batch : 7900/8000 acc : 0.37\n",
      " Current : 17 Acc : 0.34800000220537186 Test Acc : 0.3527500003576279\n",
      "\n",
      "Current Iter : 18/150 batch : 7900/8000 acc : 0.39\n",
      " Current : 18 Acc : 0.3610000014305115 Test Acc : 0.35099999997764825\n",
      "\n",
      "Current Iter : 19/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 19 Acc : 0.3654000011086464 Test Acc : 0.371000000461936\n",
      "\n",
      "Current Iter : 20/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 20 Acc : 0.36479999899864196 Test Acc : 0.3733750004321337\n",
      "\n",
      "Current Iter : 21/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 21 Acc : 0.3781999999284744 Test Acc : 0.3697499994188547\n",
      "\n",
      "Current Iter : 22/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 22 Acc : 0.37879999935626985 Test Acc : 0.38037499971687794\n",
      "\n",
      "Current Iter : 23/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 23 Acc : 0.3835999995470047 Test Acc : 0.3742500010877848\n",
      "\n",
      "Current Iter : 24/150 batch : 7900/8000 acc : 0.36\n",
      " Current : 24 Acc : 0.38399999976158145 Test Acc : 0.37837500087916853\n",
      "\n",
      "Current Iter : 25/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 25 Acc : 0.3906000000238419 Test Acc : 0.3916249979287386\n",
      "\n",
      "Current Iter : 26/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 26 Acc : 0.4013999980688095 Test Acc : 0.39199999906122684\n",
      "\n",
      "Current Iter : 27/150 batch : 7900/8000 acc : 0.37\n",
      " Current : 27 Acc : 0.4056000018119812 Test Acc : 0.3842499990016222\n",
      "\n",
      "Current Iter : 28/150 batch : 7900/8000 acc : 0.35\n",
      " Current : 28 Acc : 0.4023999977111816 Test Acc : 0.37712499871850014\n",
      "\n",
      "Current Iter : 29/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 29 Acc : 0.40499999940395354 Test Acc : 0.39100000001490115\n",
      "\n",
      "Current Iter : 30/150 batch : 7900/8000 acc : 0.34\n",
      " Current : 30 Acc : 0.40160000026226045 Test Acc : 0.39062499813735485\n",
      "\n",
      "Current Iter : 31/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 31 Acc : 0.4083999985456467 Test Acc : 0.4024999991059303\n",
      "\n",
      "Current Iter : 32/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 32 Acc : 0.42139999866485595 Test Acc : 0.39974999949336054\n",
      "\n",
      "Current Iter : 33/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 33 Acc : 0.4173999959230423 Test Acc : 0.40099999979138373\n",
      "\n",
      "Current Iter : 34/150 batch : 7900/8000 acc : 0.39\n",
      " Current : 34 Acc : 0.42339999675750734 Test Acc : 0.3997499991208315\n",
      "\n",
      "Current Iter : 35/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 35 Acc : 0.42619999647140505 Test Acc : 0.40762499794363977\n",
      "\n",
      "Current Iter : 36/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 36 Acc : 0.42779999852180484 Test Acc : 0.41049999967217443\n",
      "\n",
      "Current Iter : 37/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 37 Acc : 0.43420000016689303 Test Acc : 0.40287499912083147\n",
      "\n",
      "Current Iter : 38/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 38 Acc : 0.434599996805191 Test Acc : 0.41649999767541884\n",
      "\n",
      "Current Iter : 39/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 39 Acc : 0.43919999957084654 Test Acc : 0.4141249984502792\n",
      "\n",
      "Current Iter : 40/150 batch : 7900/8000 acc : 0.36\n",
      " Current : 40 Acc : 0.44099999725818634 Test Acc : 0.39174999929964543\n",
      "\n",
      "Current Iter : 41/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 41 Acc : 0.44059999763965607 Test Acc : 0.4194999985396862\n",
      "\n",
      "Current Iter : 42/150 batch : 7900/8000 acc : 0.43\n",
      " Current : 42 Acc : 0.44019999861717224 Test Acc : 0.41899999864399434\n",
      "\n",
      "Current Iter : 43/150 batch : 7900/8000 acc : 0.41\n",
      " Current : 43 Acc : 0.4511999958753586 Test Acc : 0.41424999833106996\n",
      "\n",
      "Current Iter : 44/150 batch : 7900/8000 acc : 0.42\n",
      " Current : 44 Acc : 0.44839999556541443 Test Acc : 0.42849999815225603\n",
      "\n",
      "Current Iter : 45/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 45 Acc : 0.457799996137619 Test Acc : 0.4251249980181456\n",
      "\n",
      "Current Iter : 46/150 batch : 7900/8000 acc : 0.39\n",
      " Current : 46 Acc : 0.4569999974966049 Test Acc : 0.40474999994039534\n",
      "\n",
      "Current Iter : 47/150 batch : 7900/8000 acc : 0.43\n",
      " Current : 47 Acc : 0.45719999611377715 Test Acc : 0.4339999996125698\n",
      "\n",
      "Current Iter : 48/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.46739999651908876 Test Acc : 0.433874998241663\n",
      "\n",
      "Current Iter : 49/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 49 Acc : 0.4659999978542328 Test Acc : 0.40949999876320364\n",
      "\n",
      "Current Iter : 50/150 batch : 7900/8000 acc : 0.43\n",
      " Current : 50 Acc : 0.4623999935388565 Test Acc : 0.437499999627471\n",
      "\n",
      "Current Iter : 51/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 51 Acc : 0.4641999971866608 Test Acc : 0.4358749981969595\n",
      "\n",
      "Current Iter : 52/150 batch : 7900/8000 acc : 0.42\n",
      " Current : 52 Acc : 0.4739999997615814 Test Acc : 0.4126249995082617\n",
      "\n",
      "Current Iter : 53/150 batch : 7900/8000 acc : 0.43\n",
      " Current : 53 Acc : 0.47019999861717227 Test Acc : 0.4441249962896109\n",
      "\n",
      "Current Iter : 54/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 54 Acc : 0.4809999948740005 Test Acc : 0.44837499894201754\n",
      "\n",
      "Current Iter : 55/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 55 Acc : 0.4781999945640564 Test Acc : 0.4493749957531691\n",
      "\n",
      "Current Iter : 56/150 batch : 7900/8000 acc : 0.38\n",
      " Current : 56 Acc : 0.4693999969959259 Test Acc : 0.3964999996125698\n",
      "\n",
      "Current Iter : 57/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 57 Acc : 0.46819999754428865 Test Acc : 0.4571249958127737\n",
      "\n",
      "Current Iter : 58/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 58 Acc : 0.4881999945640564 Test Acc : 0.4383749973028898\n",
      "\n",
      "Current Iter : 59/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 59 Acc : 0.4795999974012375 Test Acc : 0.4561249990016222\n",
      "\n",
      "Current Iter : 60/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 60 Acc : 0.4865999978780746 Test Acc : 0.45349999628961085\n",
      "\n",
      "Current Iter : 61/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 61 Acc : 0.4955999982357025 Test Acc : 0.4607499983161688\n",
      "\n",
      "Current Iter : 62/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 62 Acc : 0.4979999941587448 Test Acc : 0.46762499660253526\n",
      "\n",
      "Current Iter : 63/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 63 Acc : 0.49679999709129335 Test Acc : 0.44987499825656413\n",
      "\n",
      "Current Iter : 64/150 batch : 7900/8000 acc : 0.58\n",
      " Current : 64 Acc : 0.5038000005483627 Test Acc : 0.4738749984651804\n",
      "\n",
      "Current Iter : 65/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 65 Acc : 0.5165999954938889 Test Acc : 0.457499997317791\n",
      "\n",
      "Current Iter : 66/150 batch : 7900/8000 acc : 0.53\n",
      " Current : 66 Acc : 0.5145999974012375 Test Acc : 0.47487499564886093\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 67/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 67 Acc : 0.5201999932527542 Test Acc : 0.4617499984800816\n",
      "\n",
      "Current Iter : 68/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 68 Acc : 0.5215999972820282 Test Acc : 0.4598749980330467\n",
      "\n",
      "Current Iter : 69/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 69 Acc : 0.5119999939203262 Test Acc : 0.47162499763071536\n",
      "\n",
      "Current Iter : 70/150 batch : 7900/8000 acc : 0.53\n",
      " Current : 70 Acc : 0.5390000009536743 Test Acc : 0.48337499611079693\n",
      "\n",
      "Current Iter : 71/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 71 Acc : 0.52819999396801 Test Acc : 0.4769999966025352\n",
      "\n",
      "Current Iter : 72/150 batch : 7900/8000 acc : 0.59\n",
      " Current : 72 Acc : 0.5243999963998794 Test Acc : 0.4658749982714653\n",
      "\n",
      "Current Iter : 73/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 73 Acc : 0.5217999970912933 Test Acc : 0.47449999712407587\n",
      "\n",
      "Current Iter : 74/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 74 Acc : 0.5339999961853027 Test Acc : 0.4834999952465296\n",
      "\n",
      "Current Iter : 75/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 75 Acc : 0.5411999970674515 Test Acc : 0.47262499779462813\n",
      "\n",
      "Current Iter : 76/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 76 Acc : 0.5407999980449677 Test Acc : 0.4871249973773956\n",
      "\n",
      "Current Iter : 77/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 77 Acc : 0.5381999921798706 Test Acc : 0.4753749970346689\n",
      "\n",
      "Current Iter : 78/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 78 Acc : 0.5429999983310699 Test Acc : 0.48699999526143073\n",
      "\n",
      "Current Iter : 79/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 79 Acc : 0.5413999962806701 Test Acc : 0.48237499706447123\n",
      "\n",
      "Current Iter : 80/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 80 Acc : 0.5437999951839447 Test Acc : 0.48487499728798866\n",
      "\n",
      "Current Iter : 81/150 batch : 7900/8000 acc : 0.54\n",
      " Current : 81 Acc : 0.5507999956607819 Test Acc : 0.487874997779727\n",
      "\n",
      "Current Iter : 82/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 82 Acc : 0.5541999965906144 Test Acc : 0.4809999968856573\n",
      "\n",
      "Current Iter : 83/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 83 Acc : 0.5444000005722046 Test Acc : 0.4821249969303608\n",
      "\n",
      "Current Iter : 84/150 batch : 7900/8000 acc : 0.57\n",
      " Current : 84 Acc : 0.5549999970197678 Test Acc : 0.4799999985843897\n",
      "\n",
      "Current Iter : 85/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 85 Acc : 0.5598000013828277 Test Acc : 0.48849999718368053\n",
      "\n",
      "Current Iter : 86/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 86 Acc : 0.5555999928712845 Test Acc : 0.48524999991059303\n",
      "\n",
      "Current Iter : 87/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 87 Acc : 0.5653999948501587 Test Acc : 0.4876249980181456\n",
      "\n",
      "Current Iter : 88/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 88 Acc : 0.5612000000476837 Test Acc : 0.4732499971985817\n",
      "\n",
      "Current Iter : 89/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 89 Acc : 0.5449999994039536 Test Acc : 0.4792499952018261\n",
      "\n",
      "Current Iter : 90/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 90 Acc : 0.5703999990224838 Test Acc : 0.49199999794363974\n",
      "\n",
      "Current Iter : 91/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 91 Acc : 0.570799998641014 Test Acc : 0.48574999868869784\n",
      "\n",
      "Current Iter : 92/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 92 Acc : 0.5691999942064285 Test Acc : 0.48999999798834326\n",
      "\n",
      "Current Iter : 93/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 93 Acc : 0.5703999984264374 Test Acc : 0.47312499918043616\n",
      "\n",
      "Current Iter : 94/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 94 Acc : 0.5733999985456467 Test Acc : 0.4919999986886978\n",
      "\n",
      "Current Iter : 95/150 batch : 7900/8000 acc : 0.54\n",
      " Current : 95 Acc : 0.5731999963521958 Test Acc : 0.48162499740719794\n",
      "\n",
      "Current Iter : 96/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 96 Acc : 0.5568000006675721 Test Acc : 0.46924999728798866\n",
      "\n",
      "Current Iter : 97/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 97 Acc : 0.5734000009298325 Test Acc : 0.48274999782443045\n",
      "\n",
      "Current Iter : 98/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 98 Acc : 0.5765999984741211 Test Acc : 0.47887499667704103\n",
      "\n",
      "Current Iter : 99/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 99 Acc : 0.5715999984741211 Test Acc : 0.4903749950230122\n",
      "\n",
      "Current Iter : 100/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 100 Acc : 0.5863999950885773 Test Acc : 0.4821249973028898\n",
      "\n",
      "Current Iter : 101/150 batch : 7900/8000 acc : 0.59\n",
      " Current : 101 Acc : 0.5683999973535537 Test Acc : 0.4699999962002039\n",
      "\n",
      "Current Iter : 102/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 102 Acc : 0.575599998831749 Test Acc : 0.48137499764561653\n",
      "\n",
      "Current Iter : 103/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.5838000023365021 Test Acc : 0.47737499736249445\n",
      "\n",
      "Current Iter : 104/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 104 Acc : 0.5897999995946884 Test Acc : 0.49262499548494815\n",
      "\n",
      "Current Iter : 105/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 105 Acc : 0.5983999991416931 Test Acc : 0.48549999557435514\n",
      "\n",
      "Current Iter : 106/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 106 Acc : 0.5851999986171722 Test Acc : 0.48862499855458735\n",
      "\n",
      "Current Iter : 107/150 batch : 7900/8000 acc : 0.59\n",
      " Current : 107 Acc : 0.5925999987125397 Test Acc : 0.48874999657273294\n",
      "\n",
      "Current Iter : 108/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.5943999975919724 Test Acc : 0.4902499958872795\n",
      "\n",
      "Current Iter : 109/150 batch : 7900/8000 acc : 0.54\n",
      " Current : 109 Acc : 0.5686000019311905 Test Acc : 0.4824999958276749\n",
      "\n",
      "Current Iter : 110/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 110 Acc : 0.5891999983787537 Test Acc : 0.4802499979734421\n",
      "\n",
      "Current Iter : 111/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 111 Acc : 0.5793999952077865 Test Acc : 0.48074999675154684\n",
      "\n",
      "Current Iter : 112/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 112 Acc : 0.5890000021457672 Test Acc : 0.48624999560415744\n",
      "\n",
      "Current Iter : 113/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 113 Acc : 0.5952000027894974 Test Acc : 0.48787499628961084\n",
      "\n",
      "Current Iter : 114/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 114 Acc : 0.5959999984502793 Test Acc : 0.49337499737739565\n",
      "\n",
      "Current Iter : 115/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 115 Acc : 0.5979999995231629 Test Acc : 0.4941249959170818\n",
      "\n",
      "Current Iter : 116/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 116 Acc : 0.5955999970436097 Test Acc : 0.48987499698996545\n",
      "\n",
      "Current Iter : 117/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 117 Acc : 0.588000003695488 Test Acc : 0.4984999965876341\n",
      "\n",
      "Current Iter : 118/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 118 Acc : 0.5839999961853027 Test Acc : 0.4912499975413084\n",
      "\n",
      "Current Iter : 119/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 119 Acc : 0.5943999969959259 Test Acc : 0.5022499959915876\n",
      "\n",
      "Current Iter : 120/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.5897999966144561 Test Acc : 0.5049999944865704\n",
      "\n",
      "Current Iter : 121/150 batch : 7900/8000 acc : 0.53\n",
      " Current : 121 Acc : 0.603199999332428 Test Acc : 0.502999996393919\n",
      "\n",
      "Current Iter : 122/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 122 Acc : 0.594799998998642 Test Acc : 0.5062499947845935\n",
      "\n",
      "Current Iter : 123/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 123 Acc : 0.6085999983549119 Test Acc : 0.5098749969154597\n",
      "\n",
      "Current Iter : 124/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 124 Acc : 0.6056000030040741 Test Acc : 0.5058749947696924\n",
      "\n",
      "Current Iter : 125/150 batch : 7900/8000 acc : 0.52\n",
      " Current : 125 Acc : 0.5893999969959259 Test Acc : 0.49824999608099463\n",
      "\n",
      "Current Iter : 126/150 batch : 7900/8000 acc : 0.46\n",
      " Current : 126 Acc : 0.5943999999761581 Test Acc : 0.4941249966621399\n",
      "\n",
      "Current Iter : 127/150 batch : 7900/8000 acc : 0.56\n",
      " Current : 127 Acc : 0.6127999997138978 Test Acc : 0.5047499965876341\n",
      "\n",
      "Current Iter : 128/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 128 Acc : 0.6193999975919724 Test Acc : 0.5081249963492155\n",
      "\n",
      "Current Iter : 129/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 129 Acc : 0.6269999980926514 Test Acc : 0.5084999971091747\n",
      "\n",
      "Current Iter : 130/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 130 Acc : 0.6263999962806701 Test Acc : 0.5142499972134829\n",
      "\n",
      "Current Iter : 131/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 131 Acc : 0.6095999962091446 Test Acc : 0.5048749949783087\n",
      "\n",
      "Current Iter : 132/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 132 Acc : 0.6069999980926514 Test Acc : 0.482499997317791\n",
      "\n",
      "Current Iter : 133/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 133 Acc : 0.5990000033378601 Test Acc : 0.5041249975562095\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 134/150 batch : 7900/8000 acc : 0.42\n",
      " Current : 134 Acc : 0.589400002360344 Test Acc : 0.49337499365210535\n",
      "\n",
      "Current Iter : 135/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 135 Acc : 0.6179999995231629 Test Acc : 0.5069999977946281\n",
      "\n",
      "Current Iter : 136/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 136 Acc : 0.6142000031471252 Test Acc : 0.49812499769032004\n",
      "\n",
      "Current Iter : 137/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 137 Acc : 0.6310000014305115 Test Acc : 0.49799999557435515\n",
      "\n",
      "Current Iter : 138/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 138 Acc : 0.6242000019550323 Test Acc : 0.5007499985396862\n",
      "\n",
      "Current Iter : 139/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 139 Acc : 0.6029999947547913 Test Acc : 0.4994999963790178\n",
      "\n",
      "Current Iter : 140/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 140 Acc : 0.6160000038146972 Test Acc : 0.49149999506771563\n",
      "\n",
      "Current Iter : 141/150 batch : 7900/8000 acc : 0.48\n",
      " Current : 141 Acc : 0.6243999981880188 Test Acc : 0.5137499962002039\n",
      "\n",
      "Current Iter : 142/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 142 Acc : 0.6331999981403351 Test Acc : 0.4983749981969595\n",
      "\n",
      "Current Iter : 143/150 batch : 7900/8000 acc : 0.45\n",
      " Current : 143 Acc : 0.6225999975204468 Test Acc : 0.4977499932050705\n",
      "\n",
      "Current Iter : 144/150 batch : 7900/8000 acc : 0.58\n",
      " Current : 144 Acc : 0.6149999976158143 Test Acc : 0.5018749974668026\n",
      "\n",
      "Current Iter : 145/150 batch : 7900/8000 acc : 0.51\n",
      " Current : 145 Acc : 0.6067999958992004 Test Acc : 0.5007499981671572\n",
      "\n",
      "Current Iter : 146/150 batch : 7900/8000 acc : 0.44\n",
      " Current : 146 Acc : 0.6162000024318695 Test Acc : 0.48599999621510503\n",
      "\n",
      "Current Iter : 147/150 batch : 7900/8000 acc : 0.47\n",
      " Current : 147 Acc : 0.6169999992847442 Test Acc : 0.5013749964535237\n",
      "\n",
      "Current Iter : 148/150 batch : 7900/8000 acc : 0.49\n",
      " Current : 148 Acc : 0.6493999999761582 Test Acc : 0.5061249982565641\n",
      "\n",
      "Current Iter : 149/150 batch : 7900/8000 acc : 0.43\n",
      " Current : 149 Acc : 0.6492000019550324 Test Acc : 0.5071249973028898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc     = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test/(len(test_images)/batch_size)  )\n",
    "    \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:17:34.603828Z",
     "start_time": "2018-12-20T22:17:34.325966Z"
    }
   },
   "outputs": [],
   "source": [
    "! start ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:39:51.379493Z",
     "start_time": "2018-12-20T07:39:51.079050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:43:08.033249Z",
     "start_time": "2018-12-20T07:43:06.719715Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T20:25:08.945691Z",
     "start_time": "2018-12-20T20:25:08.918763Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T20:25:16.316488Z",
     "start_time": "2018-12-20T20:25:16.066594Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:11.376556Z",
     "start_time": "2018-12-20T07:57:11.370596Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly\n",
    "3. plot, H. (2010). How to change the font size on a matplotlib plot. Stack Overflow. Retrieved 20 December 2018, from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
