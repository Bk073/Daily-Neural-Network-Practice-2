{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T23:56:34.034594Z",
     "start_time": "2018-12-20T23:56:34.026614Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 35})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T23:38:22.125598Z",
     "start_time": "2018-12-20T23:38:19.868571Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T23:38:22.193449Z",
     "start_time": "2018-12-20T23:38:22.127592Z"
    },
    "code_folding": [
     0,
     15,
     48,
     88,
     128,
     199
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=4,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer,self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        return (self.layer - 1.0)/(self.lmbda + 1e-8)\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        \n",
    "        # Gradient that gets passed along\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0) * grad\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda1 =   (self.layer * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda2 = - (self.layer - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean((grad_lmbda1 + grad_lmbda2)*grad)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w\n",
    "    \n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T23:38:22.207478Z",
     "start_time": "2018-12-20T23:38:22.196410Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "num_epoch = 200; learning_rate = 0.0008; batch_size = 20; beta1,beta2,adam_e = 0.9,0.999,1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T00:26:44.047540Z",
     "start_time": "2018-12-20T23:56:40.621136Z"
    },
    "code_folding": [
     0,
     45,
     58
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Acc : 0.11400000230967998 Test Acc : 0.18837500314228237\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.18660000313818453 Test Acc : 0.23000000271946192\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 2 Acc : 0.22940000292658805 Test Acc : 0.2683750024437904\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 3 Acc : 0.2522000029683113 Test Acc : 0.2903750020917505\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 4 Acc : 0.27060000267624856 Test Acc : 0.29937500176019965\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 5 Acc : 0.28920000267028806 Test Acc : 0.30387500166893006\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 6 Acc : 0.29280000226199626 Test Acc : 0.30712500154040756\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Acc : 0.294200002014637 Test Acc : 0.31300000195391475\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 8 Acc : 0.3004000019729137 Test Acc : 0.3180000018142164\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 9 Acc : 0.3094000017642975 Test Acc : 0.3217500014975667\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Acc : 0.3150000014454126 Test Acc : 0.32937500181607904\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 11 Acc : 0.3204000016748905 Test Acc : 0.3350000024959445\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 12 Acc : 0.324200002104044 Test Acc : 0.3366250019706786\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 13 Acc : 0.3308000017702579 Test Acc : 0.33925000165589153\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 14 Acc : 0.33380000209808347 Test Acc : 0.3436250019911677\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 15 Acc : 0.33400000125169754 Test Acc : 0.34512500163167714\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 16 Acc : 0.33760000151395797 Test Acc : 0.3492500015348196\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 17 Acc : 0.33940000176429747 Test Acc : 0.34900000180117785\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 18 Acc : 0.3438000020980835 Test Acc : 0.347875001905486\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 19 Acc : 0.3472000020891428 Test Acc : 0.3496250008419156\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 20 Acc : 0.3504000014960766 Test Acc : 0.3543750006984919\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 21 Acc : 0.35400000217556954 Test Acc : 0.3550000005122274\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 22 Acc : 0.3576000019609928 Test Acc : 0.35587500107474623\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 23 Acc : 0.3610000019967556 Test Acc : 0.3596250008791685\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 24 Acc : 0.36220000152289866 Test Acc : 0.36000000111758707\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 25 Acc : 0.36800000140070915 Test Acc : 0.36300000119954345\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 26 Acc : 0.36840000113844873 Test Acc : 0.36487500090152025\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 27 Acc : 0.37400000089406965 Test Acc : 0.3673750007338822\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 28 Acc : 0.3750000008046627 Test Acc : 0.36625000069849195\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 29 Acc : 0.37560000115633013 Test Acc : 0.3681250007171184\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 30 Acc : 0.3792000012695789 Test Acc : 0.3708750005904585\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 31 Acc : 0.3838000013232231 Test Acc : 0.3712500004004687\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 32 Acc : 0.3848000010251999 Test Acc : 0.3717500007059425\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 33 Acc : 0.38760000041127207 Test Acc : 0.37162500105798246\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 34 Acc : 0.39260000130534173 Test Acc : 0.37325000135228037\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 35 Acc : 0.39480000203847887 Test Acc : 0.37275000136345626\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 36 Acc : 0.39360000169277193 Test Acc : 0.3718750013783574\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 37 Acc : 0.39860000187158584 Test Acc : 0.3722500015050173\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 38 Acc : 0.4020000014901161 Test Acc : 0.3733750016056001\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 39 Acc : 0.40120000195503236 Test Acc : 0.37362500121816994\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 40 Acc : 0.4052000013887882 Test Acc : 0.37312500094994905\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 41 Acc : 0.4074000016152859 Test Acc : 0.3742500009015203\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 42 Acc : 0.41000000163912775 Test Acc : 0.3791250013746321\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 43 Acc : 0.4110000011622906 Test Acc : 0.37850000146776436\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 44 Acc : 0.4124000008404255 Test Acc : 0.3808750015310943\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 45 Acc : 0.41480000033974646 Test Acc : 0.38125000132247805\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 46 Acc : 0.4162000001370907 Test Acc : 0.3822500017751008\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 47 Acc : 0.416400001257658 Test Acc : 0.38250000183470545\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 48 Acc : 0.41580000093579295 Test Acc : 0.3832500015385449\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 49 Acc : 0.41880000099539755 Test Acc : 0.38300000156275926\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 50 Acc : 0.4200000011026859 Test Acc : 0.3841250011138618\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 51 Acc : 0.4236000008285046 Test Acc : 0.38350000127218664\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 52 Acc : 0.42460000088810923 Test Acc : 0.38550000042654575\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 53 Acc : 0.42560000029206274 Test Acc : 0.3846250008419156\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 54 Acc : 0.42760000041127205 Test Acc : 0.385750000923872\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 55 Acc : 0.4298000002801418 Test Acc : 0.3861250007711351\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 56 Acc : 0.43099999997019767 Test Acc : 0.386000000834465\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 57 Acc : 0.4316000001728535 Test Acc : 0.38900000070221724\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 58 Acc : 0.43400000044703485 Test Acc : 0.38812500044703485\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 59 Acc : 0.4356000002324581 Test Acc : 0.3906250003818423\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 60 Acc : 0.43800000062584876 Test Acc : 0.38950000039301813\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 61 Acc : 0.43740000066161155 Test Acc : 0.392500000083819\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 62 Acc : 0.43920000073313714 Test Acc : 0.39325000015087425\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 63 Acc : 0.44080000108480455 Test Acc : 0.3917500002216548\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 64 Acc : 0.4434000008702278 Test Acc : 0.39325000035576524\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 65 Acc : 0.444200000166893 Test Acc : 0.39162500084377827\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 66 Acc : 0.44599999994039535 Test Acc : 0.393375000404194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 67 Acc : 0.44940000063180924 Test Acc : 0.3921250002551824\n",
      "\n",
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 68 Acc : 0.4482000005841255 Test Acc : 0.39250000049360095\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 69 Acc : 0.4492000004649162 Test Acc : 0.39524999985471365\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 70 Acc : 0.4514000003933907 Test Acc : 0.3934999998472631\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 71 Acc : 0.4526000002026558 Test Acc : 0.39524999996647237\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 72 Acc : 0.454000001013279 Test Acc : 0.3931249995343387\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 73 Acc : 0.45519999992847443 Test Acc : 0.39549999963492155\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 74 Acc : 0.4568000010251999 Test Acc : 0.39574999989941717\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 75 Acc : 0.4578000006079674 Test Acc : 0.3952500000782311\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 76 Acc : 0.45920000088214874 Test Acc : 0.39475000033155083\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 77 Acc : 0.46200000077486036 Test Acc : 0.395250000692904\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 78 Acc : 0.46300000095367433 Test Acc : 0.3950000005401671\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 79 Acc : 0.4624000009894371 Test Acc : 0.3983750005438924\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 80 Acc : 0.46280000066757204 Test Acc : 0.39875000117346643\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 81 Acc : 0.4636000008583069 Test Acc : 0.39650000104680655\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 82 Acc : 0.46400000077486037 Test Acc : 0.3991250008530915\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 83 Acc : 0.4660000002384186 Test Acc : 0.3978750009089708\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 84 Acc : 0.46699999994039537 Test Acc : 0.39962500140070917\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 85 Acc : 0.4697999999523163 Test Acc : 0.39975000094622376\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 86 Acc : 0.47160000026226045 Test Acc : 0.4006250006146729\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 87 Acc : 0.4730000008940697 Test Acc : 0.39687500102445483\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 88 Acc : 0.4728000002503395 Test Acc : 0.39612500108778476\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 89 Acc : 0.4740000004172325 Test Acc : 0.3945000009611249\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 90 Acc : 0.4763999999761581 Test Acc : 0.39537500116974117\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 91 Acc : 0.47380000019073487 Test Acc : 0.39775000128895044\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 92 Acc : 0.4750000004172325 Test Acc : 0.3930000008456409\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 93 Acc : 0.474800000667572 Test Acc : 0.39750000124797225\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 94 Acc : 0.4782000003457069 Test Acc : 0.39550000132992863\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 95 Acc : 0.4794000002741814 Test Acc : 0.39787500104866924\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 96 Acc : 0.4798000001907349 Test Acc : 0.39550000104121863\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 97 Acc : 0.47960000044107437 Test Acc : 0.39587500093504785\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 98 Acc : 0.4822000008225441 Test Acc : 0.39575000101700425\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 99 Acc : 0.48280000025033953 Test Acc : 0.39500000068917873\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 100 Acc : 0.4848000003695488 Test Acc : 0.39787500103935597\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 101 Acc : 0.4860000008940697 Test Acc : 0.39675000090152024\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 102 Acc : 0.4860000004172325 Test Acc : 0.39712500079534946\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 103 Acc : 0.48640000027418134 Test Acc : 0.3967500009480864\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 104 Acc : 0.48780000060796735 Test Acc : 0.39875000054948034\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 105 Acc : 0.49000000023841855 Test Acc : 0.39825000065378846\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 106 Acc : 0.4904000006318092 Test Acc : 0.3986250005662441\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 107 Acc : 0.4940000006556511 Test Acc : 0.4000000003445894\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 108 Acc : 0.491800000846386 Test Acc : 0.3996250008512288\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 109 Acc : 0.4908000003695488 Test Acc : 0.39775000083260237\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 110 Acc : 0.49220000034570693 Test Acc : 0.39712500050663946\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 111 Acc : 0.4936000009179115 Test Acc : 0.40050000060349705\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 112 Acc : 0.49420000094175337 Test Acc : 0.4011250009480864\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 113 Acc : 0.4944000000357628 Test Acc : 0.39975000055506826\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 114 Acc : 0.4962000008225441 Test Acc : 0.40037500075064597\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 115 Acc : 0.49500000089406965 Test Acc : 0.4015000010188669\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 116 Acc : 0.49700000101327896 Test Acc : 0.400625001238659\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 117 Acc : 0.4986000012755394 Test Acc : 0.40387500083073974\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 118 Acc : 0.5002000008225441 Test Acc : 0.40375000074505807\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 119 Acc : 0.5036000014543534 Test Acc : 0.40162500116974115\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 120 Acc : 0.5034000010490417 Test Acc : 0.40637500094249845\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 121 Acc : 0.5030000010132789 Test Acc : 0.403375000981614\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 122 Acc : 0.5038000017404556 Test Acc : 0.40537500076927246\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 123 Acc : 0.5050000011920929 Test Acc : 0.40375000118277965\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 124 Acc : 0.5060000013113022 Test Acc : 0.40450000085867943\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 125 Acc : 0.5064000014066696 Test Acc : 0.4038750011008233\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 126 Acc : 0.5068000013828278 Test Acc : 0.40412500088103115\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 127 Acc : 0.5060000023841857 Test Acc : 0.4030000005941838\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 128 Acc : 0.5082000014781952 Test Acc : 0.4033750006835908\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 129 Acc : 0.5098000019788742 Test Acc : 0.4023750008735806\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 130 Acc : 0.5124000004529953 Test Acc : 0.4026250007096678\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 131 Acc : 0.515400001168251 Test Acc : 0.4041250011045486\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 132 Acc : 0.5144000006914139 Test Acc : 0.4083750011678785\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 133 Acc : 0.5162000011205673 Test Acc : 0.4067500015255064\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 134 Acc : 0.5160000013113022 Test Acc : 0.40800000159069894\n",
      "\n",
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 135 Acc : 0.5182000017166137 Test Acc : 0.40800000057555735\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 136 Acc : 0.517400001168251 Test Acc : 0.4076250012870878\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 137 Acc : 0.5198000015020371 Test Acc : 0.40550000097602606\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 138 Acc : 0.521400001168251 Test Acc : 0.4073750007897615\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 139 Acc : 0.5210000020265579 Test Acc : 0.40812500103376803\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 140 Acc : 0.5204000022411347 Test Acc : 0.4090000006556511\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 141 Acc : 0.5206000019907951 Test Acc : 0.4088750010356307\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 142 Acc : 0.5208000018596649 Test Acc : 0.4095000003091991\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 143 Acc : 0.5226000016927719 Test Acc : 0.409875000603497\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 144 Acc : 0.5208000006079674 Test Acc : 0.4100000009126961\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 145 Acc : 0.5232000008225441 Test Acc : 0.4102500009350479\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 146 Acc : 0.5226000002026558 Test Acc : 0.4107500013336539\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 147 Acc : 0.5264000003933906 Test Acc : 0.41012500105425714\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 148 Acc : 0.5258000004291534 Test Acc : 0.4105000016652048\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 149 Acc : 0.5258000018596649 Test Acc : 0.41050000144168736\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 150 Acc : 0.5280000013113022 Test Acc : 0.40975000146776436\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 151 Acc : 0.5286000012159348 Test Acc : 0.41250000171363355\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 152 Acc : 0.5292000010609627 Test Acc : 0.41312500175088646\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 153 Acc : 0.5286000007390976 Test Acc : 0.41300000140443444\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 154 Acc : 0.5308000015020371 Test Acc : 0.4095000012218952\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 155 Acc : 0.5332000025510788 Test Acc : 0.411875001359731\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 156 Acc : 0.5322000025510788 Test Acc : 0.41300000180490315\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 157 Acc : 0.5342000016570091 Test Acc : 0.4126250016968697\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 158 Acc : 0.5352000018358231 Test Acc : 0.4130000018514693\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 159 Acc : 0.5362000018954277 Test Acc : 0.4135000021662563\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 160 Acc : 0.5354000009298324 Test Acc : 0.41462500163353977\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 161 Acc : 0.538800001502037 Test Acc : 0.41350000170990825\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 162 Acc : 0.5362000013589859 Test Acc : 0.414750002194196\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 163 Acc : 0.5382000015974044 Test Acc : 0.4142500022705644\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 164 Acc : 0.5402000015974044 Test Acc : 0.4148750019073486\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 165 Acc : 0.5394000010490417 Test Acc : 0.4152500022109598\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 166 Acc : 0.5396000015139579 Test Acc : 0.4166250022407621\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 167 Acc : 0.54200000166893 Test Acc : 0.4155000020097941\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 168 Acc : 0.5444000016450882 Test Acc : 0.4160000018496066\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 169 Acc : 0.5428000013232231 Test Acc : 0.4107500024698675\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 170 Acc : 0.5438000013232231 Test Acc : 0.4118750025797635\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 171 Acc : 0.5444000020623208 Test Acc : 0.4116250025294721\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 172 Acc : 0.5488000019192696 Test Acc : 0.413875002656132\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 173 Acc : 0.5496000016927719 Test Acc : 0.41425000234507026\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 174 Acc : 0.5500000014305114 Test Acc : 0.4150000022538006\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 175 Acc : 0.5500000019073487 Test Acc : 0.4141250027064234\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 176 Acc : 0.5494000021219253 Test Acc : 0.41225000240840015\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 177 Acc : 0.5508000020980834 Test Acc : 0.41025000234134495\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 178 Acc : 0.550200001358986 Test Acc : 0.4108750026021153\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 179 Acc : 0.5512000008821487 Test Acc : 0.41162500272504987\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 180 Acc : 0.5514000008106231 Test Acc : 0.4121250029373914\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 181 Acc : 0.5524000009298324 Test Acc : 0.41187500254251064\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 182 Acc : 0.5536000012159348 Test Acc : 0.4092500021774322\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 183 Acc : 0.5532000006437302 Test Acc : 0.4101250020880252\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 184 Acc : 0.5544000006914139 Test Acc : 0.41087500234134494\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 185 Acc : 0.5542000008821487 Test Acc : 0.4131250023189932\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 186 Acc : 0.5568000018000603 Test Acc : 0.4127500023785979\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 187 Acc : 0.5616000009179115 Test Acc : 0.41312500247731804\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 188 Acc : 0.5596000022292137 Test Acc : 0.41400000230409206\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 189 Acc : 0.5598000013828277 Test Acc : 0.4140000025276095\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 190 Acc : 0.5592000007033348 Test Acc : 0.4136250025499612\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 191 Acc : 0.5614000019431115 Test Acc : 0.4127500028628856\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 192 Acc : 0.5584000006318093 Test Acc : 0.41362500202842056\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 193 Acc : 0.5618000004887581 Test Acc : 0.4137500017974526\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 194 Acc : 0.5628000009059906 Test Acc : 0.4143750021699816\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 195 Acc : 0.5620000009536743 Test Acc : 0.41075000223703684\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 196 Acc : 0.5620000004768372 Test Acc : 0.4125000018719584\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 197 Acc : 0.5624000005722046 Test Acc : 0.4111250021774322\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 198 Acc : 0.5640000005960465 Test Acc : 0.4118750020954758\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 199 Acc : 0.5648000010251999 Test Acc : 0.41175000187940897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Normal CNN \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,16); \n",
    "l5 = CNN(3,16,16); \n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad6p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Normal/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Normal/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Normal/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Normal/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save('Normal/train.npy',train_acc)\n",
    "np.save('Normal/test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T01:00:15.179706Z",
     "start_time": "2018-12-21T00:26:44.479386Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.2766000022739172 Test Acc : 0.296625001989305\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.35040000222623346 Test Acc : 0.36412500159814953\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 2 Acc : 0.386200001552701 Test Acc : 0.38925000132061544\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 3 Acc : 0.4256000012159348 Test Acc : 0.4056250012293458\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 4 Acc : 0.4468000010251999 Test Acc : 0.401250001527369\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 5 Acc : 0.4640000008046627 Test Acc : 0.42287500207312406\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 6 Acc : 0.4894000007510185 Test Acc : 0.4295000021252781\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 7 Acc : 0.5056000011563301 Test Acc : 0.4326250012777746\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 8 Acc : 0.5252000007033348 Test Acc : 0.4442500014975667\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 9 Acc : 0.5406000008583068 Test Acc : 0.4570000011473894\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 10 Acc : 0.5544000008106231 Test Acc : 0.46700000163167715\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 11 Acc : 0.57 Test Acc : 0.46062500153668223\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 12 Acc : 0.5814000010490418 Test Acc : 0.4511250007804483\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 13 Acc : 0.5918000010251999 Test Acc : 0.4648750017117709\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 14 Acc : 0.5972000012397766 Test Acc : 0.4750000018347055\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 15 Acc : 0.6050000010728837 Test Acc : 0.48275000154972075\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 16 Acc : 0.6114000008106232 Test Acc : 0.48475000135600566\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 17 Acc : 0.6192000010013581 Test Acc : 0.48100000105798246\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 18 Acc : 0.6230000001192093 Test Acc : 0.4810000013560057\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 19 Acc : 0.6349999972581863 Test Acc : 0.48175000105053184\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Acc : 0.6411999979019165 Test Acc : 0.48175000194460155\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 21 Acc : 0.6503999980688095 Test Acc : 0.47750000055879355\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Acc : 0.657599999666214 Test Acc : 0.4742500003799796\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 23 Acc : 0.664799998998642 Test Acc : 0.4712500010803342\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 24 Acc : 0.6693999999761582 Test Acc : 0.4720000003278255\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 25 Acc : 0.671799998998642 Test Acc : 0.47250000059604647\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Acc : 0.6793999998569489 Test Acc : 0.4695000010728836\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 27 Acc : 0.683399998664856 Test Acc : 0.4632500008866191\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Acc : 0.6905999995470047 Test Acc : 0.4692500014975667\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Acc : 0.6949999997615814 Test Acc : 0.4636250005662441\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.695400000333786 Test Acc : 0.4672500016354024\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 31 Acc : 0.7052000008821487 Test Acc : 0.46412500156089664\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 32 Acc : 0.711399999499321 Test Acc : 0.46337500220164657\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.7170000004768372 Test Acc : 0.46387500189244746\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.7205999993085861 Test Acc : 0.46150000248104334\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.7260000001192093 Test Acc : 0.4635000016540289\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.7329999996423722 Test Acc : 0.46200000166893007\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.739599999666214 Test Acc : 0.4660000007972121\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.7434000005722046 Test Acc : 0.4678750012628734\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.75 Test Acc : 0.4688750021345913\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 40 Acc : 0.7517999989986419 Test Acc : 0.4690000018663704\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 41 Acc : 0.7560000007152557 Test Acc : 0.46800000151619314\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 42 Acc : 0.7664000008106232 Test Acc : 0.47050000181421636\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 43 Acc : 0.7712000012397766 Test Acc : 0.46650000227615235\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.7808000009059906 Test Acc : 0.4678750024549663\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Acc : 0.78300000166893 Test Acc : 0.46787500189617276\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Acc : 0.7868000018596649 Test Acc : 0.4643750022444874\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 47 Acc : 0.7908000006675721 Test Acc : 0.4620000019762665\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 48 Acc : 0.7992000002861023 Test Acc : 0.4607500020135194\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 49 Acc : 0.8018000018596649 Test Acc : 0.4615000021643937\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 50 Acc : 0.8082000012397766 Test Acc : 0.460875001642853\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Acc : 0.8134000022411346 Test Acc : 0.4635000022687018\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Acc : 0.81800000166893 Test Acc : 0.4582500012777746\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 53 Acc : 0.8204000012874604 Test Acc : 0.4575000007636845\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 54 Acc : 0.8216000015735626 Test Acc : 0.45250000117346645\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 55 Acc : 0.8258000023365021 Test Acc : 0.45000000240281224\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 56 Acc : 0.8320000019073487 Test Acc : 0.45137500097975136\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 57 Acc : 0.8386000015735626 Test Acc : 0.44775000100955364\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 58 Acc : 0.8405999999046325 Test Acc : 0.4435000012628734\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 59 Acc : 0.8410000004768372 Test Acc : 0.4408750011958182\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 60 Acc : 0.8475999991893768 Test Acc : 0.4410000009462237\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 61 Acc : 0.8477999994754791 Test Acc : 0.4375000006891787\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 62 Acc : 0.8543999998569488 Test Acc : 0.4373750011250377\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 63 Acc : 0.8564000000953674 Test Acc : 0.44062500149942935\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 64 Acc : 0.8551999990940093 Test Acc : 0.43900000023655594\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 65 Acc : 0.860599999666214 Test Acc : 0.4338750011380762\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 66 Acc : 0.8622000000476837 Test Acc : 0.437125000609085\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 67 Acc : 0.8652000010013581 Test Acc : 0.4346250008698553\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 68 Acc : 0.867599999666214 Test Acc : 0.4348750016186386\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 69 Acc : 0.8715999991893768 Test Acc : 0.4385000020079315\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 70 Acc : 0.8749999983310699 Test Acc : 0.4386250011064112\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 71 Acc : 0.8789999995231629 Test Acc : 0.4378750023804605\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 72 Acc : 0.8789999976158142 Test Acc : 0.4415000015310943\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 73 Acc : 0.8839999980926514 Test Acc : 0.43925000162795186\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 74 Acc : 0.8843999993801117 Test Acc : 0.439625001642853\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 75 Acc : 0.8855999977588653 Test Acc : 0.4322500024549663\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 76 Acc : 0.8903999969959259 Test Acc : 0.4378750011883676\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 77 Acc : 0.8955999956130981 Test Acc : 0.4362500007264316\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 78 Acc : 0.8949999959468842 Test Acc : 0.4370000016875565\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 79 Acc : 0.8983999948501586 Test Acc : 0.4353750012256205\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 80 Acc : 0.8977999949455261 Test Acc : 0.440250002425164\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 81 Acc : 0.905599995136261 Test Acc : 0.4365000013820827\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 82 Acc : 0.9099999935626983 Test Acc : 0.4321250011958182\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 83 Acc : 0.9119999940395356 Test Acc : 0.4357500013150275\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 84 Acc : 0.9195999917984009 Test Acc : 0.4348750018887222\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 85 Acc : 0.9159999926090241 Test Acc : 0.43450000116601584\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 86 Acc : 0.9177999935150146 Test Acc : 0.4358750007301569\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 87 Acc : 0.9169999933242798 Test Acc : 0.4328750006482005\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 88 Acc : 0.922799994468689 Test Acc : 0.4290000013820827\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 89 Acc : 0.9221999936103821 Test Acc : 0.4323750011436641\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 90 Acc : 0.9247999937534332 Test Acc : 0.4280000004731119\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 91 Acc : 0.9225999939441681 Test Acc : 0.4300000008568168\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 92 Acc : 0.9249999930858612 Test Acc : 0.4351250016503036\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 93 Acc : 0.9277999935150146 Test Acc : 0.4321250005997717\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 94 Acc : 0.9297999939918518 Test Acc : 0.43587500140070917\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 95 Acc : 0.9305999937057495 Test Acc : 0.43437500143423674\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 96 Acc : 0.9327999925613404 Test Acc : 0.4332500002533197\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 97 Acc : 0.9319999935626984 Test Acc : 0.4315000009536743\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 98 Acc : 0.9311999936103821 Test Acc : 0.43575000040233136\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 99 Acc : 0.9335999929904938 Test Acc : 0.43450000040233133\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 100 Acc : 0.9273999917507172 Test Acc : 0.43437500063329937\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 101 Acc : 0.9321999928951263 Test Acc : 0.4347500010207295\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 102 Acc : 0.9361999924182892 Test Acc : 0.43625000163912775\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 103 Acc : 0.9377999913692474 Test Acc : 0.440750000923872\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 104 Acc : 0.9381999912261962 Test Acc : 0.438500001616776\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 105 Acc : 0.9431999924182892 Test Acc : 0.4303750011324883\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 106 Acc : 0.9459999904632569 Test Acc : 0.4348750014975667\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 107 Acc : 0.9477999923229218 Test Acc : 0.4336250013485551\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 108 Acc : 0.9487999920845032 Test Acc : 0.43225000143051145\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 109 Acc : 0.951199993133545 Test Acc : 0.43362500032410023\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 110 Acc : 0.9519999923706055 Test Acc : 0.43412500120699404\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 111 Acc : 0.9555999932289123 Test Acc : 0.4303750006482005\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 112 Acc : 0.9569999933242798 Test Acc : 0.4302500011958182\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 113 Acc : 0.9567999937534333 Test Acc : 0.4275000014528632\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 114 Acc : 0.9491999933719635 Test Acc : 0.4275000014342368\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 115 Acc : 0.9483999927043915 Test Acc : 0.4213750005885959\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 116 Acc : 0.9497999930381775 Test Acc : 0.42925000036135313\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Acc : 0.9509999935626984 Test Acc : 0.43262500027194617\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 118 Acc : 0.9471999926567077 Test Acc : 0.4322500005364418\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 119 Acc : 0.9431999933719635 Test Acc : 0.43187500048428773\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 120 Acc : 0.9467999925613403 Test Acc : 0.4331250003352761\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Acc : 0.9539999916553498 Test Acc : 0.4286250004917383\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 122 Acc : 0.9559999921321869 Test Acc : 0.42875000115483997\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 123 Acc : 0.9559999935626984 Test Acc : 0.4262500010430813\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 124 Acc : 0.9565999922752381 Test Acc : 0.41900000169873236\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 125 Acc : 0.9521999921798706 Test Acc : 0.42225000105798244\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 126 Acc : 0.9605999937057496 Test Acc : 0.41687500093132257\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 127 Acc : 0.9649999938011169 Test Acc : 0.42150000110268593\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 128 Acc : 0.9639999930858612 Test Acc : 0.423750001527369\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 129 Acc : 0.9673999934196472 Test Acc : 0.4206250006519258\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 130 Acc : 0.9705999937057496 Test Acc : 0.42087500061839817\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 131 Acc : 0.9739999945163726 Test Acc : 0.4261250015348196\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 132 Acc : 0.9777999954223633 Test Acc : 0.4250000010430813\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 133 Acc : 0.9675999939441681 Test Acc : 0.42625000135973096\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 134 Acc : 0.9765999948978424 Test Acc : 0.42162500113248824\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 135 Acc : 0.9767999951839447 Test Acc : 0.42462500136345627\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 136 Acc : 0.9763999950885772 Test Acc : 0.42025000242516397\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 137 Acc : 0.975599995136261 Test Acc : 0.42750000167638064\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 138 Acc : 0.9785999956130982 Test Acc : 0.423875002078712\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 139 Acc : 0.9821999959945679 Test Acc : 0.42925000093877314\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 140 Acc : 0.9791999957561492 Test Acc : 0.43075000174343586\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 141 Acc : 0.977199994802475 Test Acc : 0.41850000189617276\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 142 Acc : 0.9791999950408935 Test Acc : 0.41737500209361317\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 143 Acc : 0.9573999927043915 Test Acc : 0.4181250017695129\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 144 Acc : 0.9747999951839447 Test Acc : 0.42087500110268594\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 145 Acc : 0.9829999959468841 Test Acc : 0.4207500008121133\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 146 Acc : 0.9863999967575073 Test Acc : 0.41400000112131236\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 147 Acc : 0.9853999965190887 Test Acc : 0.42187500160187485\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Acc : 0.990799997806549 Test Acc : 0.41462500078603626\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 149 Acc : 0.9913999979496002 Test Acc : 0.41812500144354997\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 150 Acc : 0.9873999972343445 Test Acc : 0.4200000011920929\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 151 Acc : 0.9835999960899353 Test Acc : 0.4153750003967434\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 152 Acc : 0.9465999913215637 Test Acc : 0.41787500130012634\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 153 Acc : 0.9641999936103821 Test Acc : 0.4202500013448298\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 154 Acc : 0.9845999965667724 Test Acc : 0.42137500070035455\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 155 Acc : 0.9889999973773956 Test Acc : 0.4158750008419156\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 156 Acc : 0.9935999984741211 Test Acc : 0.4226250014826655\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 157 Acc : 0.9939999985694885 Test Acc : 0.41950000120326875\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 158 Acc : 0.981599996805191 Test Acc : 0.4205000014603138\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 159 Acc : 0.9759999947547913 Test Acc : 0.4211250014975667\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 160 Acc : 0.9829999961853028 Test Acc : 0.425500001180917\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 161 Acc : 0.9755999946594238 Test Acc : 0.4185000012814999\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 162 Acc : 0.9777999949455262 Test Acc : 0.4197500012908131\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 163 Acc : 0.9871999971866607 Test Acc : 0.42550000010058286\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 164 Acc : 0.9887999975681305 Test Acc : 0.42187500119209287\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 165 Acc : 0.987399996995926 Test Acc : 0.42725000116974116\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 166 Acc : 0.987999997138977 Test Acc : 0.4243750024959445\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 167 Acc : 0.9855999968051911 Test Acc : 0.42150000082328914\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 168 Acc : 0.9861999974250794 Test Acc : 0.42250000115484\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 169 Acc : 0.99299999833107 Test Acc : 0.4235000010486692\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 170 Acc : 0.99299999833107 Test Acc : 0.415250000981614\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 171 Acc : 0.9853999979496002 Test Acc : 0.406000000461936\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 172 Acc : 0.9429999923706055 Test Acc : 0.4223750012461096\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 173 Acc : 0.9667999942302704 Test Acc : 0.4206250011175871\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 174 Acc : 0.9859999973773956 Test Acc : 0.42087500147521495\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 175 Acc : 0.990799997806549 Test Acc : 0.4195000011660159\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 176 Acc : 0.9937999985218048 Test Acc : 0.4180000015720725\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 177 Acc : 0.9937999985218048 Test Acc : 0.4235000019334257\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 178 Acc : 0.9955999989509583 Test Acc : 0.42050000114366415\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 179 Acc : 0.9959999990463256 Test Acc : 0.4155000024754554\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 180 Acc : 0.9739999952316284 Test Acc : 0.4138750014360994\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 181 Acc : 0.9607999939918518 Test Acc : 0.42000000157393513\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 182 Acc : 0.9729999942779541 Test Acc : 0.4206250006891787\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 183 Acc : 0.982799996137619 Test Acc : 0.4185000010114163\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 184 Acc : 0.9917999980449677 Test Acc : 0.4185000012721866\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 185 Acc : 0.9967999992370605 Test Acc : 0.41725000102072957\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 186 Acc : 0.9981999995708466 Test Acc : 0.4201250017527491\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 187 Acc : 0.9989999997615814 Test Acc : 0.42225000184029343\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 188 Acc : 0.9991999998092651 Test Acc : 0.42075000202283264\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 189 Acc : 0.9991999998092651 Test Acc : 0.421750001963228\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 190 Acc : 0.9993999998569488 Test Acc : 0.41800000169314444\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 191 Acc : 0.9975999994277954 Test Acc : 0.420500001758337\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 192 Acc : 0.8717999994754791 Test Acc : 0.421000001328066\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 193 Acc : 0.958399994134903 Test Acc : 0.4275000019930303\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 194 Acc : 0.989799997806549 Test Acc : 0.422750001847744\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 195 Acc : 0.995799998998642 Test Acc : 0.4210000017285347\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 196 Acc : 0.995799998998642 Test Acc : 0.4223750020377338\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 197 Acc : 0.9983999996185303 Test Acc : 0.42562500197440384\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 198 Acc : 0.9975999994277954 Test Acc : 0.41775000164285303\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 199 Acc : 0.998599999666214 Test Acc : 0.41912500191479923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. batch normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'batch Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'batch Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('batch Norm/train.npy',train_acc)\n",
    "np.save('batch Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T01:34:59.358733Z",
     "start_time": "2018-12-21T01:00:15.661417Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Acc : 0.19500000247359275 Test Acc : 0.22662500338628888\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.30560000240802765 Test Acc : 0.30075000238604843\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 2 Acc : 0.35300000140070914 Test Acc : 0.32475000170059504\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.3826000009179115 Test Acc : 0.33487500187940894\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Acc : 0.404600001424551 Test Acc : 0.34162500167265536\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 5 Acc : 0.42480000150203706 Test Acc : 0.35112500144168735\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 6 Acc : 0.44020000159740447 Test Acc : 0.35375000115484\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 7 Acc : 0.45660000091791153 Test Acc : 0.35350000121630726\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 8 Acc : 0.47300000178813933 Test Acc : 0.3557500013336539\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 9 Acc : 0.48240000212192535 Test Acc : 0.35737500013783574\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 10 Acc : 0.4946000007390976 Test Acc : 0.3540000007674098\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 11 Acc : 0.5036000007390976 Test Acc : 0.34550000187940894\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 12 Acc : 0.5085999995470047 Test Acc : 0.34050000212155285\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 13 Acc : 0.5229999994039536 Test Acc : 0.3377500017266721\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 14 Acc : 0.527600000500679 Test Acc : 0.33850000191479923\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 15 Acc : 0.53600000166893 Test Acc : 0.3380000014230609\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 16 Acc : 0.5428000011444092 Test Acc : 0.3458750013820827\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Acc : 0.5512000027894973 Test Acc : 0.34850000105798246\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 18 Acc : 0.5610000039339066 Test Acc : 0.3523750013485551\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 19 Acc : 0.5714000018835068 Test Acc : 0.3530000011064112\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 20 Acc : 0.5758000023365021 Test Acc : 0.356625001411885\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 21 Acc : 0.581800001502037 Test Acc : 0.35487500194460153\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 22 Acc : 0.5880000017881394 Test Acc : 0.36012500181794166\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Acc : 0.5934000016450882 Test Acc : 0.36150000122375786\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Acc : 0.6010000016689301 Test Acc : 0.3640000014472753\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Acc : 0.6034000018835067 Test Acc : 0.36550000093877316\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 26 Acc : 0.6110000007152557 Test Acc : 0.3656250015459955\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Acc : 0.6160000015497208 Test Acc : 0.37187500143423674\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Acc : 0.6206000003814697 Test Acc : 0.3696250011771917\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Acc : 0.6240000009536744 Test Acc : 0.3683750011213124\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.6274000008106232 Test Acc : 0.36837500154972075\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 31 Acc : 0.6343999998569488 Test Acc : 0.36812500152736904\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Acc : 0.6361999999284744 Test Acc : 0.3652500015869737\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.642199999332428 Test Acc : 0.3655000010505319\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.6449999984502792 Test Acc : 0.36712500151246785\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.6497999982833862 Test Acc : 0.36312500178813933\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.6545999984741211 Test Acc : 0.36025000164285303\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.6607999978065491 Test Acc : 0.3623750020097941\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.6657999978065491 Test Acc : 0.361250002393499\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 39 Acc : 0.6711999988555908 Test Acc : 0.3583750016056001\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 40 Acc : 0.6739999984502792 Test Acc : 0.3576250018365681\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 41 Acc : 0.6745999981164932 Test Acc : 0.35950000189244746\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 42 Acc : 0.6791999982595444 Test Acc : 0.3560000015422702\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Acc : 0.6845999987125396 Test Acc : 0.3560000014677644\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.6899999998807907 Test Acc : 0.35337500119581816\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 45 Acc : 0.6947999997138977 Test Acc : 0.35087500073015687\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 46 Acc : 0.6971999999284745 Test Acc : 0.34975000148639085\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Acc : 0.7026000000238418 Test Acc : 0.3485000012721866\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.7091999999284744 Test Acc : 0.34837500142864886\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.7100000004768372 Test Acc : 0.34450000218115745\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 50 Acc : 0.7163999998569488 Test Acc : 0.3468750021234155\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Acc : 0.7191999996900559 Test Acc : 0.34787500216625633\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Acc : 0.7222000007629394 Test Acc : 0.34937500161118806\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 53 Acc : 0.7264000010490418 Test Acc : 0.34962500175461175\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 54 Acc : 0.7302000000476837 Test Acc : 0.35125000167638065\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 55 Acc : 0.7341999996900559 Test Acc : 0.3522500013373792\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 56 Acc : 0.7372000008821488 Test Acc : 0.35162500163540245\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 57 Acc : 0.7418000009059906 Test Acc : 0.34925000157207253\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 58 Acc : 0.7444000015258789 Test Acc : 0.3507500018365681\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 59 Acc : 0.7480000004768371 Test Acc : 0.3500000016298145\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 60 Acc : 0.7534000015258789 Test Acc : 0.3495000010915101\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 61 Acc : 0.7534000005722046 Test Acc : 0.34712500145658853\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 62 Acc : 0.759800000667572 Test Acc : 0.34587500131689014\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 63 Acc : 0.7650000004768371 Test Acc : 0.343750001238659\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 64 Acc : 0.7686000010967254 Test Acc : 0.34362500111572447\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 65 Acc : 0.771400001525879 Test Acc : 0.34325000149197876\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 66 Acc : 0.774200002193451 Test Acc : 0.344500002078712\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Acc : 0.77600000166893 Test Acc : 0.3456250016205013\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 68 Acc : 0.7776000006198883 Test Acc : 0.34287500185891984\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Acc : 0.7796000008583068 Test Acc : 0.34362500183284284\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Acc : 0.7832000007629395 Test Acc : 0.34175000185146925\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Acc : 0.7860000011920929 Test Acc : 0.34487500159069895\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Acc : 0.7876000009775161 Test Acc : 0.3415000017918646\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Acc : 0.7920000004768372 Test Acc : 0.3422500019147992\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 74 Acc : 0.7900000003576279 Test Acc : 0.343375002136454\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Acc : 0.7968000019788742 Test Acc : 0.3448750018235296\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 76 Acc : 0.7948000012636185 Test Acc : 0.34125000196509064\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 77 Acc : 0.7984000015258789 Test Acc : 0.3370000018645078\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 78 Acc : 0.8022000017166138 Test Acc : 0.3363750018645078\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Acc : 0.80700000166893 Test Acc : 0.3358750012889504\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Acc : 0.8112000012397766 Test Acc : 0.3375000021327287\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.8104000029563904 Test Acc : 0.33787500170059503\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.8124000010490418 Test Acc : 0.34075000196695326\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.8144000017642975 Test Acc : 0.33825000189244747\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 84 Acc : 0.8190000021457672 Test Acc : 0.3382500021159649\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Acc : 0.8200000007152557 Test Acc : 0.3372500019520521\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 86 Acc : 0.8287999997138977 Test Acc : 0.3352500012516975\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 87 Acc : 0.8315999994277954 Test Acc : 0.3352500012516975\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 88 Acc : 0.8333999998569489 Test Acc : 0.3340000019967556\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 89 Acc : 0.8363999998569489 Test Acc : 0.3338750021345913\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 90 Acc : 0.8411999988555908 Test Acc : 0.3346250017918646\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 91 Acc : 0.8426000006198883 Test Acc : 0.33250000182539224\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 92 Acc : 0.8447999992370605 Test Acc : 0.333000002047047\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 93 Acc : 0.847599998474121 Test Acc : 0.3328750021662563\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 94 Acc : 0.8499999978542327 Test Acc : 0.3318750013876706\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 95 Acc : 0.8541999983787537 Test Acc : 0.33412500204518436\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 96 Acc : 0.856999997138977 Test Acc : 0.33975000145845113\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 97 Acc : 0.8591999967098236 Test Acc : 0.33525000129826366\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Acc : 0.8567999970912933 Test Acc : 0.3395000013150275\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Acc : 0.8591999974250794 Test Acc : 0.33925000147894024\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 100 Acc : 0.8605999956130982 Test Acc : 0.3407500015385449\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 101 Acc : 0.8645999963283539 Test Acc : 0.3397500016447157\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Acc : 0.8647999982833863 Test Acc : 0.34387500187382103\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 103 Acc : 0.867599999666214 Test Acc : 0.34512500155717135\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 104 Acc : 0.8673999984264373 Test Acc : 0.3415000012889504\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Acc : 0.868399998664856 Test Acc : 0.34062500189989803\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 106 Acc : 0.8701999974250794 Test Acc : 0.3403750015515834\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Acc : 0.8761999979019165 Test Acc : 0.3428750014398247\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.8795999982357026 Test Acc : 0.34137500177137553\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.8839999976158142 Test Acc : 0.3427500019129366\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 110 Acc : 0.8861999976634979 Test Acc : 0.3423750016465783\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 111 Acc : 0.8919999959468842 Test Acc : 0.34312500115484\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 112 Acc : 0.8943999953269959 Test Acc : 0.340875001270324\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 113 Acc : 0.8963999960422516 Test Acc : 0.3405000010225922\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 114 Acc : 0.8973999953269959 Test Acc : 0.34175000108778475\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 115 Acc : 0.9007999947071076 Test Acc : 0.34037500124424697\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 116 Acc : 0.9045999946594239 Test Acc : 0.34062500145286323\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Acc : 0.908799994468689 Test Acc : 0.3402500012330711\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 118 Acc : 0.911599995136261 Test Acc : 0.33937500141561033\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 119 Acc : 0.9135999941825866 Test Acc : 0.3406250013411045\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.9139999940395355 Test Acc : 0.3382500012498349\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Acc : 0.9191999928951263 Test Acc : 0.3342500016093254\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 122 Acc : 0.9225999937057495 Test Acc : 0.3355000019725412\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 123 Acc : 0.9219999935626984 Test Acc : 0.33575000213459133\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 124 Acc : 0.9235999948978424 Test Acc : 0.3361250019725412\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 125 Acc : 0.9231999933719635 Test Acc : 0.3341250020079315\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 126 Acc : 0.9189999935626983 Test Acc : 0.33625000216066836\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 127 Acc : 0.9169999933242798 Test Acc : 0.33637500180862845\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 128 Acc : 0.9217999930381775 Test Acc : 0.33475000225007534\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 129 Acc : 0.9261999936103821 Test Acc : 0.33462500234134496\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 130 Acc : 0.930799993276596 Test Acc : 0.33300000219605863\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 131 Acc : 0.9367999935150146 Test Acc : 0.33625000236555935\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 132 Acc : 0.9379999918937683 Test Acc : 0.33837500230409207\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 133 Acc : 0.937799993276596 Test Acc : 0.33612500269897283\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 134 Acc : 0.9393999931812287 Test Acc : 0.33625000176019965\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 135 Acc : 0.941799993276596 Test Acc : 0.3395000017620623\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 136 Acc : 0.940999993801117 Test Acc : 0.3408750015310943\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 137 Acc : 0.9373999931812287 Test Acc : 0.3386250015068799\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 138 Acc : 0.9409999928474426 Test Acc : 0.34175000175833703\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 139 Acc : 0.9443999941349029 Test Acc : 0.34362500230781734\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 140 Acc : 0.950199993133545 Test Acc : 0.34587500215508044\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 141 Acc : 0.9557999942302704 Test Acc : 0.3477500014193356\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 142 Acc : 0.9547999930381775 Test Acc : 0.3507500014360994\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 143 Acc : 0.9529999916553498 Test Acc : 0.3475000019185245\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 144 Acc : 0.9571999926567077 Test Acc : 0.3433750023134053\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 145 Acc : 0.9605999929904938 Test Acc : 0.34537500159814954\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 146 Acc : 0.960799993276596 Test Acc : 0.34837500169873237\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 147 Acc : 0.9621999933719635 Test Acc : 0.3443750019092113\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Acc : 0.9651999943256379 Test Acc : 0.34875000164844094\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 149 Acc : 0.9677999930381775 Test Acc : 0.34162500164471565\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 150 Acc : 0.9695999948978424 Test Acc : 0.3437500017974526\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 151 Acc : 0.9677999942302704 Test Acc : 0.35212500124238433\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 152 Acc : 0.9649999942779541 Test Acc : 0.3458750018384308\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 153 Acc : 0.9669999942779541 Test Acc : 0.3452500022109598\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 154 Acc : 0.9635999937057496 Test Acc : 0.3428750014677644\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 155 Acc : 0.9669999938011169 Test Acc : 0.3410000015888363\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 156 Acc : 0.9647999927997589 Test Acc : 0.3421250021085143\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 157 Acc : 0.9627999930381775 Test Acc : 0.34162500196136536\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 158 Acc : 0.9649999933242798 Test Acc : 0.3455000019352883\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 159 Acc : 0.9723999946117401 Test Acc : 0.3468750013690442\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 160 Acc : 0.9709999945163726 Test Acc : 0.3465000014938414\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 161 Acc : 0.9701999938488006 Test Acc : 0.33762500137090684\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 162 Acc : 0.972399994134903 Test Acc : 0.33812500261701645\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 163 Acc : 0.9719999940395355 Test Acc : 0.3373750018421561\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 164 Acc : 0.969399994134903 Test Acc : 0.3391250017937273\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 165 Acc : 0.9679999938011169 Test Acc : 0.33837500205263493\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 166 Acc : 0.9717999939918518 Test Acc : 0.34175000209361317\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 167 Acc : 0.972999995470047 Test Acc : 0.3340000016987324\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 168 Acc : 0.9765999948978424 Test Acc : 0.3432500019110739\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 169 Acc : 0.9829999959468841 Test Acc : 0.3427500015124679\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 170 Acc : 0.9831999959945679 Test Acc : 0.33937500216066835\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 171 Acc : 0.9799999961853028 Test Acc : 0.32962500179186466\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 172 Acc : 0.978999995470047 Test Acc : 0.33887500188313424\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 173 Acc : 0.985999997138977 Test Acc : 0.3307500021252781\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 174 Acc : 0.9859999966621399 Test Acc : 0.3385000027064234\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 175 Acc : 0.9897999975681305 Test Acc : 0.3358750017825514\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 176 Acc : 0.987399996995926 Test Acc : 0.33450000195764007\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 177 Acc : 0.9855999970436096 Test Acc : 0.33600000229664145\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 178 Acc : 0.9751999952793121 Test Acc : 0.33637500179931523\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 179 Acc : 0.9809999959468841 Test Acc : 0.3320000015944242\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 180 Acc : 0.9819999961853028 Test Acc : 0.3330000024288893\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 181 Acc : 0.982399995803833 Test Acc : 0.3340000021085143\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 182 Acc : 0.9845999963283539 Test Acc : 0.3326250015292317\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 183 Acc : 0.9835999960899353 Test Acc : 0.3337500019930303\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 184 Acc : 0.9799999961853028 Test Acc : 0.33200000224635007\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 185 Acc : 0.9747999944686889 Test Acc : 0.33887500144541266\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 186 Acc : 0.982399995803833 Test Acc : 0.3407500013429672\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 187 Acc : 0.9815999958515167 Test Acc : 0.33587500197812914\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 188 Acc : 0.982399995803833 Test Acc : 0.33450000141747294\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 189 Acc : 0.9867999975681305 Test Acc : 0.3276250016037375\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 190 Acc : 0.9885999975204468 Test Acc : 0.32437500257976354\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 191 Acc : 0.9903999977111816 Test Acc : 0.33600000211037695\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 192 Acc : 0.983199996471405 Test Acc : 0.3315000015869737\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 193 Acc : 0.9837999966144562 Test Acc : 0.33225000243633984\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 194 Acc : 0.9855999968051911 Test Acc : 0.3357500015106052\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 195 Acc : 0.9867999968528748 Test Acc : 0.33250000175088645\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 196 Acc : 0.9843999967575073 Test Acc : 0.3353750025108457\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 197 Acc : 0.9879999973773956 Test Acc : 0.33462500172667203\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 198 Acc : 0.9857999968528748 Test Acc : 0.3360000020638108\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 199 Acc : 0.9809999959468841 Test Acc : 0.3425000023469329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. layer normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l2 = CNN(3,16,16); l2n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l3 = CNN(3,16,16); l3n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l4 = CNN(3,16,16); l4n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l5 = CNN(3,16,16); l5n = tf_layer_norm_layer(batch_size,(1,2,3))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Layer Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Layer Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('Layer Norm/train.npy',train_acc)\n",
    "np.save('Layer Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T02:08:31.123482Z",
     "start_time": "2018-12-21T01:34:59.902280Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 0 Acc : 0.22260000279545783 Test Acc : 0.21975000274367631\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 1 Acc : 0.31740000219643116 Test Acc : 0.20975000359117985\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 2 Acc : 0.35960000155866145 Test Acc : 0.2136250035278499\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 3 Acc : 0.39680000112950803 Test Acc : 0.19737500299699604\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 4 Acc : 0.42100000075995925 Test Acc : 0.20587500284425914\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 5 Acc : 0.4434000019580126 Test Acc : 0.1856250030826777\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 6 Acc : 0.4574000013619661 Test Acc : 0.19950000279583036\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 7 Acc : 0.47240000143647193 Test Acc : 0.19662500304169953\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 8 Acc : 0.48620000034570693 Test Acc : 0.19575000322423874\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 9 Acc : 0.49740000122785566 Test Acc : 0.19100000334903597\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 10 Acc : 0.5029999996423722 Test Acc : 0.186375003028661\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 11 Acc : 0.5163999998569488 Test Acc : 0.18312500301748513\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 12 Acc : 0.5282000013887882 Test Acc : 0.16825000301003457\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 13 Acc : 0.5366000007688999 Test Acc : 0.16600000267848372\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 14 Acc : 0.5500000010728836 Test Acc : 0.169000002797693\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 15 Acc : 0.5598000010251999 Test Acc : 0.1611250029783696\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 16 Acc : 0.5671999999284745 Test Acc : 0.15862500290386378\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 17 Acc : 0.5746000012159348 Test Acc : 0.15587500300258397\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 18 Acc : 0.5838000009059906 Test Acc : 0.1546250027604401\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 19 Acc : 0.591800001859665 Test Acc : 0.15012500260956585\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 20 Acc : 0.604200000166893 Test Acc : 0.15550000282004475\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 21 Acc : 0.610799999833107 Test Acc : 0.14762500279583038\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 22 Acc : 0.6178000009059906 Test Acc : 0.14975000265985727\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 23 Acc : 0.6225999990701675 Test Acc : 0.1498750025127083\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 24 Acc : 0.6316000001430512 Test Acc : 0.1543750026449561\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 25 Acc : 0.6383999977111816 Test Acc : 0.15600000268779696\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 26 Acc : 0.6445999981164933 Test Acc : 0.15900000284425914\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 27 Acc : 0.6525999982357025 Test Acc : 0.15925000263378025\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 28 Acc : 0.6553999981880188 Test Acc : 0.15300000280141832\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 29 Acc : 0.662199998497963 Test Acc : 0.15775000263005495\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 30 Acc : 0.6679999983310699 Test Acc : 0.15562500262632967\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 31 Acc : 0.671199998140335 Test Acc : 0.15675000271759928\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 32 Acc : 0.6791999998092652 Test Acc : 0.1560000029206276\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 33 Acc : 0.6849999997615814 Test Acc : 0.15762500278651714\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 34 Acc : 0.6902000004053116 Test Acc : 0.15387500292621553\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 35 Acc : 0.6960000003576279 Test Acc : 0.15462500282563268\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 36 Acc : 0.6984000008106231 Test Acc : 0.15487500282935798\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 37 Acc : 0.704599999666214 Test Acc : 0.15475000287406146\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 38 Acc : 0.7052000015974045 Test Acc : 0.15312500258907677\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 39 Acc : 0.7104000012874603 Test Acc : 0.14825000283308326\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 40 Acc : 0.718399999499321 Test Acc : 0.14812500290572644\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 41 Acc : 0.725400001168251 Test Acc : 0.14912500302307308\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 42 Acc : 0.727800000667572 Test Acc : 0.14937500292435288\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 43 Acc : 0.729600001335144 Test Acc : 0.15487500296905637\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 44 Acc : 0.7364000012874603 Test Acc : 0.15325000289827584\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 45 Acc : 0.7418000011444091 Test Acc : 0.15362500303424895\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 46 Acc : 0.746600001692772 Test Acc : 0.15575000289827584\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 47 Acc : 0.7508000019788742 Test Acc : 0.15912500279024244\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 48 Acc : 0.752800000667572 Test Acc : 0.15087500329129397\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 49 Acc : 0.7590000017881393 Test Acc : 0.1567500028759241\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 50 Acc : 0.7610000022649765 Test Acc : 0.15762500318698586\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 51 Acc : 0.7684000016450881 Test Acc : 0.1582500029075891\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 52 Acc : 0.7728000024557113 Test Acc : 0.16062500313855707\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 53 Acc : 0.7762000027894974 Test Acc : 0.16062500294297932\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 54 Acc : 0.7818000019788742 Test Acc : 0.1600000030081719\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 55 Acc : 0.7836000014543534 Test Acc : 0.1578750031813979\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 56 Acc : 0.7896000019311905 Test Acc : 0.16200000301934778\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 57 Acc : 0.7898000031709671 Test Acc : 0.16400000309571625\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 58 Acc : 0.7926000031232834 Test Acc : 0.16175000295974315\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 59 Acc : 0.7972000013589859 Test Acc : 0.1587500029616058\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 60 Acc : 0.8018000003099441 Test Acc : 0.1621250030770898\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 61 Acc : 0.7999999998807907 Test Acc : 0.16000000304542483\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 62 Acc : 0.8078000011444092 Test Acc : 0.15500000327825547\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 63 Acc : 0.8084000014066696 Test Acc : 0.15087500311434268\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 64 Acc : 0.8148000028133392 Test Acc : 0.15162500298582018\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 65 Acc : 0.8212000019550324 Test Acc : 0.14925000282004475\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 66 Acc : 0.8246000022888184 Test Acc : 0.15225000272504985\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 67 Acc : 0.827200002670288 Test Acc : 0.14950000285170972\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 68 Acc : 0.8298000028133392 Test Acc : 0.15075000294484198\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 69 Acc : 0.828600002527237 Test Acc : 0.15450000327080488\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 70 Acc : 0.8310000021457672 Test Acc : 0.15237500291317702\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 71 Acc : 0.835400002002716 Test Acc : 0.1523750030528754\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 72 Acc : 0.8396000030040741 Test Acc : 0.15325000300072134\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 73 Acc : 0.842800000667572 Test Acc : 0.1546250030398369\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 74 Acc : 0.8456000018119813 Test Acc : 0.14925000303424896\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 75 Acc : 0.8474000008106232 Test Acc : 0.15112500317394734\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 76 Acc : 0.8516000003814698 Test Acc : 0.14962500297464432\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 77 Acc : 0.8563999993801117 Test Acc : 0.14762500279583038\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 78 Acc : 0.8580000002384186 Test Acc : 0.1476250030938536\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 79 Acc : 0.8565999982357025 Test Acc : 0.14812500294297934\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 80 Acc : 0.8587999994754791 Test Acc : 0.14487500289455058\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 81 Acc : 0.8599999985694885 Test Acc : 0.14337500298395753\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 82 Acc : 0.8645999987125397 Test Acc : 0.14287500265985728\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 83 Acc : 0.8659999976158143 Test Acc : 0.14212500298395753\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 84 Acc : 0.8617999987602234 Test Acc : 0.14550000293180346\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 85 Acc : 0.8625999991893768 Test Acc : 0.14537500289268793\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 86 Acc : 0.8677999994754791 Test Acc : 0.14212500288151206\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 87 Acc : 0.8725999975204468 Test Acc : 0.1416250029671937\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 88 Acc : 0.8731999971866607 Test Acc : 0.14025000287219883\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 89 Acc : 0.8787999970912933 Test Acc : 0.13962500285357238\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 90 Acc : 0.8829999980926514 Test Acc : 0.1383750028256327\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 91 Acc : 0.883799997806549 Test Acc : 0.13987500269897282\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 92 Acc : 0.8819999976158142 Test Acc : 0.1410000026319176\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 93 Acc : 0.8829999985694885 Test Acc : 0.14150000300258397\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 94 Acc : 0.8887999973297119 Test Acc : 0.1422500027436763\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 95 Acc : 0.8905999960899353 Test Acc : 0.13912500287406146\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 96 Acc : 0.8895999972820282 Test Acc : 0.13700000288896264\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 97 Acc : 0.8969999964237213 Test Acc : 0.13900000299327075\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 98 Acc : 0.8965999960899353 Test Acc : 0.14000000298954546\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 99 Acc : 0.9009999949932098 Test Acc : 0.13887500301003455\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 100 Acc : 0.9057999954223633 Test Acc : 0.14050000303424895\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 101 Acc : 0.9021999945640564 Test Acc : 0.13500000277534127\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 102 Acc : 0.8955999956130981 Test Acc : 0.13900000289082526\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 103 Acc : 0.9049999957084656 Test Acc : 0.13662500305101274\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 104 Acc : 0.9035999960899354 Test Acc : 0.13637500274926423\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 105 Acc : 0.9069999945163727 Test Acc : 0.13725000282749533\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 106 Acc : 0.9121999928951263 Test Acc : 0.1378750027436763\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 107 Acc : 0.9103999950885773 Test Acc : 0.13525000265799464\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 108 Acc : 0.9133999938964844 Test Acc : 0.13850000286474823\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.05\n",
      " Current : 109 Acc : 0.9117999932765961 Test Acc : 0.13700000273995103\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 110 Acc : 0.9177999927997589 Test Acc : 0.13850000283680855\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 111 Acc : 0.9215999934673309 Test Acc : 0.13875000281259417\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 112 Acc : 0.9175999929904938 Test Acc : 0.12562500234693288\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 113 Acc : 0.9235999927520752 Test Acc : 0.13187500262632967\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 114 Acc : 0.9243999917507172 Test Acc : 0.12900000265799463\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 115 Acc : 0.9227999927997589 Test Acc : 0.13112500256858767\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 116 Acc : 0.9283999924659729 Test Acc : 0.12912500258535148\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 117 Acc : 0.931799991607666 Test Acc : 0.12975000265985728\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 118 Acc : 0.9307999920845031 Test Acc : 0.12250000240281224\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 119 Acc : 0.934999992609024 Test Acc : 0.1257500024791807\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 120 Acc : 0.9349999928474426 Test Acc : 0.1260000026691705\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 121 Acc : 0.9367999923229218 Test Acc : 0.12162500248290599\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 122 Acc : 0.9385999927520752 Test Acc : 0.12625000247731805\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 123 Acc : 0.936599992275238 Test Acc : 0.12137500254437328\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 124 Acc : 0.9299999933242797 Test Acc : 0.12125000237487256\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 125 Acc : 0.9385999917984009 Test Acc : 0.12462500252760947\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 126 Acc : 0.940199991941452 Test Acc : 0.12637500246986746\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 127 Acc : 0.9427999927997589 Test Acc : 0.12412500254809856\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 128 Acc : 0.9439999933242798 Test Acc : 0.12650000251829624\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 129 Acc : 0.9477999925613403 Test Acc : 0.12350000249221921\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 130 Acc : 0.9475999917984009 Test Acc : 0.126500002713874\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 131 Acc : 0.945399992465973 Test Acc : 0.12962500249035658\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 132 Acc : 0.9493999922275543 Test Acc : 0.1237500024586916\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 133 Acc : 0.9487999913692474 Test Acc : 0.12762500257231296\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 134 Acc : 0.9511999928951264 Test Acc : 0.12412500253878533\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 135 Acc : 0.9503999927043915 Test Acc : 0.12637500263750553\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 136 Acc : 0.952399992465973 Test Acc : 0.12825000271201134\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 137 Acc : 0.9493999917507172 Test Acc : 0.12975000259466468\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 138 Acc : 0.9549999921321869 Test Acc : 0.13237500259652735\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 139 Acc : 0.955999992609024 Test Acc : 0.13400000284425914\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 140 Acc : 0.9601999926567077 Test Acc : 0.13537500280886888\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 141 Acc : 0.9627999925613403 Test Acc : 0.13012500274926425\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 142 Acc : 0.9659999938011169 Test Acc : 0.13050000277347862\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 143 Acc : 0.9649999933242798 Test Acc : 0.1321250027883798\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 144 Acc : 0.9629999933242798 Test Acc : 0.1327500027231872\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 145 Acc : 0.9675999932289123 Test Acc : 0.13087500259280205\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 146 Acc : 0.9569999928474426 Test Acc : 0.12875000276602805\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 147 Acc : 0.9649999928474426 Test Acc : 0.13312500273808836\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 148 Acc : 0.9713999931812286 Test Acc : 0.12800000250339508\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 149 Acc : 0.9727999937534332 Test Acc : 0.12912500243633984\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 150 Acc : 0.9729999940395355 Test Acc : 0.12725000247359275\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 151 Acc : 0.9739999945163726 Test Acc : 0.1278750024549663\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 152 Acc : 0.9729999935626984 Test Acc : 0.12862500266171992\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 153 Acc : 0.9763999950885772 Test Acc : 0.12700000246055423\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 154 Acc : 0.9767999944686889 Test Acc : 0.12437500232830644\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 155 Acc : 0.9783999953269958 Test Acc : 0.12500000243075193\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 156 Acc : 0.9763999946117401 Test Acc : 0.12762500253506004\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 157 Acc : 0.9755999946594238 Test Acc : 0.1306250024586916\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 158 Acc : 0.9761999945640564 Test Acc : 0.12287500229664147\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 159 Acc : 0.9761999945640564 Test Acc : 0.12512500233948232\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 160 Acc : 0.9819999961853028 Test Acc : 0.12575000252574683\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 161 Acc : 0.9843999962806702 Test Acc : 0.1250000023841858\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 162 Acc : 0.9829999959468841 Test Acc : 0.12237500227987766\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 163 Acc : 0.9835999963283539 Test Acc : 0.12200000241398812\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 164 Acc : 0.9793999955654145 Test Acc : 0.12500000247731805\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 165 Acc : 0.9801999952793121 Test Acc : 0.12487500249408186\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 166 Acc : 0.9833999960422516 Test Acc : 0.12550000254064797\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 167 Acc : 0.9847999963760375 Test Acc : 0.13300000264309347\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 168 Acc : 0.9847999966144562 Test Acc : 0.12525000263005495\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 169 Acc : 0.9835999960899353 Test Acc : 0.1330000028014183\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 170 Acc : 0.9875999970436096 Test Acc : 0.13275000282563268\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 171 Acc : 0.9831999959945679 Test Acc : 0.12950000265613199\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 172 Acc : 0.9861999967098236 Test Acc : 0.1282500026654452\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 173 Acc : 0.9813999955654145 Test Acc : 0.12650000248104334\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 174 Acc : 0.9845999965667724 Test Acc : 0.12712500248104333\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 175 Acc : 0.9853999965190887 Test Acc : 0.12487500253133475\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 176 Acc : 0.9853999965190887 Test Acc : 0.12950000263750552\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 177 Acc : 0.9879999973773956 Test Acc : 0.1265000024717301\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 178 Acc : 0.9899999985694885 Test Acc : 0.12775000249966978\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 179 Acc : 0.9909999978542328 Test Acc : 0.13125000235624612\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 180 Acc : 0.9905999977588653 Test Acc : 0.12712500266730786\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 181 Acc : 0.9871999969482422 Test Acc : 0.1288750025909394\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 182 Acc : 0.9879999973773956 Test Acc : 0.12775000246241688\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 183 Acc : 0.9883999972343445 Test Acc : 0.12725000246427953\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 184 Acc : 0.9919999980926514 Test Acc : 0.12762500263750554\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 185 Acc : 0.9909999978542328 Test Acc : 0.12575000265613198\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 186 Acc : 0.9925999982357026 Test Acc : 0.12400000260211527\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 187 Acc : 0.9925999982357026 Test Acc : 0.1307500025909394\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 188 Acc : 0.9935999984741211 Test Acc : 0.127625002739951\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 189 Acc : 0.9953999989032746 Test Acc : 0.12662500251084566\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 190 Acc : 0.9953999989032746 Test Acc : 0.12300000261515379\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 191 Acc : 0.9941999986171722 Test Acc : 0.1292500026151538\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 192 Acc : 0.9947999987602234 Test Acc : 0.12425000263378023\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 193 Acc : 0.9923999984264373 Test Acc : 0.12362500244751573\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 194 Acc : 0.9921999981403351 Test Acc : 0.12637500252574682\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.15\n",
      " Current : 195 Acc : 0.9949999988079071 Test Acc : 0.1251250024046749\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 196 Acc : 0.9933999984264373 Test Acc : 0.1287500024214387\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 197 Acc : 0.9965999991893768 Test Acc : 0.12762500264681875\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 198 Acc : 0.9953999989032746 Test Acc : 0.1276250025536865\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 199 Acc : 0.9935999984741211 Test Acc : 0.12412500258535147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Instance normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_instance_norm_layer(batch_size,16,(1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Instace Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Instace Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('Instace Norm/train.npy',train_acc)\n",
    "np.save('Instace Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T02:39:32.368702Z",
     "start_time": "2018-12-21T02:08:31.570288Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 0 Acc : 0.1184000024497509 Test Acc : 0.19825000354088843\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.20420000283420087 Test Acc : 0.2253750032093376\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 2 Acc : 0.24180000299215318 Test Acc : 0.28750000209547577\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 3 Acc : 0.279200002476573 Test Acc : 0.3228750020544976\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 4 Acc : 0.3046000020802021 Test Acc : 0.3195000020880252\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 5 Acc : 0.3152000018954277 Test Acc : 0.32300000156275926\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 6 Acc : 0.33840000170469287 Test Acc : 0.35512500192038715\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Acc : 0.3432000022530556 Test Acc : 0.36687500193715095\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 8 Acc : 0.3562000018209219 Test Acc : 0.36437500102445486\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 9 Acc : 0.36440000136196615 Test Acc : 0.367875001039356\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 10 Acc : 0.3720000020116568 Test Acc : 0.3762500013783574\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 11 Acc : 0.3802000005543232 Test Acc : 0.38125000124797226\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 12 Acc : 0.38760000106692316 Test Acc : 0.3875000013411045\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 13 Acc : 0.3920000002384186 Test Acc : 0.3965000008232892\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 14 Acc : 0.39740000054240227 Test Acc : 0.3941250015422702\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 15 Acc : 0.4020000011026859 Test Acc : 0.39850000087171794\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 16 Acc : 0.4120000008940697 Test Acc : 0.4038750004023314\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Acc : 0.41540000104904173 Test Acc : 0.40950000116601587\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 18 Acc : 0.4220000017285347 Test Acc : 0.4123750003427267\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 19 Acc : 0.42380000126361844 Test Acc : 0.4142500016838312\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 20 Acc : 0.4294000012874603 Test Acc : 0.41662500098347666\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 21 Acc : 0.4348000020086765 Test Acc : 0.42137500137090683\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 22 Acc : 0.43620000103116036 Test Acc : 0.421000002194196\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Acc : 0.4412000017464161 Test Acc : 0.42362500255927443\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Acc : 0.4464000009000301 Test Acc : 0.4247500019520521\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Acc : 0.4494000013768673 Test Acc : 0.4271250019967556\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 26 Acc : 0.44980000039935114 Test Acc : 0.4317500017955899\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 27 Acc : 0.45700000047683714 Test Acc : 0.43225000191479923\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 28 Acc : 0.4594000002145767 Test Acc : 0.4340000019967556\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 29 Acc : 0.4614000002741814 Test Acc : 0.4365000012516975\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 30 Acc : 0.4654000014066696 Test Acc : 0.4371250010840595\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 31 Acc : 0.46480000072717664 Test Acc : 0.4370000010728836\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 32 Acc : 0.46800000125169755 Test Acc : 0.43950000083073976\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.46980000132322314 Test Acc : 0.43912500113248826\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.4734000015258789 Test Acc : 0.44200000163167713\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.4762000011205673 Test Acc : 0.44162500139325855\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.4798000019788742 Test Acc : 0.4416250021383166\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 37 Acc : 0.4770000015497208 Test Acc : 0.44312500160187485\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 38 Acc : 0.4818000019788742 Test Acc : 0.4486250016093254\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.48460000175237655 Test Acc : 0.4491250013560057\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 40 Acc : 0.48560000187158586 Test Acc : 0.4492500015720725\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 41 Acc : 0.4840000013709068 Test Acc : 0.44987500213086606\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 42 Acc : 0.48680000060796735 Test Acc : 0.4506250013783574\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Acc : 0.49240000134706496 Test Acc : 0.45262500137090683\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.4950000012516975 Test Acc : 0.4533750009909272\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 45 Acc : 0.4958000013232231 Test Acc : 0.45425000071525573\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 46 Acc : 0.49700000154972074 Test Acc : 0.45550000086426734\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Acc : 0.4984000011086464 Test Acc : 0.45612500082701446\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.5014000018835068 Test Acc : 0.4545000009983778\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 49 Acc : 0.5054000021219254 Test Acc : 0.4563750005140901\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 50 Acc : 0.5064000009298325 Test Acc : 0.45512500083073976\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 51 Acc : 0.5088000012040138 Test Acc : 0.4562500011734664\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 52 Acc : 0.5114000019431114 Test Acc : 0.45787500133737924\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 53 Acc : 0.5158000016808509 Test Acc : 0.45887500073760745\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 54 Acc : 0.517000002682209 Test Acc : 0.45975000094622376\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 55 Acc : 0.5194000025391579 Test Acc : 0.4601250010356307\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 56 Acc : 0.5232000033259392 Test Acc : 0.46025000113993886\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 57 Acc : 0.5250000030398368 Test Acc : 0.46037500094622374\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 58 Acc : 0.5282000028491021 Test Acc : 0.46062500040978194\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 59 Acc : 0.5298000028729439 Test Acc : 0.46037500055506825\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 60 Acc : 0.5322000032067299 Test Acc : 0.46175000082701445\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 61 Acc : 0.5312000033259392 Test Acc : 0.4615000006183982\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 62 Acc : 0.5330000035166741 Test Acc : 0.4630000011995435\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 63 Acc : 0.5362000030279159 Test Acc : 0.4638750014826655\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 64 Acc : 0.5382000024914741 Test Acc : 0.464000001475215\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 65 Acc : 0.5398000026345253 Test Acc : 0.4647500018402934\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 66 Acc : 0.5414000027775765 Test Acc : 0.46737500151619316\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 67 Acc : 0.5442000019550324 Test Acc : 0.4676250018924475\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 68 Acc : 0.5448000022172927 Test Acc : 0.4693750012293458\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 69 Acc : 0.5468000020980835 Test Acc : 0.46950000133365394\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 70 Acc : 0.5484000023603439 Test Acc : 0.4696250018104911\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 71 Acc : 0.5498000022172927 Test Acc : 0.4707500020042062\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 72 Acc : 0.5516000024080276 Test Acc : 0.47062500204890967\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 73 Acc : 0.5526000024080276 Test Acc : 0.4711250024661422\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 74 Acc : 0.55480000269413 Test Acc : 0.472125001847744\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 75 Acc : 0.5568000020980834 Test Acc : 0.47162500221282244\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Acc : 0.5580000017881394 Test Acc : 0.47150000181049107\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 77 Acc : 0.5584000020027161 Test Acc : 0.47175000187009575\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 78 Acc : 0.5602000014781952 Test Acc : 0.4746250015869737\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 79 Acc : 0.5622000012397766 Test Acc : 0.4746250016614795\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 80 Acc : 0.5648000011444092 Test Acc : 0.4750000017508864\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 81 Acc : 0.5684000008702278 Test Acc : 0.47537500157952306\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 82 Acc : 0.5702000009417534 Test Acc : 0.4751250015944242\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 83 Acc : 0.5742000016570091 Test Acc : 0.4761250014230609\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 84 Acc : 0.5748000019192696 Test Acc : 0.4765000015497208\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 85 Acc : 0.5758000007867813 Test Acc : 0.47775000125169753\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 86 Acc : 0.5792000018358231 Test Acc : 0.47687500149011613\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 87 Acc : 0.5822000019550323 Test Acc : 0.47612500086426734\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 88 Acc : 0.5832000018358231 Test Acc : 0.4765000004321337\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 89 Acc : 0.5872000024914742 Test Acc : 0.4765000005811453\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 90 Acc : 0.5886000018119812 Test Acc : 0.47550000093877315\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 91 Acc : 0.5914000010490418 Test Acc : 0.4756250002235174\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 92 Acc : 0.5946000007390976 Test Acc : 0.47687500044703485\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 93 Acc : 0.5966000015735626 Test Acc : 0.4762500001117587\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 94 Acc : 0.5964000021219253 Test Acc : 0.4761250001937151\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 95 Acc : 0.6016000014543533 Test Acc : 0.4760000003501773\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 96 Acc : 0.6032000010013581 Test Acc : 0.4761250004172325\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 97 Acc : 0.6054000005722046 Test Acc : 0.47600000008940696\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 98 Acc : 0.6075999997854232 Test Acc : 0.4773750004917383\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 99 Acc : 0.6073999990224839 Test Acc : 0.4765000007301569\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 100 Acc : 0.612600000500679 Test Acc : 0.4752500006556511\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 101 Acc : 0.6135999993085861 Test Acc : 0.47812500070780517\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Acc : 0.6177999988794327 Test Acc : 0.475625000372529\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 103 Acc : 0.6197999987602234 Test Acc : 0.47475000061094763\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 104 Acc : 0.6207999994754791 Test Acc : 0.47637500081211326\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Acc : 0.6232000000476837 Test Acc : 0.4768750001862645\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 106 Acc : 0.6252000010013581 Test Acc : 0.4788750013709068\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 107 Acc : 0.6272000000476837 Test Acc : 0.47937500193715094\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 108 Acc : 0.6273999992609024 Test Acc : 0.4791250016540289\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 109 Acc : 0.6303999999761581 Test Acc : 0.47750000171363355\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 110 Acc : 0.632599998831749 Test Acc : 0.4771250019595027\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 111 Acc : 0.6336000000238419 Test Acc : 0.4762500016018748\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 112 Acc : 0.6352000004053115 Test Acc : 0.4785000021383166\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Acc : 0.6384000005722046 Test Acc : 0.4776250021532178\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Acc : 0.6392000002861022 Test Acc : 0.48150000121444464\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Acc : 0.6405999993085861 Test Acc : 0.48125000189989803\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Acc : 0.6417999986410141 Test Acc : 0.4732500010356307\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Acc : 0.6453999992609024 Test Acc : 0.47375000212341545\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Acc : 0.6469999994039536 Test Acc : 0.47000000171363354\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Acc : 0.6493999999761582 Test Acc : 0.4740000018849969\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 120 Acc : 0.6513999985456467 Test Acc : 0.47575000178068877\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Acc : 0.6503999989032745 Test Acc : 0.4788750010728836\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 122 Acc : 0.6463999984264374 Test Acc : 0.4761250004544854\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Acc : 0.6237999972105026 Test Acc : 0.47312500115484\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 124 Acc : 0.6535999995470047 Test Acc : 0.4755000016838312\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Acc : 0.6567999991178513 Test Acc : 0.4731250013411045\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Acc : 0.6633999981880188 Test Acc : 0.4706250014156103\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Acc : 0.6647999988794326 Test Acc : 0.4737500011175871\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Acc : 0.6617999979257584 Test Acc : 0.47475000120699407\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Acc : 0.6649999978542328 Test Acc : 0.4720000012591481\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Acc : 0.6631999979019165 Test Acc : 0.4700000013783574\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Acc : 0.6681999982595443 Test Acc : 0.4733750021830201\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Acc : 0.6665999981164932 Test Acc : 0.47075000178068876\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Acc : 0.6653999992609024 Test Acc : 0.4571250018849969\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 134 Acc : 0.6603999978303909 Test Acc : 0.4775000023841858\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Acc : 0.6604000000953675 Test Acc : 0.4566250013187528\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Acc : 0.6641999970674515 Test Acc : 0.4588750009983778\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 137 Acc : 0.6719999977350235 Test Acc : 0.4552500007674098\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Acc : 0.6709999973773957 Test Acc : 0.45550000097602605\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 139 Acc : 0.6715999988317489 Test Acc : 0.46300000078976156\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 140 Acc : 0.6811999982595444 Test Acc : 0.4608750012889504\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 141 Acc : 0.6505999964475632 Test Acc : 0.47462500240653754\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 142 Acc : 0.6775999997854233 Test Acc : 0.4640000019967556\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 143 Acc : 0.6833999997377396 Test Acc : 0.4621250019222498\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 144 Acc : 0.6877999981641769 Test Acc : 0.47000000104308126\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 145 Acc : 0.6923999979496002 Test Acc : 0.4688750002160668\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 146 Acc : 0.693399999499321 Test Acc : 0.47050000097602607\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 147 Acc : 0.6957999984025955 Test Acc : 0.4610000010207295\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Acc : 0.6941999994516372 Test Acc : 0.45962500184774396\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 149 Acc : 0.6959999996423721 Test Acc : 0.4662500012665987\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 150 Acc : 0.6793999977111816 Test Acc : 0.4587500010803342\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 151 Acc : 0.6818000003099441 Test Acc : 0.4617500014230609\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 152 Acc : 0.6939999994039535 Test Acc : 0.46475000098347663\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 153 Acc : 0.7014000000953674 Test Acc : 0.46500000048428775\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 154 Acc : 0.705399999499321 Test Acc : 0.4731250011920929\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 155 Acc : 0.696599999666214 Test Acc : 0.4563750012591481\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 156 Acc : 0.7055999995470047 Test Acc : 0.4687500004842877\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 157 Acc : 0.6770000005960465 Test Acc : 0.4601250013336539\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 158 Acc : 0.6962000023126602 Test Acc : 0.4587500014342368\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 159 Acc : 0.7072000012397767 Test Acc : 0.4663750019483268\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 160 Acc : 0.7122000004053116 Test Acc : 0.4661250016093254\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 161 Acc : 0.715400002360344 Test Acc : 0.4607500010356307\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 162 Acc : 0.705000000834465 Test Acc : 0.45737500172108414\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 163 Acc : 0.6962000002861023 Test Acc : 0.4673750015348196\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 164 Acc : 0.702600001335144 Test Acc : 0.44725000161677597\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 165 Acc : 0.7048000012636184 Test Acc : 0.462625001128763\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 166 Acc : 0.6936000003814697 Test Acc : 0.4500000012293458\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 167 Acc : 0.6848000013828277 Test Acc : 0.46375000160187485\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 168 Acc : 0.6968000012636185 Test Acc : 0.46450000200420616\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 169 Acc : 0.7052000020742416 Test Acc : 0.4666250018030405\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 170 Acc : 0.7188000017404557 Test Acc : 0.46775000154972074\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 171 Acc : 0.7208000017404557 Test Acc : 0.4656250013038516\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 172 Acc : 0.7230000010728836 Test Acc : 0.46650000106543305\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 173 Acc : 0.7271999999284744 Test Acc : 0.46350000105798245\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 174 Acc : 0.7232000000476837 Test Acc : 0.4532500013522804\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 175 Acc : 0.7091999998092652 Test Acc : 0.45387500114738943\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 176 Acc : 0.7114000015258789 Test Acc : 0.4625000013783574\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 177 Acc : 0.7096000006198883 Test Acc : 0.4315000019222498\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 178 Acc : 0.6810000004768372 Test Acc : 0.45262500070035455\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 179 Acc : 0.7130000007152557 Test Acc : 0.44037500144913794\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 180 Acc : 0.7174000005722045 Test Acc : 0.44312500186264514\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 181 Acc : 0.7252000010013581 Test Acc : 0.4752500007674098\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 182 Acc : 0.7306000001430512 Test Acc : 0.45287500094622374\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 183 Acc : 0.7281999995708466 Test Acc : 0.4515000018104911\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 184 Acc : 0.7293999996185303 Test Acc : 0.4441250020265579\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 185 Acc : 0.731199999332428 Test Acc : 0.42287500182166693\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 186 Acc : 0.7102000002861023 Test Acc : 0.44275000048801305\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 187 Acc : 0.7042000008821487 Test Acc : 0.4505000009387732\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 188 Acc : 0.7067999991178513 Test Acc : 0.4417500010598451\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 189 Acc : 0.7268000012636184 Test Acc : 0.4575000015087426\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 190 Acc : 0.7393999989032746 Test Acc : 0.4421250016242266\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 191 Acc : 0.7422000012397766 Test Acc : 0.448500001616776\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 192 Acc : 0.7522000012397766 Test Acc : 0.44587500173598527\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 193 Acc : 0.7535999996662139 Test Acc : 0.4390000016987324\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 194 Acc : 0.7519999985694885 Test Acc : 0.4503750012814999\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 195 Acc : 0.7486000006198883 Test Acc : 0.43387500105425714\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 196 Acc : 0.7328000004291535 Test Acc : 0.4512500022165477\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 197 Acc : 0.7268000024557114 Test Acc : 0.4131250010430813\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 198 Acc : 0.7087999995946884 Test Acc : 0.46575000151991847\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 199 Acc : 0.7432000010013581 Test Acc : 0.459375001937151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. box cox \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_box_cox()\n",
    "l2 = CNN(3,16,16); l2n = tf_box_cox()\n",
    "l3 = CNN(3,16,16); l3n = tf_box_cox()\n",
    "\n",
    "l4 = CNN(3,16,16); l4n = tf_box_cox()\n",
    "l5 = CNN(3,16,16); l5n = tf_box_cox()\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1a = l1n.feedforward(layer1a)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer2a = l2n.feedforward(layer2a)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer3a = l3n.feedforward(layer3a)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer4a = l4n.feedforward(layer4a)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer5a = l5n.feedforward(layer5a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up  = l6.backprop(gradient)\n",
    "grad5n,grad5l,grad5n_up = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up  = l5.backprop(grad5n)\n",
    "grad4n,grad4l,grad4n_up = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up  = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n,grad3l,grad3n_up = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up  = l3.backprop(grad3n,stride=2)\n",
    "grad2n,grad2l,grad2n_up = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up  = l2.backprop(grad2n,stride=2)\n",
    "grad1n,grad1l,grad1n_up = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up  = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5n_up + grad5_up + grad4n_up +  grad4_up + grad3n_up + grad3_up + grad2n_up + grad2_up + grad1n_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Box Cox/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Box Cox/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Box Cox/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Box Cox/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save('Box Cox/train.npy',train_acc)\n",
    "np.save('Box Cox/test.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T03:53:39.768614Z",
     "start_time": "2018-12-21T03:53:39.601087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read and plot all accuracy\n",
    "normal = np.load('Normal/train.npy')\n",
    "batch  = np.load(\"batch Norm/train.npy\")\n",
    "layer  = np.load(\"Layer Norm/train.npy\")\n",
    "instace= np.load(\"Instace Norm/train.npy\")\n",
    "boxcox = np.load(\"Box Cox/train.npy\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(normal); plt.plot(batch); plt.plot(layer); plt.plot(instace); plt.plot(boxcox); \n",
    "plt.show()\n",
    "\n",
    "normal = np.load('Normal/train.npy')\n",
    "batch  = np.load(\"batch Norm/train.npy\")\n",
    "layer  = np.load(\"Layer Norm/train.npy\")\n",
    "instace= np.load(\"Instace Norm/train.npy\")\n",
    "boxcox = np.load(\"Box Cox/train.npy\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(normal); plt.plot(batch); plt.plot(layer); plt.plot(instace); plt.plot(boxcox); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly\n",
    "3. plot, H. (2010). How to change the font size on a matplotlib plot. Stack Overflow. Retrieved 20 December 2018, from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n",
    "4. ShopRunner/jupyter-notify. (2018). GitHub. Retrieved 20 December 2018, from https://github.com/ShopRunner/jupyter-notify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
