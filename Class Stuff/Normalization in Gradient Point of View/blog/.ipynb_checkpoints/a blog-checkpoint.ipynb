{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:01:19.410253Z",
     "start_time": "2018-12-20T21:01:19.405232Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 35})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:00:18.567808Z",
     "start_time": "2018-12-20T21:00:16.491815Z"
    },
    "code_folding": [
     0,
     2,
     29,
     37
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read all of the data\n",
    "# https://github.com/mttk/STL10\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "def show_images(data,row=1,col=1):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    columns = col; rows = row\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(data[i-1])\n",
    "    plt.show()\n",
    "\n",
    "train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "print(train_images.shape,train_images.max(),train_images.min())\n",
    "print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "print(test_images.shape,test_images.max(),test_images.min())\n",
    "print(test_labels.shape,test_labels.max(),test_labels.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:02:00.227446Z",
     "start_time": "2018-12-20T21:02:00.144670Z"
    },
    "code_folding": [
     15,
     89,
     130,
     171,
     202
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "\n",
    "def tf_elu(x):   return tf.nn.elu(x)\n",
    "def d_tf_elu(x): return tf.cast(tf.greater(x,0),tf.float32)  + (tf_elu(tf.cast(tf.less_equal(x,0),tf.float32) * x) + 1.0)\n",
    "\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "def tf_tanh(x):   return tf.nn.tanh(x)\n",
    "def d_tf_tanh(x): return 1 - tf_tanh(x) ** 2\n",
    "\n",
    "def tf_sigmoid(x):   return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x): return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=4,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        \n",
    "    def getw(self): return self.w\n",
    "\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer,self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n",
    "class tf_layer_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[vector_shape,1,1,1],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w * self.c)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "    \n",
    "class tf_instance_norm_layer():\n",
    "    \n",
    "    def __init__(self,batch_size,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[batch_size,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "        \n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    \n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "  \n",
    "class tf_box_cox():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lmbda    = tf.Variable(2.0) \n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.lmbda)),tf.Variable(tf.zeros_like(self.lmbda))\n",
    "    def getw(self): return self.lmbda\n",
    "    \n",
    "    def feedforward(self,data):\n",
    "        self.input = data\n",
    "        self.layer = tf.pow((self.input + 1.0),self.lmbda)\n",
    "        return (self.layer - 1.0)/(self.lmbda + 1e-8)\n",
    "    \n",
    "    def backprop(self,grad):\n",
    "        \n",
    "        # Gradient that gets passed along\n",
    "        grad_pass = tf.pow((self.input + 1),self.lmbda-1.0) * grad\n",
    "        \n",
    "        # Grad respect to the lmbda value (not tested!)\n",
    "        grad_lmbda1 =   (self.layer * tf.log(self.input + 1 ))/(self.lmbda + 1e-8)\n",
    "        grad_lmbda2 = - (self.layer - 1)/(self.lmbda ** 2 + 1e-8)\n",
    "        grad_lmbda  = tf.reduce_mean((grad_lmbda1 + grad_lmbda2)*grad)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad_lmbda)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad_lmbda ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.lmbda,tf.subtract(self.lmbda,adam_middle  )))\n",
    "        \n",
    "        return grad_pass,grad_lmbda,update_w\n",
    "    \n",
    "def save_to_image(data,name):\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = data\n",
    "    l1g,l2g,l3g,l4g,l5g,l6g = np.asarray(l1g),np.asarray(l2g),np.asarray(l3g),np.asarray(l4g),np.asarray(l5g),np.asarray(l6g)\n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.suptitle('Current Iter : ' + str(iter))\n",
    "    plt.subplot(231); plt.hist(l1g.ravel(),50); plt.title('layer 1')\n",
    "    plt.subplot(232); plt.hist(l2g.ravel(),50); plt.title('layer 2')\n",
    "    plt.subplot(233); plt.hist(l3g.ravel(),50); plt.title('layer 3')\n",
    "    plt.subplot(234); plt.hist(l4g.ravel(),50); plt.title('layer 4')\n",
    "    plt.subplot(235); plt.hist(l5g.ravel(),50); plt.title('layer 5')\n",
    "    plt.subplot(236); plt.hist(l6g.ravel(),50); plt.title('layer 6')\n",
    "    plt.savefig(name + str(iter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.close('all')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:49:36.669478Z",
     "start_time": "2018-12-20T21:49:36.663494Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set hyper parameter\n",
    "num_epoch = 200; learning_rate = 0.0008; batch_size = 20; beta1,beta2,adam_e = 0.9,0.999,1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T21:49:35.661396Z",
     "start_time": "2018-12-20T21:19:25.928419Z"
    },
    "code_folding": [
     0,
     46,
     59
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 0 Acc : 0.10820000241696835 Test Acc : 0.17150000302121043\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 1 Acc : 0.17420000280439854 Test Acc : 0.24750000319443644\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 2 Acc : 0.22760000275075434 Test Acc : 0.28162500261329115\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 3 Acc : 0.26160000275075435 Test Acc : 0.2953750019427389\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 4 Acc : 0.2766000027805567 Test Acc : 0.30250000215135514\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 5 Acc : 0.29040000224113466 Test Acc : 0.3280000017210841\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 6 Acc : 0.3174000021219254 Test Acc : 0.3348750017769635\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 7 Acc : 0.3352000017762184 Test Acc : 0.34287500208243726\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 8 Acc : 0.3446000021249056 Test Acc : 0.3446250020340085\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 9 Acc : 0.35319999954104425 Test Acc : 0.352875001821667\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 10 Acc : 0.3571999998986721 Test Acc : 0.3576250019669533\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 11 Acc : 0.3621999996453524 Test Acc : 0.3651250016503036\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 12 Acc : 0.37080000016093256 Test Acc : 0.367125001559034\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 13 Acc : 0.3726000011265278 Test Acc : 0.37100000145845113\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 14 Acc : 0.37700000128149985 Test Acc : 0.3745000007655472\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 15 Acc : 0.3828000011146069 Test Acc : 0.3771250011771917\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 16 Acc : 0.38360000106692316 Test Acc : 0.3797500009648502\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 17 Acc : 0.38700000140070917 Test Acc : 0.3823750014230609\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 18 Acc : 0.39340000170469286 Test Acc : 0.38462500140070915\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 19 Acc : 0.3974000008702278 Test Acc : 0.38825000083073974\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 20 Acc : 0.3982000013589859 Test Acc : 0.3902500014193356\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 21 Acc : 0.4028000012636185 Test Acc : 0.3912500010803342\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 22 Acc : 0.40680000150203705 Test Acc : 0.39487500112503765\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 23 Acc : 0.4082000009417534 Test Acc : 0.3976250010728836\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 24 Acc : 0.4132000012993813 Test Acc : 0.3975000010803342\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 25 Acc : 0.4124000009298325 Test Acc : 0.4006250010058284\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 26 Acc : 0.41660000157356264 Test Acc : 0.40175000090152024\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 27 Acc : 0.4212000018954277 Test Acc : 0.40525000045076015\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 28 Acc : 0.4202000014781952 Test Acc : 0.4073750005103648\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 29 Acc : 0.4224000009894371 Test Acc : 0.41012500097975135\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 30 Acc : 0.42720000094175337 Test Acc : 0.4118750006519258\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 31 Acc : 0.43020000112056733 Test Acc : 0.41412500085309145\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 32 Acc : 0.4290000022649765 Test Acc : 0.4156250006891787\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 33 Acc : 0.43480000174045563 Test Acc : 0.41887500079348683\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 34 Acc : 0.4342000014781952 Test Acc : 0.42100000055506825\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 35 Acc : 0.4392000015377998 Test Acc : 0.4226250003837049\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 36 Acc : 0.4482000007033348 Test Acc : 0.4387500012293458\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 37 Acc : 0.46440000158548356 Test Acc : 0.4402500008791685\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 38 Acc : 0.46980000120401383 Test Acc : 0.4425000011920929\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 39 Acc : 0.4778000012636185 Test Acc : 0.4465000008791685\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 40 Acc : 0.47840000194311144 Test Acc : 0.44712500093504787\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 41 Acc : 0.48160000163316724 Test Acc : 0.45225000124424697\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 42 Acc : 0.48540000170469283 Test Acc : 0.45562500137835743\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 43 Acc : 0.48600000208616256 Test Acc : 0.4545000013895333\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 44 Acc : 0.4878000020980835 Test Acc : 0.46050000116229056\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 45 Acc : 0.48900000232458113 Test Acc : 0.46100000143051145\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 46 Acc : 0.4906000028252602 Test Acc : 0.4630000011995435\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 47 Acc : 0.49220000207424164 Test Acc : 0.4620000011473894\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.49480000138282776 Test Acc : 0.46700000036507844\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.5006000016331673 Test Acc : 0.4680000006407499\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 50 Acc : 0.49980000185966494 Test Acc : 0.4682500005885959\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 51 Acc : 0.5048000020980835 Test Acc : 0.47162500116974115\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 52 Acc : 0.5038000020980835 Test Acc : 0.4743750014156103\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 53 Acc : 0.5044000024795532 Test Acc : 0.47500000178813934\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 54 Acc : 0.5080000027418137 Test Acc : 0.47762500181794165\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 55 Acc : 0.5062000030279159 Test Acc : 0.47937500178813935\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 56 Acc : 0.5044000015258789 Test Acc : 0.48037500109523534\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 57 Acc : 0.5078000012636185 Test Acc : 0.4798750012740493\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 58 Acc : 0.508600000500679 Test Acc : 0.47937500055879356\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 59 Acc : 0.5092000006437302 Test Acc : 0.47775000039488075\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 60 Acc : 0.5120000004768371 Test Acc : 0.4791250005736947\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 61 Acc : 0.5124000001549721 Test Acc : 0.47987500071525574\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 62 Acc : 0.5162000007033348 Test Acc : 0.483125\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 63 Acc : 0.5162000008225441 Test Acc : 0.4838750000298023\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 64 Acc : 0.5188000007271767 Test Acc : 0.48512499980628493\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 65 Acc : 0.5196000002026558 Test Acc : 0.4856250000745058\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 66 Acc : 0.5222000007033348 Test Acc : 0.4891250002384186\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 67 Acc : 0.525200001001358 Test Acc : 0.4905000002682209\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 68 Acc : 0.5258000010251999 Test Acc : 0.4910000006109476\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 69 Acc : 0.5268000018596649 Test Acc : 0.49149999998509886\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 70 Acc : 0.5314000012874603 Test Acc : 0.4916250002011657\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 71 Acc : 0.5352000008821487 Test Acc : 0.4928750002011657\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.25\n",
      " Current : 72 Acc : 0.5358000005483627 Test Acc : 0.4956249999254942\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 73 Acc : 0.5368000009059906 Test Acc : 0.4951250002160668\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 74 Acc : 0.5396000001430511 Test Acc : 0.4948750001937151\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 75 Acc : 0.5392000013589859 Test Acc : 0.49875000096857547\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 76 Acc : 0.5426000009775162 Test Acc : 0.49862500071525573\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 77 Acc : 0.5458000013828278 Test Acc : 0.5001250007003546\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 78 Acc : 0.5456000012159348 Test Acc : 0.5021250016614794\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Acc : 0.5466000015735626 Test Acc : 0.5015000016614795\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Acc : 0.5488000020980836 Test Acc : 0.502000001333654\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.5506000012159348 Test Acc : 0.5032500005885958\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.5542000018358231 Test Acc : 0.503374999947846\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.5524000010490417 Test Acc : 0.5027500003576278\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 84 Acc : 0.5534000009298324 Test Acc : 0.5037500009685755\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Acc : 0.5552000018358231 Test Acc : 0.5060000012814999\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 86 Acc : 0.5574000014066696 Test Acc : 0.506500000655651\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 87 Acc : 0.5604000010490418 Test Acc : 0.5068750005215407\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 88 Acc : 0.5602000008821487 Test Acc : 0.504750000834465\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 89 Acc : 0.5606000000238418 Test Acc : 0.505750000923872\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 90 Acc : 0.5650000010728836 Test Acc : 0.5065000005811453\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 91 Acc : 0.563600000500679 Test Acc : 0.5080000008270145\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 92 Acc : 0.5667999995946884 Test Acc : 0.5072500010207296\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 93 Acc : 0.5681999992132187 Test Acc : 0.5067500003054738\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 94 Acc : 0.5687999993562698 Test Acc : 0.5070000007376074\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 95 Acc : 0.5711999983787537 Test Acc : 0.5072500006482005\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 96 Acc : 0.573799999833107 Test Acc : 0.5103750007972121\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 97 Acc : 0.5759999980926513 Test Acc : 0.5091250004991889\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 98 Acc : 0.5753999990224838 Test Acc : 0.5088750002905726\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Acc : 0.5778000000715255 Test Acc : 0.5083750008419156\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Acc : 0.5816000000238418 Test Acc : 0.509125000871718\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Acc : 0.5809999986886978 Test Acc : 0.5097500003129244\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 102 Acc : 0.5862000002861023 Test Acc : 0.508500000871718\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.5856000003814698 Test Acc : 0.5111250009387731\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 104 Acc : 0.5866000003814698 Test Acc : 0.5131250006705522\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 105 Acc : 0.5884000004529953 Test Acc : 0.5131250002980232\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 106 Acc : 0.5886000009775162 Test Acc : 0.5131250004470348\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Acc : 0.5900000003576279 Test Acc : 0.5123750007152558\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 108 Acc : 0.5914000002145767 Test Acc : 0.514250001013279\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.5934000000953674 Test Acc : 0.5145000006258488\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 110 Acc : 0.5936000012159347 Test Acc : 0.5151250005513429\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 111 Acc : 0.5958000004291535 Test Acc : 0.515625000745058\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 112 Acc : 0.5970000005960464 Test Acc : 0.517000001296401\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 113 Acc : 0.5964000014066696 Test Acc : 0.5176250008493661\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 114 Acc : 0.5998000001907349 Test Acc : 0.5173750007152558\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 115 Acc : 0.6008000012636184 Test Acc : 0.5173750004172325\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 116 Acc : 0.5992000002861023 Test Acc : 0.5181250009685755\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 117 Acc : 0.6008000005483627 Test Acc : 0.5202500015497208\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 118 Acc : 0.5994000005722045 Test Acc : 0.5203750013560057\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 119 Acc : 0.6012000007629394 Test Acc : 0.5203750015050173\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.603200001835823 Test Acc : 0.5232500015199184\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 121 Acc : 0.6040000007152557 Test Acc : 0.5243750016391278\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 122 Acc : 0.6044000014066696 Test Acc : 0.5236250019073486\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 123 Acc : 0.607600000500679 Test Acc : 0.5228750013560056\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 124 Acc : 0.6072000007629395 Test Acc : 0.5252500009164214\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 125 Acc : 0.6108000003099442 Test Acc : 0.5243750011175871\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 126 Acc : 0.6116000000238418 Test Acc : 0.5247500014305114\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 127 Acc : 0.609600000500679 Test Acc : 0.5245000011473894\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 128 Acc : 0.611399999499321 Test Acc : 0.5252500009536744\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 129 Acc : 0.6119999986886978 Test Acc : 0.524875001385808\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 130 Acc : 0.6147999991178512 Test Acc : 0.526750001385808\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 131 Acc : 0.6157999995946885 Test Acc : 0.5278750013560056\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 132 Acc : 0.6173999987840653 Test Acc : 0.528375001475215\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 133 Acc : 0.617399999499321 Test Acc : 0.5283750014007091\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 134 Acc : 0.6199999991655349 Test Acc : 0.5281250009685755\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 135 Acc : 0.6223999996185303 Test Acc : 0.5276250011846423\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 136 Acc : 0.6236000002622605 Test Acc : 0.5272500010952353\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 137 Acc : 0.6237999994754791 Test Acc : 0.5281250010803342\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 138 Acc : 0.6251999995708466 Test Acc : 0.52750000115484\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 139 Acc : 0.6261999998092651 Test Acc : 0.52812500115484\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 140 Acc : 0.6255999991893768 Test Acc : 0.5285000010207296\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 141 Acc : 0.6283999992609024 Test Acc : 0.5295000013336539\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 142 Acc : 0.6303999989032746 Test Acc : 0.5280000016465783\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 143 Acc : 0.6310000003576278 Test Acc : 0.5268750016018748\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 144 Acc : 0.6299999992847443 Test Acc : 0.527625001333654\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 145 Acc : 0.6325999999046326 Test Acc : 0.5283750015869737\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 146 Acc : 0.6323999991416931 Test Acc : 0.529125001616776\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 147 Acc : 0.6334000000953675 Test Acc : 0.5295000017061829\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 148 Acc : 0.6349999997615814 Test Acc : 0.5292500017210842\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 149 Acc : 0.6355999997854233 Test Acc : 0.5287500012293458\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 150 Acc : 0.6361999998092651 Test Acc : 0.5297500013187527\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 151 Acc : 0.6372000004053116 Test Acc : 0.5305000017955899\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 152 Acc : 0.6377999997138977 Test Acc : 0.5301250017806888\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 153 Acc : 0.6402000004053116 Test Acc : 0.5313750018551946\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 154 Acc : 0.6376000002622605 Test Acc : 0.5312500020489097\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 155 Acc : 0.638200000166893 Test Acc : 0.5318750025704503\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 156 Acc : 0.6387999997138977 Test Acc : 0.5320000018924474\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 157 Acc : 0.637999999165535 Test Acc : 0.5330000018328428\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 158 Acc : 0.6403999990224838 Test Acc : 0.5327500019222497\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 159 Acc : 0.6431999996900558 Test Acc : 0.5337500021606684\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 160 Acc : 0.6435999985933304 Test Acc : 0.5342500016093255\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 161 Acc : 0.6475999994277954 Test Acc : 0.5328750012442469\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 162 Acc : 0.6485999991893768 Test Acc : 0.5332500012218953\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 163 Acc : 0.648999999165535 Test Acc : 0.5323750014230609\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 164 Acc : 0.651199999332428 Test Acc : 0.5321250016987323\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 165 Acc : 0.6525999999046326 Test Acc : 0.5326250012218953\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 166 Acc : 0.6531999990940094 Test Acc : 0.5330000015720725\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 167 Acc : 0.6561999998092651 Test Acc : 0.5315000015124679\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 168 Acc : 0.6571999998092651 Test Acc : 0.5327500024437904\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 169 Acc : 0.6589999994039536 Test Acc : 0.5335000022128225\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 170 Acc : 0.6625999993085862 Test Acc : 0.5337500020489097\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 171 Acc : 0.6613999994993209 Test Acc : 0.5343750020489096\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 172 Acc : 0.6655999995470047 Test Acc : 0.5352500023320317\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 173 Acc : 0.6643999987840652 Test Acc : 0.5351250023767352\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 174 Acc : 0.6641999988555908 Test Acc : 0.5356250027194619\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 175 Acc : 0.6671999995708465 Test Acc : 0.5342500021681189\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 176 Acc : 0.6669999985694886 Test Acc : 0.534875002540648\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 177 Acc : 0.6679999992847443 Test Acc : 0.5341250025853514\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 178 Acc : 0.6705999999046326 Test Acc : 0.5357500026747585\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 179 Acc : 0.6669999988079071 Test Acc : 0.5351250018551945\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 180 Acc : 0.6689999990463257 Test Acc : 0.5365000025555492\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 181 Acc : 0.6703999997377396 Test Acc : 0.5375000031664967\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 182 Acc : 0.6697999997138977 Test Acc : 0.5373750024661422\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 183 Acc : 0.6703999989032745 Test Acc : 0.5373750038817525\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 184 Acc : 0.6741999983787537 Test Acc : 0.5361250028386713\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 185 Acc : 0.6759999995231628 Test Acc : 0.5367500029876828\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 186 Acc : 0.6733999991416931 Test Acc : 0.5377500034496188\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 187 Acc : 0.6767999987602233 Test Acc : 0.537875003144145\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 188 Acc : 0.675799998998642 Test Acc : 0.5375000036880374\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 189 Acc : 0.6763999977111816 Test Acc : 0.5373750024661422\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 190 Acc : 0.6769999988079071 Test Acc : 0.5375000026449561\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 191 Acc : 0.6785999989509582 Test Acc : 0.5380000032484531\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 192 Acc : 0.6797999987602233 Test Acc : 0.537500002682209\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 193 Acc : 0.6805999987125396 Test Acc : 0.5376250033080577\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 194 Acc : 0.6817999985218048 Test Acc : 0.5380000030994415\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 195 Acc : 0.6835999994277954 Test Acc : 0.5391250036656856\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 196 Acc : 0.6857999992370606 Test Acc : 0.5387500029057264\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 197 Acc : 0.6853999991416931 Test Acc : 0.5370000029355287\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 198 Acc : 0.6823999984264374 Test Acc : 0.5383750024437904\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 199 Acc : 0.6847999987602233 Test Acc : 0.5395000026375055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Normal CNN \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create layers\n",
    "l1 = CNN(3,3, 16); \n",
    "l2 = CNN(3,16,16); \n",
    "l3 = CNN(3,16,16); \n",
    "\n",
    "l4 = CNN(3,16,16); \n",
    "l5 = CNN(3,16,16); \n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# 2. graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer2, layer2a = l2. feedforward(layer1a,stride=2)\n",
    "layer3, layer3a = l3. feedforward(layer2a,stride=2)\n",
    "layer4, layer4a = l4. feedforward(layer3a,stride=2)\n",
    "layer5, layer5a = l5. feedforward(layer4a)\n",
    "layer6, layer6a = l6. feedforward(layer5a)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = [];test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'Normal/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'Normal/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'Normal/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'Normal/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    \n",
    "np.save('Normal/train.npy',train_acc)\n",
    "np.save('Normaltest.npy', test_acc)    \n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:32:15.740729Z",
     "start_time": "2018-12-20T22:32:15.736740Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:34:14.049038Z",
     "start_time": "2018-12-20T22:34:14.043054Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T23:10:44.764643Z",
     "start_time": "2018-12-20T22:40:32.105298Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 0/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 0 Acc : 0.2896000022888184 Test Acc : 0.3457500022649765\n",
      "\n",
      "Current Iter : 1/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 1 Acc : 0.35160000160336496 Test Acc : 0.3758750017732382\n",
      "\n",
      "Current Iter : 2/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 2 Acc : 0.3906000019311905 Test Acc : 0.3948750012926757\n",
      "\n",
      "Current Iter : 3/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 3 Acc : 0.4148000013232231 Test Acc : 0.3947500015515834\n",
      "\n",
      "Current Iter : 4/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 4 Acc : 0.44100000274181367 Test Acc : 0.3867500015813857\n",
      "\n",
      "Current Iter : 5/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 5 Acc : 0.46040000063180925 Test Acc : 0.4216250012628734\n",
      "\n",
      "Current Iter : 6/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 6 Acc : 0.4736000011563301 Test Acc : 0.40237500072456894\n",
      "\n",
      "Current Iter : 7/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 7 Acc : 0.49240000057220457 Test Acc : 0.4481250014342368\n",
      "\n",
      "Current Iter : 8/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 8 Acc : 0.5070000017881393 Test Acc : 0.4491250012628734\n",
      "\n",
      "Current Iter : 9/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 9 Acc : 0.5212000017166137 Test Acc : 0.45425000235438345\n",
      "\n",
      "Current Iter : 10/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 10 Acc : 0.5342000002861023 Test Acc : 0.4648750021308661\n",
      "\n",
      "Current Iter : 11/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 11 Acc : 0.5457999999523163 Test Acc : 0.4681250020675361\n",
      "\n",
      "Current Iter : 12/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 12 Acc : 0.5578000003099441 Test Acc : 0.4661250020749867\n",
      "\n",
      "Current Iter : 13/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 13 Acc : 0.5682000011205673 Test Acc : 0.47137500185519454\n",
      "\n",
      "Current Iter : 14/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 14 Acc : 0.5722000008821487 Test Acc : 0.46950000144541265\n",
      "\n",
      "Current Iter : 15/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 15 Acc : 0.5878000020980835 Test Acc : 0.47225000213831664\n",
      "\n",
      "Current Iter : 16/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 16 Acc : 0.5996000018119813 Test Acc : 0.47000000076368453\n",
      "\n",
      "Current Iter : 17/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 17 Acc : 0.6082000012397766 Test Acc : 0.4696250010095537\n",
      "\n",
      "Current Iter : 18/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 18 Acc : 0.6160000016689301 Test Acc : 0.47500000044703483\n",
      "\n",
      "Current Iter : 19/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 19 Acc : 0.6268000020980835 Test Acc : 0.4755000012740493\n",
      "\n",
      "Current Iter : 20/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 20 Acc : 0.6366000003814697 Test Acc : 0.4800000012293458\n",
      "\n",
      "Current Iter : 21/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 21 Acc : 0.6424000002145768 Test Acc : 0.4763750016316772\n",
      "\n",
      "Current Iter : 22/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 22 Acc : 0.6464000008106232 Test Acc : 0.479000001847744\n",
      "\n",
      "Current Iter : 23/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 23 Acc : 0.6512000005245209 Test Acc : 0.47437500111758707\n",
      "\n",
      "Current Iter : 24/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 24 Acc : 0.659999998807907 Test Acc : 0.47800000090152023\n",
      "\n",
      "Current Iter : 25/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 25 Acc : 0.6682000000476838 Test Acc : 0.47487500064074994\n",
      "\n",
      "Current Iter : 26/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 26 Acc : 0.6724000006914139 Test Acc : 0.474625000692904\n",
      "\n",
      "Current Iter : 27/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 27 Acc : 0.6798000005483628 Test Acc : 0.47262500010430814\n",
      "\n",
      "Current Iter : 28/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 28 Acc : 0.6868000007867813 Test Acc : 0.47037500005215405\n",
      "\n",
      "Current Iter : 29/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 29 Acc : 0.6938000005483628 Test Acc : 0.46875000033527614\n",
      "\n",
      "Current Iter : 30/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 30 Acc : 0.6994000000953674 Test Acc : 0.46662500087171793\n",
      "\n",
      "Current Iter : 31/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 31 Acc : 0.7049999997615815 Test Acc : 0.4657500012218952\n",
      "\n",
      "Current Iter : 32/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 32 Acc : 0.7136000002622604 Test Acc : 0.4665000006556511\n",
      "\n",
      "Current Iter : 33/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 33 Acc : 0.7187999999523162 Test Acc : 0.4651250009983778\n",
      "\n",
      "Current Iter : 34/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 34 Acc : 0.7260000011920928 Test Acc : 0.4682500010356307\n",
      "\n",
      "Current Iter : 35/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 35 Acc : 0.7294000017642975 Test Acc : 0.46375000089406965\n",
      "\n",
      "Current Iter : 36/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 36 Acc : 0.7328000011444091 Test Acc : 0.4625000008940697\n",
      "\n",
      "Current Iter : 37/200 batch : 7980/8000 acc : 0.65\n",
      " Current : 37 Acc : 0.7464000015258789 Test Acc : 0.46125\n",
      "\n",
      "Current Iter : 38/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 38 Acc : 0.7530000002384186 Test Acc : 0.4601250006631017\n",
      "\n",
      "Current Iter : 39/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 39 Acc : 0.7590000007152558 Test Acc : 0.4576250005699694\n",
      "\n",
      "Current Iter : 40/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 40 Acc : 0.7618000013828278 Test Acc : 0.4582500006724149\n",
      "\n",
      "Current Iter : 41/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 41 Acc : 0.7674000017642975 Test Acc : 0.4582500009983778\n",
      "\n",
      "Current Iter : 42/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 42 Acc : 0.7762000026702881 Test Acc : 0.454875001180917\n",
      "\n",
      "Current Iter : 43/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 43 Acc : 0.7758000018596649 Test Acc : 0.4502500009536743\n",
      "\n",
      "Current Iter : 44/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 44 Acc : 0.7806000039577484 Test Acc : 0.44487500093877314\n",
      "\n",
      "Current Iter : 45/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 45 Acc : 0.7890000035762786 Test Acc : 0.445375000834465\n",
      "\n",
      "Current Iter : 46/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 46 Acc : 0.7948000032901764 Test Acc : 0.44325000181794166\n",
      "\n",
      "Current Iter : 47/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 47 Acc : 0.8016000022888183 Test Acc : 0.43937500052154066\n",
      "\n",
      "Current Iter : 48/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 48 Acc : 0.8062000005245209 Test Acc : 0.4328750006854534\n",
      "\n",
      "Current Iter : 49/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 49 Acc : 0.8096000027656555 Test Acc : 0.43237500082701447\n",
      "\n",
      "Current Iter : 50/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 50 Acc : 0.8154000017642975 Test Acc : 0.433000000603497\n",
      "\n",
      "Current Iter : 51/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 51 Acc : 0.8180000042915344 Test Acc : 0.4298750006780028\n",
      "\n",
      "Current Iter : 52/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 52 Acc : 0.8244000010490418 Test Acc : 0.4260000003874302\n",
      "\n",
      "Current Iter : 53/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 53 Acc : 0.8236000015735626 Test Acc : 0.42762500122189523\n",
      "\n",
      "Current Iter : 54/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 54 Acc : 0.8286000020503997 Test Acc : 0.4251250008866191\n",
      "\n",
      "Current Iter : 55/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 55 Acc : 0.8362000012397766 Test Acc : 0.4257500013336539\n",
      "\n",
      "Current Iter : 56/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 56 Acc : 0.8424000012874603 Test Acc : 0.4247500012069941\n",
      "\n",
      "Current Iter : 57/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 57 Acc : 0.8414000015258789 Test Acc : 0.4273750013485551\n",
      "\n",
      "Current Iter : 58/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 58 Acc : 0.8448000001907349 Test Acc : 0.4235000018030405\n",
      "\n",
      "Current Iter : 59/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 59 Acc : 0.8498000011444092 Test Acc : 0.42725000087171794\n",
      "\n",
      "Current Iter : 60/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 60 Acc : 0.8520000016689301 Test Acc : 0.42512500066310166\n",
      "\n",
      "Current Iter : 61/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 61 Acc : 0.8559999992847442 Test Acc : 0.4297500007599592\n",
      "\n",
      "Current Iter : 62/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 62 Acc : 0.8589999985694885 Test Acc : 0.43025000113993883\n",
      "\n",
      "Current Iter : 63/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 63 Acc : 0.8595999987125397 Test Acc : 0.42975000094622373\n",
      "\n",
      "Current Iter : 64/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 64 Acc : 0.8657999982833863 Test Acc : 0.4275000013783574\n",
      "\n",
      "Current Iter : 65/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 65 Acc : 0.8679999988079071 Test Acc : 0.42987500194460154\n",
      "\n",
      "Current Iter : 66/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 66 Acc : 0.8699999980926514 Test Acc : 0.4282500018551946\n",
      "\n",
      "Current Iter : 67/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 67 Acc : 0.8723999974727631 Test Acc : 0.42475000146776437\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 68/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 68 Acc : 0.8747999966144562 Test Acc : 0.42487500108778475\n",
      "\n",
      "Current Iter : 69/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 69 Acc : 0.8781999976634979 Test Acc : 0.4227500015124679\n",
      "\n",
      "Current Iter : 70/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 70 Acc : 0.8769999983310699 Test Acc : 0.42437500137835743\n",
      "\n",
      "Current Iter : 71/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 71 Acc : 0.8781999979019165 Test Acc : 0.41587500151246787\n",
      "\n",
      "Current Iter : 72/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 72 Acc : 0.8769999978542328 Test Acc : 0.41462500171735883\n",
      "\n",
      "Current Iter : 73/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 73 Acc : 0.883399995803833 Test Acc : 0.41237500166520474\n",
      "\n",
      "Current Iter : 74/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 74 Acc : 0.8885999963283538 Test Acc : 0.41662500154227017\n",
      "\n",
      "Current Iter : 75/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 75 Acc : 0.8881999955177308 Test Acc : 0.4096250016987324\n",
      "\n",
      "Current Iter : 76/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 76 Acc : 0.8891999952793121 Test Acc : 0.4112500014156103\n",
      "\n",
      "Current Iter : 77/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 77 Acc : 0.8927999954223633 Test Acc : 0.41525000166147946\n",
      "\n",
      "Current Iter : 78/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 78 Acc : 0.8983999955654144 Test Acc : 0.41275000136345624\n",
      "\n",
      "Current Iter : 79/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 79 Acc : 0.9039999935626983 Test Acc : 0.4108750009723008\n",
      "\n",
      "Current Iter : 80/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 80 Acc : 0.9097999927997589 Test Acc : 0.40700000086799265\n",
      "\n",
      "Current Iter : 81/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 81 Acc : 0.9135999929904938 Test Acc : 0.40575000090524554\n",
      "\n",
      "Current Iter : 82/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 82 Acc : 0.9167999927997589 Test Acc : 0.40187500143423677\n",
      "\n",
      "Current Iter : 83/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 83 Acc : 0.9167999923229218 Test Acc : 0.40237500065937637\n",
      "\n",
      "Current Iter : 84/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 84 Acc : 0.9177999930381775 Test Acc : 0.4038750009704381\n",
      "\n",
      "Current Iter : 85/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 85 Acc : 0.91939999294281 Test Acc : 0.4041250010486692\n",
      "\n",
      "Current Iter : 86/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 86 Acc : 0.9191999940872192 Test Acc : 0.40012500126846134\n",
      "\n",
      "Current Iter : 87/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 87 Acc : 0.9217999939918518 Test Acc : 0.40025000195018945\n",
      "\n",
      "Current Iter : 88/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 88 Acc : 0.9169999949932098 Test Acc : 0.4057500019203871\n",
      "\n",
      "Current Iter : 89/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 89 Acc : 0.9169999940395355 Test Acc : 0.3970000018551946\n",
      "\n",
      "Current Iter : 90/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 90 Acc : 0.9265999920368194 Test Acc : 0.39787500134669246\n",
      "\n",
      "Current Iter : 91/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 91 Acc : 0.9289999916553497 Test Acc : 0.3991250010486692\n",
      "\n",
      "Current Iter : 92/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 92 Acc : 0.9267999927997589 Test Acc : 0.39737500115297736\n",
      "\n",
      "Current Iter : 93/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 93 Acc : 0.9287999923229218 Test Acc : 0.4040000013727695\n",
      "\n",
      "Current Iter : 94/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 94 Acc : 0.9285999932289124 Test Acc : 0.406500000981614\n",
      "\n",
      "Current Iter : 95/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 95 Acc : 0.9289999945163727 Test Acc : 0.4025000011175871\n",
      "\n",
      "Current Iter : 96/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 96 Acc : 0.9239999933242797 Test Acc : 0.402625001296401\n",
      "\n",
      "Current Iter : 97/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 97 Acc : 0.9291999926567077 Test Acc : 0.4013750011660159\n",
      "\n",
      "Current Iter : 98/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 98 Acc : 0.9341999914646149 Test Acc : 0.403125001527369\n",
      "\n",
      "Current Iter : 99/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 99 Acc : 0.9289999935626984 Test Acc : 0.39587500132620335\n",
      "\n",
      "Current Iter : 100/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 100 Acc : 0.9265999929904938 Test Acc : 0.3998750016652048\n",
      "\n",
      "Current Iter : 101/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 101 Acc : 0.9385999915599823 Test Acc : 0.3958750013448298\n",
      "\n",
      "Current Iter : 102/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 102 Acc : 0.9387999913692474 Test Acc : 0.39987500123679637\n",
      "\n",
      "Current Iter : 103/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 103 Acc : 0.9421999926567077 Test Acc : 0.40600000069476666\n",
      "\n",
      "Current Iter : 104/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 104 Acc : 0.9439999916553498 Test Acc : 0.4032500013243407\n",
      "\n",
      "Current Iter : 105/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 105 Acc : 0.9475999913215637 Test Acc : 0.4023750014603138\n",
      "\n",
      "Current Iter : 106/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 106 Acc : 0.9455999920368194 Test Acc : 0.40250000143423675\n",
      "\n",
      "Current Iter : 107/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 107 Acc : 0.9465999925136566 Test Acc : 0.4056250013038516\n",
      "\n",
      "Current Iter : 108/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 108 Acc : 0.9481999921798706 Test Acc : 0.40337500186637043\n",
      "\n",
      "Current Iter : 109/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 109 Acc : 0.9493999907970428 Test Acc : 0.4013750011939555\n",
      "\n",
      "Current Iter : 110/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 110 Acc : 0.954799991607666 Test Acc : 0.39500000153668224\n",
      "\n",
      "Current Iter : 111/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 111 Acc : 0.95939999127388 Test Acc : 0.3956250017043203\n",
      "\n",
      "Current Iter : 112/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 112 Acc : 0.963799993276596 Test Acc : 0.3993750014901161\n",
      "\n",
      "Current Iter : 113/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 113 Acc : 0.9609999930858613 Test Acc : 0.392500001816079\n",
      "\n",
      "Current Iter : 114/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 114 Acc : 0.9613999929428101 Test Acc : 0.3947500015608966\n",
      "\n",
      "Current Iter : 115/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 115 Acc : 0.9485999937057495 Test Acc : 0.4022500006482005\n",
      "\n",
      "Current Iter : 116/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 116 Acc : 0.9611999936103821 Test Acc : 0.4011250010691583\n",
      "\n",
      "Current Iter : 117/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 117 Acc : 0.9711999938488006 Test Acc : 0.40212500106543303\n",
      "\n",
      "Current Iter : 118/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 118 Acc : 0.9671999943256379 Test Acc : 0.40200000106357037\n",
      "\n",
      "Current Iter : 119/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 119 Acc : 0.9617999923229218 Test Acc : 0.39725000179372727\n",
      "\n",
      "Current Iter : 120/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 120 Acc : 0.9623999938964843 Test Acc : 0.39262500149197876\n",
      "\n",
      "Current Iter : 121/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 121 Acc : 0.9629999933242798 Test Acc : 0.39362500119023025\n",
      "\n",
      "Current Iter : 122/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 122 Acc : 0.9595999932289123 Test Acc : 0.3990000015031546\n",
      "\n",
      "Current Iter : 123/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 123 Acc : 0.9663999929428101 Test Acc : 0.38912500099278985\n",
      "\n",
      "Current Iter : 124/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 124 Acc : 0.9491999945640563 Test Acc : 0.39175000076182187\n",
      "\n",
      "Current Iter : 125/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 125 Acc : 0.9639999935626984 Test Acc : 0.3950000014062971\n",
      "\n",
      "Current Iter : 126/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 126 Acc : 0.9685999939441681 Test Acc : 0.3923750010225922\n",
      "\n",
      "Current Iter : 127/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 127 Acc : 0.9691999936103821 Test Acc : 0.40087500082328914\n",
      "\n",
      "Current Iter : 128/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 128 Acc : 0.9725999941825867 Test Acc : 0.396625001700595\n",
      "\n",
      "Current Iter : 129/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 129 Acc : 0.9655999932289123 Test Acc : 0.39300000090152026\n",
      "\n",
      "Current Iter : 130/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 130 Acc : 0.972399994134903 Test Acc : 0.3941250004712492\n",
      "\n",
      "Current Iter : 131/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 131 Acc : 0.9779999949932099 Test Acc : 0.392125001065433\n",
      "\n",
      "Current Iter : 132/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 132 Acc : 0.9759999949932099 Test Acc : 0.39687500131316483\n",
      "\n",
      "Current Iter : 133/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 133 Acc : 0.9655999939441681 Test Acc : 0.38687500172294675\n",
      "\n",
      "Current Iter : 134/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 134 Acc : 0.9735999951362609 Test Acc : 0.3972500003222376\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Iter : 135/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 135 Acc : 0.9725999944210052 Test Acc : 0.39450000060722235\n",
      "\n",
      "Current Iter : 136/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 136 Acc : 0.9727999947071075 Test Acc : 0.39475000062026083\n",
      "\n",
      "Current Iter : 137/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 137 Acc : 0.9771999952793121 Test Acc : 0.39312500120140614\n",
      "\n",
      "Current Iter : 138/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 138 Acc : 0.9765999956130982 Test Acc : 0.4007500017993152\n",
      "\n",
      "Current Iter : 139/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 139 Acc : 0.9743999950885772 Test Acc : 0.39200000079348685\n",
      "\n",
      "Current Iter : 140/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 140 Acc : 0.9787999951839447 Test Acc : 0.4033750009723008\n",
      "\n",
      "Current Iter : 141/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 141 Acc : 0.9783999950885772 Test Acc : 0.3968750006519258\n",
      "\n",
      "Current Iter : 142/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 142 Acc : 0.9773999953269958 Test Acc : 0.4016250013373792\n",
      "\n",
      "Current Iter : 143/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 143 Acc : 0.9711999943256379 Test Acc : 0.3961250012554228\n",
      "\n",
      "Current Iter : 144/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 144 Acc : 0.9791999957561492 Test Acc : 0.39825000094249846\n",
      "\n",
      "Current Iter : 145/200 batch : 7980/8000 acc : 0.35\n",
      " Current : 145 Acc : 0.9633999938964843 Test Acc : 0.39675000170245767\n",
      "\n",
      "Current Iter : 146/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 146 Acc : 0.9705999939441681 Test Acc : 0.3942500017117709\n",
      "\n",
      "Current Iter : 147/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 147 Acc : 0.9707999954223633 Test Acc : 0.4027500007301569\n",
      "\n",
      "Current Iter : 148/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 148 Acc : 0.9717999944686889 Test Acc : 0.39800000162795185\n",
      "\n",
      "Current Iter : 149/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 149 Acc : 0.9805999960899353 Test Acc : 0.4033750007674098\n",
      "\n",
      "Current Iter : 150/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 150 Acc : 0.976199994802475 Test Acc : 0.39912500135600565\n",
      "\n",
      "Current Iter : 151/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 151 Acc : 0.9865999970436096 Test Acc : 0.3986250007338822\n",
      "\n",
      "Current Iter : 152/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 152 Acc : 0.987399996995926 Test Acc : 0.3941250010579824\n",
      "\n",
      "Current Iter : 153/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 153 Acc : 0.9755999953746796 Test Acc : 0.3965000008326024\n",
      "\n",
      "Current Iter : 154/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 154 Acc : 0.9747999949455262 Test Acc : 0.40012500051409006\n",
      "\n",
      "Current Iter : 155/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 155 Acc : 0.9811999957561492 Test Acc : 0.3950000012293458\n",
      "\n",
      "Current Iter : 156/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 156 Acc : 0.9847999966144562 Test Acc : 0.40537500227801504\n",
      "\n",
      "Current Iter : 157/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 157 Acc : 0.984199996471405 Test Acc : 0.4066250011418015\n",
      "\n",
      "Current Iter : 158/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 158 Acc : 0.9867999968528748 Test Acc : 0.39450000145472586\n",
      "\n",
      "Current Iter : 159/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 159 Acc : 0.9875999970436096 Test Acc : 0.3973750012461096\n",
      "\n",
      "Current Iter : 160/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 160 Acc : 0.9861999967098236 Test Acc : 0.39500000142492353\n",
      "\n",
      "Current Iter : 161/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 161 Acc : 0.9817999963760375 Test Acc : 0.4036250004824251\n",
      "\n",
      "Current Iter : 162/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 162 Acc : 0.977599995136261 Test Acc : 0.3998750013671815\n",
      "\n",
      "Current Iter : 163/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 163 Acc : 0.9727999947071075 Test Acc : 0.4012500018440187\n",
      "\n",
      "Current Iter : 164/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 164 Acc : 0.9737999951839447 Test Acc : 0.4017500006780028\n",
      "\n",
      "Current Iter : 165/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 165 Acc : 0.9743999955654145 Test Acc : 0.38487500104121863\n",
      "\n",
      "Current Iter : 166/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 166 Acc : 0.9799999961853028 Test Acc : 0.3981250012293458\n",
      "\n",
      "Current Iter : 167/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 167 Acc : 0.9847999966144562 Test Acc : 0.39000000089406966\n",
      "\n",
      "Current Iter : 168/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 168 Acc : 0.9881999974250794 Test Acc : 0.3982500001881272\n",
      "\n",
      "Current Iter : 169/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 169 Acc : 0.9883999972343445 Test Acc : 0.40100000133737923\n",
      "\n",
      "Current Iter : 170/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 170 Acc : 0.9909999980926514 Test Acc : 0.39850000170990824\n",
      "\n",
      "Current Iter : 171/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 171 Acc : 0.9919999985694885 Test Acc : 0.3923750009946525\n",
      "\n",
      "Current Iter : 172/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 172 Acc : 0.9891999974250794 Test Acc : 0.3986250010319054\n",
      "\n",
      "Current Iter : 173/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 173 Acc : 0.9917999980449677 Test Acc : 0.40225000102072955\n",
      "\n",
      "Current Iter : 174/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 174 Acc : 0.9859999969005585 Test Acc : 0.40000000057742\n",
      "\n",
      "Current Iter : 175/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 175 Acc : 0.9801999952793121 Test Acc : 0.40987500062212345\n",
      "\n",
      "Current Iter : 176/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 176 Acc : 0.980399995803833 Test Acc : 0.40612500209361313\n",
      "\n",
      "Current Iter : 177/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 177 Acc : 0.982799996137619 Test Acc : 0.4002500011399388\n",
      "\n",
      "Current Iter : 178/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 178 Acc : 0.971999995470047 Test Acc : 0.4003750007972121\n",
      "\n",
      "Current Iter : 179/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 179 Acc : 0.9775999948978424 Test Acc : 0.40662500077858565\n",
      "\n",
      "Current Iter : 180/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 180 Acc : 0.9883999972343445 Test Acc : 0.4078750006016344\n",
      "\n",
      "Current Iter : 181/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 181 Acc : 0.9939999985694885 Test Acc : 0.4030000010039657\n",
      "\n",
      "Current Iter : 182/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 182 Acc : 0.9941999986171722 Test Acc : 0.40537500074133276\n",
      "\n",
      "Current Iter : 183/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 183 Acc : 0.9961999990940094 Test Acc : 0.40262500051409006\n",
      "\n",
      "Current Iter : 184/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 184 Acc : 0.998599999666214 Test Acc : 0.4018750014714897\n",
      "\n",
      "Current Iter : 185/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 185 Acc : 0.9927999982833863 Test Acc : 0.40800000024959443\n",
      "\n",
      "Current Iter : 186/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 186 Acc : 0.9561999938488006 Test Acc : 0.3892500012554228\n",
      "\n",
      "Current Iter : 187/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 187 Acc : 0.9441999924182892 Test Acc : 0.39912500004284085\n",
      "\n",
      "Current Iter : 188/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 188 Acc : 0.9753999948501587 Test Acc : 0.3995000010356307\n",
      "\n",
      "Current Iter : 189/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 189 Acc : 0.9901999979019165 Test Acc : 0.40287500058300796\n",
      "\n",
      "Current Iter : 190/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 190 Acc : 0.9927999982833863 Test Acc : 0.40087500154040756\n",
      "\n",
      "Current Iter : 191/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 191 Acc : 0.9953999989032746 Test Acc : 0.40300000095739963\n",
      "\n",
      "Current Iter : 192/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 192 Acc : 0.9983999996185303 Test Acc : 0.4022500004712492\n",
      "\n",
      "Current Iter : 193/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 193 Acc : 0.9979999995231629 Test Acc : 0.4012500011455268\n",
      "\n",
      "Current Iter : 194/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 194 Acc : 0.9919999980926514 Test Acc : 0.40225000146776435\n",
      "\n",
      "Current Iter : 195/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 195 Acc : 0.9965999991893768 Test Acc : 0.40225000091828406\n",
      "\n",
      "Current Iter : 196/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 196 Acc : 0.9931999983787536 Test Acc : 0.4003750006016344\n",
      "\n",
      "Current Iter : 197/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 197 Acc : 0.9203999934196472 Test Acc : 0.40162500091828407\n",
      "\n",
      "Current Iter : 198/200 batch : 7980/8000 acc : 0.45\n",
      " Current : 198 Acc : 0.9647999947071075 Test Acc : 0.4046250011958182\n",
      "\n",
      "Current Iter : 199/200 batch : 7980/8000 acc : 0.55\n",
      " Current : 199 Acc : 0.9851999969482422 Test Acc : 0.40837500112131236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. batch normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_batch_norm_layer(16,(0,1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'batch Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'batch Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('batch Norm/train.npy',train_acc)\n",
    "np.save('batch Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:15:40.774701Z",
     "start_time": "2018-12-20T22:15:40.752771Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T22:15:43.828650Z",
     "start_time": "2018-12-20T22:15:43.552111Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. layer normalization\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1. layers\n",
    "l1 = CNN(3,3, 16); l1n = tf_layer_norm_layer(16,(0,1,2))\n",
    "l2 = CNN(3,16,16); l2n = tf_layer_norm_layer(16,(0,1,2))\n",
    "l3 = CNN(3,16,16); l3n = tf_layer_norm_layer(16,(0,1,2))\n",
    "l4 = CNN(3,16,16); l4n = tf_layer_norm_layer(16,(0,1,2))\n",
    "l5 = CNN(3,16,16); l5n = tf_layer_norm_layer(16,(0,1,2))\n",
    "l6 = CNN(3,16,10); \n",
    "\n",
    "# create the graph \n",
    "x = tf.placeholder(tf.float32,(batch_size,96,96,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "is_train = tf.placeholder_with_default(True,())\n",
    "\n",
    "layer1, layer1a = l1. feedforward(x,stride=2)\n",
    "layer1b,update1 = l1n.feedforward(layer1a,is_train)\n",
    "layer2, layer2a = l2. feedforward(layer1b,stride=2)\n",
    "layer2b,update2 = l2n.feedforward(layer2a,is_train)\n",
    "layer3, layer3a = l3. feedforward(layer2b,stride=2)\n",
    "layer3b,update3 = l3n.feedforward(layer3a,is_train)\n",
    "layer4, layer4a = l4. feedforward(layer3b,stride=2)\n",
    "layer4b,update4 = l4n.feedforward(layer4a,is_train)\n",
    "layer5, layer5a = l5. feedforward(layer4b)\n",
    "layer5b,update5 = l5n.feedforward(layer5a,is_train)\n",
    "layer6, layer6a = l6. feedforward(layer5b)\n",
    "\n",
    "final_layer   = tf.reduce_mean(layer6a,(1,2))\n",
    "final_softmax = tf_softmax(final_layer)\n",
    "cost          = -tf.reduce_mean(y * tf.log(final_softmax + 1e-8))\n",
    "correct_prediction = tf.equal(tf.argmax(final_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "grad6p,grad6w,grad6_up = l6.backprop(gradient)\n",
    "grad5n = l5n.backprop(grad6p)\n",
    "grad5p,grad5w,grad5_up = l5.backprop(grad5n)\n",
    "grad4n = l4n.backprop(grad5p)\n",
    "grad4p,grad4w,grad4_up = l4.backprop(grad4n,stride=2)\n",
    "\n",
    "grad3n = l3n.backprop(grad4p)\n",
    "grad3p,grad3w,grad3_up = l3.backprop(grad3n,stride=2)\n",
    "grad2n = l2n.backprop(grad3p)\n",
    "grad2p,grad2w,grad2_up = l2.backprop(grad2n,stride=2)\n",
    "grad1n = l1n.backprop(grad2p)\n",
    "grad1p,grad1w,grad1_up = l1.backprop(grad1n,stride=2)\n",
    "\n",
    "update_ops  = update1 + update2 + update3 + update4 + update5\n",
    "gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "\n",
    "# train\n",
    "sess.run(tf.global_variables_initializer())\n",
    "avg_acc_train = 0; avg_acc_test  = 0; \n",
    "train_acc = []; test_acc = []\n",
    "for iter in range(num_epoch):\n",
    "\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_data  = train_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy,gradient_update,update_ops],feed_dict={x:current_data,y:current_label})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "        \n",
    "    # Get weights\n",
    "    save_to_image(sess.run([l1.getw(),l2.getw(),l3.getw(),l4.getw(),l5.getw(),l6.getw()]),'batch Norm/weights/')\n",
    "    save_to_image(sess.run([grad1w,grad2w,grad3w,grad4w,grad5w,grad6w],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientw/')\n",
    "    save_to_image(sess.run([grad1p,grad2p,grad3p,grad4p,grad5p,grad6p],feed_dict={x:current_data,y:current_label}),'batch Norm/gradientp/')\n",
    "    save_to_image(sess.run([grad1_up,grad2_up,grad3_up,grad4_up,grad5_up,grad6_up],feed_dict={x:current_data,y:current_label}),'batch Norm/gradient_update/')\n",
    "        \n",
    "    for current_batch_index in range(0,len(test_images), batch_size):\n",
    "        current_data  = test_images[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        current_label = test_labels[current_batch_index:current_batch_index+batch_size].astype(np.float32)\n",
    "        sess_results  = sess.run([accuracy],feed_dict={x:current_data,y:current_label,is_train:False})\n",
    "        sys.stdout.write('Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0]   \n",
    "        \n",
    "    print(\"\\n Current : \"+ str(iter) + \" Acc : \" + str(avg_acc_train/(len(train_images)/batch_size)) + \" Test Acc : \" + str(avg_acc_test/(len(test_images)/batch_size)) + '\\n')\n",
    "    \n",
    "    # save the training\n",
    "    train_acc.append(avg_acc_train/(len(train_images)/batch_size))\n",
    "    test_acc .append(avg_acc_test / (len(test_images)/batch_size))\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "   \n",
    "np.save('batch Norm/train.npy',train_acc)\n",
    "np.save('batch Norm/test.npy', test_acc)\n",
    "sess.close()\n",
    "tf.reset_default_graph();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T07:57:11.376556Z",
     "start_time": "2018-12-20T07:57:11.370596Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. mttk/STL10. (2018). GitHub. Retrieved 19 December 2018, from https://github.com/mttk/STL10\n",
    "2. [duplicate], H. (2018). How to display multiple images in one figure correctly?. Stack Overflow. Retrieved 19 December 2018, from https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly\n",
    "3. plot, H. (2010). How to change the font size on a matplotlib plot. Stack Overflow. Retrieved 20 December 2018, from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
