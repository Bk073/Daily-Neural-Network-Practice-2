{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:39:08.543697Z",
     "start_time": "2019-02-07T02:39:08.486850Z"
    },
    "code_folding": [
     32,
     34,
     61,
     69,
     93,
     96,
     112
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:43:36.296310Z",
     "start_time": "2019-02-07T02:43:36.230466Z"
    },
    "code_folding": [
     5,
     7,
     22,
     91,
     105,
     134
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class FNN():\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_relu,d_act=d_tf_relu,special_init=False,which_reg=0.0):\n",
    "        if special_init:\n",
    "            interval = np.sqrt(6.0 / (inc + outc + 1.0))\n",
    "            self.w = tf.Variable(tf.random_uniform(shape=(inc, outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=2))\n",
    "            self.b = tf.Variable(tf.random_uniform(shape=(outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=2))\n",
    "        else:\n",
    "            self.w = tf.Variable(tf.random_normal([inc,outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "            self.b = tf.Variable(tf.random_normal([outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "\n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.m_b,self.v_b = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg = which_reg\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input=None):\n",
    "        self.input = input\n",
    "        self.layer = tf.matmul(input,self.w) + self.b\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient=None,which_reg=0):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad  = tf.matmul(tf.transpose(grad_part_3),grad_middle)/batch_size\n",
    "        grad_b= tf.reduce_mean(grad_middle,axis=0)\n",
    "        grad_pass = tf.matmul(grad_middle,tf.transpose(self.w))\n",
    "\n",
    "        # === Reg ===\n",
    "        if self.which_reg == 0:\n",
    "            grad  = grad\n",
    "            grad_b= grad_b\n",
    "\n",
    "        if self.which_reg == 0.5:\n",
    "            grad  = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "            grad_b= grad_b+lamda * (tf.sqrt(tf.abs(self.b))) * (1.0/tf.sqrt(tf.abs(self.b)+ 10e-5)) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 1:\n",
    "            grad = grad   + lamda * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 1.5:\n",
    "            grad = grad   + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "            grad_b=grad_b + lamda * 1.0/(tf.sqrt(tf.square(self.b) + 10e-5)) * self.b\n",
    "\n",
    "        if self.which_reg == 2:\n",
    "            grad = grad  + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "            grad_b=grad_b+ lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.b))+ 10e-5)) * tf.abs(self.b) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 2.5:\n",
    "            grad = grad   + lamda * 2.0 * self.w\n",
    "            grad_b=grad_b + lamda * 2.0 * self.b\n",
    "\n",
    "        if self.which_reg == 3:\n",
    "            grad = grad   + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.pow(tf.pow(tf.abs(self.b),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.b),2) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 4:\n",
    "            grad = grad   + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.pow(tf.pow(tf.abs(self.b),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.b),3) * tf.sign(self.b)\n",
    "\n",
    "        update_w = []\n",
    "\n",
    "        # Update the Weight First\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat *  learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle )))\n",
    "\n",
    "        # Update the Bias later\n",
    "        update_w.append(tf.assign(self.m_b,self.m_b*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign(self.v_b,self.v_b*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hat_b = self.m_b / (1-beta1)\n",
    "        v_hat_b = self.v_b / (1-beta2)\n",
    "        adam_middle_b = m_hat_b *  learning_rate/(tf.sqrt(v_hat_b) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middle_b )))\n",
    "\n",
    "        return grad_pass,update_w\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.regularizer    = which_reg\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.regularizer == 'A': grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.regularizer == 'B': grad = grad + lamda * 2.0 * self.w\n",
    "        if self.regularizer == 'C': grad = grad + lamda * (1.0/tf.sqrt(tf.square(self.w)+ 10e-8)) * self.w\n",
    "        if self.regularizer == 'D': grad = grad + lamda * -(2*self.w)/(1 + self.w**2)\n",
    "        if self.regularizer == 'E': grad = grad + lamda * -(1-tf.tanh(self.w) ** 2)\n",
    "        if self.regularizer == 'F': grad = grad + lamda * -(1-tf.tanh(self.w** 2) ** 2) * 2.0 * self.w \n",
    "        if self.regularizer == 'G': grad = grad + lamda * -(1-tf.tanh(tf.abs(self.w)) ** 2) * tf.sign(self.w)\n",
    "        if self.regularizer == 'H': grad = grad + lamda * -(1-tf.tanh(tf.abs(self.w)** 2) ** 2) * 2.0 * tf.abs(self.w) *  tf.sign(self.w)\n",
    "        if self.regularizer == 'I': grad = grad + lamda * tf.cos(self.w)\n",
    "        if self.regularizer == 'J': grad = grad + lamda * tf.sign(tf.sin(self.w)) * tf.cos(self.w)\n",
    "        if self.regularizer == 'K': grad = grad + lamda * (2)/(self.w + 10e-8)\n",
    "        if self.regularizer == 'L': grad = grad + lamda * (tf.log(self.w**2) + 2.0)\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:43:46.420366Z",
     "start_time": "2019-02-07T02:43:44.157333Z"
    },
    "code_folding": [
     2,
     18
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) 1.0 0.0\n",
      "(50000, 10) 1.0 0.0\n",
      "(10000, 32, 32, 3) 1.0 0.0\n",
      "(10000, 10) 1.0 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_CIFAR10_data()\n",
    "rand_choice = np.random.choice(len(train_images))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(train_images[rand_choice])\n",
    "plt.title(str(train_labels[rand_choice]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T22:27:31.969314Z",
     "start_time": "2019-02-06T22:27:31.714466Z"
    }
   },
   "outputs": [],
   "source": [
    "# build encoder \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:18:36.811605Z",
     "start_time": "2019-02-07T02:18:35.307630Z"
    },
    "code_folding": [
     18,
     69,
     81,
     97
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                               | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn as nn\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import statistics as stats\n",
    "import argparse\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(3, 64, kernel_size=4, stride=1)\n",
    "        self.c1 = nn.Conv2d(64, 128, kernel_size=4, stride=1)\n",
    "        self.c2 = nn.Conv2d(128, 256, kernel_size=4, stride=1)\n",
    "        self.c3 = nn.Conv2d(256, 512, kernel_size=4, stride=1)\n",
    "        self.l1 = nn.Linear(512*20*20, 64)\n",
    "\n",
    "        self.b1 = nn.BatchNorm2d(128)\n",
    "        self.b2 = nn.BatchNorm2d(256)\n",
    "        self.b3 = nn.BatchNorm2d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))                      # (64, 64, 29, 29)\n",
    "        features = F.relu(self.b1(self.c1(h)))      # (64, 128, 26, 26)\n",
    "        h = F.relu(self.b2(self.c2(features)))      # (64, 256, 23, 23)\n",
    "        h = F.relu(self.b3(self.c3(h)))             # (64, 512, 20, 20)\n",
    "        encoded = self.l1(h.view(x.shape[0], -1))   # (batch,64)\n",
    "        return encoded, features\n",
    "\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(128, 64, kernel_size=3) # (64, 64, 24, 24)\n",
    "        self.c1 = nn.Conv2d(64, 32, kernel_size=3)  # (64, 32, 22, 22)\n",
    "        self.l0 = nn.Linear(32 * 22 * 22 + 64, 512) # (64, 512)\n",
    "        self.l1 = nn.Linear(512, 512)               # (512, 512)\n",
    "        self.l2 = nn.Linear(512, 1)                 # (512, 1)\n",
    "\n",
    "    def forward(self, y, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = self.c1(h)\n",
    "        h = h.view(y.shape[0], -1)\n",
    "        h = torch.cat((y, h), dim=1)\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "    \n",
    "class LocalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(192, 512, kernel_size=1)\n",
    "        self.c1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.c2 = nn.Conv2d(512, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        h = F.relu(self.c1(h))\n",
    "        return self.c2(h)\n",
    "    \n",
    "class PriorDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Linear(64, 1000)\n",
    "        self.l1 = nn.Linear(1000, 200)\n",
    "        self.l2 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return torch.sigmoid(self.l2(h))\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(64, 15)\n",
    "        self.bn1 = nn.BatchNorm1d(15)\n",
    "        self.l2 = nn.Linear(15, 10)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.l3 = nn.Linear(10, 10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded, _ = x[0], x[1]\n",
    "        clazz = F.relu(self.bn1(self.l1(encoded)))\n",
    "        clazz = F.relu(self.bn2(self.l2(clazz)))\n",
    "        clazz = F.softmax(self.bn3(self.l3(clazz)), dim=1)\n",
    "        return clazz\n",
    "class DeepInfoAsLatent(nn.Module):\n",
    "    def __init__(self, run, epoch):\n",
    "        super().__init__()\n",
    "        model_path = Path(r'c:/data/deepinfomax/models') / Path(str(run)) / Path('encoder' + str(epoch) + '.wgt')\n",
    "        self.encoder = Encoder()\n",
    "        self.encoder.load_state_dict(torch.load(str(model_path)))\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, features = self.encoder(x)\n",
    "        z = z.detach()\n",
    "        return self.classifier((z, features))\n",
    "    \n",
    "class DeepInfoMaxLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=1.0, gamma=0.1):\n",
    "        super().__init__()\n",
    "        self.global_d = GlobalDiscriminator()\n",
    "        self.local_d = LocalDiscriminator()\n",
    "        self.prior_d = PriorDiscriminator()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y, M, M_prime):\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "\n",
    "        y_exp = y.unsqueeze(-1).unsqueeze(-1)\n",
    "        y_exp = y_exp.expand(-1, -1, 26, 26)\n",
    "        y_M = torch.cat((M, y_exp), dim=1)\n",
    "        y_M_prime = torch.cat((M_prime, y_exp), dim=1)\n",
    "        Ej = -F.softplus(-self.local_d(y_M)).mean()\n",
    "        Em = F.softplus(self.local_d(y_M_prime)).mean()\n",
    "        LOCAL = (Em - Ej) * self.beta\n",
    "        \n",
    "        # global         \n",
    "        Ej = -F.softplus(-self.global_d(y, M)).mean()\n",
    "        Em = F.softplus(self.global_d(y, M_prime)).mean()\n",
    "        GLOBAL = (Em - Ej) * self.alpha\n",
    "\n",
    "        prior = torch.rand_like(y)\n",
    "        term_a = torch.log(self.prior_d(prior)).mean()\n",
    "        term_b = torch.log(1.0 - self.prior_d(y)).mean()\n",
    "        PRIOR = - (term_a + term_b) * self.gamma\n",
    "\n",
    "        return LOCAL + GLOBAL + PRIOR\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "\n",
    "# image size 3, 32, 32 batch size must be an even numbershuffle must be True\n",
    "cifar_10_train_dt = CIFAR10(r'c:\\data\\tv',  download=True, transform=ToTensor())\n",
    "cifar_10_train_l  = DataLoader(cifar_10_train_dt, batch_size=batch_size, shuffle=True, drop_last=True,pin_memory=torch.cuda.is_available())\n",
    "\n",
    "encoder    = Encoder().to(device)\n",
    "loss_fn    = DeepInfoMaxLoss().to(device)\n",
    "optim      = Adam(encoder.parameters(), lr=1e-4)\n",
    "loss_optim = Adam(loss_fn.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(100):\n",
    "    batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "    train_loss = []\n",
    "    \n",
    "    for x, target in batch:\n",
    "        x = x.to(device)\n",
    "\n",
    "        optim.zero_grad(); loss_optim.zero_grad()\n",
    "        y, M = encoder(x)\n",
    "        # y - > (64, 128, 26, 26)\n",
    "        # M - > (batch,64)\n",
    "        \n",
    "        # rotate images to create pairs for comparison (ROTATING)\n",
    "        M_prime = torch.cat((M[1:], M[0].unsqueeze(0)), dim=0)\n",
    "        loss = loss_fn(y, M, M_prime) # ()\n",
    "        sys.exit()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        batch.set_description(str(epoch) + ' Loss: ' + str(stats.mean(train_loss[-20:])))\n",
    "        loss.backward()\n",
    "        optim.step(); loss_optim.step()\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T01:49:41.457723Z",
     "start_time": "2019-02-07T01:49:41.329296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 3)\n",
      "(64,)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "for x, target in batch:\n",
    "    temp = np.swapaxes(np.swapaxes(x.numpy(),1,3),2,1)\n",
    "    plt.imshow(temp[0])\n",
    "    plt.show()\n",
    "    print(temp.shape)\n",
    "    print(target.numpy().shape)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
