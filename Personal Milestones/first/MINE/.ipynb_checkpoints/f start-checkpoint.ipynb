{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:39:08.543697Z",
     "start_time": "2019-02-07T02:39:08.486850Z"
    },
    "code_folding": [
     32,
     34,
     61,
     69,
     93,
     96,
     112
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7,
     22,
     90,
     104,
     133
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "\n",
    "class FNN():\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_relu,d_act=d_tf_relu,special_init=False,which_reg=0.0):\n",
    "        if special_init:\n",
    "            interval = np.sqrt(6.0 / (inc + outc + 1.0))\n",
    "            self.w = tf.Variable(tf.random_uniform(shape=(inc, outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=2))\n",
    "            self.b = tf.Variable(tf.random_uniform(shape=(outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=2))\n",
    "        else:\n",
    "            self.w = tf.Variable(tf.random_normal([inc,outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "            self.b = tf.Variable(tf.random_normal([outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "\n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.m_b,self.v_b = tf.Variable(tf.zeros_like(self.b)),tf.Variable(tf.zeros_like(self.b))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.which_reg = which_reg\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input=None):\n",
    "        self.input = input\n",
    "        self.layer = tf.matmul(input,self.w) + self.b\n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layerA\n",
    "\n",
    "    def backprop(self,gradient=None,which_reg=0):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad  = tf.matmul(tf.transpose(grad_part_3),grad_middle)/batch_size\n",
    "        grad_b= tf.reduce_mean(grad_middle,axis=0)\n",
    "        grad_pass = tf.matmul(grad_middle,tf.transpose(self.w))\n",
    "\n",
    "        # === Reg ===\n",
    "        if self.which_reg == 0:\n",
    "            grad  = grad\n",
    "            grad_b= grad_b\n",
    "\n",
    "        if self.which_reg == 0.5:\n",
    "            grad  = grad + lamda * (tf.sqrt(tf.abs(self.w))) * (1.0/tf.sqrt(tf.abs(self.w)+ 10e-5)) * tf.sign(self.w)\n",
    "            grad_b= grad_b+lamda * (tf.sqrt(tf.abs(self.b))) * (1.0/tf.sqrt(tf.abs(self.b)+ 10e-5)) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 1:\n",
    "            grad = grad   + lamda * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 1.5:\n",
    "            grad = grad   + lamda * 1.0/(tf.sqrt(tf.square(self.w) + 10e-5)) * self.w\n",
    "            grad_b=grad_b + lamda * 1.0/(tf.sqrt(tf.square(self.b) + 10e-5)) * self.b\n",
    "\n",
    "        if self.which_reg == 2:\n",
    "            grad = grad  + lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.w))+ 10e-5)) * tf.abs(self.w) * tf.sign(self.w)\n",
    "            grad_b=grad_b+ lamda * (1.0/tf.sqrt(tf.square(tf.abs(self.b))+ 10e-5)) * tf.abs(self.b) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 2.5:\n",
    "            grad = grad   + lamda * 2.0 * self.w\n",
    "            grad_b=grad_b + lamda * 2.0 * self.b\n",
    "\n",
    "        if self.which_reg == 3:\n",
    "            grad = grad   + lamda * tf.pow(tf.pow(tf.abs(self.w),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.w),2) * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.pow(tf.pow(tf.abs(self.b),3)+ 10e-5,-0.66) * tf.pow(tf.abs(self.b),2) * tf.sign(self.b)\n",
    "\n",
    "        if self.which_reg == 4:\n",
    "            grad = grad   + lamda * tf.pow(tf.pow(tf.abs(self.w),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.w),3) * tf.sign(self.w)\n",
    "            grad_b=grad_b + lamda * tf.pow(tf.pow(tf.abs(self.b),4)+ 10e-5,-0.75) * tf.pow(tf.abs(self.b),3) * tf.sign(self.b)\n",
    "\n",
    "        update_w = []\n",
    "\n",
    "        # Update the Weight First\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat *  learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle )))\n",
    "\n",
    "        # Update the Bias later\n",
    "        update_w.append(tf.assign(self.m_b,self.m_b*beta1 + (1-beta1) * (grad_b)   ))\n",
    "        update_w.append(tf.assign(self.v_b,self.v_b*beta2 + (1-beta2) * (grad_b ** 2)   ))\n",
    "        m_hat_b = self.m_b / (1-beta1)\n",
    "        v_hat_b = self.v_b / (1-beta2)\n",
    "        adam_middle_b = m_hat_b *  learning_rate/(tf.sqrt(v_hat_b) + adam_e)\n",
    "        update_w.append(tf.assign(self.b,tf.subtract(self.b,adam_middle_b )))\n",
    "\n",
    "        return grad_pass,update_w\n",
    "    \n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,which_reg=0,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "        self.regularizer    = which_reg\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input,stride=1,padding='SAME'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='SAME'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) / batch_size\n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        if self.regularizer == 'A': grad = grad + lamda * tf.sign(self.w)\n",
    "        if self.regularizer == 'B': grad = grad + lamda * 2.0 * self.w\n",
    "        if self.regularizer == 'C': grad = grad + lamda * (1.0/tf.sqrt(tf.square(self.w)+ 10e-8)) * self.w\n",
    "        if self.regularizer == 'D': grad = grad + lamda * -(2*self.w)/(1 + self.w**2)\n",
    "        if self.regularizer == 'E': grad = grad + lamda * -(1-tf.tanh(self.w) ** 2)\n",
    "        if self.regularizer == 'F': grad = grad + lamda * -(1-tf.tanh(self.w** 2) ** 2) * 2.0 * self.w \n",
    "        if self.regularizer == 'G': grad = grad + lamda * -(1-tf.tanh(tf.abs(self.w)) ** 2) * tf.sign(self.w)\n",
    "        if self.regularizer == 'H': grad = grad + lamda * -(1-tf.tanh(tf.abs(self.w)** 2) ** 2) * 2.0 * tf.abs(self.w) *  tf.sign(self.w)\n",
    "        if self.regularizer == 'I': grad = grad + lamda * tf.cos(self.w)\n",
    "        if self.regularizer == 'J': grad = grad + lamda * tf.sign(tf.sin(self.w)) * tf.cos(self.w)\n",
    "        if self.regularizer == 'K': grad = grad + lamda * (2)/(self.w + 10e-8)\n",
    "        if self.regularizer == 'L': grad = grad + lamda * (tf.log(self.w**2) + 2.0)\n",
    "        \n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:40:32.595836Z",
     "start_time": "2019-02-07T02:40:30.369815Z"
    },
    "code_folding": [
     2,
     18
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) 1.0 0.0\n",
      "(50000, 10) 1.0 0.0\n",
      "(10000, 32, 32, 3) 1.0 0.0\n",
      "(10000, 10) 1.0 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_CIFAR10_data()\n",
    "rand_choice = np.random.choice(len(train_images))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(train_images[rand_choice])\n",
    "plt.title(str(train_labels[rand_choice]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T22:27:31.969314Z",
     "start_time": "2019-02-06T22:27:31.714466Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T02:18:36.811605Z",
     "start_time": "2019-02-07T02:18:35.307630Z"
    },
    "code_folding": [
     18,
     69,
     81,
     97
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                               | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn as nn\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import statistics as stats\n",
    "import argparse\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(3, 64, kernel_size=4, stride=1)\n",
    "        self.c1 = nn.Conv2d(64, 128, kernel_size=4, stride=1)\n",
    "        self.c2 = nn.Conv2d(128, 256, kernel_size=4, stride=1)\n",
    "        self.c3 = nn.Conv2d(256, 512, kernel_size=4, stride=1)\n",
    "        self.l1 = nn.Linear(512*20*20, 64)\n",
    "\n",
    "        self.b1 = nn.BatchNorm2d(128)\n",
    "        self.b2 = nn.BatchNorm2d(256)\n",
    "        self.b3 = nn.BatchNorm2d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))                      # (64, 64, 29, 29)\n",
    "        features = F.relu(self.b1(self.c1(h)))      # (64, 128, 26, 26)\n",
    "        h = F.relu(self.b2(self.c2(features)))      # (64, 256, 23, 23)\n",
    "        h = F.relu(self.b3(self.c3(h)))             # (64, 512, 20, 20)\n",
    "        encoded = self.l1(h.view(x.shape[0], -1))   # (batch,64)\n",
    "        return encoded, features\n",
    "\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(128, 64, kernel_size=3) # (64, 64, 24, 24)\n",
    "        self.c1 = nn.Conv2d(64, 32, kernel_size=3)  # (64, 32, 22, 22)\n",
    "        self.l0 = nn.Linear(32 * 22 * 22 + 64, 512) # (64, 512)\n",
    "        self.l1 = nn.Linear(512, 512)               # (512, 512)\n",
    "        self.l2 = nn.Linear(512, 1)                 # (512, 1)\n",
    "\n",
    "    def forward(self, y, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = self.c1(h)\n",
    "        h = h.view(y.shape[0], -1)\n",
    "        h = torch.cat((y, h), dim=1)\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "    \n",
    "class LocalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(192, 512, kernel_size=1)\n",
    "        self.c1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.c2 = nn.Conv2d(512, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        h = F.relu(self.c1(h))\n",
    "        return self.c2(h)\n",
    "    \n",
    "class PriorDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Linear(64, 1000)\n",
    "        self.l1 = nn.Linear(1000, 200)\n",
    "        self.l2 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return torch.sigmoid(self.l2(h))\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(64, 15)\n",
    "        self.bn1 = nn.BatchNorm1d(15)\n",
    "        self.l2 = nn.Linear(15, 10)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.l3 = nn.Linear(10, 10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded, _ = x[0], x[1]\n",
    "        clazz = F.relu(self.bn1(self.l1(encoded)))\n",
    "        clazz = F.relu(self.bn2(self.l2(clazz)))\n",
    "        clazz = F.softmax(self.bn3(self.l3(clazz)), dim=1)\n",
    "        return clazz\n",
    "class DeepInfoAsLatent(nn.Module):\n",
    "    def __init__(self, run, epoch):\n",
    "        super().__init__()\n",
    "        model_path = Path(r'c:/data/deepinfomax/models') / Path(str(run)) / Path('encoder' + str(epoch) + '.wgt')\n",
    "        self.encoder = Encoder()\n",
    "        self.encoder.load_state_dict(torch.load(str(model_path)))\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, features = self.encoder(x)\n",
    "        z = z.detach()\n",
    "        return self.classifier((z, features))\n",
    "    \n",
    "class DeepInfoMaxLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=1.0, gamma=0.1):\n",
    "        super().__init__()\n",
    "        self.global_d = GlobalDiscriminator()\n",
    "        self.local_d = LocalDiscriminator()\n",
    "        self.prior_d = PriorDiscriminator()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y, M, M_prime):\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "\n",
    "        y_exp = y.unsqueeze(-1).unsqueeze(-1)\n",
    "        y_exp = y_exp.expand(-1, -1, 26, 26)\n",
    "        y_M = torch.cat((M, y_exp), dim=1)\n",
    "        y_M_prime = torch.cat((M_prime, y_exp), dim=1)\n",
    "        Ej = -F.softplus(-self.local_d(y_M)).mean()\n",
    "        Em = F.softplus(self.local_d(y_M_prime)).mean()\n",
    "        LOCAL = (Em - Ej) * self.beta\n",
    "        \n",
    "        # global         \n",
    "        Ej = -F.softplus(-self.global_d(y, M)).mean()\n",
    "        Em = F.softplus(self.global_d(y, M_prime)).mean()\n",
    "        GLOBAL = (Em - Ej) * self.alpha\n",
    "\n",
    "        prior = torch.rand_like(y)\n",
    "        term_a = torch.log(self.prior_d(prior)).mean()\n",
    "        term_b = torch.log(1.0 - self.prior_d(y)).mean()\n",
    "        PRIOR = - (term_a + term_b) * self.gamma\n",
    "\n",
    "        return LOCAL + GLOBAL + PRIOR\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "\n",
    "# image size 3, 32, 32 batch size must be an even numbershuffle must be True\n",
    "cifar_10_train_dt = CIFAR10(r'c:\\data\\tv',  download=True, transform=ToTensor())\n",
    "cifar_10_train_l  = DataLoader(cifar_10_train_dt, batch_size=batch_size, shuffle=True, drop_last=True,pin_memory=torch.cuda.is_available())\n",
    "\n",
    "encoder    = Encoder().to(device)\n",
    "loss_fn    = DeepInfoMaxLoss().to(device)\n",
    "optim      = Adam(encoder.parameters(), lr=1e-4)\n",
    "loss_optim = Adam(loss_fn.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(100):\n",
    "    batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "    train_loss = []\n",
    "    \n",
    "    for x, target in batch:\n",
    "        x = x.to(device)\n",
    "\n",
    "        optim.zero_grad(); loss_optim.zero_grad()\n",
    "        y, M = encoder(x)\n",
    "        # y - > (64, 128, 26, 26)\n",
    "        # M - > (batch,64)\n",
    "        \n",
    "        # rotate images to create pairs for comparison (ROTATING)\n",
    "        M_prime = torch.cat((M[1:], M[0].unsqueeze(0)), dim=0)\n",
    "        loss = loss_fn(y, M, M_prime) # ()\n",
    "        sys.exit()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        batch.set_description(str(epoch) + ' Loss: ' + str(stats.mean(train_loss[-20:])))\n",
    "        loss.backward()\n",
    "        optim.step(); loss_optim.step()\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T01:49:41.457723Z",
     "start_time": "2019-02-07T01:49:41.329296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32, 32, 3)\n",
      "(64,)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "for x, target in batch:\n",
    "    temp = np.swapaxes(np.swapaxes(x.numpy(),1,3),2,1)\n",
    "    plt.imshow(temp[0])\n",
    "    plt.show()\n",
    "    print(temp.shape)\n",
    "    print(target.numpy().shape)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
