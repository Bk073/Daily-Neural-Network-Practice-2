{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T21:10:38.445807Z",
     "start_time": "2019-02-11T21:10:38.355064Z"
    },
    "code_folding": [
     0,
     32,
     34,
     61,
     69,
     93,
     96
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:00:02.381628Z",
     "start_time": "2019-02-08T05:59:59.015425Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) 1.0 0.0\n",
      "(50000, 10) 1.0 0.0\n",
      "(10000, 32, 32, 3) 1.0 0.0\n",
      "(10000, 10) 1.0 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_CIFAR10_data()\n",
    "rand_choice = np.random.choice(len(train_images))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(train_images[rand_choice])\n",
    "plt.title(str(train_labels[rand_choice]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:06:42.674348Z",
     "start_time": "2019-02-07T03:06:42.670356Z"
    }
   },
   "outputs": [],
   "source": [
    "# define learning rate\n",
    "num_eps   = 10; num_epoch = 200; learning_rate = 0.0008; batch_size = 50;  beta1,beta2,adam_e = 0.9,0.999,1e-9; print_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T07:17:31.131189Z",
     "start_time": "2019-02-11T07:17:31.058138Z"
    },
    "code_folding": [
     7,
     47,
     78
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x): return tf.nn.softmax(x)\n",
    "def tf_relu(x):   return tf.nn.relu(x)\n",
    "def d_tf_relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
    "def tf_iden(x):   return x\n",
    "def d_tf_iden(x): return tf.ones_like(x)\n",
    "\n",
    "class FNN():\n",
    "\n",
    "    def __init__(self,inc,outc,act=tf_iden,d_act=d_tf_iden,special_init=False):\n",
    "        if special_init:\n",
    "            interval = np.sqrt(6.0 / (inc + outc + 1.0))\n",
    "            self.w = tf.Variable(tf.random_uniform(shape=(inc, outc),minval=-interval,maxval=interval,dtype=tf.float32,seed=2))\n",
    "        else:\n",
    "            self.w = tf.Variable(tf.random_normal([inc,outc], stddev=0.05,seed=2,dtype=tf.float32))\n",
    "\n",
    "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input=None):\n",
    "        self.input = input\n",
    "        self.layer = tf.matmul(input,self.w) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer,self.layerA\n",
    "\n",
    "    def backprop(self,gradient=None,which_reg=0):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad  = tf.matmul(tf.transpose(grad_part_3),grad_middle)\n",
    "        grad_b= tf.reduce_mean(grad_middle,axis=0)\n",
    "        grad_pass = tf.matmul(grad_middle,tf.transpose(self.w))\n",
    "\n",
    "        update_w = []\n",
    "\n",
    "        # Update the Weight First\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1)\n",
    "        v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat *  learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle )))\n",
    "\n",
    "        return grad_pass,update_w\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,act=tf_relu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input  = input\n",
    "        self.layer  = tf.nn.conv2d(input,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA = self.act(self.layer)\n",
    "        return self.layer, self.layerA\n",
    "    \n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer)\n",
    "        grad_part_3 = self.input\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input),filter= self.w,out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "class tf_batch_norm_layer():\n",
    "    \n",
    "    def __init__(self,vector_shape,axis):\n",
    "        self.moving_mean = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.moving_vari = tf.Variable(tf.zeros(shape=[1,1,1,vector_shape],dtype=tf.float32))\n",
    "        self.axis        = axis\n",
    "    def feedforward(self,input,training_phase=True,eps = 1e-8):\n",
    "        self.input = input\n",
    "        self.input_size          = self.input.shape\n",
    "        self.batch,self.h,self.w,self.c = self.input_size[0].value,self.input_size[1].value,self.input_size[2].value,self.input_size[3].value\n",
    "\n",
    "        # Training Moving Average Mean         \n",
    "        def training_fn():\n",
    "            self.mean    = tf.reduce_mean(self.input,axis=self.axis ,keepdims=True)\n",
    "            self.var     = tf.reduce_mean(tf.square(self.input-self.mean),axis=self.axis,keepdims=True)\n",
    "            centered_data= (self.input - self.mean)/tf.sqrt(self.var + eps)\n",
    "            \n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean*0.9 + 0.1 * self.mean ))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari*0.9 + 0.1 * self.var  ))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        # Testing Moving Average Mean        \n",
    "        def  testing_fn():\n",
    "            centered_data   = (self.input - self.moving_mean)/tf.sqrt(self.moving_vari + eps)\n",
    "            update_variable = []\n",
    "            update_variable.append(tf.assign(self.moving_mean,self.moving_mean))\n",
    "            update_variable.append(tf.assign(self.moving_vari,self.moving_vari))\n",
    "            return centered_data,update_variable\n",
    "        \n",
    "        self.output,update_variable = tf.cond(training_phase,true_fn=training_fn,false_fn=testing_fn)\n",
    "        return self.output,update_variable\n",
    "    def backprop(self,grad,eps = 1e-8):\n",
    "        change_parts = 1.0 /(self.batch * self.h * self.w)\n",
    "        grad_sigma   = tf.reduce_sum( grad *  (self.input-self.mean)     ,axis=self.axis,keepdims=True) * -0.5 * (self.var+eps) ** -1.5\n",
    "        grad_mean    = tf.reduce_sum( grad *  (-1./tf.sqrt(self.var+eps)),axis=self.axis,keepdims=True) + grad_sigma * change_parts * 2.0 * tf.reduce_sum((self.input-self.mean),axis=self.axis,keepdims=True) * -1\n",
    "        grad_x       = grad * 1/(tf.sqrt(self.var+eps)) + grad_sigma * change_parts * 2.0 * (self.input-self.mean) + grad_mean * change_parts\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T04:51:38.385699Z",
     "start_time": "2019-02-08T04:51:38.361758Z"
    },
    "code_folding": [
     1,
     2,
     26,
     45,
     47
    ]
   },
   "outputs": [],
   "source": [
    "# create the modules\n",
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.l1 = CNN(4,3, 64); \n",
    "        self.l2 = CNN(4,64,128); \n",
    "        self.l3 = CNN(4,128,256); \n",
    "        self.l4 = CNN(4,256,512); \n",
    "        self.l5 = FNN(512*20*20,64); \n",
    "    def feedforward(self,input):\n",
    "        layer1, layer1a = self.l1. feedforward(input,stride=1)\n",
    "        layer2, layer2a = self.l2. feedforward(layer1a,stride=1)\n",
    "        layer3, layer3a = self.l3. feedforward(layer2a,stride=1)\n",
    "        layer4, layer4a = self.l4. feedforward(layer3a,stride=1)\n",
    "        layer5_input    = tf.reshape(layer4a,[batch_size,-1])\n",
    "        layer5, layer5a = self.l5. feedforward(layer5_input)\n",
    "        return layer5a\n",
    "    def backprop(self,grad):\n",
    "        gradient = tf.tile((final_softmax-y)[:,None,None,:],[1,6,6,1])/batch_size\n",
    "        grad6p,grad6w,grad6_up = l6.backprop(gradient,std_value=std_value)\n",
    "        grad5p,grad5w,grad5_up = l5.backprop(grad6p,std_value=std_value)\n",
    "        grad4p,grad4w,grad4_up = l4.backprop(grad5p,stride=2,std_value=std_value)\n",
    "        grad3p,grad3w,grad3_up = l3.backprop(grad4p,stride=2,std_value=std_value)\n",
    "        grad2p,grad2w,grad2_up = l2.backprop(grad3p,stride=2,std_value=std_value)\n",
    "        grad1p,grad1w,grad1_up = l1.backprop(grad2p,stride=2,std_value=std_value)\n",
    "        gradient_update = grad6_up + grad5_up + grad4_up + grad3_up + grad2_up + grad1_up \n",
    "        return None\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.c0 = CNN(3,128,64)\n",
    "        self.c1 = CNN(3,64, 32,act=tf_iden,d_act=tf_iden)\n",
    "        self.l0 = FNN(32*22*22+batch_size,512,act=tf_relu,d_act=d_tf_relu)\n",
    "        self.l1 = FNN(512, 512               ,act=tf_relu,d_act=d_tf_relu)\n",
    "        self.l2 = FNN(512, 1)\n",
    "\n",
    "    def forward(self, y, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = self.c1(h)\n",
    "        h = h.view(y.shape[0], -1)\n",
    "        h = torch.cat((y, h), dim=1)\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "    \n",
    "    def backprop(self):\n",
    "        return None\n",
    "class LocalDiscriminator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.l1 = CNN(1,192,512); \n",
    "        self.l2 = CNN(1,512,512); \n",
    "        self.l3 = CNN(1,128,256); \n",
    "        \n",
    "    def feedforward(self,input):\n",
    "        layer1, layer1a = self.l1. feedforward(input,  stride=1)\n",
    "        layer2, layer2a = self.l2. feedforward(layer1a,stride=1)  \n",
    "        layer3, layer3a = self.l3. feedforward(layer2a,stride=1)  \n",
    "        return layer3a\n",
    "    \n",
    "    def backprop(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T04:51:40.509664Z",
     "start_time": "2019-02-08T04:51:40.326347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_15:0\", shape=(64, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# build encoder \n",
    "x = tf.placeholder(tf.float32,(batch_size,32,32,3))\n",
    "y = tf.placeholder(tf.float32,(batch_size,10))\n",
    "\n",
    "MI_encoder = Encoder()\n",
    "temptemp   = MI_encoder.feedforward(x)\n",
    "print(temptemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-11T06:33:51.493441Z",
     "start_time": "2019-02-11T06:33:41.148679Z"
    },
    "code_folding": [
     18,
     38,
     55,
     68,
     80,
     96,
     131
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                               | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512, 26, 26])\n",
      "torch.Size([64, 512, 26, 26])\n",
      "torch.Size([64, 512, 26, 26])\n",
      "torch.Size([64, 512, 26, 26])\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn as nn\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import statistics as stats\n",
    "import argparse\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(3, 64, kernel_size=4, stride=1)\n",
    "        self.c1 = nn.Conv2d(64, 128, kernel_size=4, stride=1)\n",
    "        self.c2 = nn.Conv2d(128, 256, kernel_size=4, stride=1)\n",
    "        self.c3 = nn.Conv2d(256, 512, kernel_size=4, stride=1)\n",
    "        self.l1 = nn.Linear(512*20*20, 64)\n",
    "\n",
    "        self.b1 = nn.BatchNorm2d(128)\n",
    "        self.b2 = nn.BatchNorm2d(256)\n",
    "        self.b3 = nn.BatchNorm2d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))                      # (64, 64, 29, 29)\n",
    "        features = F.relu(self.b1(self.c1(h)))      # (64, 128, 26, 26)\n",
    "        h = F.relu(self.b2(self.c2(features)))      # (64, 256, 23, 23)\n",
    "        h = F.relu(self.b3(self.c3(h)))             # (64, 512, 20, 20)\n",
    "        encoded = self.l1(h.view(x.shape[0], -1))   # (batch,64)\n",
    "        return encoded, features\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(128, 64, kernel_size=3) # (64, 64, 24, 24)\n",
    "        self.c1 = nn.Conv2d(64, 32,  kernel_size=3)  # (64, 32, 22, 22)\n",
    "        self.l0 = nn.Linear(32 * 22 * 22 + 64, 512) # (64, 512)\n",
    "        self.l1 = nn.Linear(512, 512)               # (512, 512)\n",
    "        self.l2 = nn.Linear(512, 1)                 # (512, 1)\n",
    "\n",
    "    def forward(self, y, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = self.c1(h)\n",
    "        h = h.view(y.shape[0], -1)\n",
    "        h = torch.cat((y, h), dim=1)\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "class LocalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(192, 512, kernel_size=1)\n",
    "        self.c1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.c2 = nn.Conv2d(512, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        print(h.size())\n",
    "        h = F.relu(self.c1(h))\n",
    "        print(h.size())\n",
    "        return self.c2(h)\n",
    "class PriorDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Linear(64, 1000)\n",
    "        self.l1 = nn.Linear(1000, 200)\n",
    "        self.l2 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return torch.sigmoid(self.l2(h))\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(64, 15)\n",
    "        self.bn1 = nn.BatchNorm1d(15)\n",
    "        self.l2 = nn.Linear(15, 10)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.l3 = nn.Linear(10, 10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded, _ = x[0], x[1]\n",
    "        clazz = F.relu(self.bn1(self.l1(encoded)))\n",
    "        clazz = F.relu(self.bn2(self.l2(clazz)))\n",
    "        clazz = F.softmax(self.bn3(self.l3(clazz)), dim=1)\n",
    "        return clazz\n",
    "class DeepInfoMaxLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=1.0, gamma=0.1):\n",
    "        super().__init__()\n",
    "        self.global_d = GlobalDiscriminator()\n",
    "        self.local_d = LocalDiscriminator()\n",
    "        self.prior_d = PriorDiscriminator()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y, M, M_prime):\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "        \n",
    "        # LOCAL\n",
    "        y_exp = y.unsqueeze(-1).unsqueeze(-1)\n",
    "        y_exp = y_exp.expand(-1, -1, 26, 26)\n",
    "        y_M = torch.cat((M, y_exp), dim=1)\n",
    "        y_M_prime = torch.cat((M_prime, y_exp), dim=1)\n",
    "        Ej = -F.softplus(-self.local_d(y_M)).mean()\n",
    "        Em = F.softplus(self.local_d(y_M_prime)).mean()\n",
    "        LOCAL = (Em - Ej) * self.beta\n",
    "        \n",
    "        # global         \n",
    "        Ej = -F.softplus(-self.global_d(y, M)).mean()\n",
    "        Em = F.softplus(self.global_d(y, M_prime)).mean()\n",
    "        GLOBAL = (Em - Ej) * self.alpha\n",
    "        \n",
    "        # have some prior\n",
    "        prior = torch.rand_like(y)\n",
    "        term_a = torch.log(self.prior_d(prior)).mean()\n",
    "        term_b = torch.log(1.0 - self.prior_d(y)).mean()\n",
    "        PRIOR = - (term_a + term_b) * self.gamma\n",
    "\n",
    "        return LOCAL + GLOBAL + PRIOR\n",
    "class DeepInfoAsLatent(nn.Module):\n",
    "    def __init__(self, run, epoch):\n",
    "        super().__init__()\n",
    "        model_path = Path(r'c:/data/deepinfomax/models') / Path(str(run)) / Path('encoder' + str(epoch) + '.wgt')\n",
    "        self.encoder = Encoder()\n",
    "        self.encoder.load_state_dict(torch.load(str(model_path)))\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, features = self.encoder(x)\n",
    "        z = z.detach()\n",
    "        return self.classifier((z, features))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "\n",
    "# image size 3, 32, 32 batch size must be an even numbershuffle must be True\n",
    "cifar_10_train_dt = CIFAR10(r'c:\\data\\tv',  download=True, transform=ToTensor())\n",
    "cifar_10_train_l  = DataLoader(cifar_10_train_dt, batch_size=batch_size, shuffle=True, drop_last=True,pin_memory=torch.cuda.is_available())\n",
    "\n",
    "encoder    = Encoder().to(device)\n",
    "loss_fn    = DeepInfoMaxLoss().to(device)\n",
    "optim      = Adam(encoder.parameters(), lr=1e-4)\n",
    "loss_optim = Adam(loss_fn.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(100):\n",
    "    batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "    train_loss = []\n",
    "    \n",
    "    for x, target in batch:\n",
    "        x = x.to(device)\n",
    "\n",
    "        optim.zero_grad(); loss_optim.zero_grad()\n",
    "        y, M = encoder(x)\n",
    "        # y - > (64, 128, 26, 26)\n",
    "        # M - > (batch,64)\n",
    "        \n",
    "        # rotate images to create pairs for comparison (ROTATING)\n",
    "        M_prime = torch.cat((M[1:], M[0].unsqueeze(0)), dim=0)\n",
    "        loss = loss_fn(y, M, M_prime) # ()\n",
    "        sys.exit()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        batch.set_description(str(epoch) + ' Loss: ' + str(stats.mean(train_loss[-20:])))\n",
    "        loss.backward()\n",
    "        optim.step(); loss_optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:12:26.562738Z",
     "start_time": "2019-02-07T03:12:19.110Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = tqdm(cifar_10_train_l, total=len(cifar_10_train_dt) // batch_size)\n",
    "for x, target in batch:\n",
    "    temp = np.swapaxes(np.swapaxes(x.numpy(),1,3),2,1)\n",
    "    plt.imshow(temp[0])\n",
    "    plt.show()\n",
    "    print(temp.shape)\n",
    "    print(target.numpy().shape)\n",
    "    sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
