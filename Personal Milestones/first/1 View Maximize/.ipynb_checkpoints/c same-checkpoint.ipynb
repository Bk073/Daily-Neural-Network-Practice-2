{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T06:27:09.857Z"
    },
    "code_folding": [
     0,
     34,
     94
    ]
   },
   "outputs": [],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imresize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T06:27:10.266Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "rand_choice  = np.random.choice(len(train_images))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(np.squeeze(train_images[rand_choice]),cmap='gray'); plt.title(str(train_labels[rand_choice])); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T06:27:29.224Z"
    },
    "code_folding": [
     17,
     35,
     46,
     62,
     73,
     105,
     110
    ]
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn as nn\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import statistics as stats\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage import feature\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(1, 32,  kernel_size=3, stride=1,padding=1)\n",
    "        self.c1 = nn.Conv2d(32, 32, kernel_size=3, stride=1,padding=1)\n",
    "        self.c2 = nn.Conv2d(32, 32, kernel_size=3, stride=1,padding=1)\n",
    "        self.c3 = nn.Conv2d(32, 32, kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "        self.b1 = nn.BatchNorm2d(32)\n",
    "        self.b2 = nn.BatchNorm2d(32)\n",
    "        self.b3 = nn.BatchNorm2d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        h = F.relu(self.b1(self.c1(h)))\n",
    "        h = F.relu(self.b2(self.c2(h)))\n",
    "        h = F.relu(self.b3(self.c3(h)))\n",
    "        return h\n",
    "class LocalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(33, 64, kernel_size=1)\n",
    "        self.c1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.c2 = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        h = F.relu(self.c1(h))\n",
    "        return self.c2(h)\n",
    "class GlobalDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c0 = nn.Conv2d(33, 64, kernel_size=3)\n",
    "        self.c1 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.l0 = nn.Linear(64 * 92 * 92, 256)\n",
    "        self.l1 = nn.Linear(256, 256)\n",
    "        self.l2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = self.c1(h)\n",
    "        h = h.view(h.shape[0], -1)\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "class PriorDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l0 = nn.Conv2d(32, 64, kernel_size=1)\n",
    "        self.l1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.l2 = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return torch.sigmoid(self.l2(h))\n",
    "class DeepInfoMaxLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.1, beta=0.1, gamma=0.8):\n",
    "        super().__init__()\n",
    "        self.global_d = GlobalDiscriminator()\n",
    "        self.local_d  = LocalDiscriminator()\n",
    "        self.prior_d  = PriorDiscriminator()\n",
    "        self.alpha = alpha\n",
    "        self.beta  = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, image,M, M_prime):\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "        y_M       = torch.cat((M, image), dim=1)\n",
    "        y_M_prime = torch.cat((M_prime, image), dim=1)\n",
    "\n",
    "        Ej = -F.softplus(-self.local_d(y_M)).mean()\n",
    "        Em = F.softplus(self.local_d(y_M_prime)).mean()\n",
    "        LOCAL = (Em - Ej) * self.beta\n",
    "\n",
    "        Ej = -F.softplus(-self.global_d(y_M)).mean()\n",
    "        Em = F.softplus(self.global_d(y_M_prime)).mean()\n",
    "        GLOBAL = (Em - Ej) * self.alpha\n",
    "        \n",
    "        prior = torch.rand_like(M)\n",
    "\n",
    "        term_a = torch.log(self.prior_d(prior)).mean()\n",
    "        term_b = torch.log(1.0 - self.prior_d(M)).mean()\n",
    "        PRIOR = - (term_a + term_b) * self.gamma\n",
    "\n",
    "        return LOCAL + GLOBAL + PRIOR\n",
    "    \n",
    "def calc_MI1(x, y, bins=30):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    g, p, dof, expected = chi2_contingency(c_xy, lambda_=\"log-likelihood\")\n",
    "    mi = 0.5 * g / c_xy.sum()\n",
    "    return mi\n",
    "def calc_MI2(x, y, bins=30):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T06:27:29.754Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up \n",
    "device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder    = Encoder().to(device)\n",
    "loss_fn    = DeepInfoMaxLoss().to(device)\n",
    "optim      = Adam(encoder.parameters(), lr=1e-4)\n",
    "loss_optim = Adam(loss_fn.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-26T06:27:33.386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "num_epoch  = 50\n",
    "batch_size = 10\n",
    "for iter in range(num_epoch):\n",
    "    train_images = shuffle(train_images)\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_batch  = train_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
    "        current_batch  = np.transpose(current_batch,(0,3,1,2)).astype(np.float32)\n",
    "        current_batch_s= np.array([resize(np.squeeze(x),(88,88)) for x in current_batch]).astype(np.float32)[:,None,:,:]\n",
    "        x         = torch.from_numpy(current_batch).to(device)\n",
    "        optim.zero_grad()\n",
    "        loss_optim.zero_grad()\n",
    "        M       = encoder(x)\n",
    "        M_prime = torch.cat((M[1:], M[0].unsqueeze(0)), dim=0)\n",
    "        loss    = loss_fn(x, M, M_prime)\n",
    "        sys.stdout.write('Current Iter: '+str(iter)+'/'+str(num_epoch)+\" Batch: \"+str(current_batch_index)+'/'+str(len(train_images))+' loss : ' + str(loss.item()) + '\\r')\n",
    "        sys.stdout.flush(); \n",
    "        loss.backward(); optim.step(); loss_optim.step()\n",
    "        sys.exit()\n",
    "    if iter % 5 == 0 : print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T06:26:05.663426Z",
     "start_time": "2019-02-26T06:26:05.622562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 96, 96)\n",
      "(10, 96, 96, 32)\n"
     ]
    }
   ],
   "source": [
    "# re-read the images\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "# plot two images and show convergence curve\n",
    "def plot_image_and_feature(first_image_select):\n",
    "    first_image_select_resize = np.squeeze(first_image_select)\n",
    "\n",
    "    first_image = torch.from_numpy(np.transpose(first_image_select[None,:,:,:],(0,3,1,2)).astype(np.float32)).to(device)\n",
    "    first_M = encoder(first_image)\n",
    "    M_np = first_M.cpu().detach().numpy()\n",
    "    M_np = np.transpose(M_np,(0,2,3,1))\n",
    "    M_np = (M_np-M_np.min((0,1,2),keepdims=True))/(M_np.max((0,1,2),keepdims=True)-M_np.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.squeeze(first_image_select),cmap='gray'); \n",
    "    plt.title(\"Upper Bound: \"+\n",
    "              str(np.around(calc_MI2(first_image_select.ravel(),first_image_select.ravel()),2)) +\n",
    "              \"\\nRandom Noise Bound: \" +\n",
    "              str(np.around(calc_MI2(np.random.normal(size=first_image_select.shape).ravel(),first_image_select.ravel()),2))\n",
    "             )\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    image = 1; total_mi = 0\n",
    "    for i in range(len(M_np.T)):\n",
    "        plt.subplot(4,8,i+1)\n",
    "        plt.imshow(M_np[0,:,:,i],cmap='gray'); \n",
    "        plt.title(str(np.around(calc_MI2(M_np[0,:,:,i].ravel(),first_image_select_resize.ravel()),2)),fontsize=15)\n",
    "        plt.axis('off')\n",
    "        total_mi = total_mi +calc_MI2(M_np[0,:,:,i].ravel(),first_image_select_resize.ravel())\n",
    "    plt.suptitle(\"Average MI: \"+str(np.around(total_mi/len(M_np.T),2) ),fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# show two images\n",
    "plot_image_and_feature(train_images[10])\n",
    "plot_image_and_feature(train_images[11])\n",
    "\n",
    "# show convergence curve / save\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(convergence_values)\n",
    "plt.title(\"Convergence Curve\")\n",
    "plt.show()\n",
    "np.save(\"c_convergence_curve.npy\",convergence_values)\n",
    "\n",
    "# for all of the images do MI \n",
    "all_image_mi = []\n",
    "for index in range(len(train_images)):\n",
    "    sys.stdout.write('Current index: '+str(index)+'/'+str(len(train_images))+'\\r')\n",
    "    sys.stdout.flush(); \n",
    "    temp_list = []\n",
    "    current_image_resize = np.squeeze(train_images[index,:,:,:])\n",
    "    current_image = torch.from_numpy(np.transpose(train_images[index,:,:,:][None,:,:,:],(0,3,1,2)).astype(np.float32)).to(device)\n",
    "    current_M = encoder(current_image)\n",
    "    M_np = current_M.cpu().detach().numpy()\n",
    "    M_np = np.squeeze((M_np-M_np.min((0,1,2),keepdims=True))/(M_np.max((0,1,2),keepdims=True)-M_np.min((0,1,2),keepdims=True)+1e-8))\n",
    "    \n",
    "    for features in M_np: temp_list.append(calc_MI2(features.ravel(),current_image_resize.ravel()))\n",
    "        \n",
    "    upper_bound = calc_MI2(current_image_resize.ravel(),current_image_resize.ravel())\n",
    "    noise_bound = calc_MI2(np.random.normal(size=current_image_resize.shape).ravel(),current_image_resize.ravel())\n",
    "    all_image_mi.append(\n",
    "        (upper_bound,noise_bound,max(temp_list),min(temp_list),np.mean(temp_list),np.std(temp_list))\n",
    "    )\n",
    "all_image_mi = np.asarray(all_image_mi)\n",
    "np.save(\"c_MI.npy\",all_image_mi)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(all_image_mi[:,0],alpha=0.5)\n",
    "plt.plot(all_image_mi[:,2])\n",
    "plt.plot(all_image_mi[:,4])\n",
    "plt.plot(all_image_mi[:,1],alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
