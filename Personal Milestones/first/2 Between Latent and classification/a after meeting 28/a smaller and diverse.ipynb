{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:11.539200Z",
     "start_time": "2019-03-01T06:19:07.093009Z"
    },
    "code_folding": [
     0,
     39,
     99
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imresize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage import feature\n",
    "from scipy import stats\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:36.164909Z",
     "start_time": "2019-03-01T06:19:36.152243Z"
    },
    "code_folding": [
     25,
     32,
     49,
     66,
     70
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x):    return tf.nn.softmax(x)\n",
    "def tf_elu(x):       return tf.nn.elu(x)\n",
    "def tf_relu(x):       return tf.nn.relu(x)\n",
    "def tf_iden(x):       return x\n",
    "def tf_sigmoid(x):    return tf.nn.sigmoid(x)\n",
    "def tf_tanh(x):    return tf.nn.tanh(x)\n",
    "def tf_softplus(x):   return tf.nn.softplus(x)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,act=tf_elu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.act = act\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    \n",
    "    # Feed Forward for two variables\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input1  = input\n",
    "        self.layer1  = tf.nn.conv2d(self.input1,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA1 = self.act(self.layer1)\n",
    "        return self.layer1, self.layerA1\n",
    "    def feedforward2(self,input,stride=1,padding='VALID'):\n",
    "        self.input2  = input\n",
    "        self.layer2  = tf.nn.conv2d(self.input2,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA2 = self.act(self.layer2)\n",
    "        return self.layer2, self.layerA2\n",
    "\n",
    "def calc_MI(x, y, bins=(90*90)/4):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi\n",
    "def softmax_multi(target, axis=(1,2), name=None):\n",
    "    max_axis   = tf.reduce_max(target, axis, keepdims=True)\n",
    "    target_exp = tf.exp(target-max_axis)\n",
    "    normalize  = tf.reduce_sum(target_exp, axis, keepdims=True)\n",
    "    softmax    = target_exp / normalize\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:14.668411Z",
     "start_time": "2019-03-01T06:19:11.560111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "# 1. sym padding \n",
    "# 2. sug metn sim -> not a good idea (sparse filtering - population sparsity -)\n",
    "# 3. sales pitch - data aug (latent space) (paper - how is different from x)\n",
    "# 4. baseline - other approaches - \n",
    "# 5. show negative images \n",
    "# 6. sparse filtering\n",
    "# 7. classifier - mmke it a dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:14.676381Z",
     "start_time": "2019-03-01T06:19:14.671395Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyeper\n",
    "num_eps   = 1; num_epoch = 10; learning_rate = 0.0001; batch_size = 20;  alpha = 0.5\n",
    "beta1,beta2,adam_e  = 0.9,0.999,1e-8; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:23:03.295152Z",
     "start_time": "2019-03-01T06:23:02.944466Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "num_of_aug  = 5\n",
    "l1_encoder  = CNN(3,1,num_of_aug,         act=tf_elu)\n",
    "l2_encoder  = CNN(3,num_of_aug,num_of_aug,act=tf_elu)\n",
    "l3_encoder  = CNN(3,num_of_aug,num_of_aug,act=tf_elu)\n",
    "\n",
    "l1_global = CNN(3,num_of_aug+1,num_of_aug+1,act=tf_elu)\n",
    "l2_global = CNN(3,num_of_aug+1,num_of_aug+1,act=tf_elu)\n",
    "l3_global = CNN(3,num_of_aug+1,num_of_aug+1,act=tf_iden)\n",
    "\n",
    "def global_feed(input_data):\n",
    "    _,layer1_g = l1_global.feedforward(input_data)\n",
    "    _,layer2_g = l2_global.feedforward(layer1_g)\n",
    "    _,layer3_g = l3_global.feedforward(layer2_g)\n",
    "    return layer3_g\n",
    "\n",
    "x_encoding = tf.placeholder(tf.float32,(None,96,96,1))\n",
    "x_reisze   = tf.image.resize_images(x_encoding,(90,90))\n",
    "\n",
    "_,layer1_e = l1_encoder.feedforward(x_encoding)\n",
    "_,layer2_e = l2_encoder.feedforward(layer1_e)\n",
    "_,layer3_e = l3_encoder.feedforward(layer2_e)\n",
    "\n",
    "layer3_s  = tf.transpose(layer3_e,(0,2,1,3))\n",
    "encoded_gt = tf.concat([layer3_e ,x_reisze],3)\n",
    "encoded_rd = tf.concat([layer3_s ,x_reisze],3)\n",
    "\n",
    "global_gt  = tf.reduce_mean(-tf_relu(-global_feed(encoded_gt)))\n",
    "global_rd  = tf.reduce_mean( tf_relu( global_feed(encoded_rd)))\n",
    "LOSS       = (global_rd - global_gt) \n",
    "reg = tf.reduce_sum(tf.nn.l2_loss(l1_encoder.getw())) + tf.reduce_sum(tf.nn.l2_loss(l2_encoder.getw())) + tf.reduce_sum(tf.nn.l2_loss(l3_encoder.getw())) \n",
    "LOSS= LOSS \n",
    "\n",
    "auto_train = tf.train.AdamOptimizer(0.0008).minimize(LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:43.447919Z",
     "start_time": "2019-03-01T06:19:42.164122Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creat classification network\n",
    "x = tf.placeholder(tf.float32,(None,90,90,1))\n",
    "y = tf.placeholder(tf.float32,(None,10))\n",
    "is_training = tf.placeholder_with_default(True,())\n",
    "\n",
    "l1 = CNN(3,1,32)\n",
    "l2 = CNN(3,32,32)\n",
    "l3 = CNN(3,32,32)\n",
    "\n",
    "l4 = CNN(3,32,64)\n",
    "l5 = CNN(3,64,64)\n",
    "l6 = CNN(3,64,64)\n",
    "\n",
    "l7 = CNN(3,64,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)\n",
    "\n",
    "_,layer1 = l1.feedforward(x)\n",
    "layer1 = tf.layers.batch_normalization(layer1, training=is_training)\n",
    "_,layer2 = l2.feedforward(layer1)\n",
    "layer2 = tf.layers.batch_normalization(layer2, training=is_training)\n",
    "_,layer3 = l3.feedforward(layer2)\n",
    "layer3   = tf.nn.avg_pool(layer3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "_,layer4 = l4.feedforward(layer3)\n",
    "layer4 = tf.layers.batch_normalization(layer4, training=is_training)\n",
    "_,layer5 = l5.feedforward(layer4)\n",
    "layer5 = tf.layers.batch_normalization(layer5, training=is_training)\n",
    "_,layer6 = l6.feedforward(layer5)\n",
    "layer6   = tf.nn.avg_pool(layer6,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "_,layer7 = l7.feedforward(layer6)\n",
    "layer7 = tf.layers.batch_normalization(layer7, training=is_training)\n",
    "_,layer8 = l8.feedforward(layer7)\n",
    "layer8 = tf.layers.batch_normalization(layer8, training=is_training)\n",
    "_,layer9 = l9.feedforward(layer8)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,(1,2))\n",
    "final_soft  = tf_softmax(final_layer)\n",
    "cost               = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y))\n",
    "correct_prediction = tf.equal(tf.argmax(final_soft, 1), tf.argmax(y, 1))\n",
    "accuracy  = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "class_train = tf.train.AdamOptimizer(learning_rate=0.0008).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:23:39.618145Z",
     "start_time": "2019-03-01T06:23:05.584173Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Current Iter : 0/10 batch : 4980/5000 loss : 6.838844e-0555\n",
      "\n",
      " Current Iter : 5/10 batch : 4980/5000 loss : 1.7553764e-065\n",
      "\n",
      " Current Iter : 9/10 batch : 4980/5000 loss : 1.91172e-0606\r"
     ]
    }
   ],
   "source": [
    "# train the network \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 10\n",
    "for iter in range(num_epoch):\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([LOSS,auto_train],feed_dict={x_encoding:current_batch})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' loss : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush();    \n",
    "    if iter%5==0: \n",
    "        print('\\n')\n",
    "        train_images = shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:23:42.308966Z",
     "start_time": "2019-03-01T06:23:42.015748Z"
    },
    "code_folding": [
     10,
     20
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8100,) (8836,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1be40a38c439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mall_image_mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_index2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mall_image_mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_feature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_index2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_image_resize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mall_image_mi_sort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mall_image_mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mbest_indexn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_image_mi_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-59cfd09e4871>\u001b[0m in \u001b[0;36mcalc_MI\u001b[1;34m(x, y, bins)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mc_xy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mmi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontingency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_xy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36mhistogram2d\u001b[1;34m(x, y, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[0mxedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mxedges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myedges\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m     \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistogramdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36mhistogramdd\u001b[1;34m(sample, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    952\u001b[0m                 raise ValueError(\n\u001b[0;32m    953\u001b[0m                     '`bins[{}]` must be positive, when an integer'.format(i))\n\u001b[1;32m--> 954\u001b[1;33m             \u001b[0msmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m             \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[1;34m(a, range)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     31\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8100,) (8836,) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "capture_best = []\n",
    "for current_batch_index in range(0,len(train_images),batch_size):\n",
    "    current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "    \n",
    "    current_image_resize = np.asarray([resize(np.squeeze(x),(9,90)) for x in current_batch])[:,:,:,None]\n",
    "    current_image_resize = (current_image_resize-current_image_resize.min((0,1,2),keepdims=True))/(current_image_resize.max((0,1,2),keepdims=True)-current_image_resize.min((0,1,2),keepdims=True)+1e-8)\n",
    "    latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch})\n",
    "    latent_feature = (latent_feature-latent_feature.min((0,1,2),keepdims=True))/(latent_feature.max((0,1,2),keepdims=True)-latent_feature.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "    for image_index in range(len(current_batch)-10):\n",
    "        plt.figure(figsize=(3*num_of_aug+1,6))\n",
    "        \n",
    "        plt.subplot(2,num_of_aug+1,1)\n",
    "        plt.imshow(np.squeeze(current_image_resize[image_index]),cmap='gray')\n",
    "        upper_bound = calc_MI(current_image_resize[image_index].ravel(),current_image_resize[image_index].ravel())\n",
    "        plt.title(str(np.around(upper_bound,2)))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        all_image_mi = []\n",
    "        for image_index2 in range(len(latent_feature.T)): \n",
    "            all_image_mi.append(calc_MI(latent_feature[image_index,:,:,image_index2].ravel(),current_image_resize[image_index].ravel()))\n",
    "        all_image_mi_sort = sorted(range(len(all_image_mi)), key=lambda k: all_image_mi[k])[::-1]\n",
    "        best_indexn = all_image_mi_sort[0]\n",
    "        print(all_image_mi_sort)\n",
    "        print(best_indexn)\n",
    "        capture_best.append(best_indexn)\n",
    "        \n",
    "        count = 2\n",
    "        for high_index in all_image_mi_sort:\n",
    "            plt.subplot(2,num_of_aug+1,count)\n",
    "            plt.imshow(np.squeeze(latent_feature[image_index,:,:,high_index]),cmap='gist_rainbow'); plt.axis('off')\n",
    "            current_mi= calc_MI(latent_feature[image_index,:,:,high_index].ravel(),current_image_resize[image_index].ravel())\n",
    "            percent   = 1-(upper_bound-current_mi)/upper_bound\n",
    "            plt.title(str(np.around(percent,2)))\n",
    "            count = count + 1\n",
    "            \n",
    "        count = count + 1\n",
    "        for high_index in all_image_mi_sort:\n",
    "            plt.subplot(2,num_of_aug+1,count)\n",
    "            plt.imshow(np.squeeze(latent_feature[image_index,:,:,high_index]),cmap='gray'); plt.axis('off')\n",
    "            current_mi= calc_MI(latent_feature[image_index,:,:,high_index].ravel(),current_image_resize[image_index].ravel())\n",
    "            percent   = current_mi/upper_bound\n",
    "            plt.title(str(np.around(percent,2)))\n",
    "            count = count + 1\n",
    "            \n",
    "        plt.show()\n",
    "    capture_best_index = stats.mode(capture_best)[0]\n",
    "    print('Best : ',capture_best_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:20:41.909675Z",
     "start_time": "2019-03-01T06:20:38.301538Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-840e69c9c4c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest_images\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_images\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "num_epoch = 200\n",
    "\n",
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "test_images  = test_images.mean(3,keepdims=True)\n",
    "test_images  = (test_images-test_images.min((0,1,2),keepdims=True))/(test_images.max((0,1,2),keepdims=True)-test_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []; dividsion = 1\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    # train for training images\n",
    "    for current_batch_index in range(0,len(train_images),batch_size//dividsion):\n",
    "        current_batch = train_images[current_batch_index:current_batch_index+batch_size//dividsion]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size//dividsion]\n",
    "        latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch}) \n",
    "        latent_feature = np.reshape(np.transpose(latent_feature,(0,3,1,2)),(batch_size//dividsion*num_of_aug,90,90))[:,:,:,None]\n",
    "        latent_labels  = np.asarray([ [x]* num_of_aug for x in current_label]).reshape((batch_size//dividsion*num_of_aug,10))\n",
    "\n",
    "        sess_results = sess.run([accuracy,class_train,extra_update_ops],feed_dict={x:latent_feature,y:latent_labels})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "\n",
    "    # test for training images\n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_batch  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label  = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch})[:,:,:,0][:,:,:,None]\n",
    "        \n",
    "        sess_results = sess.run([accuracy],feed_dict={x:latent_feature,y:current_label,is_training:False})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0] \n",
    "        \n",
    "    # ======================== print reset ========================\n",
    "    if iter%1 == 0 :\n",
    "        train_images,train_labels = shuffle(train_images,train_labels)\n",
    "        sys.stdout.write(\"Current : \"+ str(iter) + \"\\t\" +\n",
    "              \" Train Acc : \" + str(np.around(avg_acc_train/(len(train_images)/batch_size*dividsion),3)) + \"\\t\" +\n",
    "              \" Test Acc : \"  + str(np.around(avg_acc_test/(len(test_images)/batch_size),3)) + \"\\t\\n\")\n",
    "        sys.stdout.flush();\n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:14.839582Z",
     "start_time": "2019-03-01T06:19:07.267Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# len(test_images)\n",
    "accuray_test = 0\n",
    "for current_batch_index in range(len(test_images)):\n",
    "    current_batch = test_images[current_batch_index:current_batch_index+1]\n",
    "    current_label = test_labels[current_batch_index:current_batch_index+1]\n",
    "    latent_feature = sess.run(layer2_e,feed_dict={x_encoding:current_batch})\n",
    "    latent_feature = np.transpose(latent_feature,(3,1,2,0))\n",
    "    sess_results = sess.run(final_soft,feed_dict={x:latent_feature,y:current_label,is_training:False})\n",
    "    m = stats.mode(np.argmax(sess_results,1))\n",
    "    if m[0] == np.argmax(current_label,1):\n",
    "        accuray_test = accuray_test + 1\n",
    "print(accuray_test)\n",
    "print(accuray_test/len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:17:12.615183Z",
     "start_time": "2019-02-27T06:17:12.610171Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T06:19:14.840579Z",
     "start_time": "2019-03-01T06:19:07.284Z"
    }
   },
   "outputs": [],
   "source": [
    "    if avg_acc_test/(len(test_images)/batch_size) < avg_acc_train/(len(train_images)/batch_size*dividsion):\n",
    "        print('\\n MAX  \\t')\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "            sess_results  = sess.run([TOTAL_LOSS,auto_train],feed_dict={x_encoding:current_batch})\n",
    "            sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' loss : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush(); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
