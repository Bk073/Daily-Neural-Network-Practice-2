{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:43:33.208655Z",
     "start_time": "2019-03-01T04:43:29.023705Z"
    },
    "code_folding": [
     0,
     39,
     99
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Library and some random image data set\n",
    "import tensorflow as tf\n",
    "import numpy      as np\n",
    "import seaborn    as sns \n",
    "import pandas     as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "np.random.seed(78); tf.set_random_seed(78)\n",
    "\n",
    "# get some of the STL data set\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import util \n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imresize\n",
    "from skimage.io import imread\n",
    "import warnings\n",
    "from numpy import inf\n",
    "\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from IPython.display import display, clear_output\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import animation\n",
    "%load_ext jupyternotify\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage import feature\n",
    "from scipy import stats\n",
    "# Def: Read STL 10 images\n",
    "def read_STL10_data():\n",
    "    # read all of the data (STL 10) https://github.com/mttk/STL10\n",
    "    def read_all_images(path_to_data):\n",
    "        \"\"\"\n",
    "        :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "        :return: an array containing all the images\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path_to_data, 'rb') as f:\n",
    "            # read whole file in uint8 chunks\n",
    "            everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "            # We force the data into 3x96x96 chunks, since the\n",
    "            # images are stored in \"column-major order\", meaning\n",
    "            # that \"the first 96*96 values are the red channel,\n",
    "            # the next 96*96 are green, and the last are blue.\"\n",
    "            # The -1 is since the size of the pictures depends\n",
    "            # on the input file, and this way numpy determines\n",
    "            # the size on its own.\n",
    "\n",
    "            images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "            # Now transpose the images into a standard image format\n",
    "            # readable by, for example, matplotlib.imshow\n",
    "            # You might want to comment this line or reverse the shuffle\n",
    "            # if you will use a learning algorithm like CNN, since they like\n",
    "            # their channels separated.\n",
    "            images = np.transpose(images, (0, 3, 2, 1))\n",
    "            return images\n",
    "    def read_labels(path_to_labels):\n",
    "        \"\"\"\n",
    "        :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "        :return: an array containing the labels\n",
    "        \"\"\"\n",
    "        with open(path_to_labels, 'rb') as f:\n",
    "            labels = np.fromfile(f, dtype=np.uint8)\n",
    "            return labels\n",
    "    def show_images(data,row=1,col=1):\n",
    "        fig=plt.figure(figsize=(10,10))\n",
    "        columns = col; rows = row\n",
    "        for i in range(1, columns*rows +1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(data[i-1])\n",
    "        plt.show()\n",
    "\n",
    "    train_images = read_all_images(\"../../../../DataSet/STL10/stl10_binary/train_X.bin\") / 255.0\n",
    "    train_labels = read_labels    (\"../../../../DataSet/STL10/stl10_binary/train_Y.bin\")\n",
    "    test_images  = read_all_images(\"../../../../DataSet/STL10/stl10_binary/test_X.bin\")  / 255.0\n",
    "    test_labels  = read_labels    (\"../../../../DataSet/STL10/stl10_binary/test_y.bin\")\n",
    "\n",
    "    label_encoder= OneHotEncoder(sparse=False,categories='auto')\n",
    "    train_labels = label_encoder.fit_transform(train_labels.reshape((-1,1)))\n",
    "    test_labels  = label_encoder.fit_transform(test_labels.reshape((-1,1)))\n",
    "\n",
    "    print(train_images.shape,train_images.max(),train_images.min())\n",
    "    print(train_labels.shape,train_labels.max(),train_labels.min())\n",
    "    print(test_images.shape,test_images.max(),test_images.min())\n",
    "    print(test_labels.shape,test_labels.max(),test_labels.min())\n",
    "    return train_images,train_labels,test_images,test_labels\n",
    "# Def: Read CIFAR 10 images\n",
    "def read_CIFAR10_data():\n",
    "    # ====== miscellaneous =====\n",
    "    # code from: https://github.com/tensorflow/tensorflow/issues/8246\n",
    "    def tf_repeat(tensor, repeats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        input: A Tensor. 1-D or higher.\n",
    "        repeats: A list. Number of repeat for each dimension, length must be the same as the number of dimensions in input\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        A Tensor. Has the same type as input. Has the shape of tensor.shape * repeats\n",
    "        \"\"\"\n",
    "        expanded_tensor = tf.expand_dims(tensor, -1)\n",
    "        multiples = [1] + repeats\n",
    "        tiled_tensor = tf.tile(expanded_tensor, multiples = multiples)\n",
    "        repeated_tesnor = tf.reshape(tiled_tensor, tf.shape(tensor) * repeats)\n",
    "        return repeated_tesnor\n",
    "    def unpickle(file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    # ====== miscellaneous =====\n",
    "\n",
    "    # data\n",
    "    PathDicom = \"../../Dataset/cifar-10-batches-py/\"\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "        for filename in fileList:\n",
    "            if not \".html\" in filename.lower() and not  \".meta\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    # Read the data traind and Test\n",
    "    batch0 = unpickle(lstFilesDCM[0])\n",
    "    batch1 = unpickle(lstFilesDCM[1])\n",
    "    batch2 = unpickle(lstFilesDCM[2])\n",
    "    batch3 = unpickle(lstFilesDCM[3])\n",
    "    batch4 = unpickle(lstFilesDCM[4])\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=True)\n",
    "    train_batch = np.vstack((batch0[b'data'],batch1[b'data'],batch2[b'data'],batch3[b'data'],batch4[b'data']))\n",
    "    train_label = np.expand_dims(np.hstack((batch0[b'labels'],batch1[b'labels'],batch2[b'labels'],batch3[b'labels'],batch4[b'labels'])).T,axis=1).astype(np.float64)\n",
    "    train_label = onehot_encoder.fit_transform(train_label).toarray().astype(np.float64)\n",
    "\n",
    "    test_batch = unpickle(lstFilesDCM[5])[b'data']\n",
    "    test_label = np.expand_dims(np.array(unpickle(lstFilesDCM[5])[b'labels']),axis=0).T.astype(np.float64)\n",
    "    test_label = onehot_encoder.fit_transform(test_label).toarray().astype(np.float64)\n",
    "\n",
    "    # reshape data\n",
    "    train_batch = np.reshape(train_batch,(len(train_batch),3,32,32)); test_batch = np.reshape(test_batch,(len(test_batch),3,32,32))\n",
    "    # rotate data\n",
    "    train_batch = np.rot90(np.rot90(train_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64); test_batch = np.rot90(np.rot90(test_batch,1,axes=(1,3)),3,axes=(1,2)).astype(np.float64)\n",
    "    # normalize\n",
    "    train_batch= train_batch/255.0; test_batch = test_batch/255.0\n",
    "\n",
    "    # print out the data shape and the max and min value\n",
    "    print(train_batch.shape,train_batch.max(),train_batch.min())\n",
    "    print(train_label.shape,train_label.max(),train_label.min())\n",
    "    print(test_batch.shape,test_batch.max(),test_batch.min())\n",
    "    print(test_label.shape,test_label.max(),test_label.min())\n",
    "    return train_batch,train_label,test_batch,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:51:31.843539Z",
     "start_time": "2019-03-01T04:51:31.813586Z"
    },
    "code_folding": [
     18,
     34,
     41,
     58,
     75
    ]
   },
   "outputs": [],
   "source": [
    "# create the layers\n",
    "def tf_softmax(x):    return tf.nn.softmax(x)\n",
    "def tf_elu(x):       return tf.nn.elu(x)\n",
    "\n",
    "def tf_relu(x):       return tf.nn.relu(x)\n",
    "def d_tf_relu(x):     return tf.cast(tf.greater_equal(x,0),tf.float32) * 1.0\n",
    "\n",
    "def tf_iden(x):       return x\n",
    "def d_tf_iden(x):     return tf.ones_like(x)\n",
    "\n",
    "def tf_sigmoid(x):    return tf.nn.sigmoid(x)\n",
    "def d_tf_sigmoid(x):  return tf_sigmoid(x) * (1.0-tf_sigmoid(x))\n",
    "\n",
    "def tf_tanh(x):    return tf.nn.tanh(x)\n",
    "\n",
    "def tf_softplus(x):   return tf.nn.softplus(x)\n",
    "def d_tf_softplus(x): return tf.nn.sigmoid(x)\n",
    "\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self,k,inc,out, stddev=0.05,act=tf_elu,d_act=d_tf_relu):\n",
    "        self.w              = tf.Variable(tf.random_normal([k,k,inc,out],stddev=stddev,seed=2,dtype=tf.float32))\n",
    "        self.m,self.v       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.m2,self.v2       = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
    "        self.act,self.d_act = act,d_act\n",
    "\n",
    "    def getw(self): return self.w\n",
    "    \n",
    "    # Feed Forward for two variables\n",
    "    def feedforward(self,input,stride=1,padding='VALID'):\n",
    "        self.input1  = input\n",
    "        self.layer1  = tf.nn.conv2d(self.input1,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA1 = self.act(self.layer1)\n",
    "        return self.layer1, self.layerA1\n",
    "    def feedforward2(self,input,stride=1,padding='VALID'):\n",
    "        self.input2  = input\n",
    "        self.layer2  = tf.nn.conv2d(self.input2,self.w,strides=[1,stride,stride,1],padding=padding) \n",
    "        self.layerA2 = self.act(self.layer2)\n",
    "        return self.layer2, self.layerA2\n",
    "    \n",
    "    # Back Prop for two variables\n",
    "    def backprop(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer1)\n",
    "        grad_part_3 = self.input1\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input1),filter= self.w,   out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m,self.m*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v,self.v*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m / (1-beta1) ; v_hat = self.v / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "    def backprop2(self,gradient,stride=1,padding='VALID'):\n",
    "        grad_part_1 = gradient\n",
    "        grad_part_2 = self.d_act(self.layer2)\n",
    "        grad_part_3 = self.input2\n",
    "\n",
    "        grad_middle = grad_part_1 * grad_part_2\n",
    "        grad        = tf.nn.conv2d_backprop_filter(input = grad_part_3,filter_sizes = tf.shape(self.w),  out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding) \n",
    "        grad_pass   = tf.nn.conv2d_backprop_input (input_sizes = tf.shape(self.input1),filter= self.w,   out_backprop = grad_middle,strides=[1,stride,stride,1],padding=padding)\n",
    "\n",
    "        update_w = []\n",
    "        update_w.append(tf.assign( self.m2,self.m2*beta1 + (1-beta1) * (grad)   ))\n",
    "        update_w.append(tf.assign( self.v2,self.v2*beta2 + (1-beta2) * (grad ** 2)   ))\n",
    "        m_hat = self.m2 / (1-beta1) ; v_hat = self.v2 / (1-beta2)\n",
    "        adam_middle = m_hat * learning_rate/(tf.sqrt(v_hat) + adam_e)\n",
    "        update_w.append(tf.assign(self.w,tf.subtract(self.w,adam_middle  )))\n",
    "        return grad_pass,grad,update_w\n",
    "    \n",
    "def calc_MI(x, y, bins=(90*90)/4):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi\n",
    "\n",
    "class RELU_as_Reg():\n",
    "    \n",
    "    def __init__(self,width,channel):\n",
    "        self.w = tf.Variable(tf.ones([width,width,channel],tf.float32) )\n",
    "    def getw(self): return self.w\n",
    "    def feedforward(self,input):\n",
    "        self.input  = input\n",
    "        self.layerA = self.w[None,:,:,:] * input\n",
    "        return self.layerA\n",
    "    \n",
    "def softmax_multi(target, axis=(1,2), name=None):\n",
    "    max_axis   = tf.reduce_max(target, axis, keepdims=True)\n",
    "    target_exp = tf.exp(target-max_axis)\n",
    "    normalize  = tf.reduce_sum(target_exp, axis, keepdims=True)\n",
    "    softmax    = target_exp / normalize\n",
    "    return softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:49:55.069597Z",
     "start_time": "2019-03-01T04:49:52.100939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "# 1. sym padding \n",
    "# 2. sug metn sim -> not a good idea (sparse filtering - population sparsity -)\n",
    "# 3. sales pitch - data aug (latent space) (paper - how is different from x)\n",
    "# 4. baseline - other approaches - \n",
    "# 5. show negative images \n",
    "# 6. sparse filtering\n",
    "# 7. classifier - mmke it a dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:49:56.724045Z",
     "start_time": "2019-03-01T04:49:56.719025Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyeper\n",
    "num_eps   = 1; num_epoch = 10; learning_rate = 0.0001; batch_size = 20;  alpha = 0.5\n",
    "beta1,beta2,adam_e  = 0.9,0.999,1e-8; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T05:10:49.803926Z",
     "start_time": "2019-03-01T05:10:49.215452Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "num_of_aug  = 5\n",
    "l1_encoder  = CNN(3,1,num_of_aug,         act=tf_elu)\n",
    "l2_encoder  = CNN(3,num_of_aug,num_of_aug,act=tf_elu)\n",
    "l3_encoder  = CNN(1,num_of_aug,num_of_aug,act=tf_elu)\n",
    "\n",
    "l1_global = CNN(3,num_of_aug*2,num_of_aug*2,act=tf_elu)\n",
    "l2_global = CNN(3,num_of_aug*2,num_of_aug*2,act=tf_elu)\n",
    "l3_global = CNN(3,num_of_aug*2,1,           act=tf_iden)\n",
    "\n",
    "def global_feed(input_data):\n",
    "    _,layer1_g = l1_global.feedforward(input_data)\n",
    "    _,layer2_g = l2_global.feedforward(layer1_g)\n",
    "    _,layer3_g = l3_global.feedforward(layer2_g)\n",
    "    return layer3_g\n",
    "\n",
    "x_encoding = tf.placeholder(tf.float32,(None,96,96,1))\n",
    "x_reisze   = tf.image.resize_images(x_encoding,(92,92))\n",
    "x_reisze   = tf.tile(x_reisze,(1,1,1,num_of_aug))\n",
    "\n",
    "_,layer1_e = l1_encoder.feedforward(x_encoding)\n",
    "_,layer2_e = l2_encoder.feedforward(layer1_e)\n",
    "_,layer3_e = l3_encoder.feedforward(layer2_e)\n",
    "layer3_e   = layer3_e + layer2_e \n",
    "\n",
    "layer3_ee  = softmax_multi(layer3_e,axis=(1,2))\n",
    "layer3_ss  = tf.transpose(layer3_ee,(0,2,1,3))\n",
    "encoded_gt = tf.concat([layer3_ee ,x_reisze],3)\n",
    "encoded_rd = tf.concat([layer3_ss ,x_reisze],3)\n",
    "\n",
    "global_gt  = tf.reduce_mean(-tf_relu(-global_feed(encoded_gt)))\n",
    "global_rd  = tf.reduce_mean( tf_relu( global_feed(encoded_rd)))\n",
    "GLOBAL     = (global_rd - global_gt) \n",
    "\n",
    "TOTAL_LOSS = GLOBAL + tf.reduce_sum(\n",
    "    tf.nn.l2_loss(l1_encoder.getw())+\n",
    "    tf.nn.l2_loss(l2_encoder.getw())+\n",
    "    tf.nn.l2_loss(l3_encoder.getw())\n",
    ") * 0.0001\n",
    "auto_train = tf.train.AdamOptimizer(0.0001).minimize(TOTAL_LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:43:38.344886Z",
     "start_time": "2019-03-01T04:43:36.776911Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creat classification network\n",
    "x = tf.placeholder(tf.float32,(None,48,48,1))\n",
    "y = tf.placeholder(tf.float32,(None,10))\n",
    "is_training = tf.placeholder_with_default(True,())\n",
    "\n",
    "l1 = CNN(3,1,32)\n",
    "l2 = CNN(3,32,32)\n",
    "l3 = CNN(3,32,32)\n",
    "\n",
    "l4 = CNN(3,32,64)\n",
    "l5 = CNN(3,64,64)\n",
    "l6 = CNN(3,64,64)\n",
    "\n",
    "l7 = CNN(3,64,64)\n",
    "l8 = CNN(1,64,64)\n",
    "l9 = CNN(1,64,10)\n",
    "\n",
    "_,layer1 = l1.feedforward(x)\n",
    "layer1 = tf.layers.batch_normalization(layer1, training=is_training)\n",
    "_,layer2 = l2.feedforward(layer1)\n",
    "layer2 = tf.layers.batch_normalization(layer2, training=is_training)\n",
    "_,layer3 = l3.feedforward(layer2)\n",
    "layer3   = tf.nn.avg_pool(layer3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "_,layer4 = l4.feedforward(layer3)\n",
    "layer4 = tf.layers.batch_normalization(layer4, training=is_training)\n",
    "_,layer5 = l5.feedforward(layer4)\n",
    "layer5 = tf.layers.batch_normalization(layer5, training=is_training)\n",
    "_,layer6 = l6.feedforward(layer5)\n",
    "layer6   = tf.nn.avg_pool(layer6,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "_,layer7 = l7.feedforward(layer6)\n",
    "layer7 = tf.layers.batch_normalization(layer7, training=is_training)\n",
    "_,layer8 = l8.feedforward(layer7)\n",
    "layer8 = tf.layers.batch_normalization(layer8, training=is_training)\n",
    "_,layer9 = l9.feedforward(layer8)\n",
    "\n",
    "final_layer = tf.reduce_mean(layer9,(1,2))\n",
    "final_soft  = tf_softmax(final_layer)\n",
    "cost               = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,labels=y))\n",
    "correct_prediction = tf.equal(tf.argmax(final_soft, 1), tf.argmax(y, 1))\n",
    "accuracy  = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "class_train = tf.train.AdamOptimizer(learning_rate=0.0008).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T05:11:37.694994Z",
     "start_time": "2019-03-01T05:10:51.705970Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Current Iter : 0/10 batch : 4980/5000 loss : 0.00027378113\n",
      "\n",
      " Current Iter : 5/10 batch : 4980/5000 loss : 0.000105609626\n",
      "\n",
      " Current Iter : 9/10 batch : 4980/5000 loss : 4.4634286e-054\r"
     ]
    }
   ],
   "source": [
    "# train the network \n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "num_epoch = 10\n",
    "for iter in range(num_epoch):\n",
    "    for current_batch_index in range(0,len(train_images),batch_size):\n",
    "        current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "        sess_results  = sess.run([TOTAL_LOSS,auto_train],feed_dict={x_encoding:current_batch})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' loss : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush();    \n",
    "    if iter%5==0: \n",
    "        print('\\n')\n",
    "        train_images = shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T05:11:43.874766Z",
     "start_time": "2019-03-01T05:11:43.411252Z"
    },
    "code_folding": [
     19
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8464,) (8836,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-6ffc1072e6ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mall_image_mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_index2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mall_image_mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_feature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_index2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_image_resize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mall_image_mi_sort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mall_image_mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mbest_indexn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_image_mi_sort\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-1836f6df9558>\u001b[0m in \u001b[0;36mcalc_MI\u001b[1;34m(x, y, bins)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_MI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mc_xy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mmi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontingency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_xy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36mhistogram2d\u001b[1;34m(x, y, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[0mxedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myedges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mxedges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myedges\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m     \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistogramdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36mhistogramdd\u001b[1;34m(sample, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    952\u001b[0m                 raise ValueError(\n\u001b[0;32m    953\u001b[0m                     '`bins[{}]` must be positive, when an integer'.format(i))\n\u001b[1;32m--> 954\u001b[1;33m             \u001b[0msmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m             \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[1;34m(a, range)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mfirst_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     31\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8464,) (8836,) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "capture_best = []\n",
    "for current_batch_index in range(0,len(train_images),batch_size):\n",
    "    current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "    \n",
    "    current_image_resize = np.asarray([resize(np.squeeze(x),(9492)) for x in current_batch])[:,:,:,None]\n",
    "    current_image_resize = (current_image_resize-current_image_resize.min((0,1,2),keepdims=True))/(current_image_resize.max((0,1,2),keepdims=True)-current_image_resize.min((0,1,2),keepdims=True)+1e-8)\n",
    "    latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch})\n",
    "    latent_feature = (latent_feature-latent_feature.min((0,1,2),keepdims=True))/(latent_feature.max((0,1,2),keepdims=True)-latent_feature.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "    for image_index in range(len(current_batch)-10):\n",
    "        plt.figure(figsize=(3*num_of_aug+1,6))\n",
    "        \n",
    "        plt.subplot(2,num_of_aug+1,1)\n",
    "        plt.imshow(np.squeeze(current_image_resize[image_index]),cmap='gray')\n",
    "        upper_bound = calc_MI(current_image_resize[image_index].ravel(),current_image_resize[image_index].ravel())\n",
    "        plt.title(str(np.around(upper_bound,2)))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        all_image_mi = []\n",
    "        for image_index2 in range(len(latent_feature.T)): \n",
    "            all_image_mi.append(calc_MI(latent_feature[image_index,:,:,image_index2].ravel(),current_image_resize[image_index].ravel()))\n",
    "        all_image_mi_sort = sorted(range(len(all_image_mi)), key=lambda k: all_image_mi[k])[::-1]\n",
    "        best_indexn = all_image_mi_sort[0]\n",
    "        print(all_image_mi_sort)\n",
    "        print(best_indexn)\n",
    "        capture_best.append(best_indexn)\n",
    "        \n",
    "        count = 2\n",
    "        for high_index in all_image_mi_sort:\n",
    "            plt.subplot(2,num_of_aug+1,count)\n",
    "            plt.imshow(np.squeeze(latent_feature[image_index,:,:,high_index]),cmap='gist_rainbow'); plt.axis('off')\n",
    "            current_mi= calc_MI(latent_feature[image_index,:,:,high_index].ravel(),current_image_resize[image_index].ravel())\n",
    "            percent   = 1-(upper_bound-current_mi)/upper_bound\n",
    "            plt.title(str(np.around(percent,2)))\n",
    "            count = count + 1\n",
    "            \n",
    "        count = count + 1\n",
    "        for high_index in all_image_mi_sort:\n",
    "            plt.subplot(2,num_of_aug+1,count)\n",
    "            plt.imshow(np.squeeze(latent_feature[image_index,:,:,high_index]),cmap='gray'); plt.axis('off')\n",
    "            current_mi= calc_MI(latent_feature[image_index,:,:,high_index].ravel(),current_image_resize[image_index].ravel())\n",
    "            percent   = current_mi/upper_bound\n",
    "            plt.title(str(np.around(percent,2)))\n",
    "            count = count + 1\n",
    "            \n",
    "        plt.show()\n",
    "    capture_best_index = stats.mode(capture_best)[0]\n",
    "    print('Best : ',capture_best_index)\n",
    "    break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:48:47.031349Z",
     "start_time": "2019-03-01T04:44:26.836854Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3) 1.0 0.0\n",
      "(5000, 10) 1.0 0.0\n",
      "(8000, 96, 96, 3) 1.0 0.0\n",
      "(8000, 10) 1.0 0.0\n",
      "Current : 0\t Train Acc : 0.268\t Test Acc : 0.141\t5\n",
      "\n",
      " MAX  \t\n",
      "Current : 1\t Train Acc : 0.374\t Test Acc : 0.389\t55.029015\n",
      "Current : 2\t Train Acc : 0.426\t Test Acc : 0.476\t5\n",
      "Current : 3\t Train Acc : 0.464\t Test Acc : 0.486\t5\n",
      "Current : 4\t Train Acc : 0.488\t Test Acc : 0.502\t5\n",
      "Current : 5\t Train Acc : 0.509\t Test Acc : 0.529\t5\n",
      "Current : 6\t Train Acc : 0.541\t Test Acc : 0.546\t5\n",
      "Current : 7\t Train Acc : 0.566\t Test Acc : 0.535\t5\n",
      "\n",
      " MAX  \t\n",
      "Current : 8\t Train Acc : 0.582\t Test Acc : 0.555\t54.69614\n",
      "\n",
      " MAX  \t\n",
      "Current : 9\t Train Acc : 0.613\t Test Acc : 0.583\t55.22424\n",
      "\n",
      " MAX  \t\n",
      "Current : 10\t Train Acc : 0.638\t Test Acc : 0.59\t65.48305\n",
      "\n",
      " MAX  \t\n",
      "Current : 11\t Train Acc : 0.653\t Test Acc : 0.578\t58.33952\n",
      "\n",
      " MAX  \t\n",
      "Current : 12\t Train Acc : 0.675\t Test Acc : 0.6\t.650.65895\n",
      "\n",
      " MAX  \t\n",
      "Current : 13\t Train Acc : 0.691\t Test Acc : 0.553\t53.30534\n",
      "\n",
      " MAX  \t\n",
      "Current : 14\t Train Acc : 0.72\t Test Acc : 0.591\t856.14363\n",
      "\n",
      " MAX  \t\n",
      "Current : 15\t Train Acc : 0.744\t Test Acc : 0.593\t59.04044\n",
      "\n",
      " MAX  \t\n",
      "Current : 16\t Train Acc : 0.762\t Test Acc : 0.596\t51.86658\n",
      "\n",
      " MAX  \t\n",
      "Current : 17\t Train Acc : 0.782\t Test Acc : 0.568\t54.49844\n",
      "\n",
      " MAX  \t\n",
      "Current : 18\t Train Acc : 0.802\t Test Acc : 0.58\t456.81992\n",
      "\n",
      " MAX  \t\n",
      " Current Iter : 19/200 batch : 2680/5000 acc : 0.858.72406\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a4aeb7ec83fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mlatent_labels\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mnum_of_aug\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdividsion\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_of_aug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0msess_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextra_update_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlatent_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlatent_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n\u001b[0;32m     24\u001b[0m                          \u001b[1;34m' batch : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "num_epoch = 200\n",
    "\n",
    "# read the data\n",
    "train_images,train_labels,test_images,test_labels = read_STL10_data()\n",
    "train_images = train_images.mean(3,keepdims=True)\n",
    "train_images = (train_images-train_images.min((0,1,2),keepdims=True))/(train_images.max((0,1,2),keepdims=True)-train_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "test_images  = test_images.mean(3,keepdims=True)\n",
    "test_images  = (test_images-test_images.min((0,1,2),keepdims=True))/(test_images.max((0,1,2),keepdims=True)-test_images.min((0,1,2),keepdims=True)+1e-8)\n",
    "\n",
    "avg_acc_train = 0; avg_acc_test  = 0; train_acc = [];test_acc = []; dividsion = 1\n",
    "for iter in range(num_epoch):\n",
    "    \n",
    "    # train for training images\n",
    "    for current_batch_index in range(0,len(train_images),batch_size//dividsion):\n",
    "        current_batch = train_images[current_batch_index:current_batch_index+batch_size//dividsion]\n",
    "        current_label = train_labels[current_batch_index:current_batch_index+batch_size//dividsion]\n",
    "        latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch}) \n",
    "        latent_feature = np.reshape(np.transpose(latent_feature,(0,3,1,2)),(batch_size//dividsion*num_of_aug,48,48))[:,:,:,None]\n",
    "        latent_labels  = np.asarray([ [x]* num_of_aug for x in current_label]).reshape((batch_size//dividsion*num_of_aug,10))\n",
    "\n",
    "        sess_results = sess.run([accuracy,class_train,extra_update_ops],feed_dict={x:latent_feature,y:latent_labels})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_train = avg_acc_train + sess_results[0]\n",
    "\n",
    "    # test for training images\n",
    "    for current_batch_index in range(0,len(test_images),batch_size):\n",
    "        current_batch  = test_images[current_batch_index:current_batch_index+batch_size]\n",
    "        current_label  = test_labels[current_batch_index:current_batch_index+batch_size]\n",
    "        latent_feature = sess.run(layer3_e,feed_dict={x_encoding:current_batch})[:,:,:,capture_best_index[0]][:,:,:,None]\n",
    "        \n",
    "        sess_results = sess.run([accuracy],feed_dict={x:latent_feature,y:current_label,is_training:False})\n",
    "        sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + \n",
    "                         ' batch : ' + str(current_batch_index) + '/'+ str(len(test_images)) + \n",
    "                         ' acc : ' + str(sess_results[0]) + '\\r')\n",
    "        sys.stdout.flush(); avg_acc_test = avg_acc_test + sess_results[0] \n",
    "        \n",
    "    # ======================== print reset ========================\n",
    "    if iter%1 == 0 :\n",
    "        train_images,train_labels = shuffle(train_images,train_labels)\n",
    "        sys.stdout.write(\"Current : \"+ str(iter) + \"\\t\" +\n",
    "              \" Train Acc : \" + str(np.around(avg_acc_train/(len(train_images)/batch_size*dividsion),3)) + \"\\t\" +\n",
    "              \" Test Acc : \"  + str(np.around(avg_acc_test/(len(test_images)/batch_size),3)) + \"\\t\\n\")\n",
    "        sys.stdout.flush();\n",
    "        \n",
    "    if avg_acc_test/(len(test_images)/batch_size) < avg_acc_train/(len(train_images)/batch_size*dividsion):\n",
    "        print('\\n MAX  \\t')\n",
    "        for current_batch_index in range(0,len(train_images),batch_size):\n",
    "            current_batch = train_images[current_batch_index:current_batch_index+batch_size]\n",
    "            sess_results  = sess.run([TOTAL_LOSS,auto_train],feed_dict={x_encoding:current_batch})\n",
    "            sys.stdout.write(' Current Iter : ' + str(iter) + '/'+ str(num_epoch)  + ' batch : ' + str(current_batch_index) + '/'+ str(len(train_images)) + ' loss : ' + str(sess_results[0]) + '\\r')\n",
    "            sys.stdout.flush();          \n",
    "    avg_acc_train = 0 ; avg_acc_test  = 0\n",
    "    # ======================== print reset ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T04:48:47.057243Z",
     "start_time": "2019-03-01T04:43:29.074Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# len(test_images)\n",
    "from scipy import stats\n",
    "accuray_test = 0\n",
    "for current_batch_index in range(len(test_images)):\n",
    "    current_batch = test_images[current_batch_index:current_batch_index+1]\n",
    "    current_label = test_labels[current_batch_index:current_batch_index+1]\n",
    "    latent_feature = sess.run(layer2_e,feed_dict={x_encoding:current_batch})\n",
    "    latent_feature = np.transpose(latent_feature,(3,1,2,0))\n",
    "    sess_results = sess.run(final_soft,feed_dict={x:latent_feature,y:current_label,is_training:False})\n",
    "    m = stats.mode(np.argmax(sess_results,1))\n",
    "    if m[0] == np.argmax(current_label,1):\n",
    "        accuray_test = accuray_test + 1\n",
    "print(accuray_test)\n",
    "print(accuray_test/len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:17:12.615183Z",
     "start_time": "2019-02-27T06:17:12.610171Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
