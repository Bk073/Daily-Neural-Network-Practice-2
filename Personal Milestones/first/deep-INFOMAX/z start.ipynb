{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T02:00:11.472021Z",
     "start_time": "2019-02-06T02:00:11.446108Z"
    },
    "code_folding": [
     5,
     27,
     47,
     61
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6f20c5b7ef02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chainer'"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "from chainer import functions as F\n",
    "from chainer import links as L\n",
    "\n",
    "\n",
    "class Encoder(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.c0 = L.Convolution2D(None, 64, 4)\n",
    "            self.c1 = L.Convolution2D(64, 128, 4)\n",
    "            self.c2 = L.Convolution2D(128, 256, 4)\n",
    "            self.c3 = L.Convolution2D(256, 512, 4)\n",
    "            self.linear = L.Linear(None, 64)\n",
    "            #self.bn0 = L.BatchNormalization(64)\n",
    "            self.bn1 = L.BatchNormalization(128)\n",
    "            self.bn2 = L.BatchNormalization(256)\n",
    "            self.bn3 = L.BatchNormalization(512)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        features = F.relu(self.bn1(self.c1(h)))\n",
    "        h = F.relu(self.bn2(self.c2(features)))\n",
    "        h = F.relu(self.bn3(self.c3(h)))\n",
    "        return self.linear(h), features\n",
    "\n",
    "class GlobalDiscriminator(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(None, 512)\n",
    "            self.l1 = L.Linear(512, 512)\n",
    "            self.l2 = L.Linear(512, 1)\n",
    "            self.c0 = L.Convolution2D(None, 64, 3)\n",
    "            self.c1 = L.Convolution2D(64, 32, 3)\n",
    "\n",
    "    def __call__(self, y, M):\n",
    "        h = F.relu(self.c0(M))\n",
    "        h = F.reshape(self.c1(h), (y.shape[0], -1))\n",
    "        h = F.concat((y, h), axis=1)\n",
    "\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return self.l2(h)\n",
    "\n",
    "class LocalDiscriminator(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.c0 = L.Convolution2D(None, 512, 1)\n",
    "            self.c1 = L.Convolution2D(512, 512, 1)\n",
    "            self.c2 = L.Convolution2D(512, 1, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.c0(x))\n",
    "        h = F.relu(self.c1(h))\n",
    "        return self.c2(h)\n",
    "\n",
    "class PriorDiscriminator(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(None, 1000)\n",
    "            self.l1 = L.Linear(1000, 200)\n",
    "            self.l2 = L.Linear(200, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return F.sigmoid(self.l2(h))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    encoder = Encoder()\n",
    "    x = np.ones((1,3,32,32), dtype=np.float32)\n",
    "    y = encoder(x)\n",
    "    print(y.shape)\n",
    "    discriminator = Discriminator()\n",
    "    d = discriminator(y)\n",
    "    print(d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     59
    ]
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import chainer\n",
    "from chainer import iterators, optimizers, serializers, reporter, training\n",
    "from chainer.training import extensions\n",
    "from chainer import functions as F\n",
    "from chainer.dataset import concat_examples\n",
    "\n",
    "from networks import Encoder, LocalDiscriminator, GlobalDiscriminator, PriorDiscriminator\n",
    "\n",
    "\n",
    "class DeepINFOMAX(chainer.Chain):\n",
    "\n",
    "    def __init__(self, alpha=1., beta=1., gamma=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.encoder = Encoder()\n",
    "            self.local_disc = LocalDiscriminator()\n",
    "            self.global_disc = GlobalDiscriminator()\n",
    "            self.prior_disc = PriorDiscriminator()\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        # get encodings\n",
    "        y, M = self.encoder(x)\n",
    "\n",
    "        # shuffle batch to pair each element with another\n",
    "        M_prime = F.concat((M[1:], (M[0])[None,:,:,:]), axis=0)\n",
    "\n",
    "        # local DIM\n",
    "        y_M = F.concat((F.broadcast_to(y[:, :, None, None], \\\n",
    "                                       (x.shape[0], y.shape[1], M.shape[-2], M.shape[-1])), M), axis=1)\n",
    "        y_M_prime = F.concat((F.broadcast_to(y[:, :, None, None], \\\n",
    "                                             (x.shape[0], y.shape[1], M.shape[-2], M.shape[-1])), M_prime), axis=1)\n",
    "\n",
    "        Ej = F.mean(-F.softplus(-self.local_disc(y_M)))\n",
    "        Em = F.mean(F.softplus(self.local_disc(y_M_prime)))\n",
    "        local_loss = (Em - Ej) * self.beta\n",
    "\n",
    "        # global DIM\n",
    "        Ej = F.mean(-F.softplus(-self.global_disc(y, M)))\n",
    "        Em = F.mean(F.softplus(self.global_disc(y, M_prime)))\n",
    "        global_loss = (Em - Ej) * self.alpha\n",
    "\n",
    "        # prior term\n",
    "        z = self.xp.random.uniform(size=y.shape).astype(self.xp.float32)\n",
    "        \n",
    "        term_a = F.mean(F.log(self.prior_disc(z)))\n",
    "        term_b = F.mean(F.log(1. - self.prior_disc(y)))\n",
    "        prior_loss = -(term_a + term_b) * self.gamma\n",
    "\n",
    "        loss = global_loss + local_loss + prior_loss\n",
    "\n",
    "        reporter.report({\"loss\": loss, \"local_loss\": local_loss, \"global_loss\": global_loss, \"prior_loss\": prior_loss}, self)\n",
    "        return loss\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    train, test = chainer.datasets.get_cifar10()\n",
    "    train_iter = iterators.SerialIterator(train, args.batchsize)\n",
    "\n",
    "    dim = DeepINFOMAX(alpha=args.alpha, beta=args.beta, gamma=args.gamma)\n",
    "\n",
    "    if args.device >= 0:\n",
    "        chainer.backends.cuda.get_device_from_id(args.device).use()\n",
    "        dim.to_gpu(args.device)\n",
    "\n",
    "    opt = optimizers.Adam(alpha=args.learning_rate)\n",
    "    opt.setup(dim)\n",
    "\n",
    "    updater = training.updaters.StandardUpdater(\n",
    "        train_iter, opt, device=args.device)\n",
    "    trainer = training.Trainer(updater, (args.epochs, 'epoch'), out=args.output)\n",
    "\n",
    "    log_interval = (10, \"iteration\")\n",
    "    trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'iteration', 'main/loss', 'main/local_loss', 'main/global_loss', 'main/prior_loss', 'elapsed_time']), trigger=log_interval)\n",
    "\n",
    "    # Print a progress bar to stdout\n",
    "    trainer.extend(extensions.ProgressBar(update_interval=log_interval[0]))\n",
    "\n",
    "    trainer.extend(extensions.snapshot_object(dim.encoder, 'encoder_epoch_{.updater.epoch}'), trigger=(100, \"epoch\"))\n",
    "\n",
    "    # Run the training\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--device\", \"-g\", type=int, default=-1)\n",
    "    parser.add_argument(\"--epochs\", \"-e\", type=int, default=1000)\n",
    "    parser.add_argument(\"--batchsize\", \"-b\", type=int, default=256)\n",
    "    parser.add_argument(\"--learning_rate\", \"-l\", type=float, default=1.E-4)\n",
    "    parser.add_argument(\"--output\", \"-o\", type=str, default=\"results\")\n",
    "    parser.add_argument(\"--alpha\", \"-A\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--beta\", \"-B\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--gamma\", \"-G\", type=float, default=0.1)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
