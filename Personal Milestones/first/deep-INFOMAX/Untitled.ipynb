{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T02:34:32.468301Z",
     "start_time": "2019-02-06T02:34:31.195735Z"
    }
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# model definition\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "import torch, torchvision, torch.nn.functional as F\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape=(32,32), num_feature=64, out_size=64):\n",
    "        super().__init__()\n",
    "\n",
    "        assert isinstance(input_shape, tuple), \"tuple of integers.\"\n",
    "        self.input_shape = input_shape\n",
    "        self.M_shape = (input_shape[0]-3*2, input_shape[1]-3*2)\n",
    "        self.M_channels = num_feature*2\n",
    "\n",
    "        self.c0 = torch.nn.Conv2d(3, num_feature, kernel_size=4, stride=1)\n",
    "        self.c1 = torch.nn.Conv2d(num_feature, num_feature*2, kernel_size=4, stride=1)\n",
    "        self.c2 = torch.nn.Conv2d(num_feature*2, num_feature*4, kernel_size=4, stride=1)\n",
    "        self.c3 = torch.nn.Conv2d(num_feature*4, num_feature*8, kernel_size=4, stride=1)\n",
    "\n",
    "        in_feature = num_feature*8 * (input_shape[0]-3*4) * (input_shape[1]-3*4)\n",
    "        self.l1 = torch.nn.Linear(in_feature, out_size)\n",
    "\n",
    "        self.b1 = torch.nn.BatchNorm2d(num_feature*2)\n",
    "        self.b2 = torch.nn.BatchNorm2d(num_feature*4)\n",
    "        self.b3 = torch.nn.BatchNorm2d(num_feature*8)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        E = F.relu(self.c0(x))\n",
    "        M = F.relu(self.b1(self.c1(E)))\n",
    "        E = F.relu(self.b2(self.c2(M)))\n",
    "        E = F.relu(self.b3(self.c3(E)))\n",
    "        E = self.l1(E.view(x.shape[0], -1))\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "        # E is the encoded E_{phi}(x)\n",
    "        # M is the M x M feature maps\n",
    "        return E, M\n",
    "\n",
    "class GlobalDiscriminator(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    input of GlobalDiscriminator is the `M` in Encoder.forward, so with\n",
    "    channels : num_feature * 2, in_channels\n",
    "    shape    : (input_shape[0]-3*2, input_shape[1]-3*2), M_shape\n",
    "    \"\"\"\n",
    "    def __init__(self, M_channels, M_shape, E_size, interm_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_channels = M_channels; out_channels = in_channels // 2\n",
    "        self.c0 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "        in_channels = out_channels; out_channels = in_channels // 2\n",
    "        self.c1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3)\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "        # input of self.l0 is the concatenate of E and flattened output of self.c1 (C)\n",
    "        in_feature = out_channels * (M_shape[0]-2*2) * (M_shape[1]-2*2) + E_size\n",
    "        self.l0 = torch.nn.Linear(in_feature, interm_size)\n",
    "        self.l1 = torch.nn.Linear(interm_size, interm_size)\n",
    "        self.l2 = torch.nn.Linear(interm_size, 1)\n",
    "\n",
    "    def forward(self, E, M):\n",
    "\n",
    "        C = F.relu(self.c0(M))\n",
    "        C = self.c1(C)\n",
    "        C = C.view(E.shape[0], -1)\n",
    "        out = torch.cat((E, C), dim=1)\n",
    "        out = F.relu(self.l0(out))\n",
    "        out = F.relu(self.l1(out))\n",
    "        out = self.l2(out)\n",
    "\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "        # output of Table 5\n",
    "        return out\n",
    "\n",
    "\n",
    "class LocalDiscriminator(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    the local discriminator with architecture described in\n",
    "    Figure 4 and Table 6 in appendix 1A of https://arxiv.org/pdf/1808.06670.pdf.\n",
    "    input is the concatenate of\n",
    "    \"replicated feature vector E (with M_shape now)\" + \"M\"\n",
    "\n",
    "    replicated means that all pixels are the same, they are just copies.\n",
    "    \"\"\"\n",
    "    def __init__(self, M_channels, E_size, interm_channels=512):\n",
    "        super().__init__()\n",
    "\n",
    "        in_channels = E_size + M_channels\n",
    "        self.c0 = torch.nn.Conv2d(in_channels, interm_channels, kernel_size=1)\n",
    "        self.c1 = torch.nn.Conv2d(interm_channels, interm_channels, kernel_size=1)\n",
    "        self.c2 = torch.nn.Conv2d(interm_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        score = F.relu(self.c0(x))\n",
    "        score = F.relu(self.c1(score))\n",
    "        score = self.c2(score)\n",
    "\n",
    "        return score\n",
    "\n",
    "class PriorDiscriminator(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    the Prior discriminator with architecture described in\n",
    "    Figure 6 and Table 9 in appendix 1A of https://arxiv.org/pdf/1808.06670.pdf.\n",
    "\n",
    "    input will be Real feature vector E and Fake feature vector E_fake (E_like shape),\n",
    "    This discriminator is trained to distinguish Real and Fake inputs.\n",
    "    So the Encoder is trained to \"fool\" this discriminator. (idea of GAN)\n",
    "    \"\"\"\n",
    "    def __init__(self, E_size, interm_size=(1000,200)):\n",
    "        super().__init__()\n",
    "        assert isinstance(interm_size, tuple), \"tuple of integers.\"\n",
    "\n",
    "        self.l0 = torch.nn.Linear(E_size, interm_size[0])\n",
    "        self.l1 = torch.nn.Linear(interm_size[0], interm_size[1])\n",
    "        self.l2 = torch.nn.Linear(interm_size[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        score = F.relu(self.l0(x))\n",
    "        score = F.relu(self.l1(score))\n",
    "        score = torch.sigmoid(self.l2(score))\n",
    "\n",
    "        return score\n",
    "\n",
    "class DeepInfoMaxLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.5, beta=1.0, gamma=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.get_models()\n",
    "\n",
    "    def get_models(self, input_shape=(32,32), num_feature=64, out_size=64, interm_size_G=512, interm_channels_L=512, interm_size_P=(1000,200) ):\n",
    "\n",
    "        self.encoder = Encoder(input_shape=input_shape, num_feature=num_feature, out_size=out_size)\n",
    "        self.global_D = GlobalDiscriminator(M_channels=self.encoder.M_channels, M_shape=self.encoder.M_shape, E_size=out_size, interm_size=interm_size_G)\n",
    "        self.local_D = LocalDiscriminator(M_channels=self.encoder.M_channels, E_size=out_size, interm_channels=interm_channels_L)\n",
    "        self.prior_D = PriorDiscriminator(E_size=out_size, interm_size=interm_size_P)\n",
    "\n",
    "    def forward(self, Y, M, M_fake):\n",
    "        # see appendix 1A of https://arxiv.org/pdf/1808.06670.pdf\n",
    "\n",
    "        Y_replicated = Y.unsqueeze(-1).unsqueeze(-1)\n",
    "        Y_replicated = Y_replicated.expand(-1, -1, 26, 26)\n",
    "\n",
    "        Y_cat_M = torch.cat((M, Y_replicated), dim=1)\n",
    "        Y_cat_M_fake = torch.cat((M_fake, Y_replicated), dim=1)\n",
    "\n",
    "        # local loss\n",
    "        # 2nd term in equation (8) in https://arxiv.org/pdf/1808.06670.pdf\n",
    "        Ej = -F.softplus(-self.local_D(Y_cat_M)).mean()\n",
    "        Em = -F.softplus(-self.local_D(Y_cat_M_fake)).mean()\n",
    "        local_loss = (Em - Ej) * self.beta\n",
    "\n",
    "        # global loss\n",
    "        # 1st term in equation (8) in https://arxiv.org/pdf/1808.06670.pdf\n",
    "        Ej = -F.softplus(-self.global_D(Y, M)).mean()\n",
    "        Em = -F.softplus(-self.global_D(Y, M_fake)).mean()\n",
    "        global_loss= (Em - Ej) * self.alpha\n",
    "\n",
    "        # prior loss\n",
    "        # 3rd term in equation (8) in https://arxiv.org/pdf/1808.06670.pdf\n",
    "        prior = torch.rand_like(Y)\n",
    "        # 1st term in equation (7) in https://arxiv.org/pdf/1808.06670.pdf\n",
    "        term_a = torch.log(self.prior_D(prior)).mean()\n",
    "        # 2nd term in equation (7) in https://arxiv.org/pdf/1808.06670.pdf\n",
    "        term_b = torch.log(1 - self.prior_D(Y)).mean()\n",
    "        prior_loss = - (term_a + term_b) * self.gamma\n",
    "\n",
    "        return local_loss + global_loss + prior_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
