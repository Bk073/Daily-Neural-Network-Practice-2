{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T14:14:47.591280Z",
     "start_time": "2018-11-16T14:14:23.741002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy      as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from   plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# data set \n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "init_notebook_mode(connected=True); np.random.seed(6789); tf.set_random_seed(67890); plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (25.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the matrix factors from random normals with mean 0. W will\n",
    "# represent users and H will represent items.\n",
    "W = tf.Variable(tf.truncated_normal([num_users, rank], stddev=0.2, mean=0), name=\"users\")\n",
    "H = tf.Variable(tf.truncated_normal([rank, num_items], stddev=0.2, mean=0), name=\"items\")\n",
    "\n",
    "# To the user matrix we add a bias column holding the bias of each user,\n",
    "# and another column of 1s to multiply the item bias by.\n",
    "W_plus_bias = tf.concat(1, [W, tf.convert_to_tensor(user_bias, dtype=float32, name=\"user_bias\"), tf.ones((num_users,1), dtype=float32, name=\"item_bias_ones\")])\n",
    "# To the item matrix we add a row of 1s to multiply the user bias by, and\n",
    "# a bias row holding the bias of each item.\n",
    "H_plus_bias = tf.concat(0, [H, tf.ones((1, num_items), name=\"user_bias_ones\", dtype=float32), tf.convert_to_tensor(item_bias, dtype=float32, name=\"item_bias\")])\n",
    "# Multiply the factors to get our result as a dense matrix\n",
    "result = tf.matmul(W_plus_bias, H_plus_bias)\n",
    "\n",
    "# Now we just want the values represented by the pairs of user and item\n",
    "# indices for which we had known ratings. Unfortunately TensorFlow does not\n",
    "# yet support numpy-like indexing of tensors. See the issue for this at\n",
    "# https://github.com/tensorflow/tensorflow/issues/206 The workaround here\n",
    "# came from https://github.com/tensorflow/tensorflow/issues/418 and is a\n",
    "# little esoteric but in numpy this would just be done as follows:\n",
    "# result_values = result[user_indices, item_indices]\n",
    "result_values = tf.gather(tf.reshape(result, [-1]), user_indices * tf.shape(result)[1] + item_indices, name=\"extract_training_ratings\")\n",
    "\n",
    "# Same thing for the validation set ratings.\n",
    "result_values_val = tf.gather(tf.reshape(result, [-1]), user_indices_val * tf.shape(result)[1] + item_indices_val, name=\"extract_validation_ratings\")\n",
    "\n",
    "# Calculate the difference between the predicted ratings and the actual\n",
    "# ratings. The predicted ratings are the values obtained form the matrix\n",
    "# multiplication with the mean rating added on.\n",
    "diff_op = tf.sub(tf.add(result_values, mean_rating, name=\"add_mean\"), rating_values, name=\"raw_training_error\")\n",
    "diff_op_val = tf.sub(tf.add(result_values_val, mean_rating, name=\"add_mean_val\"), rating_values_val, name=\"raw_validation_error\")\n",
    "\n",
    "with tf.name_scope(\"training_cost\") as scope:\n",
    "    base_cost = tf.reduce_sum(tf.square(diff_op, name=\"squared_difference\"), name=\"sum_squared_error\")\n",
    "    # Add regularization.\n",
    "    regularizer = tf.mul(tf.add(tf.reduce_sum(tf.square(W)), tf.reduce_sum(tf.square(H))), lda, name=\"regularize\")\n",
    "    cost = tf.div(tf.add(base_cost, regularizer), num_ratings * 2, name=\"average_error\")\n",
    "\n",
    "with tf.name_scope(\"validation_cost\") as scope:\n",
    "    cost_val = tf.div(tf.reduce_sum(tf.square(diff_op_val, name=\"squared_difference_val\"), name=\"sum_squared_error_val\"), num_ratings_val * 2, name=\"average_error\")\n",
    "\n",
    "# Use an exponentially decaying learning rate.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(lr, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Passing global_step to minimize() will increment it at each step so\n",
    "    # that the learning rate will be decayed at the specified intervals.\n",
    "    train_step = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "with tf.name_scope(\"training_accuracy\") as scope:\n",
    "  # Just measure the absolute difference against the threshold\n",
    "  # TODO: support percentage-based thresholds\n",
    "  good = tf.less(tf.abs(diff_op), threshold)\n",
    "\n",
    "  accuracy_tr = tf.div(tf.reduce_sum(tf.cast(good, tf.float32)), num_ratings)\n",
    "  accuracy_tr_summary = tf.scalar_summary(\"accuracy_tr\", accuracy_tr)\n",
    "\n",
    "with tf.name_scope(\"validation_accuracy\") as scope:\n",
    "  # Validation set accuracy:\n",
    "  good_val = tf.less(tf.abs(diff_op_val), threshold)\n",
    "  accuracy_val = tf.reduce_sum(tf.cast(good_val, tf.float32)) / num_ratings_val\n",
    "  accuracy_val_summary = tf.scalar_summary(\"accuracy_val\", accuracy_val)\n",
    "\n",
    "# Create a TensorFlow session and initialize variables.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Make sure summaries get written to the logs.\n",
    "summary_op = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter(\"/tmp/recommender_logs\", sess.graph_def)\n",
    "\n",
    "# Run the graph and see how we're doing on every 500th iteration.\n",
    "for i in range(max_iter):\n",
    "    if i % 500 == 0:\n",
    "        res = sess.run([summary_op, accuracy_tr, accuracy_val, cost, cost_val])\n",
    "        summary_str = res[0]\n",
    "        acc_tr = res[1]\n",
    "        acc_val = res[2]\n",
    "        cost_ev = res[3]\n",
    "        cost_val_ev = res[4]\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print(\"Training accuracy at step %s: %s\" % (i, acc_tr))\n",
    "        print(\"Validation accuracy at step %s: %s\" % (i, acc_val))\n",
    "        print(\"Training cost: %s\" % (cost_ev))\n",
    "        print(\"Validation cost: %s\" % (cost_val_ev))\n",
    "    else:\n",
    "        sess.run(train_step)\n",
    "\n",
    "with tf.name_scope(\"final_model\") as scope:\n",
    "    # At the end we want to get the final ratings matrix by adding the mean\n",
    "    # to the result matrix and doing any further processing required\n",
    "    add_mean_final = tf.add(result, mean_rating, name=\"add_mean_final\")\n",
    "    if result_processor == None:\n",
    "        final_matrix = add_mean_final\n",
    "    else:\n",
    "        final_matrix = result_processor(add_mean_final)\n",
    "    final_res = sess.run([final_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
