{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T04:49:28.431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before learning:\n",
      "    percentage results: {'X': 58.84, 'O': 28.93, '-': 12.23}\n",
      "After 1000 learning games:\n",
      "    percentage results: {'X': 58.26, 'O': 29.54, '-': 12.2}\n",
      "After 5000 learning games:\n",
      "    percentage results: {'X': 17.09, 'O': 8.58, '-': 74.33}\n",
      "After 10000 learning games:\n",
      "    percentage results: {'X': 2.27, 'O': 0.27, '-': 97.46}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://www.kaggle.com/slobo777/tic-tac-toe-agent-using-q-learning\n",
    "   Copyright 2017 Neil Slater\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from itertools import groupby\n",
    "\n",
    "class TicTacToeGame():\n",
    "    def __init__(self):\n",
    "        self.state = '         '\n",
    "        self.player = 'X'\n",
    "        self.winner = None\n",
    "\n",
    "    def allowed_moves(self):\n",
    "        states = []\n",
    "        for i in range(len(self.state)):\n",
    "            if self.state[i] == ' ':\n",
    "                states.append(self.state[:i] + self.player + self.state[i+1:])\n",
    "        return states\n",
    "\n",
    "    def make_move(self, next_state):\n",
    "        if self.winner:\n",
    "            raise(Exception(\"Game already completed, cannot make another move!\"))\n",
    "        if not self.__valid_move(next_state):\n",
    "            raise(Exception(\"Cannot make move {} to {} for player {}\".format(\n",
    "                    self.state, next_state, self.player)))\n",
    "\n",
    "        self.state = next_state\n",
    "        self.winner = self.predict_winner(self.state)\n",
    "        if self.winner:\n",
    "            self.player = None\n",
    "        elif self.player == 'X':\n",
    "            self.player = 'O'\n",
    "        else:\n",
    "            self.player = 'X'\n",
    "\n",
    "    def playable(self):\n",
    "        return ( (not self.winner) and any(self.allowed_moves()) )\n",
    "\n",
    "    def predict_winner(self, state):\n",
    "        lines = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
    "        winner = None\n",
    "        for line in lines:\n",
    "            line_state = state[line[0]] + state[line[1]] + state[line[2]]\n",
    "            if line_state == 'XXX':\n",
    "                winner = 'X'\n",
    "            elif line_state == 'OOO':\n",
    "                winner = 'O'\n",
    "        return winner\n",
    "\n",
    "    def __valid_move(self, next_state):\n",
    "        allowed_moves = self.allowed_moves()\n",
    "        if any(state == next_state for state in allowed_moves):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def print_board(self):\n",
    "        s = self.state\n",
    "        print('     {} | {} | {} '.format(s[0],s[1],s[2]))\n",
    "        print('    -----------')\n",
    "        print('     {} | {} | {} '.format(s[3],s[4],s[5]))\n",
    "        print('    -----------')\n",
    "        print('     {} | {} | {} '.format(s[6],s[7],s[8]))\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, game_class, epsilon=0.1, alpha=0.5, value_player='X'):\n",
    "        self.V = dict()\n",
    "        self.NewGame = game_class\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.value_player = value_player\n",
    "\n",
    "    def state_value(self, game_state):\n",
    "        return self.V.get(game_state, 0.0)\n",
    "\n",
    "    def learn_game(self, num_episodes=1000):\n",
    "        for episode in range(num_episodes):\n",
    "            self.learn_from_episode()\n",
    "\n",
    "    def learn_from_episode(self):\n",
    "        game = self.NewGame()\n",
    "        _, move = self.learn_select_move(game)\n",
    "        while move:\n",
    "            move = self.learn_from_move(game, move)\n",
    "\n",
    "    def learn_from_move(self, game, move):\n",
    "        game.make_move(move)\n",
    "        r = self.__reward(game)\n",
    "        td_target = r\n",
    "        next_state_value = 0.0\n",
    "        selected_next_move = None\n",
    "        if game.playable():\n",
    "            best_next_move, selected_next_move = self.learn_select_move(game)\n",
    "            next_state_value = self.state_value(best_next_move)\n",
    "        current_state_value = self.state_value(move)\n",
    "        td_target = r + next_state_value\n",
    "        self.V[move] = current_state_value + self.alpha * (td_target - current_state_value)\n",
    "        return selected_next_move\n",
    "\n",
    "    def learn_select_move(self, game):\n",
    "        allowed_state_values = self.__state_values( game.allowed_moves() )\n",
    "        if game.player == self.value_player:\n",
    "            best_move = self.__argmax_V(allowed_state_values)\n",
    "        else:\n",
    "            best_move = self.__argmin_V(allowed_state_values)\n",
    "\n",
    "        selected_move = best_move\n",
    "        if random.random() < self.epsilon:\n",
    "            selected_move = self.__random_V(allowed_state_values)\n",
    "\n",
    "        return (best_move, selected_move)\n",
    "\n",
    "    def play_select_move(self, game):\n",
    "        allowed_state_values = self.__state_values( game.allowed_moves() )\n",
    "        if game.player == self.value_player:\n",
    "            return self.__argmax_V(allowed_state_values)\n",
    "        else:\n",
    "            return self.__argmin_V(allowed_state_values)\n",
    "\n",
    "    def demo_game(self, verbose=False):\n",
    "        game = self.NewGame()\n",
    "        t = 0\n",
    "        while game.playable():\n",
    "            if verbose:\n",
    "                print(\" \\nTurn {}\\n\".format(t))\n",
    "                game.print_board()\n",
    "            move = self.play_select_move(game)\n",
    "            game.make_move(move)\n",
    "            t += 1\n",
    "        if verbose:\n",
    "            print(\" \\nTurn {}\\n\".format(t))\n",
    "            game.print_board()\n",
    "        if game.winner:\n",
    "            if verbose:\n",
    "                print(\"\\n{} is the winner!\".format(game.winner))\n",
    "            return game.winner\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"\\nIt's a draw!\")\n",
    "            return '-'\n",
    "\n",
    "    def interactive_game(self, agent_player='X'):\n",
    "        game = self.NewGame()\n",
    "        t = 0\n",
    "        while game.playable():\n",
    "            print(\" \\nTurn {}\\n\".format(t))\n",
    "            game.print_board()\n",
    "            if game.player == agent_player:\n",
    "                move = self.play_select_move(game)\n",
    "                game.make_move(move)\n",
    "            else:\n",
    "                move = self.__request_human_move(game)\n",
    "                game.make_move(move)\n",
    "            t += 1\n",
    "\n",
    "        print(\" \\nTurn {}\\n\".format(t))\n",
    "        game.print_board()\n",
    "\n",
    "        if game.winner:\n",
    "            print(\"\\n{} is the winner!\".format(game.winner))\n",
    "            return game.winner\n",
    "        print(\"\\nIt's a draw!\")\n",
    "        return '-'\n",
    "\n",
    "    def round_V(self):\n",
    "        # After training, this makes action selection random from equally-good choices\n",
    "        for k in self.V.keys():\n",
    "            self.V[k] = round(self.V[k],1)\n",
    "\n",
    "    def save_v_table(self):\n",
    "        with open('state_values.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['State', 'Value'])\n",
    "            all_states = list(self.V.keys())\n",
    "            all_states.sort()\n",
    "            for state in all_states:\n",
    "                writer.writerow([state, self.V[state]])\n",
    "\n",
    "    def __state_values(self, game_states):\n",
    "        return dict((state, self.state_value(state)) for state in game_states)\n",
    "\n",
    "    def __argmax_V(self, state_values):\n",
    "        max_V = max(state_values.values())\n",
    "        chosen_state = random.choice([state for state, v in state_values.items() if v == max_V])\n",
    "        return chosen_state\n",
    "\n",
    "    def __argmin_V(self, state_values):\n",
    "        min_V = min(state_values.values())\n",
    "        chosen_state = random.choice([state for state, v in state_values.items() if v == min_V])\n",
    "        return chosen_state\n",
    "\n",
    "    def __random_V(self, state_values):\n",
    "        return random.choice(list(state_values.keys()))\n",
    "\n",
    "    def __reward(self, game):\n",
    "        if game.winner == self.value_player:\n",
    "            return 1.0\n",
    "        elif game.winner:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def __request_human_move(self, game):\n",
    "        allowed_moves = [i+1 for i in range(9) if game.state[i] == ' ']\n",
    "        human_move = None\n",
    "        while not human_move:\n",
    "            idx = int(input('Choose move for {}, from {} : '.format(game.player, allowed_moves)))\n",
    "            if any([i==idx for i in allowed_moves]):\n",
    "                human_move = game.state[:idx-1] + game.player + game.state[idx:]\n",
    "        return human_move\n",
    "\n",
    "def demo_game_stats(agent):\n",
    "    results = [agent.demo_game() for i in range(10000)]\n",
    "    game_stats = {k: results.count(k)/100 for k in ['X', 'O', '-']}\n",
    "    print(\"    percentage results: {}\".format(game_stats))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agent = Agent(TicTacToeGame, epsilon = 0.1, alpha = 1.0)\n",
    "    print(\"Before learning:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(1000)\n",
    "    print(\"After 1000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(4000)\n",
    "    print(\"After 5000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(5000)\n",
    "    print(\"After 10000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(10000)\n",
    "    print(\"After 20000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.learn_game(10000)\n",
    "    print(\"After 30000 learning games:\")\n",
    "    demo_game_stats(agent)\n",
    "\n",
    "    agent.round_V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-11T04:49:31.831Z"
    }
   },
   "outputs": [],
   "source": [
    "! git all-go"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
