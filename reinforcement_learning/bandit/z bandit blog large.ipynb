{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:29:27.640901Z",
     "start_time": "2019-01-13T01:29:26.638907Z"
    }
   },
   "source": [
    "### Compare Listing \n",
    "<ol>\n",
    "<li>a: vector uniform</li>\n",
    "<li>b: greedy</li>\n",
    "<li>c: e - greedy</li>\n",
    "<li>d: decay e - greedy</li>\n",
    "<li>e: Linear Reward Inaction (Pursuit Methods)</li>\n",
    "<li>f: Linear Reward Penalty (Pursuit Methods)</li>\n",
    "<li>g: UBC 1</li>\n",
    "<li>h: UCB 1-Tuned</li>\n",
    "<li>i: Thompson Sampling (beta)</li>\n",
    "<li>j: Thompson Sampling (uniform)</li>\n",
    "<li>k: Neural Network</li>\n",
    "<li>l: softmax </li>\n",
    "<li>m: Gradient Bandits</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T09:08:02.602498Z",
     "start_time": "2019-01-14T09:07:59.565321Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy,time,sys\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta\n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(5678)\n",
    "np.set_printoptions(3)\n",
    "tf.set_random_seed(678)\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T09:08:05.332184Z",
     "start_time": "2019-01-14T09:08:05.320178Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.985e-01 2.468e-01 4.049e-01 5.143e-01 8.784e-01 5.730e-01 1.863e-01\n",
      " 8.173e-01 6.897e-01 2.182e-01 9.070e-01 7.975e-02 3.765e-01 7.575e-01\n",
      " 9.264e-01 7.513e-01 2.293e-01 8.728e-01 4.411e-01 2.945e-01 1.383e-01\n",
      " 2.116e-01 9.970e-02 7.656e-01 6.761e-01 8.933e-01 8.492e-01 5.543e-01\n",
      " 1.555e-02 9.807e-01 4.410e-01 2.954e-01 3.047e-01 2.378e-01 4.053e-02\n",
      " 1.928e-01 5.942e-01 9.718e-01 1.122e-01 4.146e-01 9.596e-02 4.615e-01\n",
      " 4.102e-01 7.851e-01 6.594e-01 6.430e-01 8.628e-01 7.358e-01 3.753e-01\n",
      " 1.499e-02 9.167e-01 6.266e-01 5.835e-01 9.620e-01 3.563e-01 3.146e-01\n",
      " 2.974e-01 2.733e-01 2.759e-01 8.777e-02 1.640e-01 9.339e-01 7.837e-01\n",
      " 9.007e-01 8.759e-01 7.108e-01 6.899e-01 3.939e-01 7.935e-02 9.195e-01\n",
      " 7.454e-01 2.285e-01 8.999e-02 6.199e-01 8.322e-01 5.734e-01 2.972e-01\n",
      " 7.810e-01 9.592e-01 4.716e-01 7.766e-01 1.580e-01 5.323e-01 8.413e-02\n",
      " 6.862e-01 5.251e-01 7.035e-01 6.266e-02 1.740e-01 2.738e-01 7.370e-01\n",
      " 5.180e-01 9.440e-01 5.869e-01 5.683e-01 6.736e-01 6.040e-01 1.795e-01\n",
      " 6.692e-01 3.784e-01 5.799e-01 7.999e-01 7.164e-01 2.043e-01 5.965e-01\n",
      " 1.802e-01 5.404e-01 2.257e-01 8.393e-01 5.928e-02 7.697e-01 6.783e-01\n",
      " 2.417e-01 2.014e-02 2.213e-01 1.646e-01 9.784e-01 1.116e-01 7.692e-01\n",
      " 7.533e-02 6.196e-01 8.608e-01 6.582e-01 1.045e-01 3.834e-01 8.187e-01\n",
      " 9.441e-01 9.435e-01 1.540e-01 4.089e-01 1.342e-01 1.329e-01 2.474e-01\n",
      " 5.057e-01 8.841e-01 1.209e-01 4.777e-01 3.655e-02 2.866e-01 4.459e-01\n",
      " 3.274e-01 4.929e-01 3.193e-01 4.067e-01 3.596e-01 5.537e-01 5.443e-01\n",
      " 1.242e-02 5.984e-01 3.763e-01 2.472e-01 4.210e-01 9.832e-01 3.582e-01\n",
      " 9.756e-02 5.188e-01 8.472e-01 9.345e-01 8.728e-01 4.500e-01 4.960e-01\n",
      " 4.090e-01 2.779e-01 1.693e-02 2.318e-02 7.475e-01 1.590e-01 3.732e-02\n",
      " 7.451e-01 5.752e-01 6.708e-01 4.110e-01 1.026e-01 8.470e-02 1.025e-01\n",
      " 2.925e-01 2.006e-01 3.468e-01 3.440e-01 8.419e-01 5.450e-01 3.445e-01\n",
      " 4.356e-01 6.018e-01 6.582e-01 4.777e-01 5.090e-01 1.750e-01 7.049e-01\n",
      " 8.597e-01 9.862e-01 6.258e-02 8.467e-01 3.545e-01 6.479e-01 9.001e-01\n",
      " 6.736e-01 7.068e-01 3.297e-01 3.453e-01 7.810e-01 4.954e-01 9.578e-01\n",
      " 8.519e-01 8.053e-01 5.102e-01 1.190e-01 4.680e-01 8.261e-01 4.550e-01\n",
      " 5.082e-01 1.237e-02 7.898e-01 7.013e-01 9.319e-01 3.271e-01 8.428e-01\n",
      " 1.050e-01 8.215e-01 7.193e-01 3.678e-02 5.714e-01 9.837e-02 8.292e-01\n",
      " 1.140e-01 6.313e-01 8.248e-01 4.939e-01 9.204e-01 6.269e-01 8.511e-01\n",
      " 9.356e-01 3.757e-01 4.588e-01 3.054e-01 3.362e-01 6.466e-02 3.288e-02\n",
      " 8.716e-01 8.349e-01 4.532e-01 5.377e-01 9.514e-01 1.125e-01 5.076e-01\n",
      " 8.385e-01 6.571e-01 7.602e-01 7.426e-02 9.782e-01 2.407e-01 8.767e-01\n",
      " 3.916e-01 6.784e-01 5.506e-01 6.467e-01 1.555e-01 6.212e-01 3.338e-01\n",
      " 9.300e-01 5.977e-01 5.471e-01 7.017e-01 6.053e-01 1.741e-01 5.788e-01\n",
      " 2.797e-01 2.463e-01 4.882e-01 6.094e-01 6.771e-01 4.706e-01 9.722e-01\n",
      " 2.112e-01 4.699e-01 7.070e-01 4.071e-01 2.881e-01 7.060e-02 7.499e-01\n",
      " 1.560e-01 5.742e-01 7.218e-01 5.040e-01 7.832e-01 6.777e-01 6.963e-02\n",
      " 8.576e-01 3.801e-01 1.769e-01 5.900e-01 3.751e-01 8.342e-01 9.165e-02\n",
      " 6.948e-01 9.195e-01 6.810e-01 9.232e-01 9.121e-01 2.056e-01 2.974e-01\n",
      " 9.441e-01 6.130e-01 3.131e-01 6.014e-02 1.553e-01 9.601e-01 1.399e-01\n",
      " 9.641e-01 6.817e-01 6.543e-01 4.337e-01 6.990e-01 7.850e-01 5.505e-01\n",
      " 3.664e-01 7.645e-01 5.506e-01 2.211e-01 8.864e-02 6.537e-01 8.539e-01\n",
      " 9.674e-01 2.913e-01 2.149e-01 4.485e-02 5.380e-02 2.822e-01 2.011e-01\n",
      " 2.144e-01 5.371e-01 4.189e-01 7.701e-01 1.600e-01 5.994e-01 6.426e-01\n",
      " 3.208e-01 6.352e-01 7.675e-01 5.132e-01 5.744e-01 3.626e-02 6.616e-01\n",
      " 4.799e-01 7.827e-01 5.688e-01 8.952e-01 7.038e-01 4.372e-01 7.000e-03\n",
      " 7.275e-01 1.301e-02 2.442e-01 7.818e-01 6.423e-01 1.849e-01 1.029e-02\n",
      " 6.720e-01 1.894e-01 1.569e-01 7.577e-01 8.580e-01 1.997e-01 6.353e-01\n",
      " 6.086e-01 7.896e-02 6.784e-01 1.784e-01 9.952e-01 5.475e-01 7.798e-01\n",
      " 3.475e-01 6.226e-01 8.544e-01 1.460e-03 5.001e-01 3.718e-01 5.807e-01\n",
      " 9.152e-01 6.399e-01 2.179e-01 6.915e-01 1.929e-01 2.353e-01 2.110e-01\n",
      " 8.310e-01 2.139e-01 6.696e-02 2.600e-01 8.580e-01 2.495e-01 8.198e-01\n",
      " 8.342e-01 9.967e-01 2.632e-01 1.045e-01 1.655e-02 3.808e-01 3.311e-01\n",
      " 6.751e-01 6.021e-02 8.914e-01 7.447e-01 3.205e-01 7.287e-01 7.737e-01\n",
      " 3.099e-01 8.285e-01 9.760e-01 6.789e-01 7.289e-01 3.269e-01 8.277e-01\n",
      " 6.216e-01 5.183e-02 9.118e-01 9.298e-01 8.160e-01 1.323e-02 2.126e-01\n",
      " 1.274e-01 6.271e-01 5.204e-01 4.078e-01 3.579e-01 8.408e-01 9.339e-02\n",
      " 2.104e-01 1.484e-01 4.864e-01 2.373e-01 1.216e-01 6.979e-01 2.325e-01\n",
      " 3.531e-01 9.599e-01 6.657e-01 5.796e-01 6.655e-02 9.023e-01 3.342e-02\n",
      " 6.137e-01 8.695e-01 1.593e-01 8.088e-01 3.779e-01 3.781e-01 9.137e-01\n",
      " 7.145e-01 6.452e-01 2.884e-01 2.499e-01 9.588e-02 3.120e-01 5.792e-01\n",
      " 1.798e-01 6.113e-01 2.859e-01 9.343e-01 3.387e-01 5.798e-01 9.912e-01\n",
      " 2.213e-01 8.908e-02 1.937e-01 9.158e-01 6.473e-01 3.717e-01 1.731e-01\n",
      " 2.613e-01 3.394e-01 9.832e-01 1.065e-01 8.790e-01 1.126e-01 3.665e-02\n",
      " 6.719e-01 9.349e-01 7.927e-01 4.120e-01 2.150e-01 7.253e-01 6.126e-01\n",
      " 7.671e-01 3.984e-01 9.749e-02 5.872e-01 7.930e-02 2.015e-01 9.855e-01\n",
      " 1.222e-01 3.605e-01 8.518e-01 4.726e-02 2.788e-01 5.226e-01 2.699e-01\n",
      " 5.575e-01 2.942e-01 8.617e-01 9.510e-01 6.238e-01 6.460e-01 6.290e-02\n",
      " 1.166e-01 3.779e-01 9.457e-01 8.820e-01 8.025e-01 8.444e-01 7.673e-01\n",
      " 2.890e-01 9.168e-01 2.888e-01 5.535e-01 2.407e-01 9.745e-01 2.549e-01\n",
      " 4.930e-01 3.003e-01 3.812e-01 5.267e-01 2.516e-01 8.392e-01 7.095e-01\n",
      " 3.405e-01 8.377e-01 4.183e-01 9.013e-02 2.353e-01 2.908e-01 2.508e-01\n",
      " 4.931e-01 3.961e-01 7.626e-01 4.474e-01 6.208e-01 1.702e-01 8.447e-01\n",
      " 3.393e-01 4.848e-01 5.762e-01 3.012e-01 8.701e-01 8.852e-01 4.169e-01\n",
      " 2.058e-01 2.953e-01 9.488e-01 5.608e-01 7.966e-01 2.907e-01 3.865e-01\n",
      " 5.624e-01 9.212e-01 8.133e-01 6.274e-01 9.445e-01 2.751e-01 7.360e-01\n",
      " 8.742e-01 7.233e-01 8.710e-01 3.491e-01 3.966e-01 9.800e-01 2.672e-01\n",
      " 7.075e-01 3.490e-01 3.101e-01 9.184e-01 6.895e-01 8.948e-01 2.878e-01\n",
      " 4.404e-01 5.733e-01 3.854e-01 2.306e-01 4.859e-01 4.621e-01 5.409e-01\n",
      " 7.569e-01 3.085e-01 2.542e-01 8.930e-01 2.739e-01 2.475e-01 6.474e-02\n",
      " 4.973e-02 6.462e-01 8.104e-01 6.978e-02 5.296e-01 7.204e-01 3.796e-01\n",
      " 6.973e-01 2.754e-01 5.212e-01 1.959e-02 4.449e-01 1.627e-01 5.012e-01\n",
      " 2.052e-02 3.470e-01 3.018e-01 4.657e-01 7.055e-01 1.879e-01 1.784e-01\n",
      " 2.357e-01 8.203e-01 3.340e-01 3.389e-01 9.425e-01 5.434e-01 8.021e-01\n",
      " 1.525e-01 8.248e-02 1.531e-01 9.903e-01 4.737e-01 5.046e-01 3.516e-01\n",
      " 7.574e-01 8.574e-01 1.738e-01 3.889e-01 6.809e-01 3.687e-01 8.125e-01\n",
      " 3.760e-01 1.244e-01 9.498e-01 4.648e-01 1.986e-01 6.045e-01 7.926e-01\n",
      " 1.197e-01 6.152e-01 9.267e-02 2.616e-01 8.631e-01 9.663e-01 4.911e-01\n",
      " 7.015e-01 1.554e-01 9.391e-01 5.312e-01 9.230e-01 7.418e-01 8.000e-01\n",
      " 8.141e-01 2.338e-01 4.992e-01 1.740e-01 5.907e-01 4.115e-01 6.508e-02\n",
      " 3.046e-01 6.194e-02 7.589e-01 9.418e-01 8.243e-01 7.539e-01 3.022e-01\n",
      " 9.693e-01 7.129e-01 1.326e-02 5.039e-01 7.290e-01 9.711e-02 3.012e-01\n",
      " 4.520e-01 6.074e-01 8.244e-01 6.599e-01 5.567e-01 8.439e-03 6.260e-01\n",
      " 7.690e-01 2.456e-02 9.373e-01 3.111e-01 9.920e-01 4.871e-01 5.120e-01\n",
      " 1.151e-01 4.361e-01 9.455e-01 1.433e-01 4.698e-01 1.531e-01 2.769e-01\n",
      " 1.251e-01 4.199e-01 7.167e-01 1.558e-01 1.141e-01 3.456e-01 1.110e-01\n",
      " 7.464e-01 8.418e-01 6.999e-01 4.664e-01 7.568e-01 5.838e-01 3.591e-02\n",
      " 8.513e-01 5.107e-01 6.468e-01 6.665e-01 3.146e-01 7.972e-02 8.816e-01\n",
      " 7.423e-02 9.917e-01 3.664e-01 7.207e-01 4.169e-01 5.070e-01 8.221e-01\n",
      " 1.107e-01 1.391e-01 8.717e-01 5.178e-01 8.075e-01 2.812e-01 6.217e-01\n",
      " 8.164e-01 7.943e-01 5.222e-01 8.666e-01 1.317e-01 3.251e-01 7.776e-01\n",
      " 8.506e-01 7.199e-01 3.477e-01 8.984e-01 7.143e-01 4.433e-01 3.544e-01\n",
      " 7.527e-01 9.710e-01 4.509e-01 3.925e-01 5.077e-01 4.936e-01 8.412e-01\n",
      " 8.444e-01 2.288e-01 3.060e-01 5.307e-01 6.282e-01 5.505e-01 7.904e-01\n",
      " 8.371e-01 2.657e-01 8.138e-01 9.905e-01 2.895e-01 7.073e-01 2.142e-01\n",
      " 7.558e-01 7.567e-01 9.030e-01 3.065e-01 9.503e-01 8.015e-01 1.063e-01\n",
      " 3.926e-01 9.851e-01 2.823e-01 8.271e-01 8.929e-01 1.406e-01 7.762e-01\n",
      " 4.305e-02 8.106e-01 2.527e-01 1.867e-01 4.300e-01 9.199e-01 4.044e-01\n",
      " 4.012e-01 9.832e-01 4.138e-01 5.494e-01 2.312e-02 6.444e-01 6.904e-02\n",
      " 4.786e-01 9.655e-01 1.226e-01 2.018e-02 1.781e-02 1.657e-01 3.089e-01\n",
      " 9.541e-01 1.637e-01 7.522e-01 1.184e-01 5.191e-01 6.416e-01 6.813e-01\n",
      " 1.676e-02 1.495e-01 1.924e-01 7.898e-01 5.516e-01 2.066e-02 9.228e-01\n",
      " 1.907e-01 1.626e-01 2.728e-01 9.585e-01 8.724e-01 2.157e-01 8.748e-01\n",
      " 3.127e-01 7.666e-02 7.835e-01 3.515e-01 6.095e-02 6.860e-01 9.731e-02\n",
      " 9.529e-01 7.317e-01 5.135e-01 1.188e-02 1.856e-01 2.447e-01 1.324e-01\n",
      " 4.273e-01 2.646e-01 9.612e-01 9.042e-01 5.728e-01 9.295e-01 4.947e-01\n",
      " 4.965e-01 6.654e-01 5.485e-02 8.002e-01 6.046e-01 3.671e-01 2.203e-01\n",
      " 4.118e-01 6.095e-01 4.893e-01 4.410e-02 2.011e-01 5.797e-01 2.377e-01\n",
      " 2.705e-03 2.056e-01 6.026e-01 5.530e-01 5.206e-01 4.861e-01 6.552e-01\n",
      " 8.015e-01 2.718e-01 5.832e-01 7.984e-01 3.339e-01 5.146e-02 4.575e-01\n",
      " 8.970e-01 9.124e-01 3.843e-01 3.383e-03 3.448e-01 2.064e-01 1.251e-01\n",
      " 3.016e-01 4.556e-01 6.542e-01 1.990e-01 7.626e-01 8.168e-01 4.313e-01\n",
      " 7.061e-01 6.993e-01 1.300e-01 7.698e-01 3.785e-01 6.814e-02 1.483e-01\n",
      " 8.854e-01 1.727e-01 7.951e-04 8.353e-01 6.004e-01 9.063e-01 6.223e-01\n",
      " 9.875e-01 1.665e-01 3.264e-01 3.238e-01 4.564e-01 7.328e-01 1.923e-01\n",
      " 8.472e-01 3.691e-01 6.759e-01 6.346e-01 5.645e-01 4.224e-01 7.307e-01\n",
      " 7.347e-01 3.138e-02 6.504e-01 8.351e-01 3.016e-01 3.975e-01 7.226e-01\n",
      " 6.267e-01 1.486e-01 7.610e-01 9.541e-01 3.067e-01 2.048e-01 7.338e-01\n",
      " 5.093e-01 7.096e-01 3.507e-01 7.638e-01 4.779e-01 7.940e-01 8.054e-01\n",
      " 3.795e-01 4.364e-01 4.693e-01 1.272e-01 1.123e-01 9.812e-01 2.056e-01\n",
      " 9.819e-01 2.977e-01 3.056e-01 7.162e-01 7.786e-02 6.447e-01 1.090e-01\n",
      " 1.527e-01 1.741e-01 3.096e-03 6.373e-01 8.590e-01 9.510e-01 2.743e-01\n",
      " 3.852e-01 6.675e-01 3.623e-01 9.716e-03 8.090e-02 1.490e-01 8.416e-01\n",
      " 6.593e-01 2.101e-01 5.014e-01 5.913e-01 9.052e-01 7.493e-01 5.459e-01\n",
      " 7.501e-01 6.508e-01 8.608e-01 5.365e-03 6.583e-01 1.032e-01 1.656e-01\n",
      " 1.113e-01 3.456e-01 9.045e-01 3.633e-02 8.274e-01 7.621e-01 2.158e-01\n",
      " 8.215e-01 3.190e-01 8.206e-01 6.776e-01 2.170e-01 3.530e-01 7.934e-01\n",
      " 6.000e-01 2.685e-01 9.690e-01 3.725e-01 5.176e-01 6.378e-01 1.791e-01\n",
      " 8.455e-01 4.405e-01 8.012e-01 1.178e-03 7.326e-01 8.546e-01]\n",
      "Best Choice:  0 0.9985178952064705\n"
     ]
    }
   ],
   "source": [
    "# setting the ground truth\n",
    "num_bandit = 1000\n",
    "num_ep  = 200\n",
    "num_iter= 2000\n",
    "gt_prob = np.random.uniform(0,1,num_bandit)\n",
    "optimal_choice = np.argmax(gt_prob)\n",
    "print(gt_prob)\n",
    "print('Best Choice: ',optimal_choice,gt_prob[optimal_choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T09:08:06.744795Z",
     "start_time": "2019-01-14T09:08:06.011153Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[9.985e-01 2.468e-01 4.049e-01 5.143e-01 8.784e-01 5.730e-01 1.863e-01\n",
      " 8.173e-01 6.897e-01 2.182e-01 9.070e-01 7.975e-02 3.765e-01 7.575e-01\n",
      " 9.264e-01 7.513e-01 2.293e-01 8.728e-01 4.411e-01 2.945e-01 1.383e-01\n",
      " 2.116e-01 9.970e-02 7.656e-01 6.761e-01 8.933e-01 8.492e-01 5.543e-01\n",
      " 1.555e-02 9.807e-01 4.410e-01 2.954e-01 3.047e-01 2.378e-01 4.053e-02\n",
      " 1.928e-01 5.942e-01 9.718e-01 1.122e-01 4.146e-01 9.596e-02 4.615e-01\n",
      " 4.102e-01 7.851e-01 6.594e-01 6.430e-01 8.628e-01 7.358e-01 3.753e-01\n",
      " 1.499e-02 9.167e-01 6.266e-01 5.835e-01 9.620e-01 3.563e-01 3.146e-01\n",
      " 2.974e-01 2.733e-01 2.759e-01 8.777e-02 1.640e-01 9.339e-01 7.837e-01\n",
      " 9.007e-01 8.759e-01 7.108e-01 6.899e-01 3.939e-01 7.935e-02 9.195e-01\n",
      " 7.454e-01 2.285e-01 8.999e-02 6.199e-01 8.322e-01 5.734e-01 2.972e-01\n",
      " 7.810e-01 9.592e-01 4.716e-01 7.766e-01 1.580e-01 5.323e-01 8.413e-02\n",
      " 6.862e-01 5.251e-01 7.035e-01 6.266e-02 1.740e-01 2.738e-01 7.370e-01\n",
      " 5.180e-01 9.440e-01 5.869e-01 5.683e-01 6.736e-01 6.040e-01 1.795e-01\n",
      " 6.692e-01 3.784e-01 5.799e-01 7.999e-01 7.164e-01 2.043e-01 5.965e-01\n",
      " 1.802e-01 5.404e-01 2.257e-01 8.393e-01 5.928e-02 7.697e-01 6.783e-01\n",
      " 2.417e-01 2.014e-02 2.213e-01 1.646e-01 9.784e-01 1.116e-01 7.692e-01\n",
      " 7.533e-02 6.196e-01 8.608e-01 6.582e-01 1.045e-01 3.834e-01 8.187e-01\n",
      " 9.441e-01 9.435e-01 1.540e-01 4.089e-01 1.342e-01 1.329e-01 2.474e-01\n",
      " 5.057e-01 8.841e-01 1.209e-01 4.777e-01 3.655e-02 2.866e-01 4.459e-01\n",
      " 3.274e-01 4.929e-01 3.193e-01 4.067e-01 3.596e-01 5.537e-01 5.443e-01\n",
      " 1.242e-02 5.984e-01 3.763e-01 2.472e-01 4.210e-01 9.832e-01 3.582e-01\n",
      " 9.756e-02 5.188e-01 8.472e-01 9.345e-01 8.728e-01 4.500e-01 4.960e-01\n",
      " 4.090e-01 2.779e-01 1.693e-02 2.318e-02 7.475e-01 1.590e-01 3.732e-02\n",
      " 7.451e-01 5.752e-01 6.708e-01 4.110e-01 1.026e-01 8.470e-02 1.025e-01\n",
      " 2.925e-01 2.006e-01 3.468e-01 3.440e-01 8.419e-01 5.450e-01 3.445e-01\n",
      " 4.356e-01 6.018e-01 6.582e-01 4.777e-01 5.090e-01 1.750e-01 7.049e-01\n",
      " 8.597e-01 9.862e-01 6.258e-02 8.467e-01 3.545e-01 6.479e-01 9.001e-01\n",
      " 6.736e-01 7.068e-01 3.297e-01 3.453e-01 7.810e-01 4.954e-01 9.578e-01\n",
      " 8.519e-01 8.053e-01 5.102e-01 1.190e-01 4.680e-01 8.261e-01 4.550e-01\n",
      " 5.082e-01 1.237e-02 7.898e-01 7.013e-01 9.319e-01 3.271e-01 8.428e-01\n",
      " 1.050e-01 8.215e-01 7.193e-01 3.678e-02 5.714e-01 9.837e-02 8.292e-01\n",
      " 1.140e-01 6.313e-01 8.248e-01 4.939e-01 9.204e-01 6.269e-01 8.511e-01\n",
      " 9.356e-01 3.757e-01 4.588e-01 3.054e-01 3.362e-01 6.466e-02 3.288e-02\n",
      " 8.716e-01 8.349e-01 4.532e-01 5.377e-01 9.514e-01 1.125e-01 5.076e-01\n",
      " 8.385e-01 6.571e-01 7.602e-01 7.426e-02 9.782e-01 2.407e-01 8.767e-01\n",
      " 3.916e-01 6.784e-01 5.506e-01 6.467e-01 1.555e-01 6.212e-01 3.338e-01\n",
      " 9.300e-01 5.977e-01 5.471e-01 7.017e-01 6.053e-01 1.741e-01 5.788e-01\n",
      " 2.797e-01 2.463e-01 4.882e-01 6.094e-01 6.771e-01 4.706e-01 9.722e-01\n",
      " 2.112e-01 4.699e-01 7.070e-01 4.071e-01 2.881e-01 7.060e-02 7.499e-01\n",
      " 1.560e-01 5.742e-01 7.218e-01 5.040e-01 7.832e-01 6.777e-01 6.963e-02\n",
      " 8.576e-01 3.801e-01 1.769e-01 5.900e-01 3.751e-01 8.342e-01 9.165e-02\n",
      " 6.948e-01 9.195e-01 6.810e-01 9.232e-01 9.121e-01 2.056e-01 2.974e-01\n",
      " 9.441e-01 6.130e-01 3.131e-01 6.014e-02 1.553e-01 9.601e-01 1.399e-01\n",
      " 9.641e-01 6.817e-01 6.543e-01 4.337e-01 6.990e-01 7.850e-01 5.505e-01\n",
      " 3.664e-01 7.645e-01 5.506e-01 2.211e-01 8.864e-02 6.537e-01 8.539e-01\n",
      " 9.674e-01 2.913e-01 2.149e-01 4.485e-02 5.380e-02 2.822e-01 2.011e-01\n",
      " 2.144e-01 5.371e-01 4.189e-01 7.701e-01 1.600e-01 5.994e-01 6.426e-01\n",
      " 3.208e-01 6.352e-01 7.675e-01 5.132e-01 5.744e-01 3.626e-02 6.616e-01\n",
      " 4.799e-01 7.827e-01 5.688e-01 8.952e-01 7.038e-01 4.372e-01 7.000e-03\n",
      " 7.275e-01 1.301e-02 2.442e-01 7.818e-01 6.423e-01 1.849e-01 1.029e-02\n",
      " 6.720e-01 1.894e-01 1.569e-01 7.577e-01 8.580e-01 1.997e-01 6.353e-01\n",
      " 6.086e-01 7.896e-02 6.784e-01 1.784e-01 9.952e-01 5.475e-01 7.798e-01\n",
      " 3.475e-01 6.226e-01 8.544e-01 1.460e-03 5.001e-01 3.718e-01 5.807e-01\n",
      " 9.152e-01 6.399e-01 2.179e-01 6.915e-01 1.929e-01 2.353e-01 2.110e-01\n",
      " 8.310e-01 2.139e-01 6.696e-02 2.600e-01 8.580e-01 2.495e-01 8.198e-01\n",
      " 8.342e-01 9.967e-01 2.632e-01 1.045e-01 1.655e-02 3.808e-01 3.311e-01\n",
      " 6.751e-01 6.021e-02 8.914e-01 7.447e-01 3.205e-01 7.287e-01 7.737e-01\n",
      " 3.099e-01 8.285e-01 9.760e-01 6.789e-01 7.289e-01 3.269e-01 8.277e-01\n",
      " 6.216e-01 5.183e-02 9.118e-01 9.298e-01 8.160e-01 1.323e-02 2.126e-01\n",
      " 1.274e-01 6.271e-01 5.204e-01 4.078e-01 3.579e-01 8.408e-01 9.339e-02\n",
      " 2.104e-01 1.484e-01 4.864e-01 2.373e-01 1.216e-01 6.979e-01 2.325e-01\n",
      " 3.531e-01 9.599e-01 6.657e-01 5.796e-01 6.655e-02 9.023e-01 3.342e-02\n",
      " 6.137e-01 8.695e-01 1.593e-01 8.088e-01 3.779e-01 3.781e-01 9.137e-01\n",
      " 7.145e-01 6.452e-01 2.884e-01 2.499e-01 9.588e-02 3.120e-01 5.792e-01\n",
      " 1.798e-01 6.113e-01 2.859e-01 9.343e-01 3.387e-01 5.798e-01 9.912e-01\n",
      " 2.213e-01 8.908e-02 1.937e-01 9.158e-01 6.473e-01 3.717e-01 1.731e-01\n",
      " 2.613e-01 3.394e-01 9.832e-01 1.065e-01 8.790e-01 1.126e-01 3.665e-02\n",
      " 6.719e-01 9.349e-01 7.927e-01 4.120e-01 2.150e-01 7.253e-01 6.126e-01\n",
      " 7.671e-01 3.984e-01 9.749e-02 5.872e-01 7.930e-02 2.015e-01 9.855e-01\n",
      " 1.222e-01 3.605e-01 8.518e-01 4.726e-02 2.788e-01 5.226e-01 2.699e-01\n",
      " 5.575e-01 2.942e-01 8.617e-01 9.510e-01 6.238e-01 6.460e-01 6.290e-02\n",
      " 1.166e-01 3.779e-01 9.457e-01 8.820e-01 8.025e-01 8.444e-01 7.673e-01\n",
      " 2.890e-01 9.168e-01 2.888e-01 5.535e-01 2.407e-01 9.745e-01 2.549e-01\n",
      " 4.930e-01 3.003e-01 3.812e-01 5.267e-01 2.516e-01 8.392e-01 7.095e-01\n",
      " 3.405e-01 8.377e-01 4.183e-01 9.013e-02 2.353e-01 2.908e-01 2.508e-01\n",
      " 4.931e-01 3.961e-01 7.626e-01 4.474e-01 6.208e-01 1.702e-01 8.447e-01\n",
      " 3.393e-01 4.848e-01 5.762e-01 3.012e-01 8.701e-01 8.852e-01 4.169e-01\n",
      " 2.058e-01 2.953e-01 9.488e-01 5.608e-01 7.966e-01 2.907e-01 3.865e-01\n",
      " 5.624e-01 9.212e-01 8.133e-01 6.274e-01 9.445e-01 2.751e-01 7.360e-01\n",
      " 8.742e-01 7.233e-01 8.710e-01 3.491e-01 3.966e-01 9.800e-01 2.672e-01\n",
      " 7.075e-01 3.490e-01 3.101e-01 9.184e-01 6.895e-01 8.948e-01 2.878e-01\n",
      " 4.404e-01 5.733e-01 3.854e-01 2.306e-01 4.859e-01 4.621e-01 5.409e-01\n",
      " 7.569e-01 3.085e-01 2.542e-01 8.930e-01 2.739e-01 2.475e-01 6.474e-02\n",
      " 4.973e-02 6.462e-01 8.104e-01 6.978e-02 5.296e-01 7.204e-01 3.796e-01\n",
      " 6.973e-01 2.754e-01 5.212e-01 1.959e-02 4.449e-01 1.627e-01 5.012e-01\n",
      " 2.052e-02 3.470e-01 3.018e-01 4.657e-01 7.055e-01 1.879e-01 1.784e-01\n",
      " 2.357e-01 8.203e-01 3.340e-01 3.389e-01 9.425e-01 5.434e-01 8.021e-01\n",
      " 1.525e-01 8.248e-02 1.531e-01 9.903e-01 4.737e-01 5.046e-01 3.516e-01\n",
      " 7.574e-01 8.574e-01 1.738e-01 3.889e-01 6.809e-01 3.687e-01 8.125e-01\n",
      " 3.760e-01 1.244e-01 9.498e-01 4.648e-01 1.986e-01 6.045e-01 7.926e-01\n",
      " 1.197e-01 6.152e-01 9.267e-02 2.616e-01 8.631e-01 9.663e-01 4.911e-01\n",
      " 7.015e-01 1.554e-01 9.391e-01 5.312e-01 9.230e-01 7.418e-01 8.000e-01\n",
      " 8.141e-01 2.338e-01 4.992e-01 1.740e-01 5.907e-01 4.115e-01 6.508e-02\n",
      " 3.046e-01 6.194e-02 7.589e-01 9.418e-01 8.243e-01 7.539e-01 3.022e-01\n",
      " 9.693e-01 7.129e-01 1.326e-02 5.039e-01 7.290e-01 9.711e-02 3.012e-01\n",
      " 4.520e-01 6.074e-01 8.244e-01 6.599e-01 5.567e-01 8.439e-03 6.260e-01\n",
      " 7.690e-01 2.456e-02 9.373e-01 3.111e-01 9.920e-01 4.871e-01 5.120e-01\n",
      " 1.151e-01 4.361e-01 9.455e-01 1.433e-01 4.698e-01 1.531e-01 2.769e-01\n",
      " 1.251e-01 4.199e-01 7.167e-01 1.558e-01 1.141e-01 3.456e-01 1.110e-01\n",
      " 7.464e-01 8.418e-01 6.999e-01 4.664e-01 7.568e-01 5.838e-01 3.591e-02\n",
      " 8.513e-01 5.107e-01 6.468e-01 6.665e-01 3.146e-01 7.972e-02 8.816e-01\n",
      " 7.423e-02 9.917e-01 3.664e-01 7.207e-01 4.169e-01 5.070e-01 8.221e-01\n",
      " 1.107e-01 1.391e-01 8.717e-01 5.178e-01 8.075e-01 2.812e-01 6.217e-01\n",
      " 8.164e-01 7.943e-01 5.222e-01 8.666e-01 1.317e-01 3.251e-01 7.776e-01\n",
      " 8.506e-01 7.199e-01 3.477e-01 8.984e-01 7.143e-01 4.433e-01 3.544e-01\n",
      " 7.527e-01 9.710e-01 4.509e-01 3.925e-01 5.077e-01 4.936e-01 8.412e-01\n",
      " 8.444e-01 2.288e-01 3.060e-01 5.307e-01 6.282e-01 5.505e-01 7.904e-01\n",
      " 8.371e-01 2.657e-01 8.138e-01 9.905e-01 2.895e-01 7.073e-01 2.142e-01\n",
      " 7.558e-01 7.567e-01 9.030e-01 3.065e-01 9.503e-01 8.015e-01 1.063e-01\n",
      " 3.926e-01 9.851e-01 2.823e-01 8.271e-01 8.929e-01 1.406e-01 7.762e-01\n",
      " 4.305e-02 8.106e-01 2.527e-01 1.867e-01 4.300e-01 9.199e-01 4.044e-01\n",
      " 4.012e-01 9.832e-01 4.138e-01 5.494e-01 2.312e-02 6.444e-01 6.904e-02\n",
      " 4.786e-01 9.655e-01 1.226e-01 2.018e-02 1.781e-02 1.657e-01 3.089e-01\n",
      " 9.541e-01 1.637e-01 7.522e-01 1.184e-01 5.191e-01 6.416e-01 6.813e-01\n",
      " 1.676e-02 1.495e-01 1.924e-01 7.898e-01 5.516e-01 2.066e-02 9.228e-01\n",
      " 1.907e-01 1.626e-01 2.728e-01 9.585e-01 8.724e-01 2.157e-01 8.748e-01\n",
      " 3.127e-01 7.666e-02 7.835e-01 3.515e-01 6.095e-02 6.860e-01 9.731e-02\n",
      " 9.529e-01 7.317e-01 5.135e-01 1.188e-02 1.856e-01 2.447e-01 1.324e-01\n",
      " 4.273e-01 2.646e-01 9.612e-01 9.042e-01 5.728e-01 9.295e-01 4.947e-01\n",
      " 4.965e-01 6.654e-01 5.485e-02 8.002e-01 6.046e-01 3.671e-01 2.203e-01\n",
      " 4.118e-01 6.095e-01 4.893e-01 4.410e-02 2.011e-01 5.797e-01 2.377e-01\n",
      " 2.705e-03 2.056e-01 6.026e-01 5.530e-01 5.206e-01 4.861e-01 6.552e-01\n",
      " 8.015e-01 2.718e-01 5.832e-01 7.984e-01 3.339e-01 5.146e-02 4.575e-01\n",
      " 8.970e-01 9.124e-01 3.843e-01 3.383e-03 3.448e-01 2.064e-01 1.251e-01\n",
      " 3.016e-01 4.556e-01 6.542e-01 1.990e-01 7.626e-01 8.168e-01 4.313e-01\n",
      " 7.061e-01 6.993e-01 1.300e-01 7.698e-01 3.785e-01 6.814e-02 1.483e-01\n",
      " 8.854e-01 1.727e-01 7.951e-04 8.353e-01 6.004e-01 9.063e-01 6.223e-01\n",
      " 9.875e-01 1.665e-01 3.264e-01 3.238e-01 4.564e-01 7.328e-01 1.923e-01\n",
      " 8.472e-01 3.691e-01 6.759e-01 6.346e-01 5.645e-01 4.224e-01 7.307e-01\n",
      " 7.347e-01 3.138e-02 6.504e-01 8.351e-01 3.016e-01 3.975e-01 7.226e-01\n",
      " 6.267e-01 1.486e-01 7.610e-01 9.541e-01 3.067e-01 2.048e-01 7.338e-01\n",
      " 5.093e-01 7.096e-01 3.507e-01 7.638e-01 4.779e-01 7.940e-01 8.054e-01\n",
      " 3.795e-01 4.364e-01 4.693e-01 1.272e-01 1.123e-01 9.812e-01 2.056e-01\n",
      " 9.819e-01 2.977e-01 3.056e-01 7.162e-01 7.786e-02 6.447e-01 1.090e-01\n",
      " 1.527e-01 1.741e-01 3.096e-03 6.373e-01 8.590e-01 9.510e-01 2.743e-01\n",
      " 3.852e-01 6.675e-01 3.623e-01 9.716e-03 8.090e-02 1.490e-01 8.416e-01\n",
      " 6.593e-01 2.101e-01 5.014e-01 5.913e-01 9.052e-01 7.493e-01 5.459e-01\n",
      " 7.501e-01 6.508e-01 8.608e-01 5.365e-03 6.583e-01 1.032e-01 1.656e-01\n",
      " 1.113e-01 3.456e-01 9.045e-01 3.633e-02 8.274e-01 7.621e-01 2.158e-01\n",
      " 8.215e-01 3.190e-01 8.206e-01 6.776e-01 2.170e-01 3.530e-01 7.934e-01\n",
      " 6.000e-01 2.685e-01 9.690e-01 3.725e-01 5.176e-01 6.378e-01 1.791e-01\n",
      " 8.455e-01 4.405e-01 8.012e-01 1.178e-03 7.326e-01 8.546e-01]\n",
      "Expected \n",
      "[9.990e-01 2.470e-01 4.059e-01 5.129e-01 8.793e-01 5.758e-01 1.870e-01\n",
      " 8.169e-01 6.885e-01 2.163e-01 9.074e-01 7.995e-02 3.785e-01 7.571e-01\n",
      " 9.251e-01 7.514e-01 2.230e-01 8.708e-01 4.394e-01 2.921e-01 1.417e-01\n",
      " 2.121e-01 1.019e-01 7.633e-01 6.758e-01 8.940e-01 8.484e-01 5.516e-01\n",
      " 1.590e-02 9.807e-01 4.404e-01 2.987e-01 3.010e-01 2.390e-01 4.125e-02\n",
      " 1.903e-01 5.950e-01 9.712e-01 1.103e-01 4.184e-01 9.755e-02 4.642e-01\n",
      " 4.093e-01 7.815e-01 6.611e-01 6.411e-01 8.624e-01 7.375e-01 3.718e-01\n",
      " 1.445e-02 9.159e-01 6.263e-01 5.851e-01 9.637e-01 3.546e-01 3.160e-01\n",
      " 2.937e-01 2.726e-01 2.744e-01 8.885e-02 1.636e-01 9.334e-01 7.873e-01\n",
      " 9.005e-01 8.735e-01 7.114e-01 6.926e-01 3.936e-01 8.010e-02 9.197e-01\n",
      " 7.478e-01 2.249e-01 9.180e-02 6.176e-01 8.332e-01 5.713e-01 3.014e-01\n",
      " 7.784e-01 9.580e-01 4.753e-01 7.796e-01 1.616e-01 5.299e-01 8.400e-02\n",
      " 6.894e-01 5.255e-01 7.039e-01 6.488e-02 1.754e-01 2.722e-01 7.364e-01\n",
      " 5.207e-01 9.436e-01 5.910e-01 5.690e-01 6.719e-01 6.072e-01 1.778e-01\n",
      " 6.705e-01 3.850e-01 5.806e-01 7.978e-01 7.151e-01 2.046e-01 6.015e-01\n",
      " 1.832e-01 5.418e-01 2.253e-01 8.338e-01 5.970e-02 7.708e-01 6.774e-01\n",
      " 2.439e-01 2.032e-02 2.207e-01 1.673e-01 9.782e-01 1.130e-01 7.659e-01\n",
      " 7.728e-02 6.211e-01 8.583e-01 6.600e-01 1.044e-01 3.850e-01 8.192e-01\n",
      " 9.425e-01 9.465e-01 1.543e-01 4.105e-01 1.360e-01 1.318e-01 2.467e-01\n",
      " 5.061e-01 8.829e-01 1.221e-01 4.767e-01 3.482e-02 2.865e-01 4.449e-01\n",
      " 3.261e-01 4.885e-01 3.228e-01 4.046e-01 3.600e-01 5.521e-01 5.435e-01\n",
      " 1.200e-02 5.953e-01 3.738e-01 2.489e-01 4.197e-01 9.829e-01 3.532e-01\n",
      " 9.713e-02 5.212e-01 8.476e-01 9.358e-01 8.726e-01 4.449e-01 4.961e-01\n",
      " 4.078e-01 2.745e-01 1.630e-02 2.317e-02 7.435e-01 1.588e-01 4.022e-02\n",
      " 7.426e-01 5.740e-01 6.680e-01 4.073e-01 1.044e-01 8.370e-02 1.031e-01\n",
      " 2.905e-01 1.979e-01 3.459e-01 3.483e-01 8.424e-01 5.469e-01 3.436e-01\n",
      " 4.314e-01 6.011e-01 6.558e-01 4.766e-01 5.125e-01 1.758e-01 7.043e-01\n",
      " 8.577e-01 9.858e-01 6.427e-02 8.487e-01 3.568e-01 6.512e-01 9.015e-01\n",
      " 6.739e-01 7.024e-01 3.281e-01 3.452e-01 7.786e-01 4.924e-01 9.580e-01\n",
      " 8.507e-01 8.027e-01 5.091e-01 1.211e-01 4.657e-01 8.280e-01 4.502e-01\n",
      " 5.067e-01 1.245e-02 7.887e-01 7.015e-01 9.338e-01 3.289e-01 8.412e-01\n",
      " 1.045e-01 8.216e-01 7.216e-01 3.632e-02 5.749e-01 9.873e-02 8.293e-01\n",
      " 1.114e-01 6.317e-01 8.230e-01 4.939e-01 9.207e-01 6.272e-01 8.523e-01\n",
      " 9.339e-01 3.727e-01 4.572e-01 3.033e-01 3.335e-01 6.508e-02 3.300e-02\n",
      " 8.710e-01 8.338e-01 4.558e-01 5.369e-01 9.521e-01 1.096e-01 5.070e-01\n",
      " 8.385e-01 6.596e-01 7.631e-01 7.462e-02 9.785e-01 2.382e-01 8.791e-01\n",
      " 3.919e-01 6.808e-01 5.500e-01 6.472e-01 1.557e-01 6.208e-01 3.298e-01\n",
      " 9.288e-01 5.996e-01 5.477e-01 7.001e-01 6.059e-01 1.756e-01 5.769e-01\n",
      " 2.833e-01 2.462e-01 4.830e-01 6.039e-01 6.731e-01 4.736e-01 9.725e-01\n",
      " 2.114e-01 4.708e-01 7.076e-01 4.073e-01 2.868e-01 7.127e-02 7.500e-01\n",
      " 1.560e-01 5.749e-01 7.235e-01 5.022e-01 7.825e-01 6.798e-01 6.918e-02\n",
      " 8.574e-01 3.841e-01 1.783e-01 5.893e-01 3.746e-01 8.335e-01 9.268e-02\n",
      " 6.993e-01 9.196e-01 6.782e-01 9.229e-01 9.097e-01 2.081e-01 3.001e-01\n",
      " 9.449e-01 6.120e-01 3.127e-01 6.175e-02 1.546e-01 9.603e-01 1.422e-01\n",
      " 9.651e-01 6.805e-01 6.567e-01 4.323e-01 6.957e-01 7.825e-01 5.484e-01\n",
      " 3.655e-01 7.644e-01 5.487e-01 2.217e-01 8.710e-02 6.540e-01 8.523e-01\n",
      " 9.679e-01 2.901e-01 2.140e-01 4.520e-02 5.410e-02 2.821e-01 1.999e-01\n",
      " 2.142e-01 5.393e-01 4.212e-01 7.702e-01 1.593e-01 5.980e-01 6.421e-01\n",
      " 3.217e-01 6.362e-01 7.672e-01 5.163e-01 5.744e-01 3.663e-02 6.620e-01\n",
      " 4.791e-01 7.817e-01 5.694e-01 8.970e-01 7.081e-01 4.390e-01 6.925e-03\n",
      " 7.245e-01 1.330e-02 2.441e-01 7.821e-01 6.402e-01 1.841e-01 9.925e-03\n",
      " 6.730e-01 1.907e-01 1.575e-01 7.568e-01 8.599e-01 1.983e-01 6.335e-01\n",
      " 6.041e-01 7.975e-02 6.749e-01 1.800e-01 9.952e-01 5.473e-01 7.808e-01\n",
      " 3.506e-01 6.194e-01 8.552e-01 1.375e-03 5.023e-01 3.680e-01 5.810e-01\n",
      " 9.144e-01 6.394e-01 2.161e-01 6.921e-01 1.909e-01 2.352e-01 2.122e-01\n",
      " 8.347e-01 2.108e-01 6.572e-02 2.591e-01 8.608e-01 2.538e-01 8.186e-01\n",
      " 8.361e-01 9.966e-01 2.648e-01 1.038e-01 1.632e-02 3.815e-01 3.296e-01\n",
      " 6.764e-01 5.872e-02 8.922e-01 7.455e-01 3.223e-01 7.298e-01 7.747e-01\n",
      " 3.095e-01 8.309e-01 9.768e-01 6.814e-01 7.337e-01 3.276e-01 8.298e-01\n",
      " 6.196e-01 5.040e-02 9.135e-01 9.271e-01 8.168e-01 1.320e-02 2.098e-01\n",
      " 1.248e-01 6.261e-01 5.217e-01 4.089e-01 3.560e-01 8.423e-01 9.298e-02\n",
      " 2.089e-01 1.468e-01 4.856e-01 2.398e-01 1.246e-01 6.982e-01 2.315e-01\n",
      " 3.519e-01 9.581e-01 6.663e-01 5.787e-01 6.688e-02 9.017e-01 3.232e-02\n",
      " 6.144e-01 8.722e-01 1.571e-01 8.089e-01 3.794e-01 3.793e-01 9.144e-01\n",
      " 7.155e-01 6.454e-01 2.885e-01 2.461e-01 9.920e-02 3.120e-01 5.781e-01\n",
      " 1.808e-01 6.118e-01 2.876e-01 9.344e-01 3.387e-01 5.792e-01 9.918e-01\n",
      " 2.218e-01 8.793e-02 1.916e-01 9.172e-01 6.454e-01 3.726e-01 1.730e-01\n",
      " 2.593e-01 3.385e-01 9.835e-01 1.054e-01 8.806e-01 1.116e-01 3.698e-02\n",
      " 6.734e-01 9.342e-01 7.904e-01 4.108e-01 2.149e-01 7.225e-01 6.103e-01\n",
      " 7.632e-01 3.980e-01 9.637e-02 5.874e-01 8.145e-02 1.998e-01 9.853e-01\n",
      " 1.201e-01 3.598e-01 8.523e-01 4.727e-02 2.776e-01 5.207e-01 2.693e-01\n",
      " 5.552e-01 2.928e-01 8.599e-01 9.496e-01 6.252e-01 6.479e-01 6.187e-02\n",
      " 1.159e-01 3.755e-01 9.451e-01 8.805e-01 8.001e-01 8.436e-01 7.664e-01\n",
      " 2.871e-01 9.178e-01 2.882e-01 5.543e-01 2.411e-01 9.751e-01 2.576e-01\n",
      " 4.923e-01 3.001e-01 3.838e-01 5.288e-01 2.483e-01 8.413e-01 7.096e-01\n",
      " 3.433e-01 8.393e-01 4.225e-01 8.808e-02 2.329e-01 2.903e-01 2.475e-01\n",
      " 4.927e-01 3.951e-01 7.618e-01 4.458e-01 6.198e-01 1.680e-01 8.443e-01\n",
      " 3.357e-01 4.909e-01 5.757e-01 3.024e-01 8.722e-01 8.849e-01 4.169e-01\n",
      " 2.058e-01 2.923e-01 9.487e-01 5.638e-01 7.950e-01 2.875e-01 3.866e-01\n",
      " 5.628e-01 9.216e-01 8.130e-01 6.255e-01 9.456e-01 2.771e-01 7.320e-01\n",
      " 8.765e-01 7.237e-01 8.709e-01 3.499e-01 4.004e-01 9.799e-01 2.666e-01\n",
      " 7.096e-01 3.459e-01 3.130e-01 9.164e-01 6.923e-01 8.938e-01 2.844e-01\n",
      " 4.357e-01 5.741e-01 3.859e-01 2.270e-01 4.835e-01 4.642e-01 5.434e-01\n",
      " 7.584e-01 3.079e-01 2.522e-01 8.911e-01 2.762e-01 2.464e-01 6.315e-02\n",
      " 5.017e-02 6.470e-01 8.097e-01 7.005e-02 5.268e-01 7.201e-01 3.803e-01\n",
      " 6.974e-01 2.777e-01 5.220e-01 1.930e-02 4.452e-01 1.620e-01 5.008e-01\n",
      " 1.932e-02 3.469e-01 3.016e-01 4.672e-01 7.063e-01 1.867e-01 1.732e-01\n",
      " 2.376e-01 8.168e-01 3.343e-01 3.405e-01 9.406e-01 5.468e-01 8.017e-01\n",
      " 1.509e-01 8.035e-02 1.536e-01 9.891e-01 4.739e-01 5.106e-01 3.480e-01\n",
      " 7.626e-01 8.566e-01 1.778e-01 3.859e-01 6.828e-01 3.666e-01 8.116e-01\n",
      " 3.796e-01 1.233e-01 9.495e-01 4.657e-01 2.026e-01 6.040e-01 7.917e-01\n",
      " 1.183e-01 6.154e-01 9.220e-02 2.640e-01 8.623e-01 9.672e-01 4.876e-01\n",
      " 7.006e-01 1.564e-01 9.374e-01 5.304e-01 9.220e-01 7.439e-01 7.993e-01\n",
      " 8.120e-01 2.341e-01 4.960e-01 1.786e-01 5.940e-01 4.091e-01 6.420e-02\n",
      " 3.075e-01 6.337e-02 7.558e-01 9.411e-01 8.231e-01 7.516e-01 3.049e-01\n",
      " 9.682e-01 7.117e-01 1.360e-02 5.029e-01 7.308e-01 9.600e-02 3.005e-01\n",
      " 4.490e-01 6.045e-01 8.257e-01 6.599e-01 5.594e-01 8.475e-03 6.249e-01\n",
      " 7.686e-01 2.510e-02 9.380e-01 3.120e-01 9.917e-01 4.828e-01 5.131e-01\n",
      " 1.145e-01 4.415e-01 9.454e-01 1.441e-01 4.728e-01 1.521e-01 2.781e-01\n",
      " 1.254e-01 4.198e-01 7.155e-01 1.572e-01 1.150e-01 3.473e-01 1.121e-01\n",
      " 7.469e-01 8.448e-01 7.005e-01 4.708e-01 7.567e-01 5.827e-01 3.480e-02\n",
      " 8.508e-01 5.063e-01 6.495e-01 6.648e-01 3.149e-01 7.930e-02 8.809e-01\n",
      " 7.408e-02 9.916e-01 3.663e-01 7.205e-01 4.176e-01 5.041e-01 8.196e-01\n",
      " 1.092e-01 1.406e-01 8.747e-01 5.216e-01 8.077e-01 2.817e-01 6.240e-01\n",
      " 8.152e-01 7.933e-01 5.209e-01 8.694e-01 1.317e-01 3.251e-01 7.731e-01\n",
      " 8.527e-01 7.231e-01 3.466e-01 8.972e-01 7.121e-01 4.412e-01 3.510e-01\n",
      " 7.548e-01 9.708e-01 4.534e-01 3.924e-01 5.051e-01 4.913e-01 8.383e-01\n",
      " 8.430e-01 2.270e-01 3.081e-01 5.275e-01 6.316e-01 5.538e-01 7.908e-01\n",
      " 8.376e-01 2.661e-01 8.131e-01 9.911e-01 2.857e-01 7.041e-01 2.137e-01\n",
      " 7.561e-01 7.560e-01 9.045e-01 3.086e-01 9.513e-01 8.020e-01 1.066e-01\n",
      " 3.945e-01 9.843e-01 2.789e-01 8.274e-01 8.906e-01 1.391e-01 7.748e-01\n",
      " 4.220e-02 8.072e-01 2.497e-01 1.819e-01 4.278e-01 9.203e-01 4.069e-01\n",
      " 3.998e-01 9.832e-01 4.109e-01 5.490e-01 2.355e-02 6.454e-01 7.063e-02\n",
      " 4.786e-01 9.650e-01 1.213e-01 1.965e-02 1.805e-02 1.621e-01 3.089e-01\n",
      " 9.533e-01 1.628e-01 7.497e-01 1.176e-01 5.219e-01 6.419e-01 6.851e-01\n",
      " 1.650e-02 1.496e-01 1.918e-01 7.870e-01 5.503e-01 2.080e-02 9.244e-01\n",
      " 1.919e-01 1.585e-01 2.726e-01 9.577e-01 8.705e-01 2.160e-01 8.781e-01\n",
      " 3.142e-01 7.653e-02 7.830e-01 3.517e-01 6.190e-02 6.867e-01 9.890e-02\n",
      " 9.530e-01 7.290e-01 5.128e-01 1.237e-02 1.869e-01 2.454e-01 1.324e-01\n",
      " 4.251e-01 2.633e-01 9.631e-01 9.070e-01 5.754e-01 9.269e-01 4.928e-01\n",
      " 4.988e-01 6.671e-01 5.462e-02 8.020e-01 6.032e-01 3.655e-01 2.218e-01\n",
      " 4.108e-01 6.105e-01 4.874e-01 4.485e-02 1.984e-01 5.809e-01 2.377e-01\n",
      " 2.450e-03 2.078e-01 6.015e-01 5.556e-01 5.225e-01 4.865e-01 6.531e-01\n",
      " 8.008e-01 2.703e-01 5.851e-01 7.967e-01 3.328e-01 5.290e-02 4.553e-01\n",
      " 8.985e-01 9.129e-01 3.817e-01 3.050e-03 3.450e-01 2.087e-01 1.239e-01\n",
      " 3.038e-01 4.553e-01 6.531e-01 1.992e-01 7.621e-01 8.165e-01 4.342e-01\n",
      " 7.055e-01 7.028e-01 1.308e-01 7.679e-01 3.822e-01 6.700e-02 1.460e-01\n",
      " 8.841e-01 1.739e-01 7.750e-04 8.388e-01 6.026e-01 9.038e-01 6.265e-01\n",
      " 9.884e-01 1.656e-01 3.261e-01 3.255e-01 4.571e-01 7.309e-01 1.982e-01\n",
      " 8.491e-01 3.682e-01 6.749e-01 6.371e-01 5.660e-01 4.228e-01 7.303e-01\n",
      " 7.388e-01 3.203e-02 6.512e-01 8.346e-01 2.999e-01 3.951e-01 7.200e-01\n",
      " 6.259e-01 1.472e-01 7.621e-01 9.543e-01 3.090e-01 2.058e-01 7.333e-01\n",
      " 5.091e-01 7.130e-01 3.498e-01 7.667e-01 4.805e-01 7.974e-01 8.049e-01\n",
      " 3.811e-01 4.353e-01 4.690e-01 1.289e-01 1.138e-01 9.797e-01 2.038e-01\n",
      " 9.826e-01 2.977e-01 3.065e-01 7.201e-01 7.902e-02 6.428e-01 1.072e-01\n",
      " 1.532e-01 1.754e-01 3.050e-03 6.357e-01 8.599e-01 9.495e-01 2.776e-01\n",
      " 3.829e-01 6.732e-01 3.616e-01 1.025e-02 7.982e-02 1.483e-01 8.411e-01\n",
      " 6.572e-01 2.089e-01 5.016e-01 5.944e-01 9.051e-01 7.476e-01 5.467e-01\n",
      " 7.524e-01 6.505e-01 8.615e-01 5.150e-03 6.549e-01 1.049e-01 1.671e-01\n",
      " 1.118e-01 3.464e-01 9.044e-01 3.745e-02 8.303e-01 7.634e-01 2.150e-01\n",
      " 8.218e-01 3.158e-01 8.201e-01 6.778e-01 2.155e-01 3.552e-01 7.952e-01\n",
      " 5.973e-01 2.644e-01 9.706e-01 3.739e-01 5.159e-01 6.374e-01 1.777e-01\n",
      " 8.447e-01 4.400e-01 8.013e-01 1.300e-03 7.331e-01 8.524e-01]\n"
     ]
    }
   ],
   "source": [
    "# a vectorized\n",
    "a_expect = np.zeros((num_ep,num_bandit))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_expect = np.zeros(num_bandit)\n",
    "    temp_choice = np.zeros(num_bandit)\n",
    "                    \n",
    "    for iter in range(num_iter//10):\n",
    "        temp_choice    = temp_choice + 1\n",
    "        current_reward = np.random.uniform(0,1,num_bandit) < gt_prob\n",
    "        temp_expect    = temp_expect + current_reward\n",
    "\n",
    "    a_expect[eps,:] = temp_expect/temp_choice\n",
    "                    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(a_expect.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.110Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[9.985e-01 2.468e-01 4.049e-01 5.143e-01 8.784e-01 5.730e-01 1.863e-01\n",
      " 8.173e-01 6.897e-01 2.182e-01 9.070e-01 7.975e-02 3.765e-01 7.575e-01\n",
      " 9.264e-01 7.513e-01 2.293e-01 8.728e-01 4.411e-01 2.945e-01 1.383e-01\n",
      " 2.116e-01 9.970e-02 7.656e-01 6.761e-01 8.933e-01 8.492e-01 5.543e-01\n",
      " 1.555e-02 9.807e-01 4.410e-01 2.954e-01 3.047e-01 2.378e-01 4.053e-02\n",
      " 1.928e-01 5.942e-01 9.718e-01 1.122e-01 4.146e-01 9.596e-02 4.615e-01\n",
      " 4.102e-01 7.851e-01 6.594e-01 6.430e-01 8.628e-01 7.358e-01 3.753e-01\n",
      " 1.499e-02 9.167e-01 6.266e-01 5.835e-01 9.620e-01 3.563e-01 3.146e-01\n",
      " 2.974e-01 2.733e-01 2.759e-01 8.777e-02 1.640e-01 9.339e-01 7.837e-01\n",
      " 9.007e-01 8.759e-01 7.108e-01 6.899e-01 3.939e-01 7.935e-02 9.195e-01\n",
      " 7.454e-01 2.285e-01 8.999e-02 6.199e-01 8.322e-01 5.734e-01 2.972e-01\n",
      " 7.810e-01 9.592e-01 4.716e-01 7.766e-01 1.580e-01 5.323e-01 8.413e-02\n",
      " 6.862e-01 5.251e-01 7.035e-01 6.266e-02 1.740e-01 2.738e-01 7.370e-01\n",
      " 5.180e-01 9.440e-01 5.869e-01 5.683e-01 6.736e-01 6.040e-01 1.795e-01\n",
      " 6.692e-01 3.784e-01 5.799e-01 7.999e-01 7.164e-01 2.043e-01 5.965e-01\n",
      " 1.802e-01 5.404e-01 2.257e-01 8.393e-01 5.928e-02 7.697e-01 6.783e-01\n",
      " 2.417e-01 2.014e-02 2.213e-01 1.646e-01 9.784e-01 1.116e-01 7.692e-01\n",
      " 7.533e-02 6.196e-01 8.608e-01 6.582e-01 1.045e-01 3.834e-01 8.187e-01\n",
      " 9.441e-01 9.435e-01 1.540e-01 4.089e-01 1.342e-01 1.329e-01 2.474e-01\n",
      " 5.057e-01 8.841e-01 1.209e-01 4.777e-01 3.655e-02 2.866e-01 4.459e-01\n",
      " 3.274e-01 4.929e-01 3.193e-01 4.067e-01 3.596e-01 5.537e-01 5.443e-01\n",
      " 1.242e-02 5.984e-01 3.763e-01 2.472e-01 4.210e-01 9.832e-01 3.582e-01\n",
      " 9.756e-02 5.188e-01 8.472e-01 9.345e-01 8.728e-01 4.500e-01 4.960e-01\n",
      " 4.090e-01 2.779e-01 1.693e-02 2.318e-02 7.475e-01 1.590e-01 3.732e-02\n",
      " 7.451e-01 5.752e-01 6.708e-01 4.110e-01 1.026e-01 8.470e-02 1.025e-01\n",
      " 2.925e-01 2.006e-01 3.468e-01 3.440e-01 8.419e-01 5.450e-01 3.445e-01\n",
      " 4.356e-01 6.018e-01 6.582e-01 4.777e-01 5.090e-01 1.750e-01 7.049e-01\n",
      " 8.597e-01 9.862e-01 6.258e-02 8.467e-01 3.545e-01 6.479e-01 9.001e-01\n",
      " 6.736e-01 7.068e-01 3.297e-01 3.453e-01 7.810e-01 4.954e-01 9.578e-01\n",
      " 8.519e-01 8.053e-01 5.102e-01 1.190e-01 4.680e-01 8.261e-01 4.550e-01\n",
      " 5.082e-01 1.237e-02 7.898e-01 7.013e-01 9.319e-01 3.271e-01 8.428e-01\n",
      " 1.050e-01 8.215e-01 7.193e-01 3.678e-02 5.714e-01 9.837e-02 8.292e-01\n",
      " 1.140e-01 6.313e-01 8.248e-01 4.939e-01 9.204e-01 6.269e-01 8.511e-01\n",
      " 9.356e-01 3.757e-01 4.588e-01 3.054e-01 3.362e-01 6.466e-02 3.288e-02\n",
      " 8.716e-01 8.349e-01 4.532e-01 5.377e-01 9.514e-01 1.125e-01 5.076e-01\n",
      " 8.385e-01 6.571e-01 7.602e-01 7.426e-02 9.782e-01 2.407e-01 8.767e-01\n",
      " 3.916e-01 6.784e-01 5.506e-01 6.467e-01 1.555e-01 6.212e-01 3.338e-01\n",
      " 9.300e-01 5.977e-01 5.471e-01 7.017e-01 6.053e-01 1.741e-01 5.788e-01\n",
      " 2.797e-01 2.463e-01 4.882e-01 6.094e-01 6.771e-01 4.706e-01 9.722e-01\n",
      " 2.112e-01 4.699e-01 7.070e-01 4.071e-01 2.881e-01 7.060e-02 7.499e-01\n",
      " 1.560e-01 5.742e-01 7.218e-01 5.040e-01 7.832e-01 6.777e-01 6.963e-02\n",
      " 8.576e-01 3.801e-01 1.769e-01 5.900e-01 3.751e-01 8.342e-01 9.165e-02\n",
      " 6.948e-01 9.195e-01 6.810e-01 9.232e-01 9.121e-01 2.056e-01 2.974e-01\n",
      " 9.441e-01 6.130e-01 3.131e-01 6.014e-02 1.553e-01 9.601e-01 1.399e-01\n",
      " 9.641e-01 6.817e-01 6.543e-01 4.337e-01 6.990e-01 7.850e-01 5.505e-01\n",
      " 3.664e-01 7.645e-01 5.506e-01 2.211e-01 8.864e-02 6.537e-01 8.539e-01\n",
      " 9.674e-01 2.913e-01 2.149e-01 4.485e-02 5.380e-02 2.822e-01 2.011e-01\n",
      " 2.144e-01 5.371e-01 4.189e-01 7.701e-01 1.600e-01 5.994e-01 6.426e-01\n",
      " 3.208e-01 6.352e-01 7.675e-01 5.132e-01 5.744e-01 3.626e-02 6.616e-01\n",
      " 4.799e-01 7.827e-01 5.688e-01 8.952e-01 7.038e-01 4.372e-01 7.000e-03\n",
      " 7.275e-01 1.301e-02 2.442e-01 7.818e-01 6.423e-01 1.849e-01 1.029e-02\n",
      " 6.720e-01 1.894e-01 1.569e-01 7.577e-01 8.580e-01 1.997e-01 6.353e-01\n",
      " 6.086e-01 7.896e-02 6.784e-01 1.784e-01 9.952e-01 5.475e-01 7.798e-01\n",
      " 3.475e-01 6.226e-01 8.544e-01 1.460e-03 5.001e-01 3.718e-01 5.807e-01\n",
      " 9.152e-01 6.399e-01 2.179e-01 6.915e-01 1.929e-01 2.353e-01 2.110e-01\n",
      " 8.310e-01 2.139e-01 6.696e-02 2.600e-01 8.580e-01 2.495e-01 8.198e-01\n",
      " 8.342e-01 9.967e-01 2.632e-01 1.045e-01 1.655e-02 3.808e-01 3.311e-01\n",
      " 6.751e-01 6.021e-02 8.914e-01 7.447e-01 3.205e-01 7.287e-01 7.737e-01\n",
      " 3.099e-01 8.285e-01 9.760e-01 6.789e-01 7.289e-01 3.269e-01 8.277e-01\n",
      " 6.216e-01 5.183e-02 9.118e-01 9.298e-01 8.160e-01 1.323e-02 2.126e-01\n",
      " 1.274e-01 6.271e-01 5.204e-01 4.078e-01 3.579e-01 8.408e-01 9.339e-02\n",
      " 2.104e-01 1.484e-01 4.864e-01 2.373e-01 1.216e-01 6.979e-01 2.325e-01\n",
      " 3.531e-01 9.599e-01 6.657e-01 5.796e-01 6.655e-02 9.023e-01 3.342e-02\n",
      " 6.137e-01 8.695e-01 1.593e-01 8.088e-01 3.779e-01 3.781e-01 9.137e-01\n",
      " 7.145e-01 6.452e-01 2.884e-01 2.499e-01 9.588e-02 3.120e-01 5.792e-01\n",
      " 1.798e-01 6.113e-01 2.859e-01 9.343e-01 3.387e-01 5.798e-01 9.912e-01\n",
      " 2.213e-01 8.908e-02 1.937e-01 9.158e-01 6.473e-01 3.717e-01 1.731e-01\n",
      " 2.613e-01 3.394e-01 9.832e-01 1.065e-01 8.790e-01 1.126e-01 3.665e-02\n",
      " 6.719e-01 9.349e-01 7.927e-01 4.120e-01 2.150e-01 7.253e-01 6.126e-01\n",
      " 7.671e-01 3.984e-01 9.749e-02 5.872e-01 7.930e-02 2.015e-01 9.855e-01\n",
      " 1.222e-01 3.605e-01 8.518e-01 4.726e-02 2.788e-01 5.226e-01 2.699e-01\n",
      " 5.575e-01 2.942e-01 8.617e-01 9.510e-01 6.238e-01 6.460e-01 6.290e-02\n",
      " 1.166e-01 3.779e-01 9.457e-01 8.820e-01 8.025e-01 8.444e-01 7.673e-01\n",
      " 2.890e-01 9.168e-01 2.888e-01 5.535e-01 2.407e-01 9.745e-01 2.549e-01\n",
      " 4.930e-01 3.003e-01 3.812e-01 5.267e-01 2.516e-01 8.392e-01 7.095e-01\n",
      " 3.405e-01 8.377e-01 4.183e-01 9.013e-02 2.353e-01 2.908e-01 2.508e-01\n",
      " 4.931e-01 3.961e-01 7.626e-01 4.474e-01 6.208e-01 1.702e-01 8.447e-01\n",
      " 3.393e-01 4.848e-01 5.762e-01 3.012e-01 8.701e-01 8.852e-01 4.169e-01\n",
      " 2.058e-01 2.953e-01 9.488e-01 5.608e-01 7.966e-01 2.907e-01 3.865e-01\n",
      " 5.624e-01 9.212e-01 8.133e-01 6.274e-01 9.445e-01 2.751e-01 7.360e-01\n",
      " 8.742e-01 7.233e-01 8.710e-01 3.491e-01 3.966e-01 9.800e-01 2.672e-01\n",
      " 7.075e-01 3.490e-01 3.101e-01 9.184e-01 6.895e-01 8.948e-01 2.878e-01\n",
      " 4.404e-01 5.733e-01 3.854e-01 2.306e-01 4.859e-01 4.621e-01 5.409e-01\n",
      " 7.569e-01 3.085e-01 2.542e-01 8.930e-01 2.739e-01 2.475e-01 6.474e-02\n",
      " 4.973e-02 6.462e-01 8.104e-01 6.978e-02 5.296e-01 7.204e-01 3.796e-01\n",
      " 6.973e-01 2.754e-01 5.212e-01 1.959e-02 4.449e-01 1.627e-01 5.012e-01\n",
      " 2.052e-02 3.470e-01 3.018e-01 4.657e-01 7.055e-01 1.879e-01 1.784e-01\n",
      " 2.357e-01 8.203e-01 3.340e-01 3.389e-01 9.425e-01 5.434e-01 8.021e-01\n",
      " 1.525e-01 8.248e-02 1.531e-01 9.903e-01 4.737e-01 5.046e-01 3.516e-01\n",
      " 7.574e-01 8.574e-01 1.738e-01 3.889e-01 6.809e-01 3.687e-01 8.125e-01\n",
      " 3.760e-01 1.244e-01 9.498e-01 4.648e-01 1.986e-01 6.045e-01 7.926e-01\n",
      " 1.197e-01 6.152e-01 9.267e-02 2.616e-01 8.631e-01 9.663e-01 4.911e-01\n",
      " 7.015e-01 1.554e-01 9.391e-01 5.312e-01 9.230e-01 7.418e-01 8.000e-01\n",
      " 8.141e-01 2.338e-01 4.992e-01 1.740e-01 5.907e-01 4.115e-01 6.508e-02\n",
      " 3.046e-01 6.194e-02 7.589e-01 9.418e-01 8.243e-01 7.539e-01 3.022e-01\n",
      " 9.693e-01 7.129e-01 1.326e-02 5.039e-01 7.290e-01 9.711e-02 3.012e-01\n",
      " 4.520e-01 6.074e-01 8.244e-01 6.599e-01 5.567e-01 8.439e-03 6.260e-01\n",
      " 7.690e-01 2.456e-02 9.373e-01 3.111e-01 9.920e-01 4.871e-01 5.120e-01\n",
      " 1.151e-01 4.361e-01 9.455e-01 1.433e-01 4.698e-01 1.531e-01 2.769e-01\n",
      " 1.251e-01 4.199e-01 7.167e-01 1.558e-01 1.141e-01 3.456e-01 1.110e-01\n",
      " 7.464e-01 8.418e-01 6.999e-01 4.664e-01 7.568e-01 5.838e-01 3.591e-02\n",
      " 8.513e-01 5.107e-01 6.468e-01 6.665e-01 3.146e-01 7.972e-02 8.816e-01\n",
      " 7.423e-02 9.917e-01 3.664e-01 7.207e-01 4.169e-01 5.070e-01 8.221e-01\n",
      " 1.107e-01 1.391e-01 8.717e-01 5.178e-01 8.075e-01 2.812e-01 6.217e-01\n",
      " 8.164e-01 7.943e-01 5.222e-01 8.666e-01 1.317e-01 3.251e-01 7.776e-01\n",
      " 8.506e-01 7.199e-01 3.477e-01 8.984e-01 7.143e-01 4.433e-01 3.544e-01\n",
      " 7.527e-01 9.710e-01 4.509e-01 3.925e-01 5.077e-01 4.936e-01 8.412e-01\n",
      " 8.444e-01 2.288e-01 3.060e-01 5.307e-01 6.282e-01 5.505e-01 7.904e-01\n",
      " 8.371e-01 2.657e-01 8.138e-01 9.905e-01 2.895e-01 7.073e-01 2.142e-01\n",
      " 7.558e-01 7.567e-01 9.030e-01 3.065e-01 9.503e-01 8.015e-01 1.063e-01\n",
      " 3.926e-01 9.851e-01 2.823e-01 8.271e-01 8.929e-01 1.406e-01 7.762e-01\n",
      " 4.305e-02 8.106e-01 2.527e-01 1.867e-01 4.300e-01 9.199e-01 4.044e-01\n",
      " 4.012e-01 9.832e-01 4.138e-01 5.494e-01 2.312e-02 6.444e-01 6.904e-02\n",
      " 4.786e-01 9.655e-01 1.226e-01 2.018e-02 1.781e-02 1.657e-01 3.089e-01\n",
      " 9.541e-01 1.637e-01 7.522e-01 1.184e-01 5.191e-01 6.416e-01 6.813e-01\n",
      " 1.676e-02 1.495e-01 1.924e-01 7.898e-01 5.516e-01 2.066e-02 9.228e-01\n",
      " 1.907e-01 1.626e-01 2.728e-01 9.585e-01 8.724e-01 2.157e-01 8.748e-01\n",
      " 3.127e-01 7.666e-02 7.835e-01 3.515e-01 6.095e-02 6.860e-01 9.731e-02\n",
      " 9.529e-01 7.317e-01 5.135e-01 1.188e-02 1.856e-01 2.447e-01 1.324e-01\n",
      " 4.273e-01 2.646e-01 9.612e-01 9.042e-01 5.728e-01 9.295e-01 4.947e-01\n",
      " 4.965e-01 6.654e-01 5.485e-02 8.002e-01 6.046e-01 3.671e-01 2.203e-01\n",
      " 4.118e-01 6.095e-01 4.893e-01 4.410e-02 2.011e-01 5.797e-01 2.377e-01\n",
      " 2.705e-03 2.056e-01 6.026e-01 5.530e-01 5.206e-01 4.861e-01 6.552e-01\n",
      " 8.015e-01 2.718e-01 5.832e-01 7.984e-01 3.339e-01 5.146e-02 4.575e-01\n",
      " 8.970e-01 9.124e-01 3.843e-01 3.383e-03 3.448e-01 2.064e-01 1.251e-01\n",
      " 3.016e-01 4.556e-01 6.542e-01 1.990e-01 7.626e-01 8.168e-01 4.313e-01\n",
      " 7.061e-01 6.993e-01 1.300e-01 7.698e-01 3.785e-01 6.814e-02 1.483e-01\n",
      " 8.854e-01 1.727e-01 7.951e-04 8.353e-01 6.004e-01 9.063e-01 6.223e-01\n",
      " 9.875e-01 1.665e-01 3.264e-01 3.238e-01 4.564e-01 7.328e-01 1.923e-01\n",
      " 8.472e-01 3.691e-01 6.759e-01 6.346e-01 5.645e-01 4.224e-01 7.307e-01\n",
      " 7.347e-01 3.138e-02 6.504e-01 8.351e-01 3.016e-01 3.975e-01 7.226e-01\n",
      " 6.267e-01 1.486e-01 7.610e-01 9.541e-01 3.067e-01 2.048e-01 7.338e-01\n",
      " 5.093e-01 7.096e-01 3.507e-01 7.638e-01 4.779e-01 7.940e-01 8.054e-01\n",
      " 3.795e-01 4.364e-01 4.693e-01 1.272e-01 1.123e-01 9.812e-01 2.056e-01\n",
      " 9.819e-01 2.977e-01 3.056e-01 7.162e-01 7.786e-02 6.447e-01 1.090e-01\n",
      " 1.527e-01 1.741e-01 3.096e-03 6.373e-01 8.590e-01 9.510e-01 2.743e-01\n",
      " 3.852e-01 6.675e-01 3.623e-01 9.716e-03 8.090e-02 1.490e-01 8.416e-01\n",
      " 6.593e-01 2.101e-01 5.014e-01 5.913e-01 9.052e-01 7.493e-01 5.459e-01\n",
      " 7.501e-01 6.508e-01 8.608e-01 5.365e-03 6.583e-01 1.032e-01 1.656e-01\n",
      " 1.113e-01 3.456e-01 9.045e-01 3.633e-02 8.274e-01 7.621e-01 2.158e-01\n",
      " 8.215e-01 3.190e-01 8.206e-01 6.776e-01 2.170e-01 3.530e-01 7.934e-01\n",
      " 6.000e-01 2.685e-01 9.690e-01 3.725e-01 5.176e-01 6.378e-01 1.791e-01\n",
      " 8.455e-01 4.405e-01 8.012e-01 1.178e-03 7.326e-01 8.546e-01]\n",
      "Expected \n",
      "[0.998 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "# b greedy\n",
    "b_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "b_estimation   = np.zeros((num_ep,num_bandit))\n",
    "b_reward       = np.zeros((num_ep,num_iter))\n",
    "b_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "b_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    b_pull_count[eps,:]   = temp_pull_count\n",
    "    b_estimation[eps,:]   = temp_estimation\n",
    "    b_reward[eps,:]       = temp_reward\n",
    "    b_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    b_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(b_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.299Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[9.985e-01 2.468e-01 4.049e-01 5.143e-01 8.784e-01 5.730e-01 1.863e-01\n",
      " 8.173e-01 6.897e-01 2.182e-01 9.070e-01 7.975e-02 3.765e-01 7.575e-01\n",
      " 9.264e-01 7.513e-01 2.293e-01 8.728e-01 4.411e-01 2.945e-01 1.383e-01\n",
      " 2.116e-01 9.970e-02 7.656e-01 6.761e-01 8.933e-01 8.492e-01 5.543e-01\n",
      " 1.555e-02 9.807e-01 4.410e-01 2.954e-01 3.047e-01 2.378e-01 4.053e-02\n",
      " 1.928e-01 5.942e-01 9.718e-01 1.122e-01 4.146e-01 9.596e-02 4.615e-01\n",
      " 4.102e-01 7.851e-01 6.594e-01 6.430e-01 8.628e-01 7.358e-01 3.753e-01\n",
      " 1.499e-02 9.167e-01 6.266e-01 5.835e-01 9.620e-01 3.563e-01 3.146e-01\n",
      " 2.974e-01 2.733e-01 2.759e-01 8.777e-02 1.640e-01 9.339e-01 7.837e-01\n",
      " 9.007e-01 8.759e-01 7.108e-01 6.899e-01 3.939e-01 7.935e-02 9.195e-01\n",
      " 7.454e-01 2.285e-01 8.999e-02 6.199e-01 8.322e-01 5.734e-01 2.972e-01\n",
      " 7.810e-01 9.592e-01 4.716e-01 7.766e-01 1.580e-01 5.323e-01 8.413e-02\n",
      " 6.862e-01 5.251e-01 7.035e-01 6.266e-02 1.740e-01 2.738e-01 7.370e-01\n",
      " 5.180e-01 9.440e-01 5.869e-01 5.683e-01 6.736e-01 6.040e-01 1.795e-01\n",
      " 6.692e-01 3.784e-01 5.799e-01 7.999e-01 7.164e-01 2.043e-01 5.965e-01\n",
      " 1.802e-01 5.404e-01 2.257e-01 8.393e-01 5.928e-02 7.697e-01 6.783e-01\n",
      " 2.417e-01 2.014e-02 2.213e-01 1.646e-01 9.784e-01 1.116e-01 7.692e-01\n",
      " 7.533e-02 6.196e-01 8.608e-01 6.582e-01 1.045e-01 3.834e-01 8.187e-01\n",
      " 9.441e-01 9.435e-01 1.540e-01 4.089e-01 1.342e-01 1.329e-01 2.474e-01\n",
      " 5.057e-01 8.841e-01 1.209e-01 4.777e-01 3.655e-02 2.866e-01 4.459e-01\n",
      " 3.274e-01 4.929e-01 3.193e-01 4.067e-01 3.596e-01 5.537e-01 5.443e-01\n",
      " 1.242e-02 5.984e-01 3.763e-01 2.472e-01 4.210e-01 9.832e-01 3.582e-01\n",
      " 9.756e-02 5.188e-01 8.472e-01 9.345e-01 8.728e-01 4.500e-01 4.960e-01\n",
      " 4.090e-01 2.779e-01 1.693e-02 2.318e-02 7.475e-01 1.590e-01 3.732e-02\n",
      " 7.451e-01 5.752e-01 6.708e-01 4.110e-01 1.026e-01 8.470e-02 1.025e-01\n",
      " 2.925e-01 2.006e-01 3.468e-01 3.440e-01 8.419e-01 5.450e-01 3.445e-01\n",
      " 4.356e-01 6.018e-01 6.582e-01 4.777e-01 5.090e-01 1.750e-01 7.049e-01\n",
      " 8.597e-01 9.862e-01 6.258e-02 8.467e-01 3.545e-01 6.479e-01 9.001e-01\n",
      " 6.736e-01 7.068e-01 3.297e-01 3.453e-01 7.810e-01 4.954e-01 9.578e-01\n",
      " 8.519e-01 8.053e-01 5.102e-01 1.190e-01 4.680e-01 8.261e-01 4.550e-01\n",
      " 5.082e-01 1.237e-02 7.898e-01 7.013e-01 9.319e-01 3.271e-01 8.428e-01\n",
      " 1.050e-01 8.215e-01 7.193e-01 3.678e-02 5.714e-01 9.837e-02 8.292e-01\n",
      " 1.140e-01 6.313e-01 8.248e-01 4.939e-01 9.204e-01 6.269e-01 8.511e-01\n",
      " 9.356e-01 3.757e-01 4.588e-01 3.054e-01 3.362e-01 6.466e-02 3.288e-02\n",
      " 8.716e-01 8.349e-01 4.532e-01 5.377e-01 9.514e-01 1.125e-01 5.076e-01\n",
      " 8.385e-01 6.571e-01 7.602e-01 7.426e-02 9.782e-01 2.407e-01 8.767e-01\n",
      " 3.916e-01 6.784e-01 5.506e-01 6.467e-01 1.555e-01 6.212e-01 3.338e-01\n",
      " 9.300e-01 5.977e-01 5.471e-01 7.017e-01 6.053e-01 1.741e-01 5.788e-01\n",
      " 2.797e-01 2.463e-01 4.882e-01 6.094e-01 6.771e-01 4.706e-01 9.722e-01\n",
      " 2.112e-01 4.699e-01 7.070e-01 4.071e-01 2.881e-01 7.060e-02 7.499e-01\n",
      " 1.560e-01 5.742e-01 7.218e-01 5.040e-01 7.832e-01 6.777e-01 6.963e-02\n",
      " 8.576e-01 3.801e-01 1.769e-01 5.900e-01 3.751e-01 8.342e-01 9.165e-02\n",
      " 6.948e-01 9.195e-01 6.810e-01 9.232e-01 9.121e-01 2.056e-01 2.974e-01\n",
      " 9.441e-01 6.130e-01 3.131e-01 6.014e-02 1.553e-01 9.601e-01 1.399e-01\n",
      " 9.641e-01 6.817e-01 6.543e-01 4.337e-01 6.990e-01 7.850e-01 5.505e-01\n",
      " 3.664e-01 7.645e-01 5.506e-01 2.211e-01 8.864e-02 6.537e-01 8.539e-01\n",
      " 9.674e-01 2.913e-01 2.149e-01 4.485e-02 5.380e-02 2.822e-01 2.011e-01\n",
      " 2.144e-01 5.371e-01 4.189e-01 7.701e-01 1.600e-01 5.994e-01 6.426e-01\n",
      " 3.208e-01 6.352e-01 7.675e-01 5.132e-01 5.744e-01 3.626e-02 6.616e-01\n",
      " 4.799e-01 7.827e-01 5.688e-01 8.952e-01 7.038e-01 4.372e-01 7.000e-03\n",
      " 7.275e-01 1.301e-02 2.442e-01 7.818e-01 6.423e-01 1.849e-01 1.029e-02\n",
      " 6.720e-01 1.894e-01 1.569e-01 7.577e-01 8.580e-01 1.997e-01 6.353e-01\n",
      " 6.086e-01 7.896e-02 6.784e-01 1.784e-01 9.952e-01 5.475e-01 7.798e-01\n",
      " 3.475e-01 6.226e-01 8.544e-01 1.460e-03 5.001e-01 3.718e-01 5.807e-01\n",
      " 9.152e-01 6.399e-01 2.179e-01 6.915e-01 1.929e-01 2.353e-01 2.110e-01\n",
      " 8.310e-01 2.139e-01 6.696e-02 2.600e-01 8.580e-01 2.495e-01 8.198e-01\n",
      " 8.342e-01 9.967e-01 2.632e-01 1.045e-01 1.655e-02 3.808e-01 3.311e-01\n",
      " 6.751e-01 6.021e-02 8.914e-01 7.447e-01 3.205e-01 7.287e-01 7.737e-01\n",
      " 3.099e-01 8.285e-01 9.760e-01 6.789e-01 7.289e-01 3.269e-01 8.277e-01\n",
      " 6.216e-01 5.183e-02 9.118e-01 9.298e-01 8.160e-01 1.323e-02 2.126e-01\n",
      " 1.274e-01 6.271e-01 5.204e-01 4.078e-01 3.579e-01 8.408e-01 9.339e-02\n",
      " 2.104e-01 1.484e-01 4.864e-01 2.373e-01 1.216e-01 6.979e-01 2.325e-01\n",
      " 3.531e-01 9.599e-01 6.657e-01 5.796e-01 6.655e-02 9.023e-01 3.342e-02\n",
      " 6.137e-01 8.695e-01 1.593e-01 8.088e-01 3.779e-01 3.781e-01 9.137e-01\n",
      " 7.145e-01 6.452e-01 2.884e-01 2.499e-01 9.588e-02 3.120e-01 5.792e-01\n",
      " 1.798e-01 6.113e-01 2.859e-01 9.343e-01 3.387e-01 5.798e-01 9.912e-01\n",
      " 2.213e-01 8.908e-02 1.937e-01 9.158e-01 6.473e-01 3.717e-01 1.731e-01\n",
      " 2.613e-01 3.394e-01 9.832e-01 1.065e-01 8.790e-01 1.126e-01 3.665e-02\n",
      " 6.719e-01 9.349e-01 7.927e-01 4.120e-01 2.150e-01 7.253e-01 6.126e-01\n",
      " 7.671e-01 3.984e-01 9.749e-02 5.872e-01 7.930e-02 2.015e-01 9.855e-01\n",
      " 1.222e-01 3.605e-01 8.518e-01 4.726e-02 2.788e-01 5.226e-01 2.699e-01\n",
      " 5.575e-01 2.942e-01 8.617e-01 9.510e-01 6.238e-01 6.460e-01 6.290e-02\n",
      " 1.166e-01 3.779e-01 9.457e-01 8.820e-01 8.025e-01 8.444e-01 7.673e-01\n",
      " 2.890e-01 9.168e-01 2.888e-01 5.535e-01 2.407e-01 9.745e-01 2.549e-01\n",
      " 4.930e-01 3.003e-01 3.812e-01 5.267e-01 2.516e-01 8.392e-01 7.095e-01\n",
      " 3.405e-01 8.377e-01 4.183e-01 9.013e-02 2.353e-01 2.908e-01 2.508e-01\n",
      " 4.931e-01 3.961e-01 7.626e-01 4.474e-01 6.208e-01 1.702e-01 8.447e-01\n",
      " 3.393e-01 4.848e-01 5.762e-01 3.012e-01 8.701e-01 8.852e-01 4.169e-01\n",
      " 2.058e-01 2.953e-01 9.488e-01 5.608e-01 7.966e-01 2.907e-01 3.865e-01\n",
      " 5.624e-01 9.212e-01 8.133e-01 6.274e-01 9.445e-01 2.751e-01 7.360e-01\n",
      " 8.742e-01 7.233e-01 8.710e-01 3.491e-01 3.966e-01 9.800e-01 2.672e-01\n",
      " 7.075e-01 3.490e-01 3.101e-01 9.184e-01 6.895e-01 8.948e-01 2.878e-01\n",
      " 4.404e-01 5.733e-01 3.854e-01 2.306e-01 4.859e-01 4.621e-01 5.409e-01\n",
      " 7.569e-01 3.085e-01 2.542e-01 8.930e-01 2.739e-01 2.475e-01 6.474e-02\n",
      " 4.973e-02 6.462e-01 8.104e-01 6.978e-02 5.296e-01 7.204e-01 3.796e-01\n",
      " 6.973e-01 2.754e-01 5.212e-01 1.959e-02 4.449e-01 1.627e-01 5.012e-01\n",
      " 2.052e-02 3.470e-01 3.018e-01 4.657e-01 7.055e-01 1.879e-01 1.784e-01\n",
      " 2.357e-01 8.203e-01 3.340e-01 3.389e-01 9.425e-01 5.434e-01 8.021e-01\n",
      " 1.525e-01 8.248e-02 1.531e-01 9.903e-01 4.737e-01 5.046e-01 3.516e-01\n",
      " 7.574e-01 8.574e-01 1.738e-01 3.889e-01 6.809e-01 3.687e-01 8.125e-01\n",
      " 3.760e-01 1.244e-01 9.498e-01 4.648e-01 1.986e-01 6.045e-01 7.926e-01\n",
      " 1.197e-01 6.152e-01 9.267e-02 2.616e-01 8.631e-01 9.663e-01 4.911e-01\n",
      " 7.015e-01 1.554e-01 9.391e-01 5.312e-01 9.230e-01 7.418e-01 8.000e-01\n",
      " 8.141e-01 2.338e-01 4.992e-01 1.740e-01 5.907e-01 4.115e-01 6.508e-02\n",
      " 3.046e-01 6.194e-02 7.589e-01 9.418e-01 8.243e-01 7.539e-01 3.022e-01\n",
      " 9.693e-01 7.129e-01 1.326e-02 5.039e-01 7.290e-01 9.711e-02 3.012e-01\n",
      " 4.520e-01 6.074e-01 8.244e-01 6.599e-01 5.567e-01 8.439e-03 6.260e-01\n",
      " 7.690e-01 2.456e-02 9.373e-01 3.111e-01 9.920e-01 4.871e-01 5.120e-01\n",
      " 1.151e-01 4.361e-01 9.455e-01 1.433e-01 4.698e-01 1.531e-01 2.769e-01\n",
      " 1.251e-01 4.199e-01 7.167e-01 1.558e-01 1.141e-01 3.456e-01 1.110e-01\n",
      " 7.464e-01 8.418e-01 6.999e-01 4.664e-01 7.568e-01 5.838e-01 3.591e-02\n",
      " 8.513e-01 5.107e-01 6.468e-01 6.665e-01 3.146e-01 7.972e-02 8.816e-01\n",
      " 7.423e-02 9.917e-01 3.664e-01 7.207e-01 4.169e-01 5.070e-01 8.221e-01\n",
      " 1.107e-01 1.391e-01 8.717e-01 5.178e-01 8.075e-01 2.812e-01 6.217e-01\n",
      " 8.164e-01 7.943e-01 5.222e-01 8.666e-01 1.317e-01 3.251e-01 7.776e-01\n",
      " 8.506e-01 7.199e-01 3.477e-01 8.984e-01 7.143e-01 4.433e-01 3.544e-01\n",
      " 7.527e-01 9.710e-01 4.509e-01 3.925e-01 5.077e-01 4.936e-01 8.412e-01\n",
      " 8.444e-01 2.288e-01 3.060e-01 5.307e-01 6.282e-01 5.505e-01 7.904e-01\n",
      " 8.371e-01 2.657e-01 8.138e-01 9.905e-01 2.895e-01 7.073e-01 2.142e-01\n",
      " 7.558e-01 7.567e-01 9.030e-01 3.065e-01 9.503e-01 8.015e-01 1.063e-01\n",
      " 3.926e-01 9.851e-01 2.823e-01 8.271e-01 8.929e-01 1.406e-01 7.762e-01\n",
      " 4.305e-02 8.106e-01 2.527e-01 1.867e-01 4.300e-01 9.199e-01 4.044e-01\n",
      " 4.012e-01 9.832e-01 4.138e-01 5.494e-01 2.312e-02 6.444e-01 6.904e-02\n",
      " 4.786e-01 9.655e-01 1.226e-01 2.018e-02 1.781e-02 1.657e-01 3.089e-01\n",
      " 9.541e-01 1.637e-01 7.522e-01 1.184e-01 5.191e-01 6.416e-01 6.813e-01\n",
      " 1.676e-02 1.495e-01 1.924e-01 7.898e-01 5.516e-01 2.066e-02 9.228e-01\n",
      " 1.907e-01 1.626e-01 2.728e-01 9.585e-01 8.724e-01 2.157e-01 8.748e-01\n",
      " 3.127e-01 7.666e-02 7.835e-01 3.515e-01 6.095e-02 6.860e-01 9.731e-02\n",
      " 9.529e-01 7.317e-01 5.135e-01 1.188e-02 1.856e-01 2.447e-01 1.324e-01\n",
      " 4.273e-01 2.646e-01 9.612e-01 9.042e-01 5.728e-01 9.295e-01 4.947e-01\n",
      " 4.965e-01 6.654e-01 5.485e-02 8.002e-01 6.046e-01 3.671e-01 2.203e-01\n",
      " 4.118e-01 6.095e-01 4.893e-01 4.410e-02 2.011e-01 5.797e-01 2.377e-01\n",
      " 2.705e-03 2.056e-01 6.026e-01 5.530e-01 5.206e-01 4.861e-01 6.552e-01\n",
      " 8.015e-01 2.718e-01 5.832e-01 7.984e-01 3.339e-01 5.146e-02 4.575e-01\n",
      " 8.970e-01 9.124e-01 3.843e-01 3.383e-03 3.448e-01 2.064e-01 1.251e-01\n",
      " 3.016e-01 4.556e-01 6.542e-01 1.990e-01 7.626e-01 8.168e-01 4.313e-01\n",
      " 7.061e-01 6.993e-01 1.300e-01 7.698e-01 3.785e-01 6.814e-02 1.483e-01\n",
      " 8.854e-01 1.727e-01 7.951e-04 8.353e-01 6.004e-01 9.063e-01 6.223e-01\n",
      " 9.875e-01 1.665e-01 3.264e-01 3.238e-01 4.564e-01 7.328e-01 1.923e-01\n",
      " 8.472e-01 3.691e-01 6.759e-01 6.346e-01 5.645e-01 4.224e-01 7.307e-01\n",
      " 7.347e-01 3.138e-02 6.504e-01 8.351e-01 3.016e-01 3.975e-01 7.226e-01\n",
      " 6.267e-01 1.486e-01 7.610e-01 9.541e-01 3.067e-01 2.048e-01 7.338e-01\n",
      " 5.093e-01 7.096e-01 3.507e-01 7.638e-01 4.779e-01 7.940e-01 8.054e-01\n",
      " 3.795e-01 4.364e-01 4.693e-01 1.272e-01 1.123e-01 9.812e-01 2.056e-01\n",
      " 9.819e-01 2.977e-01 3.056e-01 7.162e-01 7.786e-02 6.447e-01 1.090e-01\n",
      " 1.527e-01 1.741e-01 3.096e-03 6.373e-01 8.590e-01 9.510e-01 2.743e-01\n",
      " 3.852e-01 6.675e-01 3.623e-01 9.716e-03 8.090e-02 1.490e-01 8.416e-01\n",
      " 6.593e-01 2.101e-01 5.014e-01 5.913e-01 9.052e-01 7.493e-01 5.459e-01\n",
      " 7.501e-01 6.508e-01 8.608e-01 5.365e-03 6.583e-01 1.032e-01 1.656e-01\n",
      " 1.113e-01 3.456e-01 9.045e-01 3.633e-02 8.274e-01 7.621e-01 2.158e-01\n",
      " 8.215e-01 3.190e-01 8.206e-01 6.776e-01 2.170e-01 3.530e-01 7.934e-01\n",
      " 6.000e-01 2.685e-01 9.690e-01 3.725e-01 5.176e-01 6.378e-01 1.791e-01\n",
      " 8.455e-01 4.405e-01 8.012e-01 1.178e-03 7.326e-01 8.546e-01]\n",
      "Expected \n",
      "[0.995 0.079 0.14  0.169 0.312 0.222 0.077 0.281 0.244 0.055 0.322 0.024\n",
      " 0.147 0.238 0.313 0.268 0.094 0.281 0.137 0.106 0.046 0.078 0.038 0.251\n",
      " 0.243 0.343 0.266 0.194 0.006 0.339 0.144 0.116 0.094 0.094 0.01  0.076\n",
      " 0.243 0.334 0.023 0.161 0.038 0.164 0.138 0.255 0.214 0.202 0.301 0.264\n",
      " 0.139 0.007 0.343 0.239 0.221 0.348 0.128 0.135 0.099 0.08  0.088 0.035\n",
      " 0.052 0.312 0.246 0.286 0.312 0.237 0.235 0.13  0.024 0.307 0.248 0.078\n",
      " 0.03  0.19  0.278 0.182 0.097 0.27  0.304 0.152 0.27  0.06  0.149 0.028\n",
      " 0.245 0.194 0.26  0.012 0.074 0.106 0.229 0.185 0.303 0.201 0.186 0.217\n",
      " 0.23  0.079 0.221 0.131 0.18  0.27  0.21  0.072 0.2   0.04  0.188 0.055\n",
      " 0.306 0.013 0.244 0.224 0.091 0.005 0.072 0.034 0.303 0.032 0.248 0.026\n",
      " 0.21  0.291 0.22  0.028 0.126 0.309 0.312 0.291 0.053 0.125 0.041 0.051\n",
      " 0.083 0.18  0.316 0.041 0.142 0.012 0.099 0.137 0.112 0.133 0.106 0.144\n",
      " 0.125 0.177 0.172 0.001 0.222 0.124 0.069 0.15  0.345 0.14  0.018 0.168\n",
      " 0.279 0.329 0.251 0.17  0.193 0.125 0.093 0.006 0.004 0.231 0.068 0.016\n",
      " 0.264 0.192 0.215 0.135 0.045 0.026 0.038 0.087 0.089 0.105 0.128 0.278\n",
      " 0.194 0.112 0.155 0.21  0.226 0.171 0.171 0.079 0.228 0.285 0.333 0.023\n",
      " 0.308 0.101 0.226 0.316 0.222 0.244 0.104 0.119 0.268 0.171 0.322 0.288\n",
      " 0.302 0.172 0.037 0.159 0.267 0.15  0.153 0.002 0.276 0.255 0.268 0.118\n",
      " 0.299 0.033 0.304 0.257 0.009 0.21  0.029 0.288 0.044 0.203 0.289 0.15\n",
      " 0.312 0.211 0.285 0.328 0.15  0.173 0.099 0.117 0.017 0.01  0.296 0.286\n",
      " 0.171 0.199 0.316 0.05  0.184 0.285 0.26  0.264 0.03  0.308 0.069 0.312\n",
      " 0.141 0.238 0.177 0.219 0.049 0.225 0.146 0.324 0.208 0.18  0.229 0.21\n",
      " 0.062 0.211 0.089 0.087 0.185 0.234 0.273 0.179 0.354 0.083 0.179 0.263\n",
      " 0.126 0.082 0.043 0.292 0.04  0.201 0.229 0.164 0.261 0.259 0.021 0.295\n",
      " 0.13  0.072 0.201 0.101 0.323 0.032 0.265 0.316 0.227 0.319 0.306 0.067\n",
      " 0.118 0.332 0.258 0.087 0.021 0.057 0.337 0.057 0.343 0.23  0.245 0.134\n",
      " 0.233 0.286 0.16  0.136 0.252 0.207 0.08  0.021 0.217 0.316 0.322 0.11\n",
      " 0.069 0.011 0.012 0.103 0.061 0.066 0.196 0.113 0.25  0.069 0.201 0.208\n",
      " 0.095 0.208 0.229 0.165 0.183 0.01  0.236 0.181 0.258 0.205 0.329 0.227\n",
      " 0.136 0.001 0.254 0.007 0.062 0.283 0.203 0.076 0.003 0.23  0.063 0.054\n",
      " 0.265 0.286 0.072 0.237 0.216 0.029 0.231 0.061 0.331 0.195 0.267 0.125\n",
      " 0.199 0.319 0.    0.164 0.13  0.18  0.306 0.214 0.091 0.251 0.069 0.098\n",
      " 0.075 0.311 0.061 0.02  0.1   0.283 0.08  0.279 0.284 0.35  0.089 0.027\n",
      " 0.003 0.106 0.11  0.22  0.019 0.295 0.275 0.105 0.266 0.249 0.126 0.263\n",
      " 0.308 0.241 0.235 0.134 0.302 0.222 0.015 0.312 0.316 0.273 0.008 0.084\n",
      " 0.055 0.222 0.173 0.118 0.114 0.297 0.045 0.064 0.039 0.18  0.089 0.048\n",
      " 0.248 0.094 0.109 0.294 0.235 0.192 0.025 0.324 0.01  0.203 0.302 0.053\n",
      " 0.271 0.126 0.122 0.306 0.23  0.222 0.101 0.06  0.026 0.106 0.207 0.056\n",
      " 0.219 0.103 0.352 0.132 0.164 0.35  0.064 0.015 0.055 0.324 0.233 0.106\n",
      " 0.072 0.078 0.099 0.374 0.039 0.315 0.034 0.02  0.266 0.32  0.274 0.127\n",
      " 0.071 0.256 0.206 0.241 0.121 0.026 0.201 0.028 0.086 0.279 0.037 0.135\n",
      " 0.265 0.019 0.107 0.167 0.101 0.198 0.105 0.288 0.354 0.181 0.211 0.028\n",
      " 0.035 0.118 0.322 0.342 0.286 0.279 0.302 0.112 0.316 0.105 0.195 0.075\n",
      " 0.326 0.089 0.174 0.096 0.139 0.181 0.086 0.317 0.239 0.111 0.267 0.136\n",
      " 0.031 0.074 0.122 0.081 0.16  0.149 0.277 0.159 0.233 0.053 0.301 0.096\n",
      " 0.18  0.212 0.118 0.287 0.294 0.133 0.075 0.115 0.341 0.188 0.297 0.119\n",
      " 0.133 0.211 0.316 0.273 0.206 0.35  0.108 0.251 0.333 0.233 0.261 0.107\n",
      " 0.108 0.335 0.1   0.234 0.118 0.124 0.333 0.24  0.324 0.114 0.139 0.228\n",
      " 0.113 0.101 0.153 0.156 0.179 0.245 0.097 0.079 0.305 0.075 0.082 0.027\n",
      " 0.007 0.22  0.27  0.02  0.173 0.236 0.126 0.276 0.082 0.188 0.    0.143\n",
      " 0.052 0.164 0.002 0.118 0.107 0.162 0.238 0.078 0.06  0.097 0.296 0.134\n",
      " 0.116 0.351 0.178 0.283 0.085 0.033 0.06  0.349 0.153 0.173 0.124 0.28\n",
      " 0.303 0.076 0.138 0.258 0.096 0.284 0.142 0.047 0.321 0.156 0.058 0.189\n",
      " 0.279 0.054 0.178 0.024 0.107 0.289 0.315 0.125 0.237 0.044 0.333 0.187\n",
      " 0.353 0.225 0.281 0.264 0.08  0.187 0.073 0.17  0.163 0.012 0.093 0.027\n",
      " 0.286 0.3   0.258 0.243 0.106 0.339 0.251 0.003 0.187 0.268 0.035 0.087\n",
      " 0.173 0.205 0.256 0.235 0.195 0.003 0.248 0.243 0.004 0.303 0.128 0.305\n",
      " 0.161 0.179 0.044 0.161 0.299 0.044 0.152 0.044 0.105 0.041 0.154 0.253\n",
      " 0.063 0.047 0.124 0.046 0.226 0.297 0.254 0.198 0.238 0.188 0.013 0.285\n",
      " 0.159 0.203 0.201 0.11  0.023 0.324 0.021 0.334 0.134 0.264 0.162 0.178\n",
      " 0.28  0.056 0.053 0.298 0.186 0.297 0.103 0.206 0.305 0.303 0.167 0.281\n",
      " 0.043 0.113 0.261 0.298 0.227 0.143 0.305 0.225 0.181 0.094 0.258 0.342\n",
      " 0.174 0.132 0.182 0.186 0.307 0.304 0.061 0.1   0.208 0.185 0.199 0.29\n",
      " 0.272 0.094 0.283 0.327 0.111 0.261 0.057 0.286 0.258 0.334 0.089 0.301\n",
      " 0.274 0.027 0.148 0.339 0.127 0.278 0.297 0.046 0.232 0.014 0.3   0.088\n",
      " 0.094 0.156 0.293 0.143 0.15  0.341 0.138 0.174 0.011 0.22  0.021 0.181\n",
      " 0.309 0.048 0.007 0.004 0.063 0.081 0.317 0.05  0.234 0.039 0.189 0.25\n",
      " 0.231 0.001 0.046 0.07  0.274 0.169 0.005 0.309 0.055 0.051 0.113 0.315\n",
      " 0.313 0.053 0.291 0.115 0.025 0.258 0.114 0.027 0.26  0.031 0.319 0.271\n",
      " 0.161 0.005 0.08  0.074 0.065 0.181 0.079 0.343 0.304 0.182 0.304 0.188\n",
      " 0.177 0.238 0.034 0.281 0.221 0.11  0.096 0.152 0.226 0.136 0.01  0.077\n",
      " 0.21  0.095 0.004 0.066 0.195 0.185 0.179 0.177 0.241 0.314 0.08  0.228\n",
      " 0.258 0.124 0.012 0.163 0.294 0.353 0.123 0.005 0.109 0.071 0.031 0.125\n",
      " 0.14  0.236 0.061 0.278 0.293 0.148 0.263 0.226 0.046 0.265 0.128 0.025\n",
      " 0.055 0.301 0.047 0.    0.269 0.175 0.283 0.215 0.322 0.049 0.114 0.101\n",
      " 0.166 0.235 0.073 0.285 0.125 0.302 0.234 0.218 0.132 0.229 0.257 0.007\n",
      " 0.217 0.297 0.121 0.159 0.272 0.202 0.049 0.237 0.331 0.111 0.07  0.262\n",
      " 0.186 0.247 0.119 0.308 0.153 0.26  0.272 0.135 0.163 0.153 0.036 0.036\n",
      " 0.337 0.073 0.356 0.088 0.112 0.243 0.03  0.216 0.028 0.037 0.067 0.003\n",
      " 0.203 0.296 0.343 0.08  0.127 0.238 0.132 0.003 0.023 0.059 0.281 0.236\n",
      " 0.07  0.188 0.191 0.317 0.29  0.174 0.258 0.23  0.3   0.    0.236 0.041\n",
      " 0.059 0.035 0.118 0.316 0.019 0.315 0.231 0.063 0.257 0.109 0.297 0.23\n",
      " 0.072 0.104 0.236 0.201 0.103 0.361 0.15  0.164 0.216 0.07  0.313 0.147\n",
      " 0.276 0.002 0.261 0.307]\n"
     ]
    }
   ],
   "source": [
    "# c e greedy \n",
    "c_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "c_estimation   = np.zeros((num_ep,num_bandit))\n",
    "c_reward       = np.zeros((num_ep,num_iter))\n",
    "c_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "c_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    epsilon = np.random.uniform(0,1)\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "  \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    c_pull_count[eps,:]   = temp_pull_count\n",
    "    c_estimation[eps,:]   = temp_estimation\n",
    "    c_reward[eps,:]       = temp_reward\n",
    "    c_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    c_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(c_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.469Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[9.985e-01 2.468e-01 4.049e-01 5.143e-01 8.784e-01 5.730e-01 1.863e-01\n",
      " 8.173e-01 6.897e-01 2.182e-01 9.070e-01 7.975e-02 3.765e-01 7.575e-01\n",
      " 9.264e-01 7.513e-01 2.293e-01 8.728e-01 4.411e-01 2.945e-01 1.383e-01\n",
      " 2.116e-01 9.970e-02 7.656e-01 6.761e-01 8.933e-01 8.492e-01 5.543e-01\n",
      " 1.555e-02 9.807e-01 4.410e-01 2.954e-01 3.047e-01 2.378e-01 4.053e-02\n",
      " 1.928e-01 5.942e-01 9.718e-01 1.122e-01 4.146e-01 9.596e-02 4.615e-01\n",
      " 4.102e-01 7.851e-01 6.594e-01 6.430e-01 8.628e-01 7.358e-01 3.753e-01\n",
      " 1.499e-02 9.167e-01 6.266e-01 5.835e-01 9.620e-01 3.563e-01 3.146e-01\n",
      " 2.974e-01 2.733e-01 2.759e-01 8.777e-02 1.640e-01 9.339e-01 7.837e-01\n",
      " 9.007e-01 8.759e-01 7.108e-01 6.899e-01 3.939e-01 7.935e-02 9.195e-01\n",
      " 7.454e-01 2.285e-01 8.999e-02 6.199e-01 8.322e-01 5.734e-01 2.972e-01\n",
      " 7.810e-01 9.592e-01 4.716e-01 7.766e-01 1.580e-01 5.323e-01 8.413e-02\n",
      " 6.862e-01 5.251e-01 7.035e-01 6.266e-02 1.740e-01 2.738e-01 7.370e-01\n",
      " 5.180e-01 9.440e-01 5.869e-01 5.683e-01 6.736e-01 6.040e-01 1.795e-01\n",
      " 6.692e-01 3.784e-01 5.799e-01 7.999e-01 7.164e-01 2.043e-01 5.965e-01\n",
      " 1.802e-01 5.404e-01 2.257e-01 8.393e-01 5.928e-02 7.697e-01 6.783e-01\n",
      " 2.417e-01 2.014e-02 2.213e-01 1.646e-01 9.784e-01 1.116e-01 7.692e-01\n",
      " 7.533e-02 6.196e-01 8.608e-01 6.582e-01 1.045e-01 3.834e-01 8.187e-01\n",
      " 9.441e-01 9.435e-01 1.540e-01 4.089e-01 1.342e-01 1.329e-01 2.474e-01\n",
      " 5.057e-01 8.841e-01 1.209e-01 4.777e-01 3.655e-02 2.866e-01 4.459e-01\n",
      " 3.274e-01 4.929e-01 3.193e-01 4.067e-01 3.596e-01 5.537e-01 5.443e-01\n",
      " 1.242e-02 5.984e-01 3.763e-01 2.472e-01 4.210e-01 9.832e-01 3.582e-01\n",
      " 9.756e-02 5.188e-01 8.472e-01 9.345e-01 8.728e-01 4.500e-01 4.960e-01\n",
      " 4.090e-01 2.779e-01 1.693e-02 2.318e-02 7.475e-01 1.590e-01 3.732e-02\n",
      " 7.451e-01 5.752e-01 6.708e-01 4.110e-01 1.026e-01 8.470e-02 1.025e-01\n",
      " 2.925e-01 2.006e-01 3.468e-01 3.440e-01 8.419e-01 5.450e-01 3.445e-01\n",
      " 4.356e-01 6.018e-01 6.582e-01 4.777e-01 5.090e-01 1.750e-01 7.049e-01\n",
      " 8.597e-01 9.862e-01 6.258e-02 8.467e-01 3.545e-01 6.479e-01 9.001e-01\n",
      " 6.736e-01 7.068e-01 3.297e-01 3.453e-01 7.810e-01 4.954e-01 9.578e-01\n",
      " 8.519e-01 8.053e-01 5.102e-01 1.190e-01 4.680e-01 8.261e-01 4.550e-01\n",
      " 5.082e-01 1.237e-02 7.898e-01 7.013e-01 9.319e-01 3.271e-01 8.428e-01\n",
      " 1.050e-01 8.215e-01 7.193e-01 3.678e-02 5.714e-01 9.837e-02 8.292e-01\n",
      " 1.140e-01 6.313e-01 8.248e-01 4.939e-01 9.204e-01 6.269e-01 8.511e-01\n",
      " 9.356e-01 3.757e-01 4.588e-01 3.054e-01 3.362e-01 6.466e-02 3.288e-02\n",
      " 8.716e-01 8.349e-01 4.532e-01 5.377e-01 9.514e-01 1.125e-01 5.076e-01\n",
      " 8.385e-01 6.571e-01 7.602e-01 7.426e-02 9.782e-01 2.407e-01 8.767e-01\n",
      " 3.916e-01 6.784e-01 5.506e-01 6.467e-01 1.555e-01 6.212e-01 3.338e-01\n",
      " 9.300e-01 5.977e-01 5.471e-01 7.017e-01 6.053e-01 1.741e-01 5.788e-01\n",
      " 2.797e-01 2.463e-01 4.882e-01 6.094e-01 6.771e-01 4.706e-01 9.722e-01\n",
      " 2.112e-01 4.699e-01 7.070e-01 4.071e-01 2.881e-01 7.060e-02 7.499e-01\n",
      " 1.560e-01 5.742e-01 7.218e-01 5.040e-01 7.832e-01 6.777e-01 6.963e-02\n",
      " 8.576e-01 3.801e-01 1.769e-01 5.900e-01 3.751e-01 8.342e-01 9.165e-02\n",
      " 6.948e-01 9.195e-01 6.810e-01 9.232e-01 9.121e-01 2.056e-01 2.974e-01\n",
      " 9.441e-01 6.130e-01 3.131e-01 6.014e-02 1.553e-01 9.601e-01 1.399e-01\n",
      " 9.641e-01 6.817e-01 6.543e-01 4.337e-01 6.990e-01 7.850e-01 5.505e-01\n",
      " 3.664e-01 7.645e-01 5.506e-01 2.211e-01 8.864e-02 6.537e-01 8.539e-01\n",
      " 9.674e-01 2.913e-01 2.149e-01 4.485e-02 5.380e-02 2.822e-01 2.011e-01\n",
      " 2.144e-01 5.371e-01 4.189e-01 7.701e-01 1.600e-01 5.994e-01 6.426e-01\n",
      " 3.208e-01 6.352e-01 7.675e-01 5.132e-01 5.744e-01 3.626e-02 6.616e-01\n",
      " 4.799e-01 7.827e-01 5.688e-01 8.952e-01 7.038e-01 4.372e-01 7.000e-03\n",
      " 7.275e-01 1.301e-02 2.442e-01 7.818e-01 6.423e-01 1.849e-01 1.029e-02\n",
      " 6.720e-01 1.894e-01 1.569e-01 7.577e-01 8.580e-01 1.997e-01 6.353e-01\n",
      " 6.086e-01 7.896e-02 6.784e-01 1.784e-01 9.952e-01 5.475e-01 7.798e-01\n",
      " 3.475e-01 6.226e-01 8.544e-01 1.460e-03 5.001e-01 3.718e-01 5.807e-01\n",
      " 9.152e-01 6.399e-01 2.179e-01 6.915e-01 1.929e-01 2.353e-01 2.110e-01\n",
      " 8.310e-01 2.139e-01 6.696e-02 2.600e-01 8.580e-01 2.495e-01 8.198e-01\n",
      " 8.342e-01 9.967e-01 2.632e-01 1.045e-01 1.655e-02 3.808e-01 3.311e-01\n",
      " 6.751e-01 6.021e-02 8.914e-01 7.447e-01 3.205e-01 7.287e-01 7.737e-01\n",
      " 3.099e-01 8.285e-01 9.760e-01 6.789e-01 7.289e-01 3.269e-01 8.277e-01\n",
      " 6.216e-01 5.183e-02 9.118e-01 9.298e-01 8.160e-01 1.323e-02 2.126e-01\n",
      " 1.274e-01 6.271e-01 5.204e-01 4.078e-01 3.579e-01 8.408e-01 9.339e-02\n",
      " 2.104e-01 1.484e-01 4.864e-01 2.373e-01 1.216e-01 6.979e-01 2.325e-01\n",
      " 3.531e-01 9.599e-01 6.657e-01 5.796e-01 6.655e-02 9.023e-01 3.342e-02\n",
      " 6.137e-01 8.695e-01 1.593e-01 8.088e-01 3.779e-01 3.781e-01 9.137e-01\n",
      " 7.145e-01 6.452e-01 2.884e-01 2.499e-01 9.588e-02 3.120e-01 5.792e-01\n",
      " 1.798e-01 6.113e-01 2.859e-01 9.343e-01 3.387e-01 5.798e-01 9.912e-01\n",
      " 2.213e-01 8.908e-02 1.937e-01 9.158e-01 6.473e-01 3.717e-01 1.731e-01\n",
      " 2.613e-01 3.394e-01 9.832e-01 1.065e-01 8.790e-01 1.126e-01 3.665e-02\n",
      " 6.719e-01 9.349e-01 7.927e-01 4.120e-01 2.150e-01 7.253e-01 6.126e-01\n",
      " 7.671e-01 3.984e-01 9.749e-02 5.872e-01 7.930e-02 2.015e-01 9.855e-01\n",
      " 1.222e-01 3.605e-01 8.518e-01 4.726e-02 2.788e-01 5.226e-01 2.699e-01\n",
      " 5.575e-01 2.942e-01 8.617e-01 9.510e-01 6.238e-01 6.460e-01 6.290e-02\n",
      " 1.166e-01 3.779e-01 9.457e-01 8.820e-01 8.025e-01 8.444e-01 7.673e-01\n",
      " 2.890e-01 9.168e-01 2.888e-01 5.535e-01 2.407e-01 9.745e-01 2.549e-01\n",
      " 4.930e-01 3.003e-01 3.812e-01 5.267e-01 2.516e-01 8.392e-01 7.095e-01\n",
      " 3.405e-01 8.377e-01 4.183e-01 9.013e-02 2.353e-01 2.908e-01 2.508e-01\n",
      " 4.931e-01 3.961e-01 7.626e-01 4.474e-01 6.208e-01 1.702e-01 8.447e-01\n",
      " 3.393e-01 4.848e-01 5.762e-01 3.012e-01 8.701e-01 8.852e-01 4.169e-01\n",
      " 2.058e-01 2.953e-01 9.488e-01 5.608e-01 7.966e-01 2.907e-01 3.865e-01\n",
      " 5.624e-01 9.212e-01 8.133e-01 6.274e-01 9.445e-01 2.751e-01 7.360e-01\n",
      " 8.742e-01 7.233e-01 8.710e-01 3.491e-01 3.966e-01 9.800e-01 2.672e-01\n",
      " 7.075e-01 3.490e-01 3.101e-01 9.184e-01 6.895e-01 8.948e-01 2.878e-01\n",
      " 4.404e-01 5.733e-01 3.854e-01 2.306e-01 4.859e-01 4.621e-01 5.409e-01\n",
      " 7.569e-01 3.085e-01 2.542e-01 8.930e-01 2.739e-01 2.475e-01 6.474e-02\n",
      " 4.973e-02 6.462e-01 8.104e-01 6.978e-02 5.296e-01 7.204e-01 3.796e-01\n",
      " 6.973e-01 2.754e-01 5.212e-01 1.959e-02 4.449e-01 1.627e-01 5.012e-01\n",
      " 2.052e-02 3.470e-01 3.018e-01 4.657e-01 7.055e-01 1.879e-01 1.784e-01\n",
      " 2.357e-01 8.203e-01 3.340e-01 3.389e-01 9.425e-01 5.434e-01 8.021e-01\n",
      " 1.525e-01 8.248e-02 1.531e-01 9.903e-01 4.737e-01 5.046e-01 3.516e-01\n",
      " 7.574e-01 8.574e-01 1.738e-01 3.889e-01 6.809e-01 3.687e-01 8.125e-01\n",
      " 3.760e-01 1.244e-01 9.498e-01 4.648e-01 1.986e-01 6.045e-01 7.926e-01\n",
      " 1.197e-01 6.152e-01 9.267e-02 2.616e-01 8.631e-01 9.663e-01 4.911e-01\n",
      " 7.015e-01 1.554e-01 9.391e-01 5.312e-01 9.230e-01 7.418e-01 8.000e-01\n",
      " 8.141e-01 2.338e-01 4.992e-01 1.740e-01 5.907e-01 4.115e-01 6.508e-02\n",
      " 3.046e-01 6.194e-02 7.589e-01 9.418e-01 8.243e-01 7.539e-01 3.022e-01\n",
      " 9.693e-01 7.129e-01 1.326e-02 5.039e-01 7.290e-01 9.711e-02 3.012e-01\n",
      " 4.520e-01 6.074e-01 8.244e-01 6.599e-01 5.567e-01 8.439e-03 6.260e-01\n",
      " 7.690e-01 2.456e-02 9.373e-01 3.111e-01 9.920e-01 4.871e-01 5.120e-01\n",
      " 1.151e-01 4.361e-01 9.455e-01 1.433e-01 4.698e-01 1.531e-01 2.769e-01\n",
      " 1.251e-01 4.199e-01 7.167e-01 1.558e-01 1.141e-01 3.456e-01 1.110e-01\n",
      " 7.464e-01 8.418e-01 6.999e-01 4.664e-01 7.568e-01 5.838e-01 3.591e-02\n",
      " 8.513e-01 5.107e-01 6.468e-01 6.665e-01 3.146e-01 7.972e-02 8.816e-01\n",
      " 7.423e-02 9.917e-01 3.664e-01 7.207e-01 4.169e-01 5.070e-01 8.221e-01\n",
      " 1.107e-01 1.391e-01 8.717e-01 5.178e-01 8.075e-01 2.812e-01 6.217e-01\n",
      " 8.164e-01 7.943e-01 5.222e-01 8.666e-01 1.317e-01 3.251e-01 7.776e-01\n",
      " 8.506e-01 7.199e-01 3.477e-01 8.984e-01 7.143e-01 4.433e-01 3.544e-01\n",
      " 7.527e-01 9.710e-01 4.509e-01 3.925e-01 5.077e-01 4.936e-01 8.412e-01\n",
      " 8.444e-01 2.288e-01 3.060e-01 5.307e-01 6.282e-01 5.505e-01 7.904e-01\n",
      " 8.371e-01 2.657e-01 8.138e-01 9.905e-01 2.895e-01 7.073e-01 2.142e-01\n",
      " 7.558e-01 7.567e-01 9.030e-01 3.065e-01 9.503e-01 8.015e-01 1.063e-01\n",
      " 3.926e-01 9.851e-01 2.823e-01 8.271e-01 8.929e-01 1.406e-01 7.762e-01\n",
      " 4.305e-02 8.106e-01 2.527e-01 1.867e-01 4.300e-01 9.199e-01 4.044e-01\n",
      " 4.012e-01 9.832e-01 4.138e-01 5.494e-01 2.312e-02 6.444e-01 6.904e-02\n",
      " 4.786e-01 9.655e-01 1.226e-01 2.018e-02 1.781e-02 1.657e-01 3.089e-01\n",
      " 9.541e-01 1.637e-01 7.522e-01 1.184e-01 5.191e-01 6.416e-01 6.813e-01\n",
      " 1.676e-02 1.495e-01 1.924e-01 7.898e-01 5.516e-01 2.066e-02 9.228e-01\n",
      " 1.907e-01 1.626e-01 2.728e-01 9.585e-01 8.724e-01 2.157e-01 8.748e-01\n",
      " 3.127e-01 7.666e-02 7.835e-01 3.515e-01 6.095e-02 6.860e-01 9.731e-02\n",
      " 9.529e-01 7.317e-01 5.135e-01 1.188e-02 1.856e-01 2.447e-01 1.324e-01\n",
      " 4.273e-01 2.646e-01 9.612e-01 9.042e-01 5.728e-01 9.295e-01 4.947e-01\n",
      " 4.965e-01 6.654e-01 5.485e-02 8.002e-01 6.046e-01 3.671e-01 2.203e-01\n",
      " 4.118e-01 6.095e-01 4.893e-01 4.410e-02 2.011e-01 5.797e-01 2.377e-01\n",
      " 2.705e-03 2.056e-01 6.026e-01 5.530e-01 5.206e-01 4.861e-01 6.552e-01\n",
      " 8.015e-01 2.718e-01 5.832e-01 7.984e-01 3.339e-01 5.146e-02 4.575e-01\n",
      " 8.970e-01 9.124e-01 3.843e-01 3.383e-03 3.448e-01 2.064e-01 1.251e-01\n",
      " 3.016e-01 4.556e-01 6.542e-01 1.990e-01 7.626e-01 8.168e-01 4.313e-01\n",
      " 7.061e-01 6.993e-01 1.300e-01 7.698e-01 3.785e-01 6.814e-02 1.483e-01\n",
      " 8.854e-01 1.727e-01 7.951e-04 8.353e-01 6.004e-01 9.063e-01 6.223e-01\n",
      " 9.875e-01 1.665e-01 3.264e-01 3.238e-01 4.564e-01 7.328e-01 1.923e-01\n",
      " 8.472e-01 3.691e-01 6.759e-01 6.346e-01 5.645e-01 4.224e-01 7.307e-01\n",
      " 7.347e-01 3.138e-02 6.504e-01 8.351e-01 3.016e-01 3.975e-01 7.226e-01\n",
      " 6.267e-01 1.486e-01 7.610e-01 9.541e-01 3.067e-01 2.048e-01 7.338e-01\n",
      " 5.093e-01 7.096e-01 3.507e-01 7.638e-01 4.779e-01 7.940e-01 8.054e-01\n",
      " 3.795e-01 4.364e-01 4.693e-01 1.272e-01 1.123e-01 9.812e-01 2.056e-01\n",
      " 9.819e-01 2.977e-01 3.056e-01 7.162e-01 7.786e-02 6.447e-01 1.090e-01\n",
      " 1.527e-01 1.741e-01 3.096e-03 6.373e-01 8.590e-01 9.510e-01 2.743e-01\n",
      " 3.852e-01 6.675e-01 3.623e-01 9.716e-03 8.090e-02 1.490e-01 8.416e-01\n",
      " 6.593e-01 2.101e-01 5.014e-01 5.913e-01 9.052e-01 7.493e-01 5.459e-01\n",
      " 7.501e-01 6.508e-01 8.608e-01 5.365e-03 6.583e-01 1.032e-01 1.656e-01\n",
      " 1.113e-01 3.456e-01 9.045e-01 3.633e-02 8.274e-01 7.621e-01 2.158e-01\n",
      " 8.215e-01 3.190e-01 8.206e-01 6.776e-01 2.170e-01 3.530e-01 7.934e-01\n",
      " 6.000e-01 2.685e-01 9.690e-01 3.725e-01 5.176e-01 6.378e-01 1.791e-01\n",
      " 8.455e-01 4.405e-01 8.012e-01 1.178e-03 7.326e-01 8.546e-01]\n",
      "Expected \n",
      "[0.998 0.013 0.013 0.028 0.048 0.033 0.003 0.043 0.015 0.009 0.035 0.005\n",
      " 0.018 0.043 0.061 0.035 0.018 0.037 0.025 0.013 0.019 0.007 0.013 0.036\n",
      " 0.035 0.03  0.036 0.015 0.002 0.052 0.028 0.01  0.01  0.011 0.003 0.009\n",
      " 0.034 0.043 0.007 0.023 0.005 0.027 0.02  0.035 0.02  0.04  0.051 0.033\n",
      " 0.015 0.002 0.033 0.022 0.018 0.035 0.022 0.007 0.021 0.007 0.01  0.003\n",
      " 0.007 0.06  0.031 0.064 0.044 0.034 0.036 0.022 0.    0.041 0.037 0.01\n",
      " 0.005 0.022 0.043 0.02  0.018 0.043 0.037 0.023 0.037 0.003 0.022 0.002\n",
      " 0.042 0.02  0.036 0.003 0.011 0.011 0.038 0.038 0.056 0.025 0.036 0.033\n",
      " 0.036 0.005 0.025 0.014 0.045 0.052 0.034 0.015 0.045 0.008 0.024 0.013\n",
      " 0.046 0.    0.036 0.031 0.02  0.    0.013 0.013 0.053 0.007 0.033 0.\n",
      " 0.037 0.049 0.033 0.    0.023 0.062 0.043 0.043 0.005 0.031 0.007 0.007\n",
      " 0.009 0.03  0.036 0.    0.028 0.    0.025 0.031 0.024 0.03  0.02  0.02\n",
      " 0.014 0.033 0.022 0.    0.037 0.023 0.015 0.02  0.041 0.015 0.005 0.025\n",
      " 0.03  0.04  0.035 0.026 0.03  0.023 0.018 0.    0.003 0.038 0.007 0.003\n",
      " 0.033 0.042 0.033 0.031 0.007 0.    0.    0.012 0.005 0.018 0.008 0.036\n",
      " 0.029 0.017 0.01  0.04  0.029 0.022 0.026 0.005 0.028 0.048 0.04  0.003\n",
      " 0.037 0.014 0.025 0.03  0.043 0.046 0.02  0.03  0.053 0.03  0.037 0.039\n",
      " 0.028 0.021 0.005 0.028 0.025 0.026 0.013 0.    0.025 0.028 0.05  0.018\n",
      " 0.03  0.013 0.037 0.022 0.005 0.028 0.003 0.043 0.007 0.037 0.033 0.003\n",
      " 0.053 0.025 0.035 0.046 0.027 0.027 0.017 0.01  0.005 0.    0.04  0.041\n",
      " 0.022 0.024 0.066 0.005 0.04  0.033 0.035 0.037 0.    0.046 0.01  0.041\n",
      " 0.02  0.027 0.03  0.029 0.013 0.036 0.01  0.058 0.018 0.037 0.023 0.034\n",
      " 0.003 0.03  0.015 0.004 0.009 0.022 0.033 0.018 0.045 0.014 0.013 0.029\n",
      " 0.017 0.013 0.005 0.05  0.005 0.043 0.045 0.03  0.033 0.047 0.003 0.046\n",
      " 0.022 0.012 0.047 0.013 0.044 0.005 0.033 0.052 0.028 0.033 0.046 0.014\n",
      " 0.01  0.049 0.035 0.014 0.002 0.    0.043 0.007 0.039 0.05  0.043 0.018\n",
      " 0.037 0.037 0.024 0.02  0.022 0.023 0.007 0.004 0.025 0.065 0.025 0.01\n",
      " 0.013 0.003 0.003 0.012 0.005 0.017 0.037 0.028 0.042 0.01  0.031 0.018\n",
      " 0.013 0.044 0.035 0.018 0.018 0.    0.035 0.022 0.035 0.013 0.041 0.033\n",
      " 0.02  0.    0.014 0.    0.003 0.048 0.015 0.01  0.    0.022 0.01  0.009\n",
      " 0.025 0.035 0.003 0.033 0.02  0.    0.033 0.007 0.034 0.015 0.026 0.014\n",
      " 0.062 0.046 0.    0.025 0.013 0.037 0.033 0.039 0.012 0.041 0.018 0.007\n",
      " 0.005 0.04  0.    0.003 0.018 0.044 0.013 0.049 0.047 0.038 0.013 0.\n",
      " 0.    0.022 0.02  0.031 0.    0.05  0.04  0.015 0.024 0.037 0.007 0.044\n",
      " 0.047 0.03  0.035 0.022 0.04  0.025 0.002 0.058 0.038 0.029 0.    0.01\n",
      " 0.005 0.03  0.045 0.009 0.015 0.029 0.007 0.017 0.005 0.015 0.019 0.005\n",
      " 0.02  0.009 0.013 0.041 0.025 0.02  0.003 0.036 0.003 0.028 0.053 0.005\n",
      " 0.03  0.026 0.02  0.053 0.045 0.03  0.018 0.012 0.007 0.018 0.03  0.01\n",
      " 0.037 0.025 0.046 0.022 0.028 0.041 0.007 0.003 0.01  0.036 0.025 0.012\n",
      " 0.005 0.014 0.019 0.037 0.01  0.05  0.005 0.003 0.02  0.054 0.04  0.027\n",
      " 0.005 0.035 0.039 0.066 0.022 0.007 0.025 0.009 0.    0.052 0.003 0.027\n",
      " 0.041 0.007 0.01  0.043 0.015 0.031 0.013 0.037 0.028 0.04  0.033 0.012\n",
      " 0.005 0.024 0.052 0.055 0.025 0.045 0.037 0.006 0.033 0.01  0.028 0.015\n",
      " 0.061 0.01  0.022 0.005 0.017 0.025 0.01  0.037 0.041 0.022 0.048 0.03\n",
      " 0.005 0.01  0.012 0.01  0.022 0.025 0.047 0.014 0.044 0.013 0.04  0.016\n",
      " 0.013 0.03  0.015 0.028 0.035 0.028 0.007 0.024 0.059 0.033 0.033 0.013\n",
      " 0.022 0.026 0.027 0.033 0.029 0.037 0.013 0.043 0.045 0.036 0.04  0.015\n",
      " 0.022 0.048 0.013 0.022 0.018 0.014 0.041 0.033 0.043 0.013 0.013 0.022\n",
      " 0.028 0.007 0.037 0.03  0.029 0.024 0.014 0.01  0.04  0.01  0.013 0.003\n",
      " 0.    0.027 0.033 0.003 0.039 0.043 0.024 0.024 0.013 0.028 0.    0.021\n",
      " 0.003 0.029 0.    0.02  0.01  0.015 0.057 0.01  0.005 0.01  0.049 0.01\n",
      " 0.017 0.046 0.015 0.049 0.005 0.013 0.013 0.03  0.022 0.018 0.02  0.018\n",
      " 0.05  0.007 0.022 0.05  0.023 0.023 0.018 0.004 0.052 0.023 0.005 0.028\n",
      " 0.03  0.003 0.02  0.005 0.02  0.049 0.037 0.019 0.03  0.003 0.05  0.03\n",
      " 0.035 0.037 0.038 0.041 0.015 0.028 0.005 0.03  0.018 0.003 0.022 0.003\n",
      " 0.045 0.045 0.025 0.043 0.007 0.04  0.04  0.    0.034 0.021 0.003 0.014\n",
      " 0.026 0.027 0.046 0.035 0.026 0.    0.038 0.028 0.003 0.058 0.009 0.05\n",
      " 0.026 0.024 0.007 0.018 0.054 0.004 0.013 0.005 0.018 0.005 0.036 0.035\n",
      " 0.005 0.003 0.03  0.    0.04  0.045 0.036 0.022 0.023 0.028 0.005 0.047\n",
      " 0.017 0.035 0.033 0.024 0.001 0.031 0.002 0.035 0.007 0.043 0.009 0.036\n",
      " 0.051 0.013 0.007 0.061 0.018 0.04  0.017 0.03  0.022 0.022 0.022 0.035\n",
      " 0.003 0.019 0.032 0.042 0.041 0.023 0.05  0.045 0.015 0.022 0.025 0.044\n",
      " 0.031 0.022 0.041 0.032 0.048 0.048 0.007 0.017 0.03  0.022 0.024 0.038\n",
      " 0.058 0.022 0.032 0.039 0.022 0.049 0.01  0.027 0.046 0.043 0.021 0.065\n",
      " 0.045 0.005 0.01  0.05  0.01  0.043 0.038 0.009 0.035 0.003 0.046 0.015\n",
      " 0.013 0.015 0.038 0.018 0.035 0.04  0.024 0.022 0.    0.023 0.005 0.028\n",
      " 0.048 0.007 0.    0.    0.012 0.017 0.047 0.004 0.024 0.005 0.025 0.018\n",
      " 0.041 0.    0.007 0.005 0.043 0.027 0.003 0.05  0.007 0.01  0.02  0.048\n",
      " 0.03  0.015 0.067 0.023 0.003 0.043 0.015 0.003 0.033 0.005 0.048 0.032\n",
      " 0.034 0.    0.007 0.007 0.01  0.014 0.003 0.045 0.056 0.026 0.07  0.045\n",
      " 0.022 0.037 0.003 0.037 0.041 0.02  0.01  0.015 0.028 0.024 0.    0.013\n",
      " 0.034 0.025 0.003 0.01  0.034 0.028 0.025 0.029 0.022 0.043 0.013 0.038\n",
      " 0.027 0.007 0.005 0.026 0.041 0.042 0.015 0.    0.021 0.018 0.008 0.018\n",
      " 0.018 0.033 0.005 0.028 0.048 0.022 0.022 0.032 0.003 0.037 0.015 0.007\n",
      " 0.005 0.053 0.012 0.    0.04  0.028 0.043 0.031 0.058 0.003 0.009 0.013\n",
      " 0.028 0.032 0.01  0.035 0.019 0.025 0.038 0.025 0.031 0.038 0.035 0.\n",
      " 0.028 0.037 0.016 0.007 0.025 0.028 0.003 0.022 0.048 0.009 0.007 0.041\n",
      " 0.022 0.041 0.022 0.028 0.035 0.05  0.048 0.018 0.018 0.03  0.008 0.007\n",
      " 0.05  0.01  0.058 0.013 0.013 0.03  0.003 0.036 0.003 0.003 0.    0.\n",
      " 0.035 0.037 0.045 0.013 0.019 0.033 0.017 0.    0.005 0.003 0.048 0.054\n",
      " 0.012 0.029 0.033 0.053 0.041 0.033 0.036 0.022 0.04  0.    0.026 0.007\n",
      " 0.007 0.    0.011 0.033 0.003 0.037 0.038 0.012 0.045 0.012 0.033 0.048\n",
      " 0.014 0.013 0.035 0.033 0.009 0.037 0.018 0.018 0.033 0.003 0.052 0.018\n",
      " 0.04  0.    0.035 0.035]\n"
     ]
    }
   ],
   "source": [
    "# d decy e greedy \n",
    "d_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "d_estimation   = np.zeros((num_ep,num_bandit))\n",
    "d_reward       = np.zeros((num_ep,num_iter))\n",
    "d_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "d_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    epsilon = 1.0\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the eps\n",
    "        epsilon = 0.99 * epsilon\n",
    "        \n",
    "    d_pull_count[eps,:]   = temp_pull_count\n",
    "    d_estimation[eps,:]   = temp_estimation\n",
    "    d_reward[eps,:]       = temp_reward\n",
    "    d_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    d_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(d_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.637Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# e Linear Reward Inaction\n",
    "e_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "e_estimation   = np.zeros((num_ep,num_bandit))\n",
    "e_reward       = np.zeros((num_ep,num_iter))\n",
    "e_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "e_regret_total = np.zeros((num_ep,num_iter))\n",
    "      \n",
    "for eps in range(num_ep):\n",
    "    learning_rate = 0.1\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + learning_rate * (1-temp_estimation)) + (1-mask) * ( (1-learning_rate) * temp_estimation)\n",
    "            \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    e_pull_count[eps,:]   = temp_pull_count\n",
    "    e_estimation[eps,:]   = temp_estimation\n",
    "    e_reward[eps,:]       = temp_reward\n",
    "    e_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    e_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(np.around(e_estimation.mean(0),3))\n",
    "print('Expected Normalized')\n",
    "print(\n",
    "    (gt_prob.max()-gt_prob.min())*(e_estimation.mean(0)-e_estimation.mean(0).min())/(e_estimation.mean(0).max()-e_estimation.mean(0).min()) + gt_prob.min()\n",
    ")\n",
    "e_estimation = (gt_prob.max()-gt_prob.min())*(e_estimation.mean(0)-e_estimation.mean(0).min())/(e_estimation.mean(0).max()-e_estimation.mean(0).min()) + gt_prob.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.813Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# f Linear Reward Penalty\n",
    "f_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "f_estimation   = np.zeros((num_ep,num_bandit))\n",
    "f_reward       = np.zeros((num_ep,num_iter))\n",
    "f_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "f_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    alpha = 0.01\n",
    "    beta  = 0.001\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "\n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + alpha * (1-temp_estimation)) + (1-mask) * ( (1-alpha) * temp_estimation)\n",
    "        else: \n",
    "            temp_estimation = (mask) * ((1-beta) * temp_estimation) + (1-mask) * ( beta/(num_bandit-1) + (1-beta) * temp_estimation )\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    f_pull_count[eps,:]   = temp_pull_count\n",
    "    f_estimation[eps,:]   = temp_estimation\n",
    "    f_reward[eps,:]       = temp_reward\n",
    "    f_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    f_regret_total[eps,:] = temp_regret\n",
    "    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(f_estimation.mean(0))\n",
    "print('Expected Normalized')\n",
    "print(\n",
    "    (gt_prob.max()-gt_prob.min())*(f_estimation.mean(0)-f_estimation.mean(0).min())/(f_estimation.mean(0).max()-f_estimation.mean(0).min()) + gt_prob.min()\n",
    ")\n",
    "f_estimation = (gt_prob.max()-gt_prob.min())*(e_estimation.mean(0)-e_estimation.mean(0).min())/(e_estimation.mean(0).max()-e_estimation.mean(0).min()) + gt_prob.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:06.979Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# g UBC 1\n",
    "g_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "g_estimation   = np.zeros((num_ep,num_bandit))\n",
    "g_reward       = np.zeros((num_ep,num_iter))\n",
    "g_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "g_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(0.5*np.log(iter+1)/(temp_pull_count+1)))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    g_pull_count[eps,:]   = temp_pull_count\n",
    "    g_estimation[eps,:]   = temp_estimation\n",
    "    g_reward[eps,:]       = temp_reward\n",
    "    g_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    g_regret_total[eps,:] = temp_regret\n",
    "  \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(g_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.145Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# h UBC 1 Tuned\n",
    "h_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "h_estimation   = np.zeros((num_ep,num_bandit))\n",
    "h_reward       = np.zeros((num_ep,num_iter))\n",
    "h_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "h_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit) \n",
    "    temp_estimation   = np.zeros(num_bandit) \n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_sumof_squares= np.zeros(num_bandit)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        v_temp = temp_sumof_squares + np.sqrt(2*np.log(iter+1)/(temp_pull_count+1))\n",
    "        current_min_value = np.minimum(v_temp,np.ones_like(v_temp)*0.25)\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(np.log(iter+1)/(temp_pull_count+1)*current_min_value))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        temp_sumof_squares[current_choice] = temp_sumof_squares[current_choice] + current_reward ** 2\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    h_pull_count[eps,:]   = temp_pull_count\n",
    "    h_estimation[eps,:]   = temp_estimation\n",
    "    h_reward[eps,:]       = temp_reward\n",
    "    h_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    h_regret_total[eps,:] = temp_regret\n",
    "    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(h_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.322Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # i Thompson Sampling (beta) (slow)\n",
    "# i_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "# i_estimation   = np.zeros((num_ep,num_bandit))\n",
    "# i_reward       = np.zeros((num_ep,num_iter))\n",
    "# i_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "# i_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "# for eps in range(num_ep):\n",
    "\n",
    "#     temp_pull_count   = np.zeros(num_bandit)\n",
    "#     temp_estimation   = np.zeros(num_bandit)\n",
    "#     temp_reward       = np.zeros(num_iter)\n",
    "#     temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "#     for iter in range(num_iter):\n",
    "        \n",
    "#         theta_samples = [stats.beta(a=1+w,b=1+t-w).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "#         # select bandit / get reward /increase count / update estimate\n",
    "#         current_choice = np.argmax(theta_samples)\n",
    "#         current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "#         temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "#         temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "#         # update reward and optimal choice\n",
    "#         temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "#         temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "#         temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "#     i_pull_count[eps,:]   = temp_pull_count\n",
    "#     i_estimation[eps,:]   = theta_samples\n",
    "#     i_reward[eps,:]       = temp_reward\n",
    "#     i_optimal_pull[eps,:] = temp_optimal_pull\n",
    "#     i_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "# print('Ground Truth')\n",
    "# print(gt_prob)\n",
    "# print('Expected ')\n",
    "# print(i_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.491Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # j Thompson Sampling (uniform) (slow)\n",
    "# j_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "# j_estimation   = np.zeros((num_ep,num_bandit))\n",
    "# j_reward       = np.zeros((num_ep,num_iter))\n",
    "# j_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "# j_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "# for eps in range(num_ep):\n",
    "\n",
    "#     temp_pull_count   = np.zeros(num_bandit)\n",
    "#     temp_estimation   = np.zeros(num_bandit)\n",
    "#     temp_reward       = np.zeros(num_iter)\n",
    "#     temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "#     for iter in range(num_iter):\n",
    "        \n",
    "#         theta_samples = [stats.uniform(w/(t+0.000000001),1-w/(t+0.000000001)).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "#         # select bandit / get reward /increase count / update estimate\n",
    "#         current_choice = np.argmax(theta_samples)\n",
    "#         current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "#         temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "#         temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "#         # update reward and optimal choice\n",
    "#         temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "#         temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "#         temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "#     j_pull_count[eps,:]   = temp_pull_count\n",
    "#     j_estimation[eps,:]   = theta_samples\n",
    "#     j_reward[eps,:]       = temp_reward\n",
    "#     j_optimal_pull[eps,:] = temp_optimal_pull\n",
    "#     j_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "# print('Ground Truth')\n",
    "# print(gt_prob)\n",
    "# print('Expected ')\n",
    "# print(j_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.656Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# k neural network (with adam)\n",
    "k_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "k_estimation   = np.zeros((num_ep,num_bandit))\n",
    "k_reward       = np.zeros((num_ep,num_iter))\n",
    "k_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "k_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def d_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    weights = np.random.randn(num_bandit,1)\n",
    "    moment  = np.zeros_like(weights); \n",
    "    velocity = np.zeros_like(weights);\n",
    "    epsilon  = 0.3\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        if np.random.uniform(0,1)>epsilon:\n",
    "            current_choice = np.argmax(weights)\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "        else:\n",
    "            current_choice = np.random.choice(np.arange(num_bandit))\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "\n",
    "        layer1 = current_input @ weights\n",
    "        layer1a= sigmoid(layer1)\n",
    "\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        # KL Divergence https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "        grad3 = np.log(layer1a+0.0000001) - np.log(temp_estimation[current_choice]/(temp_pull_count[current_choice])+0.0000001)\n",
    "        grad2 = d_sigmoid(layer1)\n",
    "        grad1 = current_input\n",
    "        grad  = grad1.T @ (grad3 * grad2)\n",
    "        \n",
    "        moment   = 0.9*moment + (1-0.9) * grad\n",
    "        velocity = 0.999*velocity + (1-0.999) * grad**2\n",
    "        moment_hat   = moment/(1-0.9)\n",
    "        velocity_hat = velocity/(1-0.999)\n",
    "        weights  = weights - 0.08 * (moment_hat/(np.sqrt(velocity_hat)+1e-8))\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # Decay the learning rate\n",
    "        epsilon = epsilon * 0.999\n",
    "        \n",
    "    k_pull_count[eps,:]   = temp_pull_count\n",
    "    k_estimation[eps,:]   = np.squeeze(sigmoid(weights))\n",
    "    k_reward[eps,:]       = temp_reward\n",
    "    k_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    k_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(k_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.813Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# l softmax\n",
    "l_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "l_estimation   = np.zeros((num_ep,num_bandit))\n",
    "l_reward       = np.zeros((num_ep,num_iter))\n",
    "l_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "l_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "    tempture = 30\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        pi  = np.exp(temp_estimation/tempture) / np.sum(np.exp(temp_estimation/tempture))\n",
    "        current_choice = np.random.choice(num_bandit,p=pi)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the temp\n",
    "        tempture = tempture * 0.99\n",
    "        \n",
    "    l_pull_count[eps,:]   = temp_pull_count\n",
    "    l_estimation[eps,:]   = temp_estimation\n",
    "    l_reward[eps,:]       = temp_reward\n",
    "    l_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    l_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(l_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:07.972Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# m gradient base\n",
    "m_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "m_estimation   = np.zeros((num_ep,num_bandit))\n",
    "m_reward       = np.zeros((num_ep,num_iter))\n",
    "m_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "m_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "    temp_mean_reward = 0\n",
    "    alpha = 0.8\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        pi  = np.exp(temp_estimation) / np.sum(np.exp(temp_estimation))\n",
    "        current_choice = np.random.choice(num_bandit,p=pi)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        temp_mean_reward = temp_mean_reward + ((current_reward-temp_mean_reward))/(iter) if not iter==0 else ((current_reward-temp_mean_reward))\n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1\n",
    "        \n",
    "        temp_estimation = (mask)   * (temp_estimation+alpha*(current_reward-temp_mean_reward)*(1-pi)) + \\\n",
    "                          (1-mask) * (temp_estimation-alpha*(current_reward-temp_mean_reward)*(pi))\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    m_pull_count[eps,:]   = temp_pull_count\n",
    "    m_estimation[eps,:]   = temp_estimation\n",
    "    m_reward[eps,:]       = temp_reward\n",
    "    m_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    m_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(np.around(m_estimation.mean(0),2))\n",
    "print('Expected Normalized')\n",
    "print(\n",
    "    (gt_prob.max()-gt_prob.min())*(m_estimation.mean(0)-m_estimation.mean(0).min())/(m_estimation.mean(0).max()-m_estimation.mean(0).min()) + gt_prob.min()\n",
    ")\n",
    "m_estimation = (gt_prob.max()-gt_prob.min())*(m_estimation.mean(0)-m_estimation.mean(0).min())/(m_estimation.mean(0).max()-m_estimation.mean(0).min()) + gt_prob.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:08.177Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot the regret\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(b_regret_total.mean(0),c='red',    label='greedy')\n",
    "plt.plot(c_regret_total.mean(0),c='blue',   label='e greedy')\n",
    "plt.plot(d_regret_total.mean(0),c='green',  label='decay e greedy')\n",
    "plt.plot(e_regret_total.mean(0),c='yellow', label='Linear Reward Inaction')\n",
    "plt.plot(f_regret_total.mean(0),c='purple', label='Linear Reward Penalty')\n",
    "plt.plot(g_regret_total.mean(0),c='black',  label='UBC')\n",
    "plt.plot(h_regret_total.mean(0),c='gold',   label='UBC tuned')\n",
    "# plt.plot(i_regret_total.mean(0),c='pink',   label='beta')\n",
    "# plt.plot(j_regret_total.mean(0),c='grey',   label='uniform')\n",
    "plt.plot(k_regret_total.mean(0),c='skyblue',label='NN')\n",
    "plt.plot(l_regret_total.mean(0),c='cyan',   label='softmax')\n",
    "plt.plot(m_regret_total.mean(0),c='magenta',label='Grad')\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:08.573Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot the reward\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(b_reward.mean(0),c='red',    label='greedy')\n",
    "plt.plot(c_reward.mean(0),c='blue',   label='e greedy')\n",
    "plt.plot(d_reward.mean(0),c='green',  label='decay e greedy')\n",
    "plt.plot(e_reward.mean(0),c='yellow', label='Linear Reward Inaction')\n",
    "plt.plot(f_reward.mean(0),c='purple', label='Linear Reward Penalty')\n",
    "plt.plot(g_reward.mean(0),c='black',  label='UBC')\n",
    "plt.plot(h_reward.mean(0),c='gold',   label='UBC tuned')\n",
    "# plt.plot(i_reward.mean(0),c='pink',   label='beta')\n",
    "# plt.plot(j_reward.mean(0),c='grey',   label='uniform')\n",
    "plt.plot(k_reward.mean(0),c='skyblue',label='NN')\n",
    "plt.plot(l_reward.mean(0),c='cyan',   label='softmax')\n",
    "plt.plot(m_reward.mean(0),c='magenta',label='Grad')\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:08.887Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot the reward\n",
    "print(gt_prob)\n",
    "print(b_estimation.mean(0))\n",
    "print(c_estimation.mean(0))\n",
    "print(d_estimation.mean(0))\n",
    "print(e_estimation)\n",
    "print(f_estimation)\n",
    "print(g_estimation.mean(0))\n",
    "print(h_estimation.mean(0))\n",
    "# print(i_estimation.mean(0))\n",
    "# print(j_estimation.mean(0))\n",
    "print(k_estimation.mean(0))\n",
    "print(l_estimation.mean(0))\n",
    "print(m_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T09:08:09.279Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# correaltion\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "data = pd.DataFrame({\n",
    "        'GT':gt_prob,\n",
    "        'Vector': a_expect.mean(0),\n",
    "        'greedy':b_estimation.mean(0),\n",
    "        'e-greedy':c_estimation.mean(0),\n",
    "        'decay e-greedy':d_estimation.mean(0),\n",
    "        'Linear Reward Inaction':e_estimation,\n",
    "        'Linear Reward Penalty':f_estimation,\n",
    "        'UCB1':g_estimation.mean(0),\n",
    "        'UCB1 Tuned':h_estimation.mean(0),\n",
    "        #'beta':i_estimation.mean(0),\n",
    "        #'uniform':j_estimation.mean(0),\n",
    "        'NN':k_estimation.mean(0),\n",
    "        'softmax':l_estimation.mean(0),\n",
    "        'grad':m_estimation\n",
    "    })\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data.corr(),annot=True,linewidths=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:50:52.230664Z",
     "start_time": "2019-01-13T01:50:51.987646Z"
    }
   },
   "source": [
    "# Reference \n",
    "1. numpy.set_printoptions — NumPy v1.14 Manual. (2019). Docs.scipy.org. Retrieved 13 January 2019, from https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.set_printoptions.html\n",
    "2. [ Archived Post ] Random Note about Multi-Arm Bandit Problem 2. (2019). Medium. Retrieved 13 January 2019, from https://medium.com/@SeoJaeDuk/archived-post-random-note-about-multi-arm-bandit-problem-2-5c522d1dfbdc\n",
    "3. Vieira, T. (2014). KL-divergence as an objective function — Graduate Descent. Timvieira.github.io. Retrieved 13 January 2019, from https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "4. Some Reinforcement Learning: The Greedy and Explore-Exploit Algorithms for the Multi-Armed Bandit Framework in Python. (2019). Datasciencecentral.com. Retrieved 13 January 2019, from https://www.datasciencecentral.com/profiles/blogs/some-reinforcement-learning-the-greedy-and-explore-exploit\n",
    "5. (2019). Cs.mcgill.ca. Retrieved 13 January 2019, from https://www.cs.mcgill.ca/~vkules/bandits.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
