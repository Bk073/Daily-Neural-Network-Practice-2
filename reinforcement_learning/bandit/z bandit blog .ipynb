{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:29:27.640901Z",
     "start_time": "2019-01-13T01:29:26.638907Z"
    }
   },
   "source": [
    "### Compare Listing \n",
    "<ol>\n",
    "<li>a: vector uniform</li>\n",
    "<li>b: greedy</li>\n",
    "<li>c: e - greedy</li>\n",
    "<li>d: decay e - greedy</li>\n",
    "<li>e: Linear Reward Inaction (Pursuit Methods)</li>\n",
    "<li>f: Linear Reward Penalty (Pursuit Methods)</li>\n",
    "<li>g: UBC 1</li>\n",
    "<li>h: UCB 1-Tuned</li>\n",
    "<li>i: Thompson Sampling (beta)</li>\n",
    "<li>j: Thompson Sampling (uniform)</li>\n",
    "<li>k: Neural Network</li>\n",
    "<li>l: softmax </li>\n",
    "<li>m: Gradient Bandits</li>\n",
    "<li>n: Non Stationary</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:31:39.383974Z",
     "start_time": "2019-01-14T05:31:26.552073Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy,time,sys\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta\n",
    "np.random.seed(5678)\n",
    "np.set_printoptions(3)\n",
    "tf.set_random_seed(678)\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:31:39.403920Z",
     "start_time": "2019-01-14T05:31:39.394945Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Best Choice:  11 0.7364685816073836\n"
     ]
    }
   ],
   "source": [
    "# setting the ground truth\n",
    "num_bandit = 12\n",
    "num_ep  = 20\n",
    "num_iter= 1000\n",
    "gt_prob = np.random.uniform(0,1,num_bandit)\n",
    "optimal_choice = np.argmax(gt_prob)\n",
    "print(gt_prob)\n",
    "print('Best Choice: ',optimal_choice,gt_prob[optimal_choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:32:08.136712Z",
     "start_time": "2019-01-14T05:32:08.110745Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.481 0.057 0.354 0.528 0.599 0.423 0.17  0.275 0.084 0.182 0.084 0.758]\n"
     ]
    }
   ],
   "source": [
    "# a vectorized\n",
    "a_expect = np.zeros((num_ep,num_bandit))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_expect = np.zeros(num_bandit)\n",
    "    temp_choice = np.zeros(num_bandit)\n",
    "                    \n",
    "    for iter in range(num_iter//10):\n",
    "        temp_choice    = temp_choice + 1\n",
    "        current_reward = np.random.uniform(0,1,num_bandit) < gt_prob\n",
    "        temp_expect    = temp_expect + current_reward\n",
    "\n",
    "    a_expect[eps,:] = temp_expect/temp_choice\n",
    "                    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(a_expect.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:25:36.813205Z",
     "start_time": "2019-01-14T06:25:36.653641Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.484 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "# b greedy\n",
    "b_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "b_estimation   = np.zeros((num_ep,num_bandit))\n",
    "b_reward       = np.zeros((num_ep,num_iter))\n",
    "b_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "b_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    b_pull_count[eps,:]   = temp_pull_count\n",
    "    b_estimation[eps,:]   = temp_estimation\n",
    "    b_reward[eps,:]       = temp_reward\n",
    "    b_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    b_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(b_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:25:37.435275Z",
     "start_time": "2019-01-14T06:25:37.184025Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.461 0.049 0.316 0.513 0.577 0.401 0.164 0.244 0.071 0.184 0.074 0.734]\n"
     ]
    }
   ],
   "source": [
    "# c e greedy \n",
    "c_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "c_estimation   = np.zeros((num_ep,num_bandit))\n",
    "c_reward       = np.zeros((num_ep,num_iter))\n",
    "c_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "c_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    epsilon = np.random.uniform(0,1)\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "  \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    c_pull_count[eps,:]   = temp_pull_count\n",
    "    c_estimation[eps,:]   = temp_estimation\n",
    "    c_reward[eps,:]       = temp_reward\n",
    "    c_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    c_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(c_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:27:32.900065Z",
     "start_time": "2019-01-14T06:27:32.701597Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.436 0.018 0.359 0.438 0.487 0.39  0.155 0.221 0.034 0.118 0.076 0.734]\n"
     ]
    }
   ],
   "source": [
    "# d decy e greedy \n",
    "d_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "d_estimation   = np.zeros((num_ep,num_bandit))\n",
    "d_reward       = np.zeros((num_ep,num_iter))\n",
    "d_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "d_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    epsilon = 1.0\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_expect) if epsilon < np.random.uniform(0,1) else np.random.choice(np.arange(num_bandit))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the eps\n",
    "        epsilon = 0.99 * epsilon\n",
    "        \n",
    "    d_pull_count[eps,:]   = temp_pull_count\n",
    "    d_estimation[eps,:]   = temp_estimation\n",
    "    d_reward[eps,:]       = temp_reward\n",
    "    d_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    d_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(d_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:33:35.557535Z",
     "start_time": "2019-01-14T06:33:34.744770Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.   0.   0.   0.1  0.2  0.05 0.   0.   0.   0.   0.   0.65]\n",
      "Expected Normalized\n",
      "[0.    0.    0.    0.401 0.801 0.2   0.    0.    0.    0.    0.    2.604]\n"
     ]
    }
   ],
   "source": [
    "# e Linear Reward Inaction\n",
    "e_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "e_estimation   = np.zeros((num_ep,num_bandit))\n",
    "e_reward       = np.zeros((num_ep,num_iter))\n",
    "e_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "e_regret_total = np.zeros((num_ep,num_iter))\n",
    "      \n",
    "for eps in range(num_ep):\n",
    "    learning_rate = 0.1\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + learning_rate * (1-temp_estimation)) + (1-mask) * ( (1-learning_rate) * temp_estimation)\n",
    "            \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    e_pull_count[eps,:]   = temp_pull_count\n",
    "    e_estimation[eps,:]   = temp_estimation\n",
    "    e_reward[eps,:]       = temp_reward\n",
    "    e_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    e_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(np.around(e_estimation.mean(0),3))\n",
    "print('Expected Normalized')\n",
    "print(np.around(e_estimation.mean(0),3)* gt_prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:35:57.107981Z",
     "start_time": "2019-01-14T06:35:56.257980Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.057 0.007 0.031 0.08  0.15  0.037 0.008 0.017 0.007 0.009 0.006 0.591]\n",
      "Expected Normalized\n",
      "[0.229 0.028 0.124 0.319 0.6   0.147 0.034 0.069 0.026 0.036 0.026 2.37 ]\n"
     ]
    }
   ],
   "source": [
    "# f Linear Reward Penalty\n",
    "f_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "f_estimation   = np.zeros((num_ep,num_bandit))\n",
    "f_reward       = np.zeros((num_ep,num_iter))\n",
    "f_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "f_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    alpha = 0.01\n",
    "    beta  = 0.001\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit) + 1.0/num_bandit\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    for iter in range(num_iter):\n",
    "\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.random.choice(num_bandit, p=temp_estimation)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "\n",
    "        mask = np.zeros(num_bandit)\n",
    "        mask[current_choice] = 1.0\n",
    "        \n",
    "        if current_reward == 1.0:\n",
    "            temp_estimation = (mask) * (temp_estimation + alpha * (1-temp_estimation)) + (1-mask) * ( (1-alpha) * temp_estimation)\n",
    "        else: \n",
    "            temp_estimation = (mask) * ((1-beta) * temp_estimation) + (1-mask) * ( beta/(num_bandit-1) + (1-beta) * temp_estimation )\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    f_pull_count[eps,:]   = temp_pull_count\n",
    "    f_estimation[eps,:]   = temp_estimation\n",
    "    f_reward[eps,:]       = temp_reward\n",
    "    f_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    f_regret_total[eps,:] = temp_regret\n",
    "    \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(f_estimation.mean(0))\n",
    "print('Expected Normalized')\n",
    "print(f_estimation.mean(0) * gt_prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:37:39.496894Z",
     "start_time": "2019-01-14T06:37:39.202158Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.429 0.033 0.277 0.414 0.556 0.404 0.115 0.17  0.037 0.164 0.077 0.732]\n"
     ]
    }
   ],
   "source": [
    "# g UBC\n",
    "g_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "g_estimation   = np.zeros((num_ep,num_bandit))\n",
    "g_reward       = np.zeros((num_ep,num_iter))\n",
    "g_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "g_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(0.5*np.log(iter+1)/(temp_pull_count+1)))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    g_pull_count[eps,:]   = temp_pull_count\n",
    "    g_estimation[eps,:]   = temp_estimation\n",
    "    g_reward[eps,:]       = temp_reward\n",
    "    g_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    g_regret_total[eps,:] = temp_regret\n",
    "  \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(g_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:21:50.280119Z",
     "start_time": "2019-01-14T06:21:49.983217Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.46  0.047 0.34  0.514 0.568 0.428 0.142 0.244 0.058 0.145 0.066 0.732]\n"
     ]
    }
   ],
   "source": [
    "# h UBC Tuned\n",
    "h_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "h_estimation   = np.zeros((num_ep,num_bandit))\n",
    "h_reward       = np.zeros((num_ep,num_iter))\n",
    "h_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit) \n",
    "    temp_estimation   = np.zeros(num_bandit) \n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        current_min_value = 1\n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(temp_estimation + np.sqrt(np.log(iter+1)/(temp_pull_count+1)*current_min_value))\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = temp_reward[iter] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        \n",
    "    h_pull_count[eps,:]   = temp_pull_count\n",
    "    h_estimation[eps,:]   = temp_estimation\n",
    "    h_reward[eps,:]       = temp_reward\n",
    "    h_optimal_pull[eps,:] = temp_optimal_pull\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(h_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:42:23.483603Z",
     "start_time": "2019-01-14T06:39:25.279995Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "[0.489 0.059 0.366 0.519 0.598 0.431 0.179 0.285 0.071 0.185 0.088 0.736]\n",
      "Expected \n",
      "[0.462 0.2   0.312 0.394 0.545 0.35  0.203 0.33  0.14  0.247 0.253 0.735]\n"
     ]
    }
   ],
   "source": [
    "# i Thompson Sampling (beta) (slow)\n",
    "i_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "i_estimation   = np.zeros((num_ep,num_bandit))\n",
    "i_reward       = np.zeros((num_ep,num_iter))\n",
    "i_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "i_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        theta_samples = [stats.beta(a=1+w,b=1+t-w).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(theta_samples)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    i_pull_count[eps,:]   = temp_pull_count\n",
    "    i_estimation[eps,:]   = theta_samples\n",
    "    i_reward[eps,:]       = temp_reward\n",
    "    i_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    i_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(i_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T06:40:07.337Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# j Thompson Sampling (uniform) (slow)\n",
    "j_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "j_estimation   = np.zeros((num_ep,num_bandit))\n",
    "j_reward       = np.zeros((num_ep,num_iter))\n",
    "j_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "j_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        theta_samples = [stats.uniform(w/(t+0.000000001),1-w/(t+0.000000001)).rvs(size=1) for t, w in zip(temp_pull_count, temp_estimation)]\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        current_choice = np.argmax(theta_samples)\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        \n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "    j_pull_count[eps,:]   = temp_pull_count\n",
    "    j_estimation[eps,:]   = theta_samples\n",
    "    j_reward[eps,:]       = temp_reward\n",
    "    j_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    j_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(j_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T06:40:33.544Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# k neural network (with adam)\n",
    "k_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "k_estimation   = np.zeros((num_ep,num_bandit))\n",
    "k_reward       = np.zeros((num_ep,num_iter))\n",
    "k_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "k_regret_total = np.zeros((num_ep,num_iter))\n",
    "\n",
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def d_sigmoid(x): return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    \n",
    "    weights = np.random.randn(num_bandit,1)\n",
    "    moment  = np.zeros_like(weights); \n",
    "    velocity = np.zeros_like(weights);\n",
    "    epsilon  = 1.0 \n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        if np.random.uniform(0,1)>epsilon:\n",
    "            current_choice = np.argmax(weights)\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "        else:\n",
    "            current_choice = np.random.choice(np.arange(num_bandit))\n",
    "            current_input  = np.zeros((1,num_bandit))\n",
    "            current_input[0,current_choice] = 1\n",
    "\n",
    "        layer1 = current_input @ weights\n",
    "        layer1a= sigmoid(layer1)\n",
    "\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + current_reward\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        \n",
    "        # KL Divergence https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "        grad3 = np.log(layer1a+0.0000001) - np.log(temp_estimation[current_choice]/(temp_pull_count[current_choice])+0.0000001)\n",
    "        grad2 = d_sigmoid(layer1)\n",
    "        grad1 = current_input\n",
    "        grad  = grad1.T @ (grad3 * grad2)\n",
    "        \n",
    "        moment   = 0.9*moment + (1-0.9) * grad\n",
    "        velocity = 0.999*velocity + (1-0.999) * grad**2\n",
    "        moment_hat   = moment/(1-0.9)\n",
    "        velocity_hat = velocity/(1-0.999)\n",
    "        weights  = weights - 0.08 * (moment_hat/(np.sqrt(velocity_hat)+1e-8))\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # Decay the learning rate\n",
    "        epsilon = epsilon * 0.999\n",
    "        \n",
    "    k_pull_count[eps,:]   = temp_pull_count\n",
    "    k_estimation[eps,:]   = np.squeeze(sigmoid(weights))\n",
    "    k_reward[eps,:]       = temp_reward\n",
    "    k_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    k_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(k_estimation.mean(0))\n",
    "print('Scaled ')\n",
    "print((gt_prob.max()-gt_prob.min())*(k_estimation.mean(0)-k_estimation.mean(0).min())/(k_estimation.mean(0).max()-k_estimation.mean(0).min()) + gt_prob.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-14T06:40:52.631Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# l softmax\n",
    "l_pull_count   = np.zeros((num_ep,num_bandit))\n",
    "l_estimation   = np.zeros((num_ep,num_bandit))\n",
    "l_reward       = np.zeros((num_ep,num_iter))\n",
    "l_optimal_pull = np.zeros((num_ep,num_iter))\n",
    "l_regret_total = np.zeros((num_ep,num_iter))\n",
    "                    \n",
    "for eps in range(num_ep):\n",
    "    temp_pull_count   = np.zeros(num_bandit)\n",
    "    temp_estimation   = np.zeros(num_bandit)\n",
    "    temp_reward       = np.zeros(num_iter)\n",
    "    temp_optimal_pull = np.zeros(num_iter)\n",
    "    temp_regret = np.zeros(num_iter)\n",
    "    tempture = 300\n",
    "                    \n",
    "    for iter in range(num_iter):\n",
    "        \n",
    "        # select bandit / get reward /increase count / update estimate\n",
    "        pi  = np.exp(temp_estimation/tempture) / np.sum(np.exp(temp_estimation/tempture))\n",
    "        cdf = np.cumsum(pi)\n",
    "        current_choice = np.where(np.random.uniform(0,1) < cdf)[0][0]\n",
    "        current_reward = 1 if np.random.uniform(0,1) < gt_prob[current_choice] else 0\n",
    "        temp_pull_count[current_choice] = temp_pull_count[current_choice] + 1\n",
    "        temp_estimation[current_choice] = temp_estimation[current_choice] + (1/(temp_pull_count[current_choice]+1)) * (current_reward-temp_estimation[current_choice])\n",
    "\n",
    "        # update reward and optimal choice\n",
    "        temp_reward[iter] = current_reward if iter == 0 else temp_reward[iter-1] + current_reward\n",
    "        temp_optimal_pull[iter] = 1 if current_choice == optimal_choice else 0\n",
    "        temp_regret[iter] = gt_prob[optimal_choice] - gt_prob[current_choice] if iter == 0 else temp_regret[iter-1] + (gt_prob[optimal_choice] - gt_prob[current_choice])\n",
    "        \n",
    "        # decay the temp\n",
    "        tempture = tempture * 0.999999\n",
    "        \n",
    "    l_pull_count[eps,:]   = temp_pull_count\n",
    "    l_estimation[eps,:]   = temp_estimation\n",
    "    l_reward[eps,:]       = temp_reward\n",
    "    l_optimal_pull[eps,:] = temp_optimal_pull\n",
    "    l_regret_total[eps,:] = temp_regret\n",
    "        \n",
    "print('Ground Truth')\n",
    "print(gt_prob)\n",
    "print('Expected ')\n",
    "print(l_estimation.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:38:20.290265Z",
     "start_time": "2019-01-14T06:38:20.129515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(b_regret_total.mean(0),label='greedy')\n",
    "plt.plot(c_regret_total.mean(0),label='e greedy')\n",
    "plt.plot(d_regret_total.mean(0),label='decay e greedy')\n",
    "plt.plot(e_regret_total.mean(0),label='pursit')\n",
    "plt.plot(f_regret_total.mean(0),label='pursit')\n",
    "plt.plot(g_regret_total.mean(0),label='UBC')\n",
    "plt.plot(h_regret_total.mean(0),label='UBC')\n",
    "plt.plot(i_regret_total.mean(0),label='UBC')\n",
    "plt.plot(j_regret_total.mean(0),label='UBC')\n",
    "plt.plot(k_regret_total.mean(0),label='UBC')\n",
    "plt.plot(l_regret_total.mean(0),label='UBC')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T06:10:36.712012Z",
     "start_time": "2019-01-14T06:10:36.708024Z"
    }
   },
   "outputs": [],
   "source": [
    "# m gradient base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n non stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:59:47.235732Z",
     "start_time": "2019-01-13T08:59:47.225357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"e3ef950a-4475-4c9a-8746-7db3cbb41e8d\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"e3ef950a-4475-4c9a-8746-7db3cbb41e8d\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T01:50:52.230664Z",
     "start_time": "2019-01-13T01:50:51.987646Z"
    }
   },
   "source": [
    "# Reference \n",
    "1. numpy.set_printoptions — NumPy v1.14 Manual. (2019). Docs.scipy.org. Retrieved 13 January 2019, from https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.set_printoptions.html\n",
    "2. [ Archived Post ] Random Note about Multi-Arm Bandit Problem 2. (2019). Medium. Retrieved 13 January 2019, from https://medium.com/@SeoJaeDuk/archived-post-random-note-about-multi-arm-bandit-problem-2-5c522d1dfbdc\n",
    "3. Vieira, T. (2014). KL-divergence as an objective function — Graduate Descent. Timvieira.github.io. Retrieved 13 January 2019, from https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/\n",
    "4. Some Reinforcement Learning: The Greedy and Explore-Exploit Algorithms for the Multi-Armed Bandit Framework in Python. (2019). Datasciencecentral.com. Retrieved 13 January 2019, from https://www.datasciencecentral.com/profiles/blogs/some-reinforcement-learning-the-greedy-and-explore-exploit\n",
    "5. (2019). Cs.mcgill.ca. Retrieved 13 January 2019, from https://www.cs.mcgill.ca/~vkules/bandits.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
