{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-10T05:08:27.330613Z",
     "start_time": "2019-01-10T05:08:27.283494Z"
    },
    "code_folding": [
     13,
     18,
     47,
     85,
     115,
     137,
     170,
     195,
     244
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Randomly generated Bernoulli bandit has reward probabilities:\\n\", b.probas)? (<ipython-input-2-deddadc28ee0>, line 244)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-deddadc28ee0>\"\u001b[1;36m, line \u001b[1;32m244\u001b[0m\n\u001b[1;33m    print \"Randomly generated Bernoulli bandit has reward probabilities:\\n\", b.probas\u001b[0m\n\u001b[1;37m                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Randomly generated Bernoulli bandit has reward probabilities:\\n\", b.probas)?\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib  # noqa\n",
    "matplotlib.use('Agg')  # noqa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from bandits import BernoulliBandit\n",
    "from solvers import Solver, EpsilonGreedy, UCB1, BayesianUCB, ThompsonSampling\n",
    "from __future__ import division\n",
    "import time\n",
    "\n",
    "class Bandit(object):\n",
    "\n",
    "    def generate_reward(self, i):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BernoulliBandit(Bandit):\n",
    "\n",
    "    def __init__(self, n, probas=None):\n",
    "        assert probas is None or len(probas) == n\n",
    "        self.n = n\n",
    "        if probas is None:\n",
    "            np.random.seed(int(time.time()))\n",
    "            self.probas = [np.random.random() for _ in range(self.n)]\n",
    "        else:\n",
    "            self.probas = probas\n",
    "\n",
    "        self.best_proba = max(self.probas)\n",
    "\n",
    "    def generate_reward(self, i):\n",
    "        # The player selected the i-th machine.\n",
    "        if np.random.random() < self.probas[i]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class Solver(object):\n",
    "    def __init__(self, bandit):\n",
    "        \"\"\"\n",
    "        bandit (Bandit): the target bandit to solve.\n",
    "        \"\"\"\n",
    "        assert isinstance(bandit, BernoulliBandit)\n",
    "        np.random.seed(int(time.time()))\n",
    "\n",
    "        self.bandit = bandit\n",
    "\n",
    "        self.counts = [0] * self.bandit.n\n",
    "        self.actions = []  # A list of machine ids, 0 to bandit.n-1.\n",
    "        self.regret = 0.  # Cumulative regret.\n",
    "        self.regrets = [0.]  # History of cumulative regret.\n",
    "\n",
    "    def update_regret(self, i):\n",
    "        # i (int): index of the selected machine.\n",
    "        self.regret += self.bandit.best_proba - self.bandit.probas[i]\n",
    "        self.regrets.append(self.regret)\n",
    "\n",
    "    @property\n",
    "    def estimated_probas(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run_one_step(self):\n",
    "        \"\"\"Return the machine index to take action on.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self, num_steps):\n",
    "        assert self.bandit is not None\n",
    "        for _ in range(num_steps):\n",
    "            i = self.run_one_step()\n",
    "\n",
    "            self.counts[i] += 1\n",
    "            self.actions.append(i)\n",
    "            self.update_regret(i)\n",
    "\n",
    "class EpsilonGreedy(Solver):\n",
    "    def __init__(self, bandit, eps, init_proba=1.0):\n",
    "        \"\"\"\n",
    "        eps (float): the probability to explore at each time step.\n",
    "        init_proba (float): default to be 1.0; optimistic initialization\n",
    "        \"\"\"\n",
    "        super(EpsilonGreedy, self).__init__(bandit)\n",
    "\n",
    "        assert 0. <= eps <= 1.0\n",
    "        self.eps = eps\n",
    "\n",
    "        self.estimates = [init_proba] * self.bandit.n  # Optimistic initialization\n",
    "\n",
    "    @property\n",
    "    def estimated_probas(self):\n",
    "        return self.estimates\n",
    "\n",
    "    def run_one_step(self):\n",
    "        if np.random.random() < self.eps:\n",
    "            # Let's do random exploration!\n",
    "            i = np.random.randint(0, self.bandit.n)\n",
    "        else:\n",
    "            # Pick the best one.\n",
    "            i = max(range(self.bandit.n), key=lambda x: self.estimates[x])\n",
    "\n",
    "        r = self.bandit.generate_reward(i)\n",
    "        self.estimates[i] += 1. / (self.counts[i] + 1) * (r - self.estimates[i])\n",
    "\n",
    "        return i\n",
    "\n",
    "class UCB1(Solver):\n",
    "    def __init__(self, bandit, init_proba=1.0):\n",
    "        super(UCB1, self).__init__(bandit)\n",
    "        self.t = 0\n",
    "        self.estimates = [init_proba] * self.bandit.n\n",
    "\n",
    "    @property\n",
    "    def estimated_probas(self):\n",
    "        return self.estimates\n",
    "\n",
    "    def run_one_step(self):\n",
    "        self.t += 1\n",
    "\n",
    "        # Pick the best one with consideration of upper confidence bounds.\n",
    "        i = max(range(self.bandit.n), key=lambda x: self.estimates[x] + np.sqrt(\n",
    "            2 * np.log(self.t) / (1 + self.counts[x])))\n",
    "        r = self.bandit.generate_reward(i)\n",
    "\n",
    "        self.estimates[i] += 1. / (self.counts[i] + 1) * (r - self.estimates[i])\n",
    "\n",
    "        return i\n",
    "\n",
    "class BayesianUCB(Solver):\n",
    "    \"\"\"Assuming Beta prior.\"\"\"\n",
    "\n",
    "    def __init__(self, bandit, c=3, init_a=1, init_b=1):\n",
    "        \"\"\"\n",
    "        c (float): how many standard dev to consider as upper confidence bound.\n",
    "        init_a (int): initial value of a in Beta(a, b).\n",
    "        init_b (int): initial value of b in Beta(a, b).\n",
    "        \"\"\"\n",
    "        super(BayesianUCB, self).__init__(bandit)\n",
    "        self.c = c\n",
    "        self._as = [init_a] * self.bandit.n\n",
    "        self._bs = [init_b] * self.bandit.n\n",
    "\n",
    "    @property\n",
    "    def estimated_probas(self):\n",
    "        return [self._as[i] / float(self._as[i] + self._bs[i]) for i in range(self.bandit.n)]\n",
    "\n",
    "    def run_one_step(self):\n",
    "        # Pick the best one with consideration of upper confidence bounds.\n",
    "        i = max(\n",
    "            range(self.bandit.n),\n",
    "            key=lambda x: self._as[x] / float(self._as[x] + self._bs[x]) + beta.std(\n",
    "                self._as[x], self._bs[x]) * self.c\n",
    "        )\n",
    "        r = self.bandit.generate_reward(i)\n",
    "\n",
    "        # Update Gaussian posterior\n",
    "        self._as[i] += r\n",
    "        self._bs[i] += (1 - r)\n",
    "\n",
    "        return i\n",
    "\n",
    "class ThompsonSampling(Solver):\n",
    "    def __init__(self, bandit, init_a=1, init_b=1):\n",
    "        \"\"\"\n",
    "        init_a (int): initial value of a in Beta(a, b).\n",
    "        init_b (int): initial value of b in Beta(a, b).\n",
    "        \"\"\"\n",
    "        super(ThompsonSampling, self).__init__(bandit)\n",
    "\n",
    "        self._as = [init_a] * self.bandit.n\n",
    "        self._bs = [init_b] * self.bandit.n\n",
    "\n",
    "    @property\n",
    "    def estimated_probas(self):\n",
    "        return [self._as[i] / (self._as[i] + self._bs[i]) for i in range(self.bandit.n)]\n",
    "\n",
    "    def run_one_step(self):\n",
    "        samples = [np.random.beta(self._as[x], self._bs[x]) for x in range(self.bandit.n)]\n",
    "        i = max(range(self.bandit.n), key=lambda x: samples[x])\n",
    "        r = self.bandit.generate_reward(i)\n",
    "\n",
    "        self._as[i] += r\n",
    "        self._bs[i] += (1 - r)\n",
    "\n",
    "        return i \n",
    "        \n",
    "def plot_results(solvers, solver_names, figname):\n",
    "    \"\"\"\n",
    "    Plot the results by multi-armed bandit solvers.\n",
    "    Args:\n",
    "        solvers (list<Solver>): All of them should have been fitted.\n",
    "        solver_names (list<str)\n",
    "        figname (str)\n",
    "    \"\"\"\n",
    "    assert len(solvers) == len(solver_names)\n",
    "    assert all(map(lambda s: isinstance(s, Solver), solvers))\n",
    "    assert all(map(lambda s: len(s.regrets) > 0, solvers))\n",
    "\n",
    "    b = solvers[0].bandit\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 4))\n",
    "    fig.subplots_adjust(bottom=0.3, wspace=0.3)\n",
    "\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "\n",
    "    # Sub.fig. 1: Regrets in time.\n",
    "    for i, s in enumerate(solvers):\n",
    "        ax1.plot(range(len(s.regrets)), s.regrets, label=solver_names[i])\n",
    "\n",
    "    ax1.set_xlabel('Time step')\n",
    "    ax1.set_ylabel('Cumulative regret')\n",
    "    ax1.legend(loc=9, bbox_to_anchor=(1.82, -0.25), ncol=5)\n",
    "    ax1.grid('k', ls='--', alpha=0.3)\n",
    "\n",
    "    # Sub.fig. 2: Probabilities estimated by solvers.\n",
    "    sorted_indices = sorted(range(b.n), key=lambda x: b.probas[x])\n",
    "    ax2.plot(range(b.n), [b.probas[x] for x in sorted_indices], 'k--', markersize=12)\n",
    "    for s in solvers:\n",
    "        ax2.plot(range(b.n), [s.estimated_probas[x] for x in sorted_indices], 'x', markeredgewidth=2)\n",
    "    ax2.set_xlabel('Actions sorted by ' + r'$\\theta$')\n",
    "    ax2.set_ylabel('Estimated')\n",
    "    ax2.grid('k', ls='--', alpha=0.3)\n",
    "\n",
    "    # Sub.fig. 3: Action counts\n",
    "    for s in solvers:\n",
    "        ax3.plot(range(b.n), np.array(s.counts) / float(len(solvers[0].regrets)), ls='steps', lw=2)\n",
    "    ax3.set_xlabel('Actions')\n",
    "    ax3.set_ylabel('Frac. # trials')\n",
    "    ax3.grid('k', ls='--', alpha=0.3)\n",
    "\n",
    "    plt.savefig(figname)\n",
    "\n",
    "\n",
    "def experiment(K, N):\n",
    "    \"\"\"\n",
    "    Run a small experiment on solving a Bernoulli bandit with K slot machines,\n",
    "    each with a randomly initialized reward probability.\n",
    "    Args:\n",
    "        K (int): number of slot machiens.\n",
    "        N (int): number of time steps to try.\n",
    "    \"\"\"\n",
    "\n",
    "    b = BernoulliBandit(K)\n",
    "    print \"Randomly generated Bernoulli bandit has reward probabilities:\\n\", b.probas\n",
    "    print \"The best machine has index: {} and proba: {}\".format(\n",
    "        max(range(K), key=lambda i: b.probas[i]), max(b.probas))\n",
    "\n",
    "    test_solvers = [\n",
    "        # EpsilonGreedy(b, 0),\n",
    "        # EpsilonGreedy(b, 1),\n",
    "        EpsilonGreedy(b, 0.01),\n",
    "        UCB1(b),\n",
    "        BayesianUCB(b, 3, 1, 1),\n",
    "        ThompsonSampling(b, 1, 1)\n",
    "    ]\n",
    "    names = [\n",
    "        # 'Full-exploitation',\n",
    "        # 'Full-exploration',\n",
    "        r'$\\epsilon$' + '-Greedy',\n",
    "        'UCB1',\n",
    "        'Bayesian UCB',\n",
    "        'Thompson Sampling'\n",
    "    ]\n",
    "\n",
    "    for s in test_solvers:\n",
    "        s.run(N)\n",
    "\n",
    "    plot_results(test_solvers, names, \"results_K{}_N{}.png\".format(K, N))\n",
    "\n",
    "# experiment(10, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
